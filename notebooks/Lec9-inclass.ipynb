{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO02vENdpRlThDAFWCB69xA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# from google.colab import drive\n","# drive.flush_and_unmount()           # ignore errors if already unmounted\n","\n","#If cannot remount, simply delete the mounted drive and then remount\n","# rm -rf /content/drive\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-1K7L9NJHMB","executionInfo":{"status":"ok","timestamp":1758657441100,"user_tz":300,"elapsed":53,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"24b333e3-082c-4de0-cee1-057b264d367f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive not mounted, so nothing to flush and unmount.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3b0cacda","outputId":"93d3dd45-7d67-4887-9d35-b7b4cda556a1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758664401784,"user_tz":300,"elapsed":3090,"user":{"displayName":"David W.","userId":"14633192575819064045"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Colab cell\n","from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01f28b78"},"outputs":[],"source":["# Adjust these two for YOUR repo\n","REPO_OWNER = \"ywanglab\"\n","REPO_NAME  = \"STAT4160\"   # e.g., unified-stocks-team1\n","BASE_DIR   = \"/content/drive/MyDrive/dspt25\"\n","CLONE_DIR  = f\"{BASE_DIR}/{REPO_NAME}\"\n","REPO_URL   = f\"https://github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n","\n","# if on my office computer\n","\n","# REPO_NAME  = \"lectureNotes\"   # e.g., on my office computer\n","# BASE_DIR = r\"E:\\OneDrive - Auburn University Montgomery\\teaching\\AUM\\STAT 4160 Productivity Tools\" # on my office computer\n","# CLONE_DIR  = f\"{BASE_DIR}\\{REPO_NAME}\"\n","\n","import os, pathlib\n","pathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True)\n"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"36277e0a","outputId":"03d50f34-d511-4c58-b29e-4d9351481aa7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758664559712,"user_tz":300,"elapsed":17,"user":{"displayName":"David W.","userId":"14633192575819064045"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Working dir: /content/drive/MyDrive/dspt25/STAT4160\n"]}],"source":["import os, subprocess, shutil, pathlib\n","\n","if not pathlib.Path(CLONE_DIR).exists():\n","    !git clone {REPO_URL} {CLONE_DIR}\n","else:\n","    # If the folder exists, just ensure it's a git repo and pull latest\n","    os.chdir(CLONE_DIR)\n","    # !git status\n","    # !git pull --rebase # !git pull --ff-only\n","os.chdir(CLONE_DIR)\n","print(\"Working dir:\", os.getcwd())"]},{"cell_type":"markdown","source":["* `glob` is a Python **standard library module** for Unix-style pathname pattern expansion (wildcards).\n","* `glob.glob(pattern)` returns a **list of pathnames** matching the given `pattern`.\n","\n","### 2. Wildcards you can use\n","\n","* `*` → matches **any number of characters** (including none).\n","\n","  * `\"*.csv\"` → all CSV files.\n","* `?` → matches **exactly one character**.\n","\n","  * `\"file?.txt\"` → `file1.txt`, `fileA.txt` but not `file10.txt`.\n","* `[abc]` → matches one character from the set.\n","\n","  * `\"file[12].txt\"` → `file1.txt`, `file2.txt`.\n","* `[0-9]` → range inside brackets.\n","\n","  * `\"file[0-9].txt\"` → `file0.txt` … `file9.txt`.\n","\n","### 4. Key options\n","\n","* `recursive=True` → lets `**` mean “match in all subdirectories.”\n","\n","  ```python\n","  glob.glob(\"**/*.py\", recursive=True)  \n","  # finds all .py files in current directory tree\n","  ```\n","* Returns a **list of strings** (file paths).\n","* The list order is arbitrary; use `sorted(...)` if you need consistency.\n","\n","## `grep`\n","`grep` searches text for lines that match a pattern (string or regex) and prints the matching lines. It’s your go-to tool for “find in files” on the command line.\n","\n","## Basic forms\n","\n","```bash\n","grep \"needle\" file.txt          # print lines containing needle\n","grep -i \"needle\" file.txt       # case-insensitive\n","grep -n \"needle\" file.txt       # show line numbers\n","grep -r \"needle\" path/          # recursive through directories\n","grep -R \"needle\" path/          # like -r, also follows symlinks\n","```\n","\n","## Regex vs fixed string\n","\n","```bash\n","grep -E \"foo|bar\" file.txt      # extended regex (egrep; preferred)\n","grep -F \"a?b*c\" file.txt        # fixed string (treats metacharacters literally; fgrep)\n","```\n","\n","## Show only what you need\n","\n","```bash\n","grep -l \"needle\" -r path/       # list filenames with a match\n","grep -L \"needle\" -r path/       # list filenames with NO match\n","grep -c \"needle\" file.txt       # count matches per file\n","grep -oE \"[A-Z]{3}[0-9]{2}\" f   # print only the matched part(s)\n","```\n","\n","\n","## Exit codes (useful in scripts/CI)\n","\n","* `0` = found at least one match\n","* `1` = no matches\n","* `>1` = error (e.g., unreadable file)\n","\n","\n","### Notes\n","\n","* `egrep` and `fgrep` are legacy names; use `grep -E` and `grep -F`.\n","* Regex metacharacters: `. ^ $ * + ? ( ) [ ] { } |` (escape with `\\` when needed).\n","* For binary-safe fixed searches (e.g., large data files), prefer `grep -F`.\n","\n","\n"],"metadata":{"id":"E3I9JYoqOkAc"}},{"cell_type":"code","source":["from pathlib import Path\n","import pandas as pd, numpy as np, datetime as dt\n","import glob\n","\n","raw_candidates = []\n","if Path(\"data/raw/prices.csv\").exists():\n","    raw_candidates = [\"data/raw/prices.csv\"]\n","else:\n","    raw_candidates = sorted(glob.glob(\"data/raw/prices*.csv\")) or sorted(glob.glob(\"data/raw/prices/*.csv\"))\n","\n","def _make_synthetic_prices():\n","    # Small 2-year synthetic daily prices for AAPL/MSFT/GOOGL\n","    tickers = [\"AAPL\",\"MSFT\",\"GOOGL\"]\n","    dates = pd.bdate_range(\"2022-01-03\", periods=520, freq=\"B\")\n","    rows = []\n","    rng = np.random.default_rng(0)\n","    for t in tickers:\n","        price = 100 + rng.normal(0, 1).cumsum()\n","        price = np.maximum(price, 1.0)\n","        vol = rng.integers(5e6, 2e7, size=len(dates)) #[low, high)\n","        df = pd.DataFrame({\n","            \"date\": dates,\n","            \"ticker\": t,\n","            \"open\": price * (1 + rng.normal(0, 0.002, size=len(dates))),\n","            \"high\": price * (1 + rng.normal(0.003, 0.003, size=len(dates))).clip(min=1), #set all values below 1 to 1, leave others unchanged.\n","            \"low\":  price * (1 - np.abs(rng.normal(0.003, 0.003, size=len(dates)))),\n","            \"close\": price,\n","            \"adj_close\": price * (1 + rng.normal(0, 0.0005, size=len(dates))),\n","            \"volume\": vol\n","        })\n","        rows.append(df)\n","    out = pd.concat(rows, ignore_index=True)\n","    Path(\"data/raw\").mkdir(parents=True, exist_ok=True)\n","    out.to_csv(\"data/raw/prices.csv\", index=False)\n","    return [\"data/raw/prices.csv\"]\n","\n","if not raw_candidates:\n","    print(\"No raw prices found; creating a small synthetic dataset...\")\n","    raw_candidates = _make_synthetic_prices()\n","\n","raw_candidates"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cgqI6QmJGTbp","executionInfo":{"status":"ok","timestamp":1758658088079,"user_tz":300,"elapsed":7,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"3dbc6b29-33f1-4d33-b40c-c39da552bcc5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['data/raw/prices.csv']"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["from pathlib import Path\n","meta_path = Path(\"data/static/tickers.csv\")\n","if meta_path.exists():\n","    meta = pd.read_csv(meta_path)\n","else:\n","    # Build a minimal metadata table from raw tickers\n","    tmp = pd.read_csv(raw_candidates[0])\n","    tickers = sorted(pd.unique(tmp[\"ticker\"]))\n","    meta = pd.DataFrame({\"ticker\": tickers,\n","                         \"name\": tickers,\n","                         \"sector\": [\"Unknown\"]*len(tickers)})\n","    Path(\"data/static\").mkdir(parents=True, exist_ok=True)\n","    meta.to_csv(meta_path, index=False)\n","meta.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"b_8vIuAES2Tn","executionInfo":{"status":"ok","timestamp":1758660030413,"user_tz":300,"elapsed":1138,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"a6d9bf3d-0c11-486b-b477-c1212d6109a1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  ticker  name   sector\n","0   AAPL  AAPL  Unknown\n","1   AMZN  AMZN  Unknown\n","2    BAC   BAC  Unknown\n","3   CSCO  CSCO  Unknown\n","4    CVX   CVX  Unknown"],"text/html":["\n","  <div id=\"df-7f6ca8e1-1788-4e8d-8ca6-9f2919a60552\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ticker</th>\n","      <th>name</th>\n","      <th>sector</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AAPL</td>\n","      <td>AAPL</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AMZN</td>\n","      <td>AMZN</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BAC</td>\n","      <td>BAC</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>CSCO</td>\n","      <td>CSCO</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>CVX</td>\n","      <td>CVX</td>\n","      <td>Unknown</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f6ca8e1-1788-4e8d-8ca6-9f2919a60552')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7f6ca8e1-1788-4e8d-8ca6-9f2919a60552 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7f6ca8e1-1788-4e8d-8ca6-9f2919a60552');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-9c1da0f0-8617-4b87-91c7-679d5504706d\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c1da0f0-8617-4b87-91c7-679d5504706d')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-9c1da0f0-8617-4b87-91c7-679d5504706d button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"meta","summary":"{\n  \"name\": \"meta\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"INTC\",\n          \"ORCL\",\n          \"AAPL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"INTC\",\n          \"ORCL\",\n          \"AAPL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Unknown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["\n","```python\n","s = re.sub(r\"[^\\w\\s]\", \"_\", s)\n","```\n","\n","* Pattern: `[^\\w\\s]`\n","\n","  * `\\w` = “word characters” (`[A-Za-z0-9_]`)\n","  * `\\s` = whitespace\n","  * `^` inside brackets = negation\n","* So `[^\\w\\s]` = **any character that is NOT a word character and NOT whitespace**.\n","* Replace those with `_`.\n","* Effect: strip punctuation and special symbols, turn them into underscores.\n","\n","**Example:**\n","\n","```python\n","\"Price%Change!\".sub(...)  →  \"Price_Change_\"\n","```\n","\n","---\n","\n","\n","```python\n","s = re.sub(r\"\\s+\", \"_\", s.strip().lower())\n","```\n","\n","* First `s.strip().lower()` → trims leading/trailing spaces and makes lowercase.\n","* Regex: `\\s+` = one or more whitespace characters.\n","* Replace with `_`.\n","* Effect: turn spaces (tabs, newlines, etc.) into underscores, collapse runs of them into one.\n","\n","**Example:**\n","\n","```python\n","\"  Stock Price Change \".sub(...)  →  \"stock_price_change\"\n","```\n","\n","---\n","\n","\n","```python\n","s = re.sub(r\"_+\", \"_\", s)\n","```\n","\n","* Regex: `_+` = one or more underscores in a row.\n","* Replace with a single `_`.\n","* Effect: collapse multiple underscores into just one.\n","\n","**Example:**\n","\n","```python\n","\"stock__price___change\".sub(...)  →  \"stock_price_change\"\n","```\n","\n","\n","\n","```python\n","pd.to_datetime(out[\"date\"], errors=\"coerce\")\n","```\n","\n"," The option `errors=\"coerce\"`\n","\n","* Controls what happens if a value **cannot** be parsed as a date.\n","* Choices:\n","\n","  * `\"raise\"` (default) → throw an error if parsing fails.\n","  * `\"ignore\"` → return the original value unchanged if parsing fails.\n","  * `\"coerce\"` → invalid parsing becomes `NaT` (Not a Time, like `NaN` for dates).\n","\n","So with `\"coerce\"`, you won’t crash on bad data — instead, those entries become `NaT`.\n","\n","---\n","\n","### 4. Example\n","\n","```python\n","import pandas as pd\n","\n","s = pd.Series([\"2020-01-01\", \"06/30/2020\", \"not_a_date\", None])\n","\n","parsed = pd.to_datetime(s, errors=\"coerce\")\n","print(parsed)\n","```\n","\n","Output:\n","\n","```\n","0   2020-01-01\n","1   2020-06-30\n","2          NaT\n","3          NaT\n","dtype: datetime64[ns]\n","```\n","\n","\n","```python\n","out[\"volume\"] = out[\"volume\"].round().astype(\"Int64\")  # nullable int\n","```\n","\n","\n","* **`.astype(\"Int64\")`**\n","  → Converts the column to **pandas’ nullable integer dtype**, `Int64` (capital `I`).\n","  This is different from NumPy’s plain `int64`.\n","\n","  * `int64` cannot hold missing values (`NaN`).\n","  * `Int64` can hold **`<NA>`** (pandas’ missing marker).\n","\n","So now `volume` is an integer column that can still represent missing data.\n","\n","---\n","\n","### 2.\n","\n","```python\n","out.loc[out[\"volume\"] < 0, \"volume\"] = pd.NA\n","```\n","\n","* **`out[\"volume\"] < 0`** → Boolean mask of rows where `volume` is negative.\n","* **`.loc[..., \"volume\"]`** → Select those rows in the `volume` column.\n","* **`= pd.NA`** → Replace them with pandas’ `NA` (nullable missing value).\n","\n","\n","### 3. Example\n","\n","```python\n","import pandas as pd\n","import numpy as np\n","\n","out = pd.DataFrame({\"volume\": [1.2e7, -5000, 8.9e6, np.nan]})\n","\n","out[\"volume\"] = out[\"volume\"].round().astype(\"Int64\")\n","out.loc[out[\"volume\"] < 0, \"volume\"] = pd.NA\n","\n","print(out)\n","print(out.dtypes)\n","```\n","\n","Output:\n","\n","```\n","     volume\n","0  12000000\n","1      <NA>\n","2   8900000\n","3      <NA>\n","\n","volume    Int64\n","dtype: object\n","```\n","\n","\n","```python\n","out.reset_index(drop=True)\n","```\n","\n","* `reset_index()` **resets the index back to the default `RangeIndex` (0,1,2,...)**.\n","\n","* By default, it takes the old index and moves it into a new column.\n","\n","---\n","\n","### 2. The option `drop=True`\n","\n","* Without it:\n","\n","  ```python\n","  df.reset_index()\n","  ```\n","\n","  keeps the old index as a new column named `\"index\"`.\n","\n","* With `drop=True`:\n","\n","  ```python\n","  df.reset_index(drop=True)\n","  ```\n","\n","  **discards** the old index entirely, instead of adding it back as a column.\n","\n","---\n","\n","### 3. Example\n","\n","```python\n","import pandas as pd\n","\n","out = pd.DataFrame({\"A\":[10,20,30]}, index=[\"x\",\"y\",\"z\"])\n","print(out)\n","```\n","\n","```\n","   A\n","x  10\n","y  20\n","z  30\n","```\n","\n","Now reset:\n","\n","```python\n","print(out.reset_index(drop=True))\n","```\n","\n","```\n","    A\n","0  10\n","1  20\n","2  30\n","```\n","\n","```python\n","pd.api.types.is_datetime64_any_dtype(out[\"date\"])\n","```\n","\n","\n","* `pd.api.types` = pandas’ internal type-checking utilities.\n","* Functions like `is_numeric_dtype`, `is_string_dtype`, `is_datetime64_any_dtype` let you test the dtype of a Series/DataFrame column.\n","\n","---\n","\n","### 2. What `is_datetime64_any_dtype` checks\n","\n","* Returns **True** if the data type of the Series (or array) is **any kind of datetime64**.\n","* That includes:\n","\n","  * `datetime64[ns]` (the most common, nanosecond precision)\n","  * `datetime64[ns, tz]` (timezone-aware)\n","  * Or other datetime64 precisions (like `[s]`, `[ms]`, `[us]`).\n","\n","`datetime64[ms]` → millisecond precision\n","\n","`datetime64[us]` → microsecond precision (µs; written us since µ isn’t ASCII)\n","---\n","\n","### 3. Example\n","\n","```python\n","import pandas as pd\n","\n","df = pd.DataFrame({\n","    \"date\": pd.to_datetime([\"2020-01-01\", \"2020-06-30\"]),\n","    \"value\": [1, 2]\n","})\n","\n","print(pd.api.types.is_datetime64_any_dtype(df[\"date\"]))   # True\n","print(pd.api.types.is_datetime64_any_dtype(df[\"value\"]))  # False\n","```\n","\n","\n","```python\n","prices.merge(meta2, on=\"ticker\", how=\"left\", validate=\"many_to_one\")\n","```\n","\n","* `DataFrame.merge()` combines two DataFrames (like SQL JOIN).\n","* You specify the key(s) to join on (`on=\"ticker\"` here).\n","* Returns a new DataFrame with columns from both.\n","\n","---\n","\n","### 2. `on=\"ticker\"`\n","\n","* The join key is the column `\"ticker\"`.\n","* Must exist in both `prices` and `meta2`.\n","\n","---\n","\n","### 3. `how=\"left\"`\n","\n","* Do a **left join**:\n","\n","  * Keep **all rows from `prices`** (the left DataFrame).\n","  * Attach matching info from `meta2` (the right DataFrame).\n","  * If a `ticker` from `prices` doesn’t exist in `meta2`, the extra columns will be filled with `NaN`.\n","\n","This mirrors SQL:\n","\n","```sql\n","SELECT *\n","FROM prices\n","LEFT JOIN meta2 USING (ticker)  --USING only for the sanem name in both tables. Otherwise use ON\n","```\n","\n","---\n","\n","### 4. `validate=\"many_to_one\"`\n","\n","This is a **sanity check** to catch join mistakes.\n","\n","* `\"many_to_one\"` means:\n","\n","  * Left DataFrame (`prices`) may have **many rows per ticker** (because each ticker has daily prices).\n","  * Right DataFrame (`meta2`) must have **at most one row per ticker** (e.g. ticker metadata like name, sector).\n","* If `meta2` has duplicates in `\"ticker\"`, pandas will raise a `MergeError`.\n","\n","This protects against accidentally duplicating rows.\n","\n","Other options:\n","\n","* `\"one_to_one\"`\n","* `\"one_to_many\"`\n","* `\"many_to_many\"`\n","\n","---\n","\n","### 5. Example\n","\n","```python\n","import pandas as pd\n","\n","prices = pd.DataFrame({\n","    \"ticker\": [\"AAPL\", \"AAPL\", \"MSFT\"],\n","    \"date\": [\"2020-01-01\", \"2020-01-02\", \"2020-01-01\"],\n","    \"adj_close\": [300, 305, 160]\n","})\n","\n","meta2 = pd.DataFrame({\n","    \"ticker\": [\"AAPL\", \"MSFT\"],\n","    \"sector\": [\"Tech\", \"Tech\"]\n","})\n","\n","merged = prices.merge(meta2, on=\"ticker\", how=\"left\", validate=\"many_to_one\")\n","print(merged)\n","```\n","\n","Output:\n","\n","```\n","  ticker        date  adj_close sector\n","0   AAPL  2020-01-01        300   Tech\n","1   AAPL  2020-01-02        305   Tech\n","2   MSFT  2020-01-01        160   Tech\n","```\n","\n","\n"],"metadata":{"id":"z3Wr0tJcUzdE"}},{"cell_type":"code","source":["import re\n","\n","def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Lowercase snake_case; repair common price column name variants.\"\"\"\n","    def snake(s):\n","        s = re.sub(r\"[^\\w\\s]\", \"_\", s)\n","        s = re.sub(r\"\\s+\", \"_\", s.strip().lower())\n","        s = re.sub(r\"_+\", \"_\", s)\n","        return s\n","    out = df.copy()\n","    out.columns = [snake(c) for c in out.columns]\n","    # Normalize known variants\n","    ren = {\n","        \"adjclose\":\"adj_close\", \"adj_close_\":\"adj_close\",\n","        \"close_adj\":\"adj_close\", \"adj_close_close\":\"adj_close\"\n","    }\n","    out = out.rename(columns={k:v for k,v in ren.items() if k in out.columns})\n","    # If no adj_close but close exists, create it\n","    if \"adj_close\" not in out and \"close\" in out:\n","        out = out.assign(adj_close=out[\"close\"])\n","    return out\n","\n","def clean_prices(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Coerce dtypes, drop dupes, basic sanity checks; add minor derived fields.\"\"\"\n","    cols = [\"date\",\"ticker\",\"open\",\"high\",\"low\",\"close\",\"adj_close\",\"volume\"]\n","    keep = [c for c in cols if c in df.columns]\n","    out = df.loc[:, keep].copy()\n","\n","    # Parse date, coerce numerics\n","    out[\"date\"] = pd.to_datetime(out[\"date\"], errors=\"coerce\")\n","    for c in [\"open\",\"high\",\"low\",\"close\",\"adj_close\"]:\n","        if c in out: out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n","    if \"volume\" in out: out[\"volume\"] = pd.to_numeric(out[\"volume\"], errors=\"coerce\")\n","\n","    # Drop bad rows\n","    out = out.dropna(subset=[\"date\",\"ticker\",\"adj_close\"])\n","    # Deduplicate by (ticker, date)\n","    out = out.sort_values([\"ticker\",\"date\"])\n","    out = out.drop_duplicates(subset=[\"ticker\",\"date\"], keep=\"last\")\n","\n","    # Enforce dtypes\n","    if \"volume\" in out:\n","        out[\"volume\"] = out[\"volume\"].round().astype(\"Int64\")  # nullable int\n","        out.loc[out[\"volume\"] < 0, \"volume\"] = pd.NA\n","    # Use category for low-cardinality strings\n","    out[\"ticker\"] = out[\"ticker\"].astype(\"category\")\n","    # Use consistent float dtype\n","    for c in [\"open\",\"high\",\"low\",\"close\",\"adj_close\"]:\n","        if c in out: out[c] = out[c].astype(\"float32\")  #  change to float64 if you need more precision\n","\n","    # Quick sanity checks\n","    assert out[[\"ticker\",\"date\"]].duplicated().sum() == 0, \"Duplicates remain\"\n","    assert pd.api.types.is_datetime64_any_dtype(out[\"date\"]), \"date not datetime\"\n","    return out.reset_index(drop=True)\n","\n","def join_meta(prices: pd.DataFrame, meta: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Left join metadata; keep minimal meta columns; set dtypes.\"\"\"\n","    keep_meta = [c for c in [\"ticker\",\"name\",\"sector\"] if c in meta.columns]\n","    meta2 = meta.loc[:, keep_meta].copy()\n","    # Make strings consistent and compact\n","    if \"name\" in meta2:   meta2[\"name\"]   = meta2[\"name\"].astype(\"string\")\n","    if \"sector\" in meta2: meta2[\"sector\"] = meta2[\"sector\"].astype(\"category\")\n","    out = prices.merge(meta2, on=\"ticker\", how=\"left\", validate=\"many_to_one\")\n","    return out"],"metadata":{"id":"dBFSY5C6TyTc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","```python\n","tidy = (raw\n","            .pipe(standardize_columns)  # <- consistent names\n","            .pipe(clean_prices))\n","```\n","\n","### 2. `.pipe(func, *args, **kwargs)`\n","\n","* In pandas, `.pipe()` lets you pass a DataFrame into a function in a **chainable** way.\n","* `df.pipe(f)` is equivalent to `f(df)`.\n","* If the function needs extra arguments:\n","\n","  ```python\n","  df.pipe(f, arg1, kwarg1=value)\n","  # same as\n","  f(df, arg1, kwarg1=value)\n","  ```\n","* Advantage: keeps the **method-chaining style** consistent (like dplyr in R).\n","\n","\n","### 2. `memory_usage=\"deep\"`\n","\n","* By default, `info()` shows a **shallow** memory estimate (just the arrays).\n","* With `\"deep\"`, pandas does a **full introspection**, especially for `object` columns (like strings).\n","\n","  * Measures actual Python object memory, not just array references.\n","  * Much more accurate for text-heavy data.\n","* It can take longer if the DataFrame is big.\n","\n","Example difference:\n","\n","```python\n","df = pd.DataFrame({\"col\": [\"a\"*100, \"b\"*200, \"c\"*300]})\n","print(df.info())                  # shallow\n","print(df.info(memory_usage=\"deep\"))  # deep, counts string lengths\n","```\n","\n","Output:\n","\n","```\n","memory usage: 152.0+ bytes\n","memory usage: 1.1 KB\n","```\n","\n"],"metadata":{"id":"m95lvWZVfmMm"}},{"cell_type":"code","source":["dfs = []\n","for path in raw_candidates:\n","    raw = pd.read_csv(path)\n","    tidy = (raw\n","            .pipe(standardize_columns)  # <- consistent names\n","            .pipe(clean_prices))        # <- dtypes and sanity checks\n","    dfs.append(tidy)\n","\n","prices = pd.concat(dfs, ignore_index=True)\n","prices = prices.pipe(join_meta, meta=meta)\n","\n","print(\"Preview:\")\n","display(prices.head(3))\n","print(\"\\nInfo:\")\n","print(prices.info(memory_usage=\"deep\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"id":"JslUXC2meY7h","executionInfo":{"status":"ok","timestamp":1758662948153,"user_tz":300,"elapsed":181,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"86fa2a50-3aa3-4508-d05b-5b1a8ca3f5ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preview:\n"]},{"output_type":"display_data","data":{"text/plain":["        date ticker   adj_close   volume  name   sector\n","0 2020-01-01   AAPL  100.001228  4457901  AAPL  Unknown\n","1 2020-01-02   AAPL  100.300423  2664190  AAPL  Unknown\n","2 2020-01-03   AAPL  100.025841  4100245  AAPL  Unknown"],"text/html":["\n","  <div id=\"df-9f73afc2-7633-4d16-96bc-e14188a379f4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>ticker</th>\n","      <th>adj_close</th>\n","      <th>volume</th>\n","      <th>name</th>\n","      <th>sector</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2020-01-01</td>\n","      <td>AAPL</td>\n","      <td>100.001228</td>\n","      <td>4457901</td>\n","      <td>AAPL</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2020-01-02</td>\n","      <td>AAPL</td>\n","      <td>100.300423</td>\n","      <td>2664190</td>\n","      <td>AAPL</td>\n","      <td>Unknown</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2020-01-03</td>\n","      <td>AAPL</td>\n","      <td>100.025841</td>\n","      <td>4100245</td>\n","      <td>AAPL</td>\n","      <td>Unknown</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f73afc2-7633-4d16-96bc-e14188a379f4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9f73afc2-7633-4d16-96bc-e14188a379f4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9f73afc2-7633-4d16-96bc-e14188a379f4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-577929c0-56d0-4047-8502-572fee29a0aa\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-577929c0-56d0-4047-8502-572fee29a0aa')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-577929c0-56d0-4047-8502-572fee29a0aa button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"print(prices\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-01-01 00:00:00\",\n        \"max\": \"2020-01-03 00:00:00\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2020-01-01 00:00:00\",\n          \"2020-01-02 00:00:00\",\n          \"2020-01-03 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AAPL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adj_close\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          100.00122833251953\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4457901\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AAPL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Unknown\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Info:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4500 entries, 0 to 4499\n","Data columns (total 6 columns):\n"," #   Column     Non-Null Count  Dtype         \n","---  ------     --------------  -----         \n"," 0   date       4500 non-null   datetime64[ns]\n"," 1   ticker     4500 non-null   object        \n"," 2   adj_close  4500 non-null   float32       \n"," 3   volume     4500 non-null   Int64         \n"," 4   name       4500 non-null   string        \n"," 5   sector     4500 non-null   category      \n","dtypes: Int64(1), category(1), datetime64[ns](1), float32(1), object(1), string(1)\n","memory usage: 555.4 KB\n","None\n"]}]},{"cell_type":"markdown","source":["```python\n","prices.to_parquet(single_path, engine=\"pyarrow\", compression=\"zstd\", index=False)\n","```\n","\n","\n","### 1. `to_parquet`\n","\n","* A pandas method to save a DataFrame as a **Parquet file**.\n","* Parquet = a **columnar, compressed, binary format** widely used in data science and big data (efficient storage + fast reads).\n","\n","---\n","\n","* **`engine=\"pyarrow\"`**\n","  Pandas can use either:\n","\n","  * `pyarrow` (Apache Arrow’s Python library — fast, modern, supports advanced features).\n","  * `fastparquet` (older, pure Python, slower for some cases).\n","    You chose `pyarrow`, which is the default if installed.\n","\n","* **`compression=\"zstd\"`**\n","\n","  * Use **Zstandard** compression (modern, high compression ratio, fast).\n","  * Alternatives: `\"snappy\"`, `\"gzip\"`, `\"brotli\"`, `\"lz4\"`, or `None`.\n","  * Zstandard is excellent for large datasets — smaller than Snappy, faster than Gzip.\n","\n","* **`index=False`**\n","\n","  * Don’t save the DataFrame’s index as a column in the Parquet file.\n","  * Keeps the file clean if your index is just `0,1,2,...`.\n","\n","---\n","\n","### 3. Example\n","\n","```python\n","import pandas as pd\n","\n","prices = pd.DataFrame({\n","    \"ticker\": [\"AAPL\", \"MSFT\"],\n","    \"date\": pd.to_datetime([\"2020-01-01\", \"2020-01-02\"]),\n","    \"adj_close\": [300, 160]\n","})\n","\n","prices.to_parquet(\"prices.parquet\", engine=\"pyarrow\", compression=\"zstd\", index=False)\n","\n","# Read back\n","df = pd.read_parquet(\"prices.parquet\", engine=\"pyarrow\")\n","print(df)\n","```\n","\n","Output:\n","\n","```\n","  ticker       date  adj_close\n","0   AAPL 2020-01-01        300\n","1   MSFT 2020-01-02        160\n","```\n","\n","---\n","\n","### 4. Why use Parquet\n","\n","* Much smaller than CSV.\n","* Much faster to load into pandas (especially with Arrow).\n","* Preserves dtypes (like `datetime64[ns]`, `Int64`, `category`).\n","* Plays nicely with Spark, Dask, DuckDB, BigQuery, etc.\n","\n","\n","\n","```python\n","prices.to_parquet(\n","    part_dir,\n","    engine=\"pyarrow\",\n","    compression=\"zstd\",\n","    index=False,\n","    partition_cols=[\"ticker\"]\n",")\n","```\n","\n","\n","\n","### 1. `partition_cols=[\"ticker\"]`\n","\n","* Instead of writing **one single Parquet file**, pandas will write a **Parquet dataset**.\n","* The dataset is split into **subdirectories by the values in `ticker`**.\n","* Each unique `ticker` value gets its own folder.\n","* Inside each folder is one (or more) Parquet files containing only rows with that ticker.\n","\n","---\n","\n","### 2. Directory structure example\n","\n","If `prices` has three tickers (`AAPL`, `MSFT`, `GOOG`), the output looks like:\n","\n","```\n","part_dir/\n","├── ticker=AAPL/\n","│   └── part-0.parquet\n","├── ticker=MSFT/\n","│   └── part-0.parquet\n","└── ticker=GOOG/\n","    └── part-0.parquet\n","```\n","\n","So the folder name encodes the partition column value: `ticker=AAPL`.\n","\n","\n","---\n","\n","### 4. Other options\n","\n","* You can partition by **multiple columns**:\n","\n","  ```python\n","  partition_cols=[\"sector\", \"year\"]\n","  ```\n","\n","  Then the directory hierarchy will nest:\n","\n","  ```\n","  sector=Tech/year=2020/part-0.parquet\n","  ```\n","* Works only with Parquet (not CSV).\n","\n","---\n","\n","### 5. Reading it back\n","\n","```python\n","import pandas as pd\n","\n","df = pd.read_parquet(part_dir, engine=\"pyarrow\")\n","print(df.head())\n","```\n","\n","* This automatically reassembles all partitions into one DataFrame.\n","* If you want only one ticker:\n","\n","  ```python\n","  df = pd.read_parquet(part_dir, filters=[(\"ticker\", \"=\", \"AAPL\")], engine=\"pyarrow\")\n","  ```\n","\n","\n"],"metadata":{"id":"feFZZ6PuiBFv"}},{"cell_type":"code","source":["# Single-file Parquet\n","single_path = \"data/processed/prices.parquet\"\n","prices.to_parquet(single_path, engine=\"pyarrow\", compression=\"zstd\", index=False)\n","print(\"Wrote:\", single_path)\n","\n","# Partitioned dataset by ticker (directory with /ticker=.../)\n","part_dir = \"data/processed/prices_by_ticker\"\n","# pandas to_parquet supports partition_cols with pyarrow engine\n","try:\n","    prices.to_parquet(part_dir, engine=\"pyarrow\", compression=\"zstd\",\n","                      index=False, partition_cols=[\"ticker\"])\n","    print(\"Wrote partitioned dataset:\", part_dir)\n","except TypeError:\n","    # Fallback via pyarrow dataset API\n","    import pyarrow as pa, pyarrow.parquet as pq\n","    pa_tbl = pa.Table.from_pandas(prices, preserve_index=False)\n","    pq.write_to_dataset(pa_tbl, root_path=part_dir, partition_cols=[\"ticker\"], compression=\"zstd\")\n","    print(\"Wrote (fallback) partitioned dataset:\", part_dir)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XxC9WsQ6hUOQ","executionInfo":{"status":"ok","timestamp":1758663645142,"user_tz":300,"elapsed":958,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"08c67108-600f-4eb3-a8b3-33e4a5e0ad88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wrote: data/processed/prices.parquet\n","Wrote partitioned dataset: data/processed/prices_by_ticker\n"]}]},{"cell_type":"code","source":["# 6a) Read a few columns from single-file Parquet\n","cols = [\"ticker\",\"date\",\"adj_close\",\"volume\"]\n","df_small = pd.read_parquet(\"data/processed/prices.parquet\", columns=cols)\n","df_small.head()\n","\n","# 6b) Read one ticker from the partitioned dataset using pyarrow.dataset\n","import pyarrow.dataset as ds\n","dataset = ds.dataset(\"data/processed/prices_by_ticker\", format=\"parquet\", partitioning=\"hive\")\n","# Choose a ticker present in the data\n","one_ticker = str(prices[\"ticker\"].cat.categories[0])\n","flt = (ds.field(\"ticker\") == one_ticker)\n","tbl = dataset.to_table(filter=flt, columns=[\"date\",\"adj_close\",\"volume\"])\n","df_one = tbl.to_pandas()\n","df_one.head()"],"metadata":{"id":"LVtwUXzpj9TQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json, pathlib\n","schema = {c: str(t) for c,t in prices.dtypes.items()}\n","pathlib.Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n","with open(\"data/processed/prices_schema.json\",\"w\") as f:\n","    json.dump(schema, f, indent=2)\n","print(\"Wrote data/processed/prices_schema.json\")"],"metadata":{"id":"krZjKogvkBWn"},"execution_count":null,"outputs":[]}]}