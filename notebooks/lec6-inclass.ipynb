{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNLauyLKLkdvr2SM0pdVZve"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Colab cell\n","from google.colab import drive\n","\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"id":"I4_j62ifBNHb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757619152103,"user_tz":300,"elapsed":16259,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"9ab69423-cb03-4544-f203-950e8caf7aca"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"KQB-iMN3BDQ4","executionInfo":{"status":"ok","timestamp":1757619153437,"user_tz":300,"elapsed":366,"user":{"displayName":"David W.","userId":"14633192575819064045"}}},"outputs":[],"source":["# Adjust these two for YOUR repo\n","REPO_OWNER = \"ywanglab\"\n","REPO_NAME  = \"STAT4160\"   # e.g., unified-stocks-team1\n","\n","BASE_DIR   = \"/content/drive/MyDrive/dspt25\"\n","CLONE_DIR  = f\"{BASE_DIR}/{REPO_NAME}\"\n","REPO_URL   = f\"https://github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n","\n","import os, pathlib\n","pathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True)\n"]},{"cell_type":"code","source":["import os, subprocess, shutil, pathlib\n","\n","if not pathlib.Path(CLONE_DIR).exists():\n","    !git clone {REPO_URL} {CLONE_DIR}\n","else:\n","    # If the folder exists, just ensure it's a git repo and pull latest\n","    os.chdir(CLONE_DIR)\n","    # !git status\n","    # !git pull --rebase # !git pull --ff-only\n","os.chdir(CLONE_DIR)\n","print(\"Working dir:\", os.getcwd())"],"metadata":{"id":"n6jMrUCACz0a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757619155571,"user_tz":300,"elapsed":29,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"c2d547a3-e6e6-48b4-8614-96ca9895d2bf"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Working dir: /content/drive/MyDrive/dspt25/STAT4160\n"]}]},{"cell_type":"code","source":["import subprocess, shutil\n","def check(cmd):\n","    try:\n","        out = subprocess.check_output(cmd, text=True)\n","        print(cmd[0], \"OK\")\n","    except Exception as e:\n","        print(cmd[0], \"NOT FOUND\")\n","check([\"make\", \"--version\"])\n","check([\"rsync\", \"--version\"])\n","check([\"quarto\", \"--version\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UuD1BPfG-U7t","executionInfo":{"status":"ok","timestamp":1757619160862,"user_tz":300,"elapsed":30,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"63e579f1-5036-4c10-9c46-b2c131e59d49"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["make OK\n","rsync OK\n","quarto NOT FOUND\n"]}]},{"cell_type":"code","source":["# Install Quarto CLI (one-time per Colab runtime)\n","# !wget -q https://quarto.org/download/latest/quarto-linux-amd64.deb -O /tmp/quarto.deb\n","# !dpkg -i /tmp/quarto.deb || apt-get -y -f install >/dev/null && dpkg -i /tmp/quarto.deb\n","# !quarto --version\n","\n","#Alternatively, save it to G-drive, and only need to download the first time. The size of  quarto-linux-amd64.deb is ~125Mb.\n","# Path to store the deb package\n","deb_path = \"/content/drive/MyDrive/quarto-linux-amd64.deb\"\n","\n","# Download only if not already saved\n","!test -f $deb_path || wget -q https://quarto.org/download/latest/quarto-linux-amd64.deb -O $deb_path\n","\n","# Install from Drive (fast, no re-download)\n","!dpkg -i $deb_path || apt-get -y -f install >/dev/null && dpkg -i $deb_path #-f: fix package dependency issues\n","!quarto --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJdlv_BqFpEu","executionInfo":{"status":"ok","timestamp":1757605356065,"user_tz":300,"elapsed":17265,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"9019a327-bfeb-4abf-d96b-4c10cea993a1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["(Reading database ... 130485 files and directories currently installed.)\n","Preparing to unpack .../MyDrive/quarto-linux-amd64.deb ...\n","Unpacking quarto (1.7.33) over (1.7.33) ...\n","Setting up quarto (1.7.33) ...\n","(Reading database ... 130485 files and directories currently installed.)\n","Preparing to unpack .../MyDrive/quarto-linux-amd64.deb ...\n","Unpacking quarto (1.7.33) over (1.7.33) ...\n","Setting up quarto (1.7.33) ...\n","1.7.33\n"]}]},{"cell_type":"markdown","source":["* **`auto_adjust=True`**\n","\n","  * Adjusts prices for dividends and stock splits.\n","  * With this option:\n","\n","    * `Open`, `High`, `Low`, `Close` are adjusted values.\n","    * Column `Adj Close` is dropped (since it would duplicate `Close`).\n","  * If `False`, you’ll get both `Close` (raw) and `Adj Close`.\n","\n","* **`progress=False`**\n","\n","  * Suppresses the progress bar output in the terminal.\n","  * Useful when running inside scripts or notebooks to keep output clean.\n","\n","* `df.rename` changes column names.\n","* `columns=str.lower` means: apply the function `str.lower` to every column name.\n","* Example:\n","  Before: `[\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]`\n","  After:  `[\"open\",\"high\",\"low\",\"close\",\"volume\"]`\n","\n","* After `reset_index()`: This turns the index into a normal column.\n","\n","```python\n","ap = argparse.ArgumentParser()\n","```\n","\n","* Creates an argument parser object.\n","* This object knows how to read and interpret arguments from the command line.\n","\n","\n","```python\n","args = ap.parse_args()\n","```\n","\n","* Actually parses the arguments given when the script runs.\n","* Creates a namespace object (`args`) with attributes:\n","\n","  * `args.tickers`\n","  * `args.start`\n","  * `args.end`\n","  * `args.out`\n","\n","If you run:\n","\n","```bash\n","./scripts/get_prices.py --tickers=mylist.csv --start=2019-01-01 --end=2022-12-31 --out=data/prices.csv\n","```\n","\n","Then inside Python:\n","\n","```python\n","args.tickers   # \"mylist.csv\"\n","args.start     # \"2019-01-01\"\n","args.end       # \"2022-12-31\"\n","args.out       # \"data/prices.csv\"\n","```\n","\n","If you run without arguments:\n","\n","```bash\n","./scripts/get_prices.py\n","```\n","\n","Then you get the **defaults**:\n","\n","* `tickers_25.csv`\n","* `2020-01-01`\n","* `\"\"` (empty string, → treated as today)\n","* `data/raw/prices.csv`\n","\n","Nice catch — that’s a little trick inside the synthetic-data generator.\n","\n","* **`hash(t)`**\n","\n","   * Built-in Python function.\n","   * Returns an integer hash value of the object `t` (here, the ticker symbol string, e.g. `\"AAPL\"`).\n","   * Same `t` in the same run → same hash.\n","   * But note: in different Python processes, `hash()` is *seeded randomly by default* (for security), so the raw number can vary between runs.\n","\n","\n","**In short:**\n","`hash(t) % 1000` maps each ticker to a number between 0–999, so each ticker gets its own random-generator seed for reproducible synthetic data.\n","\n","* **`pd.to_datetime(df[\"date\"])`**\n","\n","   * Takes the `\"date\"` column (which might be strings like `\"2020-01-02\"` or Timestamps) and converts it into pandas `Datetime64[ns]` objects.\n","   * Example: `\"2020-01-02\"` → `Timestamp('2020-01-02 00:00:00')`.\n","\n","* **`.dt` accessor**\n","\n","   * Lets you pull datetime-specific components (like `.year`, `.month`, `.day`, `.weekday`, etc.) from a pandas datetime series.\n","\n","* **`.date`**\n","\n","   * Extracts the underlying Python `datetime.date` object from each `Timestamp`.\n","   * Drops the time-of-day information, leaving just the calendar date.\n","\n","That’s the **standard Python entry-point idiom** — it controls when your `main()` function runs.\n","\n","```python\n","if __name__ == \"__main__\":\n","    sys.exit(main())\n","```\n","\n","1. **`__name__`**\n","\n","   * A special variable set by Python.\n","   * If you **run a file directly** (e.g. `python get_prices.py`), then `__name__` is set to `\"__main__\"`.\n","   * If you **import that file as a module** (e.g. `import get_prices`), then `__name__` is set to the module name (`\"get_prices\"`).\n","\n","2. **`if __name__ == \"__main__\":`**\n","\n","   * Ensures the block only runs when the script is executed directly, **not** when imported.\n","   * This way, you can safely import functions like `fetch_yf` elsewhere without auto-running the downloader.\n","\n","3. **`sys.exit(main())`**\n","\n","   * Calls the `main()` function.\n","   * `main()` returns `None` unless you `return` something — but if it raised an error, `sys.exit()` would propagate a nonzero exit code to the shell.\n","   * Using `sys.exit()` makes it explicit that this script is a **command-line program**, with exit codes that tools/shells can check.\n","\n","\n","```python\n","import os, stat\n","os.chmod(\"scripts/get_prices.py\", os.stat(\"scripts/get_prices.py\").st_mode | stat.S_IEXEC)\n","```\n","\n","1. **`os.stat(\"scripts/get_prices.py\").st_mode`**\n","\n","   * `os.stat` gets file metadata (permissions, size, etc.).\n","   * `.st_mode` is an integer bitmask that encodes the file’s permission bits (read, write, execute).\n","   * Example: `0o644` → means `rw-r--r--`.\n","\n","2. **`| stat.S_IEXEC`**\n","\n","   * `stat.S_IEXEC` is the “executable” bit.\n","   * The `|` is a bitwise OR — it adds that permission without removing the existing ones.\n","   * So if the file was `rw-r--r--` (644), it becomes `rwxr--r--` (744).\n","\n","3. **`os.chmod(\"scripts/get_prices.py\", new_mode)`**\n","\n","   * Actually changes the file’s mode (permissions) to include “executable.”\n","\n","By default, when you `open(...,\"w\").write(get_py)`, the file has normal text-file permissions (read/write).\n","But after this command, the file is **executable**, so you can run it directly from the shell:\n","\n","```bash\n","./scripts/get_prices.py --start=2021-01-01 --end=2023-01-01\n","```\n","\n","Instead of having to type:\n","\n","```bash\n","python scripts/get_prices.py --start=2021-01-01 --end=2023-01-01\n","```\n","\n","`stat.S_IEXEC` is the **execute bit for the owner only**.\n","\n","* **Group execute:** use `stat.S_IXGRP`\n","* **Others execute:** use `stat.S_IXOTH`\n","* **All three at once:** use `stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH`\n","\n","So, for example:\n","\n","```python\n","os.chmod(\"scripts/get_prices.py\",\n","         os.stat(\"scripts/get_prices.py\").st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH)\n","```\n","\n","would make it executable by everyone (`rwxr-xr-x`).\n","\n","\n","* In personal projects, usually only you need to run it.\n","* Keeping group/others non-executable is a small security measure.\n","* It mimics `chmod u+x file.py` (owner execute only), which is the most common.\n","\n","\n","\n","* Starts with `#!` → tells the operating system: *“Use this program to interpret the rest of the file.”*\n","\n","\n","* `/usr/bin/env` is a small program that looks up another program in your **PATH**.\n","\n","* By writing:\n","\n","  ```bash\n","  #!/usr/bin/env python\n","  ```\n","\n","  you’re saying: *“Find whatever `python` is in my PATH, and use that.”*\n","\n","* This is more flexible than hardcoding:\n","\n","  ```bash\n","  #!/usr/bin/python\n","  ```\n","\n","  because:\n","\n","  * Some systems call it `python3`\n","  * Some install it in `/usr/local/bin`\n","  * Some use Conda or virtual environments with different paths\n","\n"],"metadata":{"id":"oAdBZqDSA4dE"}},{"cell_type":"code","source":["from pathlib import Path\n","Path(\"scripts\").mkdir(exist_ok=True)\n","\n","get_py = r\"\"\"#!/usr/bin/env python\n","import argparse, sys, time\n","from pathlib import Path\n","import pandas as pd, numpy as np\n","\n","def fetch_yf(ticker, start, end):\n","    import yfinance as yf\n","    df = yf.download(ticker, start=start, end=end, auto_adjust=True, progress=False)\n","    if df is None or df.empty:\n","        raise RuntimeError(\"empty\")\n","    df = df.rename(columns=str.lower)[[\"close\",\"volume\"]]\n","    # --- minimal sanitize to avoid NaNs in adj_close/log_return ---\n","    df = df.sort_index()\n","    df = df[~df.index.duplicated(keep=\"last\")]\n","    df = df.dropna(subset=[\"close\"])\n","    df[\"volume\"] = df[\"volume\"].fillna(0)\n","    # --------------------------------------------------------------\n","    df.index.name = \"date\"\n","    df = df.reset_index()\n","    df[\"ticker\"] = ticker\n","    return df[[\"ticker\",\"date\",\"close\",\"volume\"]]\n","\n","def main():\n","    ap = argparse.ArgumentParser()\n","    ap.add_argument(\"--tickers\", default=\"tickers_25.csv\")\n","    ap.add_argument(\"--start\", default=\"2020-01-01\")\n","    ap.add_argument(\"--end\", default=\"\")\n","    ap.add_argument(\"--out\", default=\"data/raw/prices.csv\")\n","    args = ap.parse_args()\n","\n","    out = Path(args.out)\n","    out.parent.mkdir(parents=True, exist_ok=True)\n","    tickers = pd.read_csv(args.tickers)[\"ticker\"].dropna().unique().tolist()\n","\n","    rows = []\n","    for t in tickers:\n","        try:\n","            df = fetch_yf(t, args.start, args.end or None)\n","        except Exception:\n","            # synthetic fallback\n","            idx = pd.bdate_range(args.start, args.end or pd.Timestamp.today().date())\n","            rng = np.random.default_rng(42 + hash(t)%1000)\n","            r = rng.normal(0, 0.01, len(idx))\n","            price = 100*np.exp(np.cumsum(r))\n","            vol = rng.integers(1e5, 5e6, len(idx))\n","            df = pd.DataFrame({\"ticker\": t, \"date\": idx, \"close\": price, \"volume\": vol})\n","        df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n","        df[\"adj_close\"] = df[\"close\"]\n","        df = df.drop(columns=[\"close\"])\n","        df[\"log_return\"] = np.log(df[\"adj_close\"]).diff().fillna(0.0)\n","        rows.append(df)\n","\n","    allp = pd.concat(rows, ignore_index=True)\n","    allp = allp[[\"ticker\",\"date\",\"adj_close\",\"volume\",\"log_return\"]]\n","    allp.to_csv(out, index=False)\n","    print(\"Wrote\", out, \"rows:\", len(allp))\n","\n","if __name__ == \"__main__\":\n","    sys.exit(main())\n","\"\"\"\n","open(\"scripts/get_prices.py\",\"w\").write(get_py)\n","import os, stat\n","os.chmod(\"scripts/get_prices.py\", os.stat(\"scripts/get_prices.py\").st_mode | stat.S_IEXEC)\n","print(\"Created scripts/get_prices.py\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YB5FwD4_WXn","executionInfo":{"status":"ok","timestamp":1757605357666,"user_tz":300,"elapsed":82,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"9e12af60-2673-447c-f3d1-beefce8ddedf"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Created scripts/get_prices.py\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"ypzE7zhnQR9k"}},{"cell_type":"markdown","source":["* `.shift(k)`: moves values down by `k` rows within each group.\n","\n","So for each stock:\n","\n","* `lag1` = yesterday’s return\n","* `lag2` = return from 2 days ago\n","* `lag3` = return from 3 days ago\n","\n","This ensures we can use past returns as predictors.\n","\n","Example:\n","\n","| ticker | date       | r\\_1d | lag1  | lag2 |\n","| ------ | ---------- | ----- | ----- | ---- |\n","| AAPL   | 2020-01-02 | 0.02  | NaN   | NaN  |\n","| AAPL   | 2020-01-03 | -0.01 | 0.02  | NaN  |\n","| AAPL   | 2020-01-06 | 0.03  | -0.01 | 0.02 |\n","\n","\n","* `.rolling(args.roll, min_periods=args.roll//2)`:\n","\n","  * Creates a moving window of length `args.roll` (say 30 days).\n","  * `min_periods=args.roll//2`: only compute a mean if at least half the window has non-missing data.\n","* `.reset_index(level=0, drop=True)`: because rolling adds a hierarchical index (ticker + date), we drop the extra ticker level and align back to the DataFrame.\n","\n","This creates a smoothed return trend for each stock.\n","\n"],"metadata":{"id":"jlK69nGaQXG3"}},{"cell_type":"code","source":["feat_py = r\"\"\"#!/usr/bin/env python\n","import argparse\n","from pathlib import Path\n","import pandas as pd, numpy as np\n","\n","def main():\n","    ap = argparse.ArgumentParser()\n","    ap.add_argument(\"--input\", default=\"data/raw/prices.csv\")\n","    ap.add_argument(\"--out\", default=\"data/processed/features.parquet\")\n","    ap.add_argument(\"--roll\", type=int, default=20)\n","    args = ap.parse_args()\n","\n","    df = pd.read_csv(args.input, parse_dates=[\"date\"])\n","    df = df.sort_values([\"ticker\",\"date\"])\n","    # groupwise lags\n","    df[\"r_1d\"] = df[\"log_return\"]\n","    for k in (1,2,3):\n","        df[f\"lag{k}\"] = df.groupby(\"ticker\")[\"r_1d\"].shift(k)\n","    df[\"roll_mean\"] = (df.groupby(\"ticker\")[\"r_1d\"]\n","                         .rolling(args.roll, min_periods=args.roll//2).mean()\n","                         .reset_index(level=0, drop=True))\n","    df[\"roll_std\"]  = (df.groupby(\"ticker\")[\"r_1d\"]\n","                         .rolling(args.roll, min_periods=args.roll//2).std()\n","                         .reset_index(level=0, drop=True))\n","    out = Path(args.out)\n","    out.parent.mkdir(parents=True, exist_ok=True)\n","    # Save compactly\n","    df.to_parquet(out, index=False)\n","    print(\"Wrote\", out, \"rows:\", len(df))\n","\n","if __name__ == \"__main__\":\n","    main()\n","\"\"\"\n","open(\"scripts/build_features.py\",\"w\").write(feat_py)\n","import os, stat\n","os.chmod(\"scripts/build_features.py\", os.stat(\"scripts/build_features.py\").st_mode | stat.S_IEXEC)\n","print(\"Created scripts/build_features.py\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hz4W8MRZJJ3R","executionInfo":{"status":"ok","timestamp":1757605364054,"user_tz":300,"elapsed":51,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"8de70e03-18e9-445c-d880-5dd10c462c03"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Created scripts/build_features.py\n"]}]},{"cell_type":"markdown","source":["```bash\n","ROOT=\"${1:-backups}\"\n","```\n","\n","* `$1` = the first argument passed to the script.\n","* `${1:-backups}` means:\n","\n","  * If `$1` is provided → use it.\n","  * If `$1` is empty/missing → fall back to `\"backups\"`.\n","\n","So:\n","\n","* Run as `./myscript.sh /tmp/saves` → `ROOT=\"/tmp/saves\"`.\n","* Run as `./myscript.sh` → `ROOT=\"backups\"`.\n","\n","```bash\n","STAMP=\"$(date +%Y%m%d-%H%M%S)\"\n","```\n","\n","* `$( ... )` runs a command and captures its output.\n","* `date +%Y%m%d-%H%M%S` formats the current date/time as:\n","\n","  * `%Y` = year (2025)\n","  * `%m` = month (09)\n","  * `%d` = day (09)\n","  * `%H` = hour (10, 24-hour clock)\n","  * `%M` = minute\n","  * `%S` = second\n","\n","Example result:\n","\n","```\n","STAMP=\"20250909-103512\"\n","```\n","\n","```bash\n","INCLUDE=(\"data/processed\" \"reports\" \"docs\")\n","```\n","\n","* This is a Bash **array** with three entries.\n","* Each entry is a directory path you want to include in your backup.\n","\n","So `${INCLUDE[@]}` expands to:\n","\n","```\n","data/processed reports docs\n","```\n","\n","```bash\n","if [[ -d \"$src\" ]]; then\n","```\n","\n","* `-d` checks “does this path exist and is it a directory?”\n","* Prevents errors if one of the folders is missing.\n","\n","```bash\n","rsync -avh --delete --exclude 'raw/' --exclude 'interim/' \"$src\"/ \"$DEST/$src\"/\n","```\n","\n","* **`rsync`** = tool for efficient folder copying.\n","* Flags:\n","\n","  * `-a` → archive mode (preserves permissions, timestamps, symlinks, etc.).\n","  * `-v` → verbose (print what’s happening).\n","  * `-h` → human-readable sizes.\n","* `--delete` → remove files in destination that no longer exist in source.\n","* `--exclude 'raw/' --exclude 'interim/'` → skip those subfolders.\n","* `\"$src\"/` → source directory, with trailing `/` meaning “copy contents, not the folder itself.”\n","* `\"$DEST/$src\"/` → destination path inside the backup directory. `rsync` can create the last directory in the path automatically.\n","\n","But you must ensure the parent directories already exist (with `mkdir -p \"$DEST\"`).\n","\n","So, e.g. if `DEST=\"backups/run-20250909-105530\"` and `src=\"reports\"`, then files are copied into:\n","\n","```\n","backups/run-20250909-105530/reports/\n","```\n","\n"],"metadata":{"id":"LKqfxI6ZSD9A"}},{"cell_type":"code","source":["backup_sh = r\"\"\"#!/usr/bin/env bash\n","# Sync selected artifacts to backups/<timestamp> using rsync.\n","# Usage: scripts/backup.sh [DEST_ROOT]\n","set -euo pipefail\n","ROOT=\"${1:-backups}\"\n","STAMP=\"$(date +%Y%m%d-%H%M%S)\"\n","DEST=\"${ROOT}/run-${STAMP}\"\n","mkdir -p \"$DEST\"\n","\n","# What to back up (adjust as needed)\n","INCLUDE=(\"data/processed\" \"reports\" \"docs\")\n","\n","for src in \"${INCLUDE[@]}\"; do\n","  if [[ -d \"$src\" ]]; then\n","    echo \"Syncing $src -> $DEST/$src\"\n","    rsync -avh --delete --exclude 'raw/' --exclude 'interim/' \"$src\"/ \"$DEST/$src\"/\n","  fi\n","done\n","\n","echo \"Backup complete at $DEST\"\n","\"\"\"\n","open(\"scripts/backup.sh\",\"w\").write(backup_sh)\n","import os, stat\n","os.chmod(\"scripts/backup.sh\", os.stat(\"scripts/backup.sh\").st_mode | stat.S_IEXEC)\n","print(\"Created scripts/backup.sh\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QA_-joiPuqm","executionInfo":{"status":"ok","timestamp":1757605370542,"user_tz":300,"elapsed":53,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"a2efa593-44d2-4c6f-8baf-6a152b759fd2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Created scripts/backup.sh\n"]}]},{"cell_type":"markdown","source":["* `SHELL := /bin/bash` — tell `make` to run recipe commands with **bash** (not `/bin/sh`). Good if you rely on Bash-isms (arrays, `[[ ]]`, brace-expansion, etc.).\n","* `.SHELLFLAGS := -eu -o pipefail -c`\n","\n","  * `-e` → exit immediately if any command in a recipe fails (non-zero status).\n","  * `-u` → treat **unset variables as an error** (helps catch typos like `$DATA_RAWW`).\n","  * `-o pipefail` → in pipelines (`a | b | c`), fail the whole pipeline if **any** part fails (not just the last command).\n","  * `-c` → standard: execute the following command string.\n","\n","### Tool “aliases”\n","\n","```make\n","PY := python\n","QUARTO := quarto\n","```\n","\n","* Variables for executables. If you need a specific interpreter, you can override:\n","\n","  * `make REPORT PY=python3.11`\n","  * `make REPORT QUARTO=/opt/quarto/bin/quarto`\n","\n","### Tunable parameters (with defaults)\n","\n","```make\n","START ?= 2020-01-01\n","END   ?= 2025-08-01\n","ROLL  ?= 30\n","```\n","\n","* `?=` is **conditional assignment**: set a default **only if not already set** in the environment or on the CLI.\n","* This lets you override at run time without editing the Makefile:\n","\n","  * `make report START=2019-01-01 END=2024-12-31 ROLL=60`\n","  * Or `START=2019-01-01 make report`\n","\n","### File path variables\n","\n","```make\n","DATA_RAW := data/raw/prices.csv\n","FEATS    := data/processed/features.parquet\n","REPORT   := docs/reports/eda.html\n","```\n","\n","* `:=` is **immediate assignment**: evaluate right now. (Here it’s identical to `=`, but `:=` avoids surprises if the RHS referenced other vars that might change later.)\n","* These centralize paths so your rules can reference them consistently:\n","\n","  ```make\n","  $(DATA_RAW)\n","  $(FEATS)\n","  $(REPORT)\n","  ```\n","\n","\n","### Tips / gotchas\n","\n","* On macOS/WSL/Windows Git Bash, ensure `/bin/bash` exists; otherwise use the path your system provides (e.g., `/usr/bin/env bash` in recipes: `bash -eu -o pipefail -c '...'`).\n","* With `-u`, any missing var expansion in recipes will fail fast—helpful during development.\n","* Prefer `?=` for user-tunable params; prefer `:=` for fixed paths/commands.\n","\n","```make\n",".DEFAULT_GOAL := help\n","```\n","\n","* Tells `make` what to run when you just type `make` with no arguments.\n","* By default, `make` uses the **first target defined in the file**, which can be confusing if it’s something destructive.\n","* Here, you explicitly set the default to the `help` target.\n","  So:\n","\n","  ```bash\n","  make\n","  ```\n","\n","  is equivalent to:\n","\n","  ```bash\n","  make help\n","  ```\n","\n","```make\n",".PHONY: help all clean clobber qa report backup\n","```\n","\n","* Declares that these are **not actual files**, just “commands” to run.\n","* Why? Because by default, `make` thinks targets represent files that should be built.\n","\n","  * If a file named `report` existed, `make report` would do nothing (because the file is “already up to date”).\n","* Declaring them `.PHONY` forces `make` to always run their recipes.\n","\n","So each of these (`help`, `all`, `clean`, `clobber`, `qa`, `report`, `backup`) will always run when called.\n","\n","### 3. Typical roles of those targets\n","\n","* **help**: print usage instructions (often lists all available targets).\n","* **all**: build everything (full pipeline).\n","* **clean**: remove temporary or generated files.\n","* **clobber**: stronger clean (maybe also remove large datasets, caches).\n","* **qa**: quality assurance checks (linting, validation, etc.).\n","* **report**: build analysis reports (Quarto, Rmarkdown, LaTeX, etc.).\n","* **backup**: run your backup script/rsync workflow.\n","\n","* `.PHONY` ensures those targets run unconditionally, without being mistaken for filenames.\n","\n","\n","```make\n","help: ## Show help for each target\n","```\n","\n","* Target is `help`.\n","* The `## ...` comment is special: it’s parsed by the `awk` command below.\n","* When you type `make help`, this recipe runs.\n","\n","```make\n","@awk 'BEGIN {FS = \":.*##\"; printf \"Available targets:\\n\"} \\\n","/^[a-zA-Z0-9_\\-]+:.*##/ { \\\n","  printf \"  \\033[36m%-18s\\033[0m %s\\n\", $1, $2 \\\n","}' $(MAKEFILE_LIST)\n","```\n","\n","* **`@`** → suppresses echo of the command itself. Only prints what `awk` produces.\n","* **`awk`** processes your Makefile(s) (`$(MAKEFILE_LIST)` expands to the current Makefile and any included ones).\n","\n","* **`FS = \":.*##\"`** → Field Separator: split lines at the colon + `##` marker.\n","\n","  * Example line:\n","\n","    ```\n","    report: $(FEATS) ## Build the HTML report\n","    ```\n","\n","    splits into:\n","\n","    * `$1 = \"report\"`\n","    * `$2 = \" Build the HTML report\"`\n","\n","* **Regex `/^[a-zA-Z0-9_\\-]+:.*##/`**\n","\n","  * Match any line that starts with a valid target name followed by a colon and containing `##`.\n","  * Ensures only documented targets show up.\n","  * `[a-zA-Z0-9_\\-]+` → one or more characters that can be:\n","\n","    * `a–z` (lowercase letters)\n","\n","    * `A–Z` (uppercase letters)\n","\n","    * `0–9` (digits)\n","\n","    * `_` (underscore)\n","\n","    * `-` (hyphen)\n","    → this matches a typical Make target name.\n","\n","* `.` → a **dot** in regex means:\n","  “match any single character (except a newline, by default).”\n","  Examples:\n","\n","  * `a.b` matches `acb`, `a9b`, `a-b`, etc.\n","\n","* `*` → a **quantifier** meaning:\n","  “repeat the previous thing **zero or more times**.”\n","\n","Put together:\n","\n","* `.*` → “match **any sequence of characters**, including the empty string.”\n","\n","After the `:`, you might have prerequisites, variables, whitespace, etc.\n","`.*` is just a “catch-all” to absorb whatever is there until the `##` marker.\n","\n","So for:\n","\n","```\n","report: $(FEATS) ## Build the report\n","```\n","\n","* `[a-zA-Z0-9_\\-]+` → `report`\n","* `:` → literal colon\n","* `.*` → `$(FEATS)` (the prerequisites part)\n","* `##` → start of the help text\n","\n","\n","\n","* **`printf` with colors**\n","\n","  * `\\033[36m` = cyan (for target names).\n","  * `%-18s` = left-align names in 18-character column.\n","  * `\\033[0m` = reset color.\n","  * `$1` = target name, `$2` = help text.\n","\n","If your Makefile has:\n","\n","```make\n","report: $(FEATS) ## Build the HTML report\n","clean:  ## Remove temporary files\n","backup: ## Back up data and reports\n","```\n","\n","Running:\n","\n","```bash\n","make help\n","```\n","\n","Output:\n","\n","```\n","Available targets:\n","  report             Build the HTML report\n","  clean              Remove temporary files\n","  backup             Back up data and reports\n","```\n","\n","(with the target names in cyan).\n","\n","**In short:**\n","This `help` target auto-extracts `##` comments after targets and prints a pretty help menu. It keeps your Makefile self-documenting.\n","\n","###  Why `$$1` instead of `$1`?\n","\n","* In **awk**, you’d normally write `$1` to mean “first field.”\n","* But in a **Makefile recipe**, `$` is special — it’s Make’s variable syntax.\n","* To get a literal `$` into the shell command, you need to escape it as `$$`.\n","\n","* `MAKEFILE_LIST` is a **built-in Make variable**.\n","* It contains the list of all Makefiles that have been read, in the order they were parsed.\n","* The current Makefile is always included.\n","\n","So when you write:\n","\n","```make\n","awk ... $(MAKEFILE_LIST)\n","```\n","\n","it means “run awk on this Makefile (and any included ones).”\n","\n","That’s how the `help` target can scan your Makefile itself and pull out the `##` comments.\n","\n","\n","  * `$(DATA_RAW)` → expands to `data/raw/prices.csv` (your raw price data file).\n","  * `$(FEATS)` → expands to `data/processed/features.parquet` (your engineered features).\n","  * `report` → another target (probably builds your Quarto report).\n","  * `backup` → another target (runs your rsync backup script).\n","\n","If any are missing or outdated, Make will run their recipes in the right order.\n","\n","There’s no indented command block after `all:`.\n","That’s because `all` is just an **aggregate target** — it depends on others, but doesn’t do extra work itself.\n","\n","**In short:**\n","`all` is a convenience target that ties together your **data download**, **feature generation**, **report building**, and **backup** steps. Running `make all` executes the whole workflow end to end.\n","\n","\n"],"metadata":{"id":"n60jgrJNYSaD"}},{"cell_type":"markdown","source":["\n","### 1. Target\n","\n","```make\n","$(DATA_RAW):\n","```\n","\n","* `$(DATA_RAW)` expands to `data/raw/prices.csv` (from your earlier definition).\n","* So this rule builds that file.\n","* In Make terms: *“to produce `data/raw/prices.csv`, do the following …”*\n","\n","---\n","\n","### 2. Prerequisites\n","\n","```make\n","scripts/get_prices.py tickers_25.csv\n","```\n","\n","* These are the dependencies.\n","* Meaning: if either the script (`scripts/get_prices.py`) or the ticker list (`tickers_25.csv`) is newer than `data/raw/prices.csv`, then this target is out-of-date and should be rebuilt.\n","* If `data/raw/prices.csv` is missing entirely → it will also be rebuilt.\n","\n","---\n","\n","### 3. Recipe\n","\n","```make\n","$(PY) scripts/get_prices.py --tickers tickers_25.csv --start $(START) --end $(END) --out $(DATA_RAW)\n","```\n","\n","* `$(PY)` expands to `python` (from your earlier variable).\n","* So the command is:\n","\n","  ```bash\n","  python scripts/get_prices.py --tickers tickers_25.csv --start 2020-01-01 --end 2025-08-01 --out data/raw/prices.csv\n","  ```\n","* This runs your stock-data downloader script, generating the CSV.\n","\n","Nice — that’s the **report-building rule** in your pipeline. Let’s unpack it carefully.\n","\n","\n","```make\n","report: $(REPORT) ## Render Quarto EDA to docs/\n","```\n","\n","* Declares `report` as a phony-style alias for the actual file target `$(REPORT)`.\n","\n","So:\n","\n","```bash\n","make report\n","```\n","\n","actually means *“make sure `docs/reports/eda.html` is up to date.”*\n","\n","\n","```make\n","@test -f $(REPORT) || (echo \"Report not generated.\" && exit 1)\n","```\n","\n","* `@` suppresses the echo of the command itself.\n","* `test -f $(REPORT)` checks if the report file exists.\n","* If not, it prints an error and exits with code 1.\n","* This is a sanity check to fail loudly if Quarto didn’t actually produce the file.\n","\n","\n","```bash\n","rm -rf data/processed/*.parquet\n","```\n","\n","* `rm` = remove (delete files).\n","* `-r` = recursive (needed if directories are involved).\n","* `-f` = force (don’t ask, don’t complain if the file doesn’t exist).\n","* `data/processed/*.parquet` = all `.parquet` files in `data/processed/`.\n","\n","So this deletes all processed parquet files.\n","\n","---\n","\n","### 2. The `|| true` part\n","\n","```bash\n","... || true\n","```\n","\n","* `||` = “OR” in shell.\n","* `true` is a command that always succeeds (exit status 0).\n","* Meaning: if the `rm` command fails (e.g. no matching `.parquet` files → `rm` exits with error), the whole line still returns success.\n","\n","---\n","\n","### 3. Why this matters in Make\n","\n","* With `set -e` (or `.SHELLFLAGS := -eu -o pipefail -c` in your Makefile), any nonzero exit code would cause `make` to stop.\n","* `rm` on a glob with no matches can exit with error (`No such file or directory`).\n","* Adding `|| true` ensures the target won’t fail just because there’s nothing to delete.\n","\n"],"metadata":{"id":"oqT915zFbJ6W"}},{"cell_type":"markdown","source":["**Note**: in the Makefile, I changed `docs/` to `docs1/` to avoid output into the lecture notes folders `docs/`"],"metadata":{"id":"NZud-7D8po6B"}},{"cell_type":"code","source":["makefile = r\"\"\"# Makefile — unified-stocks\n","SHELL := /bin/bash\n",".SHELLFLAGS := -eu -o pipefail -c\n","\n","PY := python\n","QUARTO := quarto\n","\n","START ?= 2020-01-01\n","END   ?= 2025-08-01\n","ROLL  ?= 30\n","\n","DATA_RAW := data/raw/prices.csv\n","FEATS    := data/processed/features.parquet\n","REPORT   := docs/reports/eda.html\n","\n","# Default target\n",".DEFAULT_GOAL := help\n","\n",".PHONY: help all clean clobber qa report backup\n","\n","help: ## Show help for each target\n","    @awk 'BEGIN {FS = \":.*##\"; printf \"Available targets:\\n\"} /^[a-zA-Z0-9_\\-]+:.*##/ {printf \"  \\033[36m%-18s\\033[0m %s\\n\", $$1, $$2}' $(MAKEFILE_LIST)\n","\n","all: $(DATA_RAW) $(FEATS) report backup ## Run the full pipeline and back up artifacts\n","\n","$(DATA_RAW): scripts/get_prices.py tickers_25.csv\n","    $(PY) scripts/get_prices.py --tickers tickers_25.csv --start $(START) --end $(END) --out $(DATA_RAW)\n","\n","$(FEATS): scripts/build_features.py $(DATA_RAW) scripts/qa_csv.sh\n","    # Basic QA first\n","    scripts/qa_csv.sh $(DATA_RAW)\n","    $(PY) scripts/build_features.py --input $(DATA_RAW) --out $(FEATS) --roll $(ROLL)\n","\n","report: $(REPORT) ## Render Quarto EDA to docs1/\n","$(REPORT): reports/eda.qmd _quarto.yml docs1/style.css\n","    $(QUARTO) render reports/eda.qmd -P symbol:AAPL -P start_date=$(START) -P end_date=$(END) -P rolling=$(ROLL) --output-dir docs1/\n","    @test -f $(REPORT) || (echo \"Report not generated.\" && exit 1)\n","\n","backup: ## Rsync selected artifacts to backups/<timestamp>/\n","    ./scripts/backup.sh\n","\n","clean: ## Remove intermediate artifacts (safe)\n","    rm -rf data/interim\n","    rm -rf data/processed/*.parquet || true\n","\n","clobber: clean ## Remove generated reports and backups (dangerous)\n","    rm -rf docs/reports || true\n","    rm -rf backups || true\n","\"\"\"\n","open(\"Makefile\",\"w\").write(makefile)\n","print(open(\"Makefile\").read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_LfTZPuV61d","executionInfo":{"status":"ok","timestamp":1757605890898,"user_tz":300,"elapsed":27,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"703801b3-50dd-4e3c-955a-dabf8144ea18"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["# Makefile — unified-stocks\n","SHELL := /bin/bash\n",".SHELLFLAGS := -eu -o pipefail -c\n","\n","PY := python\n","QUARTO := quarto\n","\n","START ?= 2020-01-01\n","END   ?= 2025-08-01\n","ROLL  ?= 30\n","\n","DATA_RAW := data/raw/prices.csv\n","FEATS    := data/processed/features.parquet\n","REPORT   := docs/reports/eda.html\n","\n","# Default target\n",".DEFAULT_GOAL := help\n","\n",".PHONY: help all clean clobber qa report backup\n","\n","help: ## Show help for each target\n","    @awk 'BEGIN {FS = \":.*##\"; printf \"Available targets:\\n\"} /^[a-zA-Z0-9_\\-]+:.*##/ {printf \"  \\033[36m%-18s\\033[0m %s\\n\", $$1, $$2}' $(MAKEFILE_LIST)\n","\n","all: $(DATA_RAW) $(FEATS) report backup ## Run the full pipeline and back up artifacts\n","\n","$(DATA_RAW): scripts/get_prices.py tickers_25.csv\n","    $(PY) scripts/get_prices.py --tickers tickers_25.csv --start $(START) --end $(END) --out $(DATA_RAW)\n","\n","$(FEATS): scripts/build_features.py $(DATA_RAW) scripts/qa_csv.sh\n","    # Basic QA first\n","    scripts/qa_csv.sh $(DATA_RAW)\n","    $(PY) scripts/build_features.py --input $(DATA_RAW) --out $(FEATS) --roll $(ROLL)\n","\n","report: $(REPORT) ## Render Quarto EDA to docs1/\n","$(REPORT): reports/eda.qmd _quarto.yml docs1/style.css\n","    $(QUARTO) render reports/eda.qmd -P symbol:AAPL -P start_date=$(START) -P end_date=$(END) -P rolling=$(ROLL) --output-dir docs1/\n","    @test -f $(REPORT) || (echo \"Report not generated.\" && exit 1)\n","\n","backup: ## Rsync selected artifacts to backups/<timestamp>/\n","    ./scripts/backup.sh\n","\n","clean: ## Remove intermediate artifacts (safe)\n","    rm -rf data/interim\n","    rm -rf data/processed/*.parquet || true\n","\n","clobber: clean ## Remove generated reports and backups (dangerous)\n","    rm -rf docs/reports || true\n","    rm -rf backups || true\n","\n"]}]},{"cell_type":"markdown","source":["1. `subprocess.check_output`\n","\n","* From Python’s built-in [`subprocess`](https://docs.python.org/3/library/subprocess.html) module.\n","* Runs a command in a child process.\n","* Captures what the command prints to **stdout**.\n","* Returns it as a string (or bytes, if `text=True` isn’t set).\n","The `text=True` argument\n","\n","* Converts the output from **bytes** to a regular Python **string**.\n","* Without it:\n","\n","  ```python\n","  b\"Available targets:\\n  report   Build the HTML report\\n...\"\n","  ```\n","* With it:\n","\n","  ```python\n","  \"Available targets:\\n  report   Build the HTML report\\n...\"\n","  ```\n","\n"],"metadata":{"id":"lBm1cNf2e6aT"}},{"cell_type":"code","source":["import subprocess, os, textwrap, sys\n","try:\n","  print(subprocess.check_output([\"make\", \"help\"], text=True))\n","except:\n","  print(\"cwd:\", os.getcwd())\n","  print(\"make present?\", shutil.which(\"make\"))\n","  print(\"awk present?\", shutil.which(\"awk\"))\n","  print(\"Makefile exists?\", os.path.exists(\"Makefile\"))\n","\n","  res = subprocess.run([\"make\", \"help\"], text=True, capture_output=True)\n","  print(\"returncode:\", res.returncode)\n","  print(\"STDOUT:\\n\", res.stdout)\n","  print(\"STDERR:\\n\", res.stderr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757605896821,"user_tz":300,"elapsed":33,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"49a96d69-0727-4d2f-8ee8-af58756c31ec","id":"k010fBG_Y0QH"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["cwd: /content/drive/MyDrive/dspt25/STAT4160\n","make present? /usr/bin/make\n","awk present? /usr/bin/awk\n","Makefile exists? True\n","returncode: 2\n","STDOUT:\n"," \n","STDERR:\n"," Makefile:27: *** missing separator.  Stop.\n","\n"]}]},{"cell_type":"markdown","source":["```bash\n","perl -i -pe 's/^\\h{4}(?=\\S)/\\t/' Makefile\n","```\n","\n","### Pieces explained\n","\n","* **`perl`** → use Perl for in-place text processing.\n","* **`-i`** → edit the file in place (overwrites `Makefile`).\n","* **`-pe`** →\n","\n","  * `-p` loops over each line of the file,\n","  * `-e` executes the following code.\n","* **`s/.../.../`** → substitution regex.\n","\n","#### Regex\n","\n","* `^` → start of line.\n","* `\\h{4}` → 4 horizontal whitespace characters (spaces or tabs, but usually spaces).\n","* `(?=\\S)` → lookahead ensuring a non-whitespace character follows (so you don’t match lines that are just spaces).\n","* Replace that with `\\t` → a single literal tab.\n","* `(...)` → parentheses = a **group**.\n","* `?=` → this makes it a **lookahead**.\n","* `\\S` → “non-whitespace character” (the opposite of `\\s`).\n","\n","So effectively: **replace exactly 4 leading spaces before text with a tab.**\n","\n","\n","\n","\n"],"metadata":{"id":"e-s0ALrwaM5Y"}},{"cell_type":"code","source":["%%bash\n","# BACK UP FIRST\n","cp Makefile Makefile.bak\n","# Replace lines that BEGIN with 4 spaces by a single tab\n","perl -i -pe 's/^\\h{4}(?=\\S)/\\t/' Makefile\n","cat Makefile"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i927u11zYSmY","executionInfo":{"status":"ok","timestamp":1757605900496,"user_tz":300,"elapsed":40,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"0054fdac-3143-4f84-9060-b797885514c8"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["# Makefile — unified-stocks\n","SHELL := /bin/bash\n",".SHELLFLAGS := -eu -o pipefail -c\n","\n","PY := python\n","QUARTO := quarto\n","\n","START ?= 2020-01-01\n","END   ?= 2025-08-01\n","ROLL  ?= 30\n","\n","DATA_RAW := data/raw/prices.csv\n","FEATS    := data/processed/features.parquet\n","REPORT   := docs/reports/eda.html\n","\n","# Default target\n",".DEFAULT_GOAL := help\n","\n",".PHONY: help all clean clobber qa report backup\n","\n","help: ## Show help for each target\n","\t@awk 'BEGIN {FS = \":.*##\"; printf \"Available targets:\\n\"} /^[a-zA-Z0-9_\\-]+:.*##/ {printf \"  \\033[36m%-18s\\033[0m %s\\n\", $$1, $$2}' $(MAKEFILE_LIST)\n","\n","all: $(DATA_RAW) $(FEATS) report backup ## Run the full pipeline and back up artifacts\n","\n","$(DATA_RAW): scripts/get_prices.py tickers_25.csv\n","\t$(PY) scripts/get_prices.py --tickers tickers_25.csv --start $(START) --end $(END) --out $(DATA_RAW)\n","\n","$(FEATS): scripts/build_features.py $(DATA_RAW) scripts/qa_csv.sh\n","\t# Basic QA first\n","\tscripts/qa_csv.sh $(DATA_RAW)\n","\t$(PY) scripts/build_features.py --input $(DATA_RAW) --out $(FEATS) --roll $(ROLL)\n","\n","report: $(REPORT) ## Render Quarto EDA to docs1/\n","$(REPORT): reports/eda.qmd _quarto.yml docs1/style.css\n","\t$(QUARTO) render reports/eda.qmd -P symbol:AAPL -P start_date=$(START) -P end_date=$(END) -P rolling=$(ROLL) --output-dir docs1/\n","\t@test -f $(REPORT) || (echo \"Report not generated.\" && exit 1)\n","\n","backup: ## Rsync selected artifacts to backups/<timestamp>/\n","\t./scripts/backup.sh\n","\n","clean: ## Remove intermediate artifacts (safe)\n","\trm -rf data/interim\n","\trm -rf data/processed/*.parquet || true\n","\n","clobber: clean ## Remove generated reports and backups (dangerous)\n","\trm -rf docs/reports || true\n","\trm -rf backups || true\n"]}]},{"cell_type":"code","source":["import subprocess, os, textwrap, sys\n","try:\n","  print(subprocess.check_output([\"make\", \"help\"], text=True))\n","except:\n","  print(\"cwd:\", os.getcwd())\n","  print(\"make present?\", shutil.which(\"make\"))\n","  print(\"awk present?\", shutil.which(\"awk\"))\n","  print(\"Makefile exists?\", os.path.exists(\"Makefile\"))\n","\n","  res = subprocess.run([\"make\", \"help\"], text=True, capture_output=True)\n","  print(\"returncode:\", res.returncode)\n","  print(\"STDOUT:\\n\", res.stdout)\n","  print(\"STDERR:\\n\", res.stderr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DWs-jWIUd90i","executionInfo":{"status":"ok","timestamp":1757605903711,"user_tz":300,"elapsed":37,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"c2bd604c-f2f7-4b94-97a8-459f664fb238"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Available targets:\n","  \u001b[36mhelp              \u001b[0m  Show help for each target\n","  \u001b[36mall               \u001b[0m  Run the full pipeline and back up artifacts\n","  \u001b[36mreport            \u001b[0m  Render Quarto EDA to docs1/\n","  \u001b[36mbackup            \u001b[0m  Rsync selected artifacts to backups/<timestamp>/\n","  \u001b[36mclean             \u001b[0m  Remove intermediate artifacts (safe)\n","  \u001b[36mclobber           \u001b[0m  Remove generated reports and backups (dangerous)\n","\n"]}]},{"cell_type":"code","source":["!chmod +x scripts/qa_csv.sh scripts/backup.sh\n"],"metadata":{"id":"VfgUF5g0gEMp","executionInfo":{"status":"ok","timestamp":1757605906645,"user_tz":300,"elapsed":153,"user":{"displayName":"David W.","userId":"14633192575819064045"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["!pip install papermill"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEHk-ncyY5Tc","executionInfo":{"status":"ok","timestamp":1757605416812,"user_tz":300,"elapsed":5248,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"52ee1a9a-ac33-4c62-9242-2768fe9e5549"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: papermill in /usr/local/lib/python3.12/dist-packages (2.6.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from papermill) (8.2.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from papermill) (6.0.2)\n","Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.12/dist-packages (from papermill) (5.10.4)\n","Requirement already satisfied: nbclient>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from papermill) (0.10.2)\n","Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.12/dist-packages (from papermill) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from papermill) (2.32.4)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from papermill) (0.4)\n","Requirement already satisfied: tenacity>=5.0.2 in /usr/local/lib/python3.12/dist-packages (from papermill) (8.5.0)\n","Requirement already satisfied: ansicolors in /usr/local/lib/python3.12/dist-packages (from papermill) (1.1.8)\n","Requirement already satisfied: aiohttp>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from papermill) (3.12.15)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->papermill) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->papermill) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->papermill) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->papermill) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->papermill) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->papermill) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.9.0->papermill) (1.20.1)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from nbclient>=0.2.0->papermill) (7.4.9)\n","Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbclient>=0.2.0->papermill) (5.8.1)\n","Requirement already satisfied: traitlets>=5.4 in /usr/local/lib/python3.12/dist-packages (from nbclient>=0.2.0->papermill) (5.7.1)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.2.0->papermill) (2.21.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.2.0->papermill) (4.25.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->papermill) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->papermill) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->papermill) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->papermill) (2025.8.3)\n","Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp>=3.9.0->papermill) (4.15.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (0.27.1)\n","Requirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (1.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (2.9.0.post0)\n","Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (26.2.1)\n","Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (6.4.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbclient>=0.2.0->papermill) (4.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (1.17.0)\n"]}]},{"cell_type":"code","source":["# Fetch raw, build features, render report, back up artifacts\n","import subprocess\n","try:\n","  print(subprocess.check_output([\"make\", \"all\"], text=True))\n","except:\n","  import subprocess, os, shutil\n","  print(\"cwd:\", os.getcwd())\n","  res = subprocess.run([\"make\", \"all\"], text=True, capture_output=True)\n","  print(\"returncode:\", res.returncode)\n","  print(\"STDOUT:\\n\", res.stdout)\n","  print(\"STDERR:\\n\", res.stderr)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_23RA-HbfNY","executionInfo":{"status":"ok","timestamp":1757605952868,"user_tz":300,"elapsed":42991,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"d132e515-f0da-4857-e877-3a87094dab32"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["cwd: /content/drive/MyDrive/dspt25/STAT4160\n","returncode: 2\n","STDOUT:\n"," quarto render reports/eda.qmd -P symbol:AAPL -P start_date=2020-01-01 -P end_date=2025-08-01 -P rolling=30 --output-dir docs1/\n","Report not generated.\n","\n","STDERR:\n"," \n","Starting python3 kernel...[ColabKernelApp] ERROR | No such comm target registered: quarto_kernel_setup\n","Done\n","\n","Executing 'eda.quarto_ipynb'\n","  Cell 1/8: ''...Done\n","  Cell 2/8: ''...Done\n","  Cell 3/8: ''...Done\n","  Cell 4/8: ''...Done\n","  Cell 5/8: ''...Done\n","  Cell 6/8: ''...Done\n","  Cell 7/8: ''...Done\n","  Cell 8/8: ''...Done\n","\n","\u001b[1mpandoc \u001b[22m\n","  to: html\n","  output-file: eda.html\n","  standalone: true\n","  title-prefix: Unified Stocks — EDA\n","  section-divs: true\n","  html-math-method: mathjax\n","  wrap: none\n","  default-image-extension: png\n","  toc: true\n","  number-sections: false\n","  variables: {}\n","  \n","\u001b[1mmetadata\u001b[22m\n","  document-css: false\n","  link-citations: true\n","  date-format: long\n","  lang: en\n","  theme: cosmo\n","  title: Stock EDA\n","  execute-dir: /content/drive/MyDrive/dspt25/STAT4160/reports\n","  jupyter: python3\n","  \n","Output created: ../docs1/reports/eda.html\n","\n","make: *** [Makefile:37: docs/reports/eda.html] Error 1\n","\n"]}]},{"cell_type":"markdown","source":["The above error in the last line is expected because I changed the output to docs1/."],"metadata":{"id":"gqrIIZ25eyr4"}},{"cell_type":"markdown","source":["```bash\n","set -e\n","if ! command -v just >/dev/null 2>&1; then\n","  echo \"just not found; skipping optional step.\"\n","  exit 0\n","fi\n","```\n","\n","1. **`set -e`**\n","\n","   * Tells the shell: *“exit immediately if any command fails (non-zero status).”*\n","   * Useful for scripts where you want to stop on the first error.\n","\n","2. **`command -v just >/dev/null 2>&1`**\n","\n","   * `command -v prog` is the POSIX-portable way to check if `prog` is available in `$PATH`.\n","   * Here it checks if `just` (the [Just command runner](https://github.com/casey/just)) is installed.\n","   * `>/dev/null 2>&1` discards both stdout and stderr, so no messages are printed.\n","\n","In POSIX shells, each process has numbered **file descriptors**:\n","\n","* `0` = stdin\n","* `1` = stdout\n","* `2` = stderr\n","\n","```bash\n","2>&1\n","```\n","\n","it means:\n","“Redirect file descriptor 2 (stderr) to the same destination as file descriptor 1 (stdout).”\n","\n","So both stdout and stderr go to the same place (screen, file, pipe…).\n","\n","`justfile` is from a different tool called **[Just](https://github.com/casey/just)**.\n","\n","\n","* Just is a **command runner** (like Make, but simpler).\n","* It’s designed to save and organize shell commands you use often.\n","* You install it (`cargo install just` or via package manager), then you create a file named `justfile` in your project.\n","\n","\n","```just\n","set shell := [\"bash\", \"-eu\", \"-o\", \"pipefail\", \"-c\"]\n","```\n","\n","* `set shell := [...]` → tells `just` which program to use as the command shell.\n","* The list form means: explicitly pass the program and its arguments.\n","\n","So:\n","\n","1. **`bash`** → use Bash as the shell (instead of `/bin/sh`).\n","2. **`-e`** → exit immediately if any command fails.\n","3. **`-u`** → error if an unset variable is used.\n","4. **`-o pipefail`** → in a pipeline (`a | b | c`), fail if *any* command fails, not just the last one.\n","5. **`-c`** → tells Bash to run the following string as a command.\n","\n","By default, `just` runs recipes in `/bin/sh`. On Linux/macOS, `/bin/sh` can be a minimal shell (dash), which doesn’t support all Bash features. Setting this makes recipes behave more like what you’d expect from a robust Bash script with safe defaults.\n","\n","You’ve already seen something very similar in your Makefile:\n","\n","```make\n","SHELL := /bin/bash\n",".SHELLFLAGS := -eu -o pipefail -c\n","```\n","\n","\n","* Use `$(START)`/`$(END)` if you’re writing a Makefile.\n","* Use `{{start}}`/`{{end}}` only in a Justfile recipe.\n","\n","\n","\n","\n"],"metadata":{"id":"uLlFBwtPgOEr"}},{"cell_type":"code","source":["%%bash\n","set -e\n","if ! command -v just >/dev/null 2>&1; then\n","  echo \"just not found; skipping optional step.\"\n","  exit 0\n","fi\n","cat > justfile << 'EOF'\n","# justfile — optional convenience recipes\n","set shell := [\"bash\", \"-eu\", \"-o\", \"pipefail\", \"-c\"]\n","\n","start := \"2020-01-01\"\n","end   := \"2025-08-01\"\n","roll  := \"30\"\n","\n","help:\n","\\t@echo \"Recipes: get-data, features, report, all, backup\"\n","\n","get-data:\n","\\tpython scripts/get_prices.py --tickers tickers_25.csv --start {{start}} --end {{end}} --out data/raw/prices.csv\n","\n","features:\n","\\tbash -lc 'scripts/qa_csv.sh data/raw/prices.csv'\n","\\tpython scripts/build_features.py --input data/raw/prices.csv --out data/processed/features.parquet --roll {{roll}}\n","\n","report:\n","\\tquarto render reports/eda.qmd -P symbol:AAPL -P start_date={{start}} -P end_date={{end}} -P rolling:{{roll}} --output-dir docs1/\n","\n","all: get-data features report\n","\n","backup:\n","\\t./scripts/backup.sh\n","EOF\n","echo \"Wrote justfile (optional).\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1hfXn-Re5vM","executionInfo":{"status":"ok","timestamp":1757607559710,"user_tz":300,"elapsed":44,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"479dde56-e29f-4e25-fd0e-22a225a73134"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["just not found; skipping optional step.\n"]}]},{"cell_type":"code","source":["!cat justfile"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8hDVccNPkw8v","executionInfo":{"status":"ok","timestamp":1757607585447,"user_tz":300,"elapsed":103,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"dce371a3-4c23-405c-cb39-d3611eda0650"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["cat: justfile: No such file or directory\n"]}]},{"cell_type":"markdown","source":["The standard workflow for generating a new SSH key pair and making it usable with services like GitHub or your own servers.\n","\n","```bash\n","ssh-keygen -t ed25519 -C \"you@school.edu\"\n","```\n","\n","* `ssh-keygen` → program to create a new SSH key pair.\n","* `-t ed25519` → use the modern **Ed25519** algorithm (faster, shorter, more secure than RSA).\n","* **`-t`** = *type of key to create*.\n","* Common values:\n","\n","  * `rsa` (older, 2048/4096-bit keys)\n","  * `ed25519` (modern, shorter, secure, recommended)\n","  * `ecdsa` (rare, not widely used anymore)\n","* So `-t ed25519` means “generate an Ed25519 keypair.”\n","* `-C \"you@school.edu\"` → add a comment label in the key (often your email).\n","\n","**During the prompts:**\n","\n","* *File location*: press **Enter** to accept the default `~/.ssh/id_ed25519`.\n","  (If that file already exists and you don’t want to overwrite it, pick another name like `~/.ssh/id_ed25519_github`.)\n","* *Passphrase*: recommended to add one (adds security in case someone steals your private key). Leave blank if you want passwordless, but less secure.\n","\n","This creates two files:\n","\n","* `~/.ssh/id_ed25519` → **private key** (keep secret, never share).\n","* `~/.ssh/id_ed25519.pub` → **public key** (safe to share).\n","\n","### View the public key\n","\n","```bash\n","cat ~/.ssh/id_ed25519.pub\n","```\n","\n","* Prints the public key.\n","* You copy the whole line starting with `ssh-ed25519 ...` and paste it:\n","\n","  * Into **GitHub → Settings → SSH and GPG keys → New SSH key**, or\n","  * Into a server’s `~/.ssh/authorized_keys` file.\n","\n","\n","### Test the key\n","\n","Once added, test with:\n","\n","```bash\n","ssh -T git@github.com\n","```\n","\n","You should see something like:\n","\n","```\n","Hi your-username! You've successfully authenticated, but GitHub does not provide shell access.\n","```\n","\n","* **`-T`** = *disable pseudo-tty allocation*.\n","* Normally `ssh` gives you an interactive terminal session on the remote machine.\n","* With `-T`, you’re saying “don’t open a terminal, just run the command.”\n","* GitHub specifically tells you to use `ssh -T` when testing keys, because GitHub doesn’t provide shell access — you just want authentication to succeed.\n","\n","\n"],"metadata":{"id":"0LSAO5Ycn3fC"}},{"cell_type":"code","source":["### Run the followng code in a Terminal , and\n"," #Press enter to accept default path (~/.ssh/id_ed25519), set a passphrase (recommended)\n","\n","ssh-keygen -t ed25519 -C \"you@school.edu\""],"metadata":{"id":"gy2GzdgJk2XS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Run the followng code in a Terminal , and\n"," Press enter to accept default path (~/.ssh/id_ed25519), set a passphrase (recommended)\n","```bash\n","ssh-keygen -t ed25519 -C \"you@school.edu\"\n","```"],"metadata":{"id":"DdxmDYB7so8f"}},{"cell_type":"code","source":["cat ~/.ssh/id_ed25519.pub   # copy this PUBLIC key where needed (GitHub/servers)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qUAfrqjtpIhe","executionInfo":{"status":"ok","timestamp":1757609661050,"user_tz":300,"elapsed":97,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"d5e97165-27db-4200-d569-dbd782058377"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIBHbSPan69Pcxm1N08IGYJFn3bv/xNqXDQ0aq+ByPAsJ you@school.edu\n"]}]},{"cell_type":"markdown","source":["## non-interactive fix (works in Colab/terminals)\n","\n","```bash\n","# 1) Ensure the .ssh dir exists and has safe perms\n","mkdir -p ~/.ssh && chmod 700 ~/.ssh\n","\n","# 2) Generate the keypair without prompts:\n","#    -f = filename; -N = passphrase (empty \"\" here; set one if you want)\n","ssh-keygen -t ed25519 -C \"you@school.edu\" -f ~/.ssh/id_ed25519 -N \"\"\n","\n","# 3) Show your PUBLIC key (copy this to GitHub/servers)\n","cat ~/.ssh/id_ed25519.pub\n","```\n","\n","`~/` is a shell shortcut for “inside my home directory”, which in Colab means `/root/`."],"metadata":{"id":"GgX6BmfGtNJ9"}},{"cell_type":"code","source":["%%bash\n","# 1) Ensure the .ssh dir exists and has safe perms\n","mkdir -p ~/.ssh && chmod 700 ~/.ssh\n","\n","# 2) Generate the keypair without prompts:\n","#    -f = filename; -N = passphrase (empty \"\" here; set one if you want)\n","ssh-keygen -t ed25519 -C \"you@school.edu\" -f ~/.ssh/id_ed25519 -N \"\"\n","\n","# 3) Show your PUBLIC key (copy this to GitHub/servers)\n","cat ~/.ssh/id_ed25519.pub\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhOPTafZtlzJ","executionInfo":{"status":"ok","timestamp":1757619381913,"user_tz":300,"elapsed":100,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"24735588-0ec5-42be-d62a-6346859dc892"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Generating public/private ed25519 key pair.\n","Your identification has been saved in /root/.ssh/id_ed25519\n","Your public key has been saved in /root/.ssh/id_ed25519.pub\n","The key fingerprint is:\n","SHA256:Idt7w12+YGj9CMbv0O9M2M5mgWOVxr9Qtcu+XYv2XkI you@school.edu\n","The key's randomart image is:\n","+--[ED25519 256]--+\n","|                 |\n","|                .|\n","|      . .    . .o|\n","|       + .    =o |\n","|      . S    +E..|\n","|         + =+B.o.|\n","|        . @.B.B.+|\n","|         + * @+==|\n","|           .==@=o|\n","+----[SHA256]-----+\n","ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAINEa/ANyxBiPcVaJV8x+qxGK75bJxYOV8KBserQxqOrr you@school.edu\n"]}]},{"cell_type":"markdown","source":["Note: the public key include three parts sepated spaces. After having generated the public key, copy the public key into GitHub->settings->SSH keys->new SSH key"],"metadata":{"id":"n6fYpkZQS53e"}},{"cell_type":"code","source":["!ssh -T git@github.com"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9rl-KEVwkfR","executionInfo":{"status":"ok","timestamp":1757620897094,"user_tz":300,"elapsed":351,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"d8de1b70-4f03-48d9-9a48-8c2ffb6c5ab3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Hi ywanglab! You've successfully authenticated, but GitHub does not provide shell access.\n"]}]},{"cell_type":"code","source":["%%bash\n","cat >> ~/.ssh/config <<'CFG'\n","Host github\n","  HostName github.com\n","  User git\n","  IdentityFile ~/.ssh/id_ed25519\n","  IdentitiesOnly yes\n","  AddKeysToAgent yes\n","CFG\n","\n","chmod 600 ~/.ssh/config\n"],"metadata":{"id":"-4Ao0FmlwmNz","executionInfo":{"status":"ok","timestamp":1757620910659,"user_tz":300,"elapsed":65,"user":{"displayName":"David W.","userId":"14633192575819064045"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["!ssh -T github || true\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0hVqxe_KUT7h","executionInfo":{"status":"ok","timestamp":1757620913257,"user_tz":300,"elapsed":418,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"08401875-367c-46a4-bbec-8d1fa9fea755"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Hi ywanglab! You've successfully authenticated, but GitHub does not provide shell access.\n"]}]},{"cell_type":"markdown","source":["**`tmux`** stands for **terminal multiplexer**. It’s a tool that lets you manage multiple terminal sessions inside a single terminal window. Think of it as a \"window manager for your terminal.\"\n","\n","* You can start a program (like training a model) inside `tmux`.\n","* If you disconnect (close your laptop, lose SSH connection, etc.), the program keeps running in the background.\n","* Later, you can **reattach** and see the output as if you never left.\n","* You can split your terminal screen into **panes** (horizontal/vertical).\n","* You can also create multiple **windows** inside the same `tmux` session.\n","* This means you can run different processes (e.g., monitoring logs, editing code, running a server) side by side.\n","\n","\n","* `tmux new -s train` → start a new session named `train`.\n","* `Ctrl-b d` → detach (session continues running in background).\n","* `tmux ls` → list all active sessions.\n","* `tmux attach -t train` → reconnect to the session. `-t`: target session\n","* `tmux kill-session -t train` → end the session (kills all processes inside it).\n","\n","\n"],"metadata":{"id":"-ftEbIVLZK6-"}},{"cell_type":"code","source":["%%bash\n","tmux new -s train              # start session \"train\"\n","# ... run your long job ...\n","# detach: press Ctrl-b then d\n","tmux ls                        # list sessions\n","tmux attach -t train           # reattach\n","tmux kill-session -t train     # end session"],"metadata":{"id":"cCP-oReQVFJa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Homework"],"metadata":{"id":"J54H1sTFc_zv"}},{"cell_type":"markdown","source":["```python\n","json.dump(\n","    {\"model\": \"linear(lag1,lag2,lag3)\",  # a string describing your model\n","     \"test_mae\": mae,                   # test mean absolute error (probably a float variable)\n","     \"n_test\": len(yte)},               # number of test samples\n","    f,                                  # file object, e.g., opened with open(\"results.json\", \"w\")\n","    indent=2                            # pretty-print with 2 spaces indentation\n",")\n","```\n","\n","\n","\n"],"metadata":{"id":"8m6uuGAJm6n1"}},{"cell_type":"code","source":["train_py = r\"\"\"#!/usr/bin/env python\n","import argparse, json\n","from pathlib import Path\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error\n","\n","def main():\n","    ap = argparse.ArgumentParser()\n","    ap.add_argument(\"--features\", default=\"data/processed/features.parquet\")\n","    ap.add_argument(\"--out-metrics\", default=\"reports/baseline_metrics.json\")\n","    args = ap.parse_args()\n","\n","    df = pd.read_parquet(args.features)\n","    # Train/test split by date (last 20% for test)\n","    df = df.dropna(subset=[\"lag1\",\"lag2\",\"lag3\",\"r_1d\"])\n","    n = len(df)\n","    split = int(n*0.8)\n","    Xtr = df[[\"lag1\",\"lag2\",\"lag3\"]].iloc[:split].values\n","    ytr = df[\"r_1d\"].iloc[:split].values\n","    Xte = df[[\"lag1\",\"lag2\",\"lag3\"]].iloc[split:].values\n","    yte = df[\"r_1d\"].iloc[split:].values\n","\n","    model = LinearRegression().fit(Xtr, ytr)\n","    pred = model.predict(Xte)\n","    mae = float(mean_absolute_error(yte, pred))\n","\n","    Path(\"reports\").mkdir(exist_ok=True)\n","    with open(args.out_metrics, \"w\") as f:\n","        json.dump({\"model\":\"linear(lag1,lag2,lag3)\",\"test_mae\":mae,\"n_test\":len(yte)}, f, indent=2)\n","    print(\"Wrote\", args.out_metrics, \"MAE:\", mae)\n","\n","if __name__ == \"__main__\":\n","    main()\n","\"\"\"\n","open(\"scripts/train_baseline.py\",\"w\").write(train_py)\n","import os, stat\n","os.chmod(\"scripts/train_baseline.py\", os.stat(\"scripts/train_baseline.py\").st_mode | stat.S_IEXEC)\n","print(\"Created scripts/train_baseline.py\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PH51osqedCMN","executionInfo":{"status":"ok","timestamp":1757624941988,"user_tz":300,"elapsed":50,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"a847228d-fbd4-46a5-fd79-10335887e143"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Created scripts/train_baseline.py\n"]}]},{"cell_type":"markdown","source":["Append these to your `Makefile`:\n","\n","``` make\n","# --- add after FEATS definition, near other targets ---\n","\n","TRAIN_METRICS := reports/baseline_metrics.json\n","\n",".PHONY: train\n","train: $(TRAIN_METRICS) ## Train toy baseline and write metrics\n","\n","$(TRAIN_METRICS): scripts/train_baseline.py $(FEATS)\n","    $(PY) scripts/train_baseline.py --features $(FEATS) --out-metrics $(TRAIN_METRICS)\n","\n","# Update 'all' to include 'train'\n","# all: $(DATA_RAW) $(FEATS) report backup   # OLD\n","# Replace with:\n","# all: $(DATA_RAW) $(FEATS) report train backup\n","```"],"metadata":{"id":"2zysSXHdnx6j"}},{"cell_type":"code","source":["makefile = r\"\"\"# Makefile — unified-stocks\n","SHELL := /bin/bash\n",".SHELLFLAGS := -eu -o pipefail -c\n","\n","PY := python\n","QUARTO := quarto\n","\n","START ?= 2020-01-01\n","END   ?= 2025-08-01\n","ROLL  ?= 30\n","\n","DATA_RAW := data/raw/prices.csv\n","FEATS    := data/processed/features.parquet\n","REPORT   := docs/reports/eda.html\n","\n","# Default target\n",".DEFAULT_GOAL := help\n","\n",".PHONY: help all clean clobber qa report backup\n","\n","help: ## Show help for each target\n","    @awk 'BEGIN {FS = \":.*##\"; printf \"Available targets:\\n\"} /^[a-zA-Z0-9_\\-]+:.*##/ {printf \"  \\033[36m%-18s\\033[0m %s\\n\", $$1, $$2}' $(MAKEFILE_LIST)\n","\n","# all: $(DATA_RAW) $(FEATS) report backup ## Run the full pipeline and back up artifacts\n","all: $(DATA_RAW) $(FEATS) report train backup\n","\n","$(DATA_RAW): scripts/get_prices.py tickers_25.csv\n","    $(PY) scripts/get_prices.py --tickers tickers_25.csv --start $(START) --end $(END) --out $(DATA_RAW)\n","\n","$(FEATS): scripts/build_features.py $(DATA_RAW) scripts/qa_csv.sh\n","    # Basic QA first\n","    scripts/qa_csv.sh $(DATA_RAW)\n","    $(PY) scripts/build_features.py --input $(DATA_RAW) --out $(FEATS) --roll $(ROLL)\n","\n","# --- add after FEATS definition, near other targets ---\n","\n","TRAIN_METRICS := reports/baseline_metrics.json\n","\n",".PHONY: train\n","train: $(TRAIN_METRICS) ## Train toy baseline and write metrics\n","\n","$(TRAIN_METRICS): scripts/train_baseline.py $(FEATS)\n","    $(PY) scripts/train_baseline.py --features $(FEATS) --out-metrics $(TRAIN_METRICS)\n","\n","report: $(REPORT) ## Render Quarto EDA to docs1/\n","$(REPORT): reports/eda.qmd _quarto.yml docs1/style.css\n","    $(QUARTO) render reports/eda.qmd -P symbol:AAPL -P start_date=$(START) -P end_date=$(END) -P rolling=$(ROLL) --output-dir docs1/\n","    @test -f $(REPORT) || (echo \"Report not generated.\" && exit 1)\n","\n","backup: ## Rsync selected artifacts to backups/<timestamp>/\n","    ./scripts/backup.sh\n","\n","clean: ## Remove intermediate artifacts (safe)\n","    rm -rf data/interim\n","    rm -rf data/processed/*.parquet || true\n","\n","clobber: clean ## Remove generated reports and backups (dangerous)\n","    rm -rf docs/reports || true\n","    rm -rf backups || true\n","\"\"\"\n","open(\"Makefile\",\"w\").write(makefile)\n","print(open(\"Makefile\").read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iUqQqBQDn-Ja","executionInfo":{"status":"ok","timestamp":1757625436241,"user_tz":300,"elapsed":356,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"3b1658a1-67c9-449a-f71c-7286b208e1a6"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["# Makefile — unified-stocks\n","SHELL := /bin/bash\n",".SHELLFLAGS := -eu -o pipefail -c\n","\n","PY := python\n","QUARTO := quarto\n","\n","START ?= 2020-01-01\n","END   ?= 2025-08-01\n","ROLL  ?= 30\n","\n","DATA_RAW := data/raw/prices.csv\n","FEATS    := data/processed/features.parquet\n","REPORT   := docs/reports/eda.html\n","\n","# Default target\n",".DEFAULT_GOAL := help\n","\n",".PHONY: help all clean clobber qa report backup\n","\n","help: ## Show help for each target\n","    @awk 'BEGIN {FS = \":.*##\"; printf \"Available targets:\\n\"} /^[a-zA-Z0-9_\\-]+:.*##/ {printf \"  \\033[36m%-18s\\033[0m %s\\n\", $$1, $$2}' $(MAKEFILE_LIST)\n","\n","# all: $(DATA_RAW) $(FEATS) report backup ## Run the full pipeline and back up artifacts\n","all: $(DATA_RAW) $(FEATS) report train backup\n","\n","$(DATA_RAW): scripts/get_prices.py tickers_25.csv\n","    $(PY) scripts/get_prices.py --tickers tickers_25.csv --start $(START) --end $(END) --out $(DATA_RAW)\n","\n","$(FEATS): scripts/build_features.py $(DATA_RAW) scripts/qa_csv.sh\n","    # Basic QA first\n","    scripts/qa_csv.sh $(DATA_RAW)\n","    $(PY) scripts/build_features.py --input $(DATA_RAW) --out $(FEATS) --roll $(ROLL)\n","\n","# --- add after FEATS definition, near other targets ---\n","\n","TRAIN_METRICS := reports/baseline_metrics.json\n","\n",".PHONY: train\n","train: $(TRAIN_METRICS) ## Train toy baseline and write metrics\n","\n","$(TRAIN_METRICS): scripts/train_baseline.py $(FEATS)\n","    $(PY) scripts/train_baseline.py --features $(FEATS) --out-metrics $(TRAIN_METRICS)\n","\n","report: $(REPORT) ## Render Quarto EDA to docs1/\n","$(REPORT): reports/eda.qmd _quarto.yml docs1/style.css\n","    $(QUARTO) render reports/eda.qmd -P symbol:AAPL -P start_date=$(START) -P end_date=$(END) -P rolling=$(ROLL) --output-dir docs1/\n","    @test -f $(REPORT) || (echo \"Report not generated.\" && exit 1)\n","\n","backup: ## Rsync selected artifacts to backups/<timestamp>/\n","    ./scripts/backup.sh\n","\n","clean: ## Remove intermediate artifacts (safe)\n","    rm -rf data/interim\n","    rm -rf data/processed/*.parquet || true\n","\n","clobber: clean ## Remove generated reports and backups (dangerous)\n","    rm -rf docs/reports || true\n","    rm -rf backups || true\n","\n"]}]},{"cell_type":"code","source":["import subprocess, os, textwrap, sys\n","try:\n","  print(subprocess.check_output([\"make\", \"help\"], text=True))\n","except:\n","  print(\"cwd:\", os.getcwd())\n","  print(\"make present?\", shutil.which(\"make\"))\n","  print(\"awk present?\", shutil.which(\"awk\"))\n","  print(\"Makefile exists?\", os.path.exists(\"Makefile\"))\n","\n","  res = subprocess.run([\"make\", \"help\"], text=True, capture_output=True)\n","  print(\"returncode:\", res.returncode)\n","  print(\"STDOUT:\\n\", res.stdout)\n","  print(\"STDERR:\\n\", res.stderr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DuHr_mKmpUNa","executionInfo":{"status":"ok","timestamp":1757625536680,"user_tz":300,"elapsed":46,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"9ed2f4c0-1d14-453b-c8bb-da421475cb69"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["cwd: /content/drive/MyDrive/dspt25/STAT4160\n","make present? /usr/bin/make\n","awk present? /usr/bin/awk\n","Makefile exists? True\n","returncode: 2\n","STDOUT:\n"," \n","STDERR:\n"," Makefile:28: *** missing separator.  Stop.\n","\n"]}]},{"cell_type":"code","source":["%%bash\n","# BACK UP FIRST\n","cp Makefile Makefile.bak\n","# Replace lines that BEGIN with 4 spaces by a single tab\n","perl -i -pe 's/^\\h{4}(?=\\S)/\\t/' Makefile\n","cat Makefile"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4neVNFNpVAE","executionInfo":{"status":"ok","timestamp":1757625589606,"user_tz":300,"elapsed":421,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"5c97d4cc-ab73-4d64-afd5-c2ee0d4b5d00"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["# Makefile — unified-stocks\n","SHELL := /bin/bash\n",".SHELLFLAGS := -eu -o pipefail -c\n","\n","PY := python\n","QUARTO := quarto\n","\n","START ?= 2020-01-01\n","END   ?= 2025-08-01\n","ROLL  ?= 30\n","\n","DATA_RAW := data/raw/prices.csv\n","FEATS    := data/processed/features.parquet\n","REPORT   := docs/reports/eda.html\n","\n","# Default target\n",".DEFAULT_GOAL := help\n","\n",".PHONY: help all clean clobber qa report backup\n","\n","help: ## Show help for each target\n","\t@awk 'BEGIN {FS = \":.*##\"; printf \"Available targets:\\n\"} /^[a-zA-Z0-9_\\-]+:.*##/ {printf \"  \\033[36m%-18s\\033[0m %s\\n\", $$1, $$2}' $(MAKEFILE_LIST)\n","\n","# all: $(DATA_RAW) $(FEATS) report backup ## Run the full pipeline and back up artifacts\n","all: $(DATA_RAW) $(FEATS) report train backup\n","\n","$(DATA_RAW): scripts/get_prices.py tickers_25.csv\n","\t$(PY) scripts/get_prices.py --tickers tickers_25.csv --start $(START) --end $(END) --out $(DATA_RAW)\n","\n","$(FEATS): scripts/build_features.py $(DATA_RAW) scripts/qa_csv.sh\n","\t# Basic QA first\n","\tscripts/qa_csv.sh $(DATA_RAW)\n","\t$(PY) scripts/build_features.py --input $(DATA_RAW) --out $(FEATS) --roll $(ROLL)\n","\n","# --- add after FEATS definition, near other targets ---\n","\n","TRAIN_METRICS := reports/baseline_metrics.json\n","\n",".PHONY: train\n","train: $(TRAIN_METRICS) ## Train toy baseline and write metrics\n","\n","$(TRAIN_METRICS): scripts/train_baseline.py $(FEATS)\n","\t$(PY) scripts/train_baseline.py --features $(FEATS) --out-metrics $(TRAIN_METRICS)\n","\n","report: $(REPORT) ## Render Quarto EDA to docs1/\n","$(REPORT): reports/eda.qmd _quarto.yml docs1/style.css\n","\t$(QUARTO) render reports/eda.qmd -P symbol:AAPL -P start_date=$(START) -P end_date=$(END) -P rolling=$(ROLL) --output-dir docs1/\n","\t@test -f $(REPORT) || (echo \"Report not generated.\" && exit 1)\n","\n","backup: ## Rsync selected artifacts to backups/<timestamp>/\n","\t./scripts/backup.sh\n","\n","clean: ## Remove intermediate artifacts (safe)\n","\trm -rf data/interim\n","\trm -rf data/processed/*.parquet || true\n","\n","clobber: clean ## Remove generated reports and backups (dangerous)\n","\trm -rf docs/reports || true\n","\trm -rf backups || true\n"]}]},{"cell_type":"code","source":["import subprocess, os, textwrap, sys\n","try:\n","  print(subprocess.check_output([\"make\", \"help\"], text=True))\n","except:\n","  print(\"cwd:\", os.getcwd())\n","  print(\"make present?\", shutil.which(\"make\"))\n","  print(\"awk present?\", shutil.which(\"awk\"))\n","  print(\"Makefile exists?\", os.path.exists(\"Makefile\"))\n","\n","  res = subprocess.run([\"make\", \"help\"], text=True, capture_output=True)\n","  print(\"returncode:\", res.returncode)\n","  print(\"STDOUT:\\n\", res.stdout)\n","  print(\"STDERR:\\n\", res.stderr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757625653020,"user_tz":300,"elapsed":48,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"3e796c7b-8d5c-44c7-c57e-201ce7c992cb","id":"TTE0Qbf2pv4U"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Available targets:\n","  \u001b[36mhelp              \u001b[0m  Show help for each target\n","  \u001b[36mtrain             \u001b[0m  Train toy baseline and write metrics\n","  \u001b[36mreport            \u001b[0m  Render Quarto EDA to docs1/\n","  \u001b[36mbackup            \u001b[0m  Rsync selected artifacts to backups/<timestamp>/\n","  \u001b[36mclean             \u001b[0m  Remove intermediate artifacts (safe)\n","  \u001b[36mclobber           \u001b[0m  Remove generated reports and backups (dangerous)\n","\n"]}]},{"cell_type":"code","source":["!chmod +x scripts/qa_csv.sh scripts/backup.sh\n"],"metadata":{"id":"PvrytG17pv4V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","set -euo pipefail\n","cd \"/content/drive/MyDrive/dspt25/STAT4160\"\n","make train\n","cat reports/baseline_metrics.json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7fdZidGfp2ed","executionInfo":{"status":"ok","timestamp":1757625733406,"user_tz":300,"elapsed":4524,"user":{"displayName":"David W.","userId":"14633192575819064045"}},"outputId":"522871cb-d1e6-459c-b12d-32c3e471ecfe"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["python scripts/train_baseline.py --features data/processed/features.parquet --out-metrics reports/baseline_metrics.json\n","Wrote reports/baseline_metrics.json MAE: 0.00775245930297027\n","{\n","  \"model\": \"linear(lag1,lag2,lag3)\",\n","  \"test_mae\": 0.00775245930297027,\n","  \"n_test\": 885\n","}"]}]}]}