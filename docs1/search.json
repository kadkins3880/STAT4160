[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Unified Stocks Project",
    "section": "",
    "text": "Welcome! Use the navigation to view the EDA report.\n\nStock set: see tickers_25.csv\nNote: Educational use only — no trading advice."
  },
  {
    "objectID": "reports/eda-MSFT.html",
    "href": "reports/eda-MSFT.html",
    "title": "Stock EDA",
    "section": "",
    "text": "Note\n\n\n\nThis report is parameterized. To change inputs without editing code, pass -P symbol:MSFT -P start_date:2019-01-01 -P end_date:2025-08-01 -P rolling:30 to quarto render."
  },
  {
    "objectID": "reports/eda-MSFT.html#setup-if-using-python",
    "href": "reports/eda-MSFT.html#setup-if-using-python",
    "title": "Stock EDA",
    "section": "Setup if using Python",
    "text": "Setup if using Python\n\n\n('AAPL', '2018-01-01', '2025-08-22', 20)"
  },
  {
    "objectID": "reports/eda-MSFT.html#download-and-prepare-data",
    "href": "reports/eda-MSFT.html#download-and-prepare-data",
    "title": "Stock EDA",
    "section": "Download and prepare data",
    "text": "Download and prepare data\n\n\n\n    \n\n\n\n\n\nPrice\nclose\nvolume\nlog_return\nroll_mean\nroll_vol\n\n\nTicker\naapl\naapl\n\n\n\n\n\nDate\n\n\n\n\n\n\n\n\n\n2018-01-17\n41.984425\n137547200\n0.016381\n0.003894\n0.007023\n\n\n2018-01-18\n42.021923\n124773600\n0.000893\n0.003621\n0.006724\n\n\n2018-01-19\n41.834408\n129700400\n-0.004472\n0.002947\n0.006823\n\n\n2018-01-22\n41.492146\n108434400\n-0.008215\n0.002088\n0.007229\n\n\n2018-01-23\n41.501518\n130756400\n0.000226\n0.001955\n0.006963"
  },
  {
    "objectID": "reports/eda-MSFT.html#price-over-time",
    "href": "reports/eda-MSFT.html#price-over-time",
    "title": "Stock EDA",
    "section": "Price over time",
    "text": "Price over time\n\n\nPosixPath('figs/AAPL_price.png')"
  },
  {
    "objectID": "reports/eda-MSFT.html#daily-log-returns-histogram",
    "href": "reports/eda-MSFT.html#daily-log-returns-histogram",
    "title": "Stock EDA",
    "section": "Daily log returns — histogram",
    "text": "Daily log returns — histogram\n\n\nPosixPath('figs/AAPL_hist.png')"
  },
  {
    "objectID": "reports/eda-MSFT.html#rolling-mean-volatility-window-params.rolling",
    "href": "reports/eda-MSFT.html#rolling-mean-volatility-window-params.rolling",
    "title": "Stock EDA",
    "section": "Rolling mean & volatility (window = {params.rolling})",
    "text": "Rolling mean & volatility (window = {params.rolling})\n\n\nPosixPath('figs/AAPL_rolling.png')"
  },
  {
    "objectID": "reports/eda-MSFT.html#summary-table",
    "href": "reports/eda-MSFT.html#summary-table",
    "title": "Stock EDA",
    "section": "Summary table",
    "text": "Summary table\n\n\n\n    \n\n\n\n\n\n\nn_days\nstart\nend\nmean_daily_ret\nstd_daily_ret\nann_vol_approx\n\n\n\n\n0\n1910\n2018-01-17\n2025-08-21\n0.000887\n0.01968\n0.312412\n\n\n\n\n\n    \n      \n  \n    \n      \n  \n    \n  \n    \n    \n  \n\n    \n  \n  \n    \n  \n\n\nNote: Educational use only. This is not trading advice."
  },
  {
    "objectID": "reports/eda.html",
    "href": "reports/eda.html",
    "title": "Stock EDA",
    "section": "",
    "text": "Note\n\n\n\nThis report is parameterized. To change inputs without editing code, pass -P symbol:MSFT -P start_date:2019-01-01 -P end_date:2025-08-01 -P rolling:30 to quarto render."
  },
  {
    "objectID": "reports/eda.html#setup-if-using-python",
    "href": "reports/eda.html#setup-if-using-python",
    "title": "Stock EDA",
    "section": "Setup if using Python",
    "text": "Setup if using Python\n\n\n('AAPL', '2018-01-01', '2025-08-26', 20)"
  },
  {
    "objectID": "reports/eda.html#download-and-prepare-data",
    "href": "reports/eda.html#download-and-prepare-data",
    "title": "Stock EDA",
    "section": "Download and prepare data",
    "text": "Download and prepare data\n\n\n\n    \n\n\n\n\n\nPrice\nclose\nvolume\nlog_return\nroll_mean\nroll_vol\n\n\nTicker\naapl\naapl\n\n\n\n\n\nDate\n\n\n\n\n\n\n\n\n\n2018-01-17\n41.984421\n137547200\n0.016381\n0.003894\n0.007023\n\n\n2018-01-18\n42.021927\n124773600\n0.000893\n0.003621\n0.006724\n\n\n2018-01-19\n41.834400\n129700400\n-0.004473\n0.002947\n0.006823\n\n\n2018-01-22\n41.492138\n108434400\n-0.008215\n0.002088\n0.007229\n\n\n2018-01-23\n41.501522\n130756400\n0.000226\n0.001955\n0.006963"
  },
  {
    "objectID": "reports/eda.html#price-over-time",
    "href": "reports/eda.html#price-over-time",
    "title": "Stock EDA",
    "section": "Price over time",
    "text": "Price over time\n\n\nPosixPath('figs/AAPL_price.png')"
  },
  {
    "objectID": "reports/eda.html#daily-log-returns-histogram",
    "href": "reports/eda.html#daily-log-returns-histogram",
    "title": "Stock EDA",
    "section": "Daily log returns — histogram",
    "text": "Daily log returns — histogram\n\n\nPosixPath('figs/AAPL_hist.png')"
  },
  {
    "objectID": "reports/eda.html#rolling-mean-volatility-window-params.rolling",
    "href": "reports/eda.html#rolling-mean-volatility-window-params.rolling",
    "title": "Stock EDA",
    "section": "Rolling mean & volatility (window = {params.rolling})",
    "text": "Rolling mean & volatility (window = {params.rolling})\n\n\nPosixPath('figs/AAPL_rolling.png')"
  },
  {
    "objectID": "reports/eda.html#summary-table",
    "href": "reports/eda.html#summary-table",
    "title": "Stock EDA",
    "section": "Summary table",
    "text": "Summary table\n\n\n\n    \n\n\n\n\n\n\nn_days\nstart\nend\nmean_daily_ret\nstd_daily_ret\nann_vol_approx\n\n\n\n\n0\n1912\n2018-01-17\n2025-08-25\n0.000892\n0.019672\n0.31228\n\n\n\n\n\n    \n      \n  \n    \n      \n  \n    \n  \n    \n    \n  \n\n    \n  \n  \n    \n  \n\n\nNote: Educational use only. This is not trading advice."
  },
  {
    "objectID": "notebooks/lec3_code_inside_QMD_testing.html",
    "href": "notebooks/lec3_code_inside_QMD_testing.html",
    "title": "Unified Stocks — EDA",
    "section": "",
    "text": "# Colab cell\nfrom google.colab import drive\ndrive.mount('/content/drive', force_remount=True)\n\nMounted at /content/drive\n\n\n\n# Adjust these two for YOUR repo\nREPO_OWNER = \"ywanglab\"\nREPO_NAME  = \"STAT4160\"   # e.g., unified-stocks-team1\n\nBASE_DIR   = \"/content/drive/MyDrive/dspt25\"\nCLONE_DIR  = f\"{BASE_DIR}/{REPO_NAME}\"\nREPO_URL   = f\"https://github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n\nimport os, pathlib\npathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True)\n\n\nimport os, subprocess, shutil, pathlib\n\nif not pathlib.Path(CLONE_DIR).exists():\n    !git clone {REPO_URL} {CLONE_DIR}\nelse:\n    # If the folder exists, just ensure it's a git repo and pull latest\n    os.chdir(CLONE_DIR)\n    # !git status\n    # !git pull --rebase # !git pull --ff-only\nos.chdir(CLONE_DIR)\nprint(\"Working dir:\", os.getcwd())\n\nWorking dir: /content/drive/MyDrive/dspt25/STAT4160\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yfinance as yf\nfrom pathlib import Path\nfrom datetime import datetime\n\n#| tags: [parameters]\n# Default values (overridden by -P at render time)\nsymbol = \"AAPL\"\nstart_date = \"2018-01-01\"\nend_date = \"\"          # empty means \"open ended\"\nrolling = 20\n# Read parameters\n# SYMBOL = params.get(\"symbol\", \"AAPL\")\n# START  = params.get(\"start_date\", \"2018-01-01\")\n# END    = params.get(\"end_date\", \"\")\n# ROLL   = int(params.get(\"rolling\", 20))\nSYMBOL = \"AAPL\"\nSTART  = \"2018-01-01\"\nEND    = \"\"\nROLL   =  20\n\nif not END:\n    END = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n\nSYMBOL, START, END, ROLL\n\n('AAPL', '2018-01-01', '2025-08-22', 20)\n\n\n\n# Fetch adjusted OHLCV\ntry:\n    data = yf.download(SYMBOL, start=START, end=END, auto_adjust=True, progress=False)\nexcept Exception as e:\n    print(\"yfinance failed, falling back to synthetic series:\", e)\n    idx = pd.bdate_range(START, END)\n    rng = np.random.default_rng(42)\n    ret = rng.normal(0, 0.01, len(idx))\n    price = 100 * np.exp(np.cumsum(ret))\n    vol = rng.integers(1e5, 5e6, len(idx))\n    data = pd.DataFrame({\"Close\": price, \"Volume\": vol}, index=idx)\n\n# Tidy & features\ndf = data.rename(columns=str.lower).copy()\ndf = df[[\"close\",\"volume\"]].dropna()\ndf[\"log_return\"] = np.log(df[\"close\"]).diff()\ndf[\"roll_mean\"]  = df[\"log_return\"].rolling(ROLL, min_periods=ROLL//2).mean()\ndf[\"roll_vol\"]   = df[\"log_return\"].rolling(ROLL, min_periods=ROLL//2).std()\ndf = df.dropna()\ndf.head()\n\n\n    \n\n\n\n\n\nPrice\nclose\nvolume\nlog_return\nroll_mean\nroll_vol\n\n\nTicker\naapl\naapl\n\n\n\n\n\nDate\n\n\n\n\n\n\n\n\n\n2018-01-17\n41.984413\n137547200\n0.016381\n0.003894\n0.007023\n\n\n2018-01-18\n42.021935\n124773600\n0.000893\n0.003621\n0.006724\n\n\n2018-01-19\n41.834400\n129700400\n-0.004473\n0.002947\n0.006823\n\n\n2018-01-22\n41.492134\n108434400\n-0.008215\n0.002088\n0.007229\n\n\n2018-01-23\n41.501522\n130756400\n0.000226\n0.001955\n0.006963\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\n# Add to the \"Tidy & features\" section in eda.qmd\ndf[\"cum_return\"] = df[\"log_return\"].cumsum().fillna(0.0)\npeak = df[\"cum_return\"].cummax()\ndf[\"drawdown\"] = df[\"cum_return\"] - peak\n\n# Regime via rolling volatility terciles\nvol = df[\"log_return\"].rolling(ROLL, min_periods=ROLL//2).std()\nq1, q2 = vol.quantile([0.33, 0.66])\ndef regime(v):\n    if np.isnan(v): return \"mid\"\n    return \"low\" if v &lt; q1 else (\"high\" if v &gt; q2 else \"mid\")\ndf[\"regime\"] = [regime(v) for v in vol]\ndf[\"regime\"].value_counts().to_frame(\"days\").T\n\n\n    \n\n\n\n\n\nregime\nhigh\nmid\nlow\n\n\n\n\ndays\n646\n637\n627\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n  \n\n\n\n# Drawdown plot\nfig, ax = plt.subplots(figsize=(8,3))\nax.plot(df.index, df[\"drawdown\"])\nax.set_title(f\"{SYMBOL} — Drawdown (log-return cumulative)\")\nax.set_xlabel(\"Date\"); ax.set_ylabel(\"drawdown\")\nfig.tight_layout()\nfigpath = Path(\"reports/figs\")/f\"{SYMBOL}_drawdown.png\"\nfig.savefig(figpath, dpi=144)\nfigpath\n\nPosixPath('reports/figs/AAPL_drawdown.png')\n\n\n\n\n\n\n\n\n\n\n# Price with regime shading (simple)\nfig, ax = plt.subplots(figsize=(8,3))\nax.plot(df.index, df[\"close\"])\nax.set_title(f\"{SYMBOL} — Price with High-Volatility Shading\")\nax.set_xlabel(\"Date\"); ax.set_ylabel(\"Price\")\n\n# Shade where regime == 'high'\nmask = (df[\"regime\"] == \"high\")\n# merge contiguous regions\nin_region = False\nstart = None\nfor i, (ts, is_high) in enumerate(zip(df.index, mask)):\n    if is_high and not in_region:\n        in_region = True\n        start = ts\n    if in_region and (not is_high or i == len(df)-1):\n        end = df.index[i-1] if not is_high else ts\n        ax.axvspan(start, end, alpha=0.15)  # shaded band\n        in_region = False\nfig.tight_layout()\nfigpath = Path(\"reports/figs\")/f\"{SYMBOL}_price_regimes.png\"\nfig.savefig(figpath, dpi=144)\nfigpath\n\nPosixPath('reports/figs/AAPL_price_regimes.png')\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(8,3))\nax.plot(df.index, df[\"close\"])\nax.set_title(f\"{SYMBOL} — Adjusted Close\")\nax.set_xlabel(\"Date\"); ax.set_ylabel(\"Price\")\nfig.tight_layout()\nfigpath = Path(\"reports/figs\")/f\"{SYMBOL}_price.png\"\nfig.savefig(figpath, dpi=144)\nfigpath\n\nPosixPath('reports/figs/AAPL_price.png')\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(6,3))\nax.hist(df[\"log_return\"], bins=50, alpha=0.8)\nax.set_title(f\"{SYMBOL} — Daily Log Return Distribution\")\nax.set_xlabel(\"log return\"); ax.set_ylabel(\"count\")\nfig.tight_layout()\nfigpath = Path(\"reports/figs\")/f\"{SYMBOL}_hist.png\"\nfig.savefig(figpath, dpi=144)\nfigpath\n\nPosixPath('reports/figs/AAPL_hist.png')\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(8,3))\nax.plot(df.index, df[\"roll_mean\"], label=\"rolling mean\")\nax.plot(df.index, df[\"roll_vol\"],  label=\"rolling std\")\nax.set_title(f\"{SYMBOL} — Rolling Return Stats (window={ROLL})\")\nax.set_xlabel(\"Date\"); ax.set_ylabel(\"value\")\nax.legend()\nfig.tight_layout()\nfigpath = Path(\"reports/figs\")/f\"{SYMBOL}_rolling.png\"\nfig.savefig(figpath, dpi=144)\nfigpath\n\nPosixPath('reports/figs/AAPL_rolling.png')\n\n\n\n\n\n\n\n\n\n\nsummary = pd.DataFrame({\n    \"n_days\": [len(df)],\n    \"start\": [df.index.min().date()],\n    \"end\":   [df.index.max().date()],\n    \"mean_daily_ret\": [df[\"log_return\"].mean()],\n    \"std_daily_ret\":  [df[\"log_return\"].std()],\n    \"ann_vol_approx\": [df[\"log_return\"].std()*np.sqrt(252)]\n})\nsummary\n\n\n    \n\n\n\n\n\n\nn_days\nstart\nend\nmean_daily_ret\nstd_daily_ret\nann_vol_approx\n\n\n\n\n0\n1909\n2018-01-17\n2025-08-20\n0.00089\n0.019685\n0.312487"
  },
  {
    "objectID": "notebooks/system_check.html",
    "href": "notebooks/system_check.html",
    "title": "Unified Stocks — EDA",
    "section": "",
    "text": "from google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\n# Colab cell\nCOURSE_DIR = \"/content/drive/MyDrive/dspt25\"  # change if you prefer another path\nPROJECT_NAME = \"unified-stocks\"               # course project folder/repo name\n\n\n# Colab cell: make directories and cd into project folder\nimport os, pathlib\nbase = pathlib.Path(COURSE_DIR)\nproj = base / PROJECT_NAME\nfor p in [base, proj, proj/\"reports\", proj/\"notebooks\", proj/\"data\"]:\n    p.mkdir(parents=True, exist_ok=True)\n\nimport os\nos.chdir(proj) # change dir\nprint(\"Working in:\", os.getcwd())\n\nWorking in: /content/drive/MyDrive/dspt25/unified-stocks\n\n\n\n# Colab cell: clone via HTTPS (public or your private; for private, you can upload later instead of pushing from Colab)\nREPO_URL = \"https://github.com/ywanglab/STAT4160.git\"  # &lt;- change me\nimport subprocess, os\nos.chdir(base)  # clone next to your project folder, only clone one time\n# subprocess.run([\"git\", \"clone\", REPO_URL], check=True)\n# Optionally, use that cloned repo as the working directory:\nREPO_NAME = REPO_URL.split(\"/\")[-1].replace(\".git\",\"\")\nos.chdir(base/REPO_NAME)\nprint(\"Working in:\", os.getcwd())\n\nWorking in: /content/drive/MyDrive/dspt25/STAT4160\n\n\n\n# Adjust these two for YOUR repo\nREPO_OWNER = \"ywanglab\"\nREPO_NAME  = \"STAT4160\"   # e.g., unified-stocks-team1\n\nBASE_DIR   = \"/content/drive/MyDrive/dspt25\"\nCLONE_DIR  = f\"{BASE_DIR}/{REPO_NAME}\"\nREPO_URL   = f\"https://github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n\nimport os, pathlib\npathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True)\n\n\nimport os, subprocess, shutil, pathlib\n\nif not pathlib.Path(CLONE_DIR).exists():\n    !git clone {REPO_URL} {CLONE_DIR}\nelse:\n    # If the folder exists, just ensure it's a git repo and pull latest\n    os.chdir(CLONE_DIR)\n    !git status\n    !git pull --ff-only\nos.chdir(CLONE_DIR)\nprint(\"Working dir:\", os.getcwd())\n\n\nRefresh index: 100% (48/48), done.\n\nOn branch main\n\nYour branch is up to date with 'origin/main'.\n\n\n\nChanges not staged for commit:\n\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   notebooks/system_check.ipynb\n\n\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nAlready up to date.\n\nWorking dir: /content/drive/MyDrive/dspt25/STAT4160\n\n\n\n\n\n# Colab cell: write a soft-pinned requirements.txt\nreq = \"\"\"\\\npandas&gt;=2.2,&lt;3.0\nnumpy&gt;=2.0.0,&lt;3.0\npyarrow&gt;=15,&lt;17\nmatplotlib&gt;=3.8,&lt;4.0\nscikit-learn&gt;=1.6,&lt;2.0\nyfinance&gt;=0.2,&lt;0.3\npython-dotenv&gt;=1.0,&lt;2.0\n\"\"\"\nopen(\"requirements.txt\",\"w\").write(req)\nprint(open(\"requirements.txt\").read())\n\npandas&gt;=2.2,&lt;3.0\nnumpy&gt;=2.0.0,&lt;3.0\npyarrow&gt;=15,&lt;17\nmatplotlib&gt;=3.8,&lt;4.0\nscikit-learn&gt;=1.6,&lt;2.0\nyfinance&gt;=0.2,&lt;0.3\npython-dotenv&gt;=1.0,&lt;2.0\n\n\n\n\n# Colab cell: install (quietly). Torch is usually preinstalled in Colab; we'll check separately.\n!pip install -q -r requirements.txt\n\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.8/40.8 MB 30.8 MB/s eta 0:00:00\n\n\n\n\n\n\n# Colab cell: environment info + GPU check\nimport sys, platform, json, time\nimport pandas as pd\nimport numpy as np\n\nenv = {\n    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n    \"python\": sys.version,\n    \"os\": platform.platform(),\n    \"pandas\": pd.__version__,\n    \"numpy\": np.__version__,\n}\n\ntry:\n    import torch\n    env[\"torch\"] = torch.__version__\n    env[\"cuda_available\"] = bool(torch.cuda.is_available())\n    env[\"cuda_device\"] = torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"\nexcept Exception as e:\n    env[\"torch\"] = \"not importable\"\n    env[\"cuda_available\"] = False\n    env[\"cuda_device\"] = \"CPU\"\n\nprint(env)\nos.makedirs(\"reports\", exist_ok=True)\nwith open(\"reports/environment.json\",\"w\") as f:\n    json.dump(env, f, indent=2)\n\n{'timestamp': '2025-08-20 14:09:32', 'python': '3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]', 'os': 'Linux-6.1.123+-x86_64-with-glibc2.35', 'pandas': '2.2.2', 'numpy': '2.0.2', 'torch': '2.8.0+cu126', 'cuda_available': False, 'cuda_device': 'CPU'}\n\n\n\n# Colab cell: PyTorch check. If not available (rare in Colab), install CPU-only as a fallback.\ntry:\n    import torch\n    print(\"PyTorch:\", torch.__version__)\nexcept Exception as e:\n    print(\"PyTorch not found; installing CPU-only wheel as fallback...\")\n    !pip install -q torch\n    import torch\n    print(\"PyTorch:\", torch.__version__)\n\nPyTorch: 2.8.0+cu126\n\n\n\n# Colab cell: reproducibility helpers\nimport random\nimport numpy as np\n\ndef set_seed(seed: int = 42, deterministic_torch: bool = True):\n    random.seed(seed)\n    np.random.seed(seed)\n    try:\n        import torch\n        torch.manual_seed(seed)  #cpu side\n        torch.cuda.manual_seed_all(seed)  # cuda side\n        if deterministic_torch:\n            torch.backends.cudnn.deterministic = True\n            torch.backends.cudnn.benchmark = False  #disable automatic algorithm\n            try:\n                torch.use_deterministic_algorithms(True)\n            except Exception:\n                pass\n    except Exception:\n        pass\n\ndef sample_rng_fingerprint(n=5, seed=42):\n    set_seed(seed)\n    a = np.random.rand(n).round(6).tolist()\n    try:\n        import torch\n        b = torch.rand(n).tolist()\n        b = [round(x,6) for x in b]\n    except Exception:\n        b = [\"torch-missing\"]*n\n    return {\"numpy\": a, \"torch\": b}\n\nf1 = sample_rng_fingerprint(n=6, seed=123)\nf2 = sample_rng_fingerprint(n=6, seed=123)\nprint(\"Fingerprint #1:\", f1)\nprint(\"Fingerprint #2:\", f2)\nprint(\"Match:\", f1 == f2)\n\nwith open(\"reports/seed_fingerprint.json\",\"w\") as f:\n    json.dump({\"f1\": f1, \"f2\": f2, \"match\": f1==f2}, f, indent=2)\n\nFingerprint #1: {'numpy': [0.696469, 0.286139, 0.226851, 0.551315, 0.719469, 0.423106], 'torch': [0.296112, 0.516562, 0.251671, 0.688557, 0.073972, 0.866522]}\nFingerprint #2: {'numpy': [0.696469, 0.286139, 0.226851, 0.551315, 0.719469, 0.423106], 'torch': [0.296112, 0.516562, 0.251671, 0.688557, 0.073972, 0.866522]}\nMatch: True\n\n\n\n# Colab cell: create stock list if it doesn't exist yet\nimport pandas as pd, os\ntickers = [\n    \"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"NVDA\",\"TSLA\",\"JPM\",\"JNJ\",\"V\",\n    \"PG\",\"HD\",\"BAC\",\"XOM\",\"CVX\",\"PFE\",\"KO\",\"DIS\",\"NFLX\",\"INTC\",\n    \"CSCO\",\"ORCL\",\"T\",\"VZ\",\"WMT\"\n]\npath = \"tickers_25.csv\"\nif not os.path.exists(path):\n    pd.DataFrame({\"ticker\": tickers}).to_csv(path, index=False)\npd.read_csv(path).head()\n\n\n    \n\n\n\n\n\n\nticker\n\n\n\n\n0\nAAPL\n\n\n1\nMSFT\n\n\n2\nAMZN\n\n\n3\nGOOGL\n\n\n4\nMETA\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\n# Colab cell: tiny GPU smoke test (safe if CUDA available)\nimport torch, time\nimport os\n\n# change back to not use deterministic_algorithm to do the matrix computation if use GPU\n# torch.use_deterministic_algorithms(False)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nx = torch.randn(1000, 1000, device=device)\ny = x @ x.T\nprint(\"Device:\", device, \"| y shape:\", y.shape, \"| mean:\", y.float().mean().item()) #cast y into float32, extract the mean as a python float.\n\nDevice: cpu | y shape: torch.Size([1000, 1000]) | mean: 0.963737428188324\n\n\n\n# Colab cell: write a small Markdown summary for humans\nfrom textwrap import dedent  # dedent removes the common indentation\nsummary = dedent(f\"\"\"\n# System Check\n\n- Timestamp: {env['timestamp']}\n- Python: `{env['python']}`\n- OS: `{env['os']}`\n- pandas: `{env['pandas']}` | numpy: `{env['numpy']}` | torch: `{env['torch']}`\n- CUDA available: `{env['cuda_available']}` | Device: `{env['cuda_device']}`\n\n## RNG Fingerprint\n- Match on repeated seeds: `{f1 == f2}`\n- numpy: `{f1['numpy']}`\n- torch: `{f1['torch']}`\n\"\"\").strip()\n\nopen(\"reports/system_check.md\",\"w\").write(summary)\nprint(summary)\n\n# System Check\n\n- Timestamp: 2025-08-16 16:20:34\n- Python: `3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]`\n- OS: `Linux-6.1.123+-x86_64-with-glibc2.35`\n- pandas: `2.2.2` | numpy: `2.0.2` | torch: `2.6.0+cu124`\n- CUDA available: `False` | Device: `CPU`\n\n## RNG Fingerprint\n- Match on repeated seeds: `True`\n- numpy: `[0.696469, 0.286139, 0.226851, 0.551315, 0.719469, 0.423106]`\n- torch: `[0.296112, 0.516562, 0.251671, 0.688557, 0.073972, 0.866522]`\n\n\n\n# code to save this notebook. (too complicated)\nfrom google.colab import  _message\nnotebook_name = \"system_check.ipynb\"\n# Create the 'notebooks' subdirectory path\nout_dir = proj / \"notebooks\"\nout_path = out_dir / notebook_name\n\n# Make sure the folder exists\nout_dir.mkdir(parents=True, exist_ok=True)\n\n# Get the CURRENT notebook JSON from Colab\nresp = _message.blocking_request('get_ipynb', timeout_sec=10)\nnb = resp.get('ipynb') if isinstance(resp, dict) else None\n\n# Basic sanity check: ensure there are cells\nif not nb or not isinstance(nb, dict) or not nb.get('cells'):\n    raise RuntimeError(\"Could not capture the current notebook contents (no cells returned). \"\n                       \"Try running this cell again after a quick edit, or use File → Save a copy in Drive once.\")\n\n# Write to Drive\nwith open(out_path, 'w', encoding='utf-8') as f:\n    json.dump(nb, f, ensure_ascii=False, indent=2)\n\nprint(\"Saved notebook to:\", out_path)\n\n\n# Colab cell: freeze exact versions\n!pip freeze &gt; requirements-lock.txt\nprint(\"Wrote requirements-lock.txt with exact versions\")\n!head -n 20 requirements-lock.txt\n\nWrote requirements-lock.txt with exact versions\nabsl-py==1.4.0\naccelerate==1.10.0\naiofiles==24.1.0\naiohappyeyeballs==2.6.1\naiohttp==3.12.15\naiosignal==1.4.0\nalabaster==1.0.0\nalbucore==0.0.24\nalbumentations==2.0.8\nale-py==0.11.2\naltair==5.5.0\nannotated-types==0.7.0\nantlr4-python3-runtime==4.9.3\nanyio==4.10.0\nanywidget==0.9.18\nargon2-cffi==25.1.0\nargon2-cffi-bindings==25.1.0\narray_record==0.7.2\narviz==0.22.0\nastropy==7.1.0\n\n\n\nimport numpy as np, torch, random, json, os, time\n\ndef set_seed(seed=123):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    try:\n        torch.use_deterministic_algorithms(True)\n    except Exception:\n        pass\n\ndef make_toy(n=512, d=10, noise=0.1, seed=123):\n    set_seed(seed)\n    X = torch.randn(n, d)\n    true_w = torch.randn(d, 1)\n    y = X @ true_w + noise * torch.randn(n, 1)\n    return X, y, true_w\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nX, y, true_w = make_toy()\nX, y = X.to(device), y.to(device)\n\n\n# torch.use_deterministic_algorithms(False)\ndef train_once(lr=0.05, steps=300, seed=123):\n    set_seed(seed)\n    model = torch.nn.Linear(X.shape[1], 1, bias=False).to(device) #torch.nn.Linear(in_features, out_features, bias=False)\n    opt = torch.optim.SGD(model.parameters(), lr=lr)\n    loss_fn = torch.nn.MSELoss()\n    losses=[]\n    for t in range(steps):\n        opt.zero_grad(set_to_none=True) # set_to_none: slightly faster\n        yhat = model(X)\n        loss = loss_fn(yhat, y)\n        loss.backward() # compute the loss\n        opt.step() # update weights\n        losses.append(loss.item())\n    return model.weight.detach().cpu().numpy(), losses[-1] #detatch from computing graph, moved to cpu to create np array\n\nw1, final_loss1 = train_once(seed=2025)\nw2, final_loss2 = train_once(seed=2025)\n\nprint(\"Final loss 1:\", round(final_loss1, 6))\nprint(\"Final loss 2:\", round(final_loss2, 6))\nprint(\"Weights equal:\", np.allclose(w1, w2, atol=1e-7))\n\nFinal loss 1: 0.01057\nFinal loss 2: 0.01057\nWeights equal: True\n\n\n\nos.makedirs(\"reports\", exist_ok=True)\nresult = {\n    \"device\": device,\n    \"final_loss1\": float(final_loss1),\n    \"final_loss2\": float(final_loss2),\n    \"weights_equal\": bool(np.allclose(w1, w2, atol=1e-7)),\n    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n}\nwith open(\"reports/reproducibility_results.json\",\"w\") as f:\n    json.dump(result, f, indent=2)\nresult\n\n{'device': 'cpu',\n 'final_loss1': 0.010570256970822811,\n 'final_loss2': 0.010570256970822811,\n 'weights_equal': True,\n 'timestamp': '2025-08-15 21:10:06'}\n\n\n\nenv_example = \"\"\"\\\n# Example environment variables (do NOT commit a real .env with secrets)\nALPHA_VANTAGE_KEY=\nFRED_API_KEY=\n\"\"\"\nopen(\".env.example\", \"w\").write(env_example)\nprint(open(\".env.example\").read())\n\n# Example environment variables (do NOT commit a real .env with secrets)\nALPHA_VANTAGE_KEY=\nFRED_API_KEY="
  },
  {
    "objectID": "notebooks/testing.html",
    "href": "notebooks/testing.html",
    "title": "Unified Stocks — EDA",
    "section": "",
    "text": "# blah blah blah"
  },
  {
    "objectID": "notebooks/lec2-hw.html",
    "href": "notebooks/lec2-hw.html",
    "title": "Unified Stocks — EDA",
    "section": "",
    "text": "# Colab cell\nfrom google.colab import drive\ndrive.mount('/content/drive', force_remount=True)\n\nMounted at /content/drive\n\n\n\n# Adjust these two for YOUR repo\nREPO_OWNER = \"ywanglab\"\nREPO_NAME  = \"STAT4160\"   # e.g., unified-stocks-team1\n\nBASE_DIR   = \"/content/drive/MyDrive/dspt25\"\nCLONE_DIR  = f\"{BASE_DIR}/{REPO_NAME}\"\nREPO_URL   = f\"https://github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n\nimport os, pathlib\npathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True)\n\n\nimport os, subprocess, shutil, pathlib\n\nif not pathlib.Path(CLONE_DIR).exists():\n    !git clone {REPO_URL} {CLONE_DIR}\nelse:\n    # If the folder exists, just ensure it's a git repo and pull latest\n    os.chdir(CLONE_DIR)\n    !git status\n    !git pull --ff-only\nos.chdir(CLONE_DIR)\nprint(\"Working dir:\", os.getcwd())\n\n\nRefresh index: 100% (47/47), done.\n\nOn branch main\n\nYour branch is ahead of 'origin/main' by 1 commit.\n\n  (use \"git push\" to publish your local commits)\n\n\n\nIt took 2.46 seconds to compute the branch ahead/behind values.\n\nYou can use '--no-ahead-behind' to avoid this.\n\n\n\nChanges not staged for commit:\n\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   notebooks/lec2-hw.ipynb\n\n\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nremote: Enumerating objects: 6, done.\n\nremote: Counting objects: 100% (6/6), done.\n\nremote: Compressing objects: 100% (4/4), done.\n\nremote: Total 4 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\n\nUnpacking objects: 100% (4/4), 3.79 KiB | 5.00 KiB/s, done.\n\nFrom https://github.com/ywanglab/STAT4160\n\n   f06c03f..061cdfd  main       -&gt; origin/main\n\nfatal: Not possible to fast-forward, aborting.\n\nWorking dir: /content/drive/MyDrive/dspt25/STAT4160\n\n\n\n\n\n# run the following shell command before push:\n# !chmod +x .git/hooks/*\n\n\n# Run in your repo root\nimport os, pathlib, textwrap\npathlib.Path(\".github\").mkdir(exist_ok=True)\ntpl = textwrap.dedent(\"\"\"\\\n    ## Summary\n    What does this PR do and why?\n\n    ## Changes\n    -\n\n    ## How to test\n    - From a fresh clone: steps to run\n\n    ## Checklist\n    - [ ] Runs from a fresh clone (README steps)\n    - [ ] No secrets committed; `.env` only (and `.env.example` updated if needed)\n    - [ ] Large artifacts tracked by LFS (`git lfs ls-files` shows expected files)\n    - [ ] Clear, small diff; comments where useful\n\"\"\")\nopen(\".github/pull_request_template.md\",\"w\").write(tpl)\nprint(\"Wrote .github/pull_request_template.md\")\n\nWrote .github/pull_request_template.md\n\n\n\nowners = \"\"\"\\\n# Replace with your GitHub handles\n* @teammate1 @teammate2 @ywanglab\n\"\"\"\nopen(\".github/CODEOWNERS\",\"w\").write(owners)\nprint(\"Wrote .github/CODEOWNERS (edit handles!)\")\n\nWrote .github/CODEOWNERS (edit handles!)\n\n\n\n# tools/guard_large_files.py\nimport os, subprocess, sys\n\nLIMIT_MB = 10\nROOT = os.getcwd()\n\ndef lfs_tracked_paths(): # find files tracked by lfs\n    try:\n        out = subprocess.check_output([\"git\", \"lfs\", \"ls-files\"], text=True)\n        tracked = set()\n        for line in out.strip().splitlines():\n            # line format: \"&lt;oid&gt; &lt;path&gt;\" ex: line = \"3b2d8c7d53   data/processed/file.parquet\"\n            p = line.split(None, 1)[-1].strip() #split on whitespace at most once.\n            tracked.add(os.path.normpath(p)) # normpath(p): ensure consistent slashes (\\ vs /)\n        return tracked\n    except Exception:\n        return set()\n\ndef humanize(bytes_):\n    return f\"{bytes_/(1024*1024):.2f} MB\"\n\nlfs_set = lfs_tracked_paths()\nbad = []\nfor dirpath, dirnames, filenames in os.walk(ROOT):\n  #os.walk() is a generator that recursively traverses a directory tree.\n  # At each step it yields a tuple:(dirpath, subdirnames, filenames)\n\n    # skip .git directory\n    if \".git\" in dirpath.split(os.sep):#using os specific separator os.sep (/ for linus, \\ for windows)\n        continue\n    for fn in filenames:\n        path = os.path.normpath(os.path.join(dirpath, fn))\n        try:\n            size = os.path.getsize(path)\n        except FileNotFoundError:\n            continue\n        if size &gt;= LIMIT_MB * 1024 * 1024:\n            rel = os.path.relpath(path, ROOT)\n            if rel not in lfs_set:\n                bad.append((rel, size))\n\nif bad:\n    print(\"ERROR: Large non-LFS files found:\")\n    for rel, size in bad:\n        print(f\" - {rel} ({humanize(size)})\")\n    sys.exit(1)\nelse:\n    print(\"OK: No large non-LFS files detected.\")\n\nOK: No large non-LFS files detected.\n\n\n\n# Define the path to the tools directory\ntools_dir = Path(\"tools\")\n\n# Create it if it doesn't exist (including any parents)\ntools_dir.mkdir(parents=True, exist_ok=True)\n\nprint(f\"Directory '{tools_dir}' is ready.\")\n\nDirectory 'tools' is ready.\n\n\n\nfrom pathlib import Path\n\ntools_dir = Path(\"tools\")\ntools_dir.mkdir(parents=True, exist_ok=True)\n\nscript = tools_dir / \"guard_large_files.py\"\n\ncode = '''#!/usr/bin/env python3\nimport os\nimport sys\nimport subprocess\n\nLIMIT_MB = 10  # size threshold for LFS in megabytes\nROOT = os.path.abspath(os.path.dirname(__file__) + \"/..\")\n\ndef humanize(nbytes):\n    # format size in human-friendly units\n    for unit in ['B','KB','MB','GB','TB']:\n        if nbytes &lt; 1024:\n            return f\"{nbytes:.1f}{unit}\"\n        nbytes /= 1024\n    return f\"{nbytes:.1f}PB\"\n\ndef lfs_tracked_paths():\n    try:\n        out = subprocess.check_output([\"git\", \"lfs\", \"ls-files\"], text=True)\n        tracked = set()\n        for line in out.strip().splitlines():\n            # line format: \"&lt;oid&gt; &lt;path&gt;\"\n            p = line.split(None, 1)[-1].strip()\n            tracked.add(os.path.normpath(p))\n        return tracked\n    except Exception:\n        return set()\n\ndef main():\n    lfs_set = lfs_tracked_paths()\n    bad = []\n    for dirpath, dirnames, filenames in os.walk(ROOT):\n        # skip .git and other hidden dirs\n        if \".git\" in dirpath.split(os.sep):\n            continue\n        for fn in filenames:\n            path = os.path.normpath(os.path.join(dirpath, fn))\n            try:\n                size = os.path.getsize(path)\n            except FileNotFoundError:\n                continue\n            if size &gt;= LIMIT_MB * 1024 * 1024:\n                rel = os.path.relpath(path, ROOT)\n                if rel not in lfs_set:\n                    bad.append((rel, size))\n\n    if bad:\n        print(\"ERROR: Large non-LFS files found:\")\n        for rel, size in sorted(bad, key=lambda x: x[1], reverse=True):\n            print(f\" - {rel} ({humanize(size)})\")\n        sys.exit(1)\n    else:\n        print(f\"OK: No large non-LFS files detected (limit {LIMIT_MB} MB).\")\n\nif __name__ == \"__main__\":\n    main()\n'''\n\n# Write the file\nscript.write_text(code)\nscript.chmod(0o755)  # make it executable 0o means base-8. r:4, w: 2, x:1\n\nprint(f\"Created {script}\")\n\nCreated tools/guard_large_files.py\n\n\n\n# Create/append Makefile target\nfrom pathlib import Path\ntext = \"\\n\\nguard:\\n\\tpython tools/guard_large_files.py\\n\" # guard: Makefile target. \\t: tab required.\np = Path(\"Makefile\") # point to the Makefile\n# p.write_text(p.read_text() + text if p.exists() else text) # if p exists, read exising content and append text and overwrites.\n# the above code will append text everytime, casue error if repeatedly excute.\nif p.exists():\n    content = p.read_text()\n    if \"guard:\" not in content:\n        p.write_text(content + text)\nelse:\n    p.write_text(text)\n\nprint(\"Added 'guard' target to Makefile\")\n\nAdded 'guard' target to Makefile\n\n\n\n!python tools/guard_large_files.py\n\nOK: No large non-LFS files detected (limit 10 MB)."
  },
  {
    "objectID": "notebooks/lec3-inclass.html",
    "href": "notebooks/lec3-inclass.html",
    "title": "Unified Stocks — EDA",
    "section": "",
    "text": "# Unmount if necessary\n# from google.colab import drive\n# drive.flush_and_unmount()\n\nDrive not mounted, so nothing to flush and unmount.\n# Colab cell\nfrom google.colab import drive\n\ndrive.mount('/content/drive', force_remount=True)\n\nMounted at /content/drive\n# Adjust these two for YOUR repo\nREPO_OWNER = \"ywanglab\"\nREPO_NAME  = \"STAT4160\"   # e.g., unified-stocks-team1\n\nBASE_DIR   = \"/content/drive/MyDrive/dspt25\"\nCLONE_DIR  = f\"{BASE_DIR}/{REPO_NAME}\"\nREPO_URL   = f\"https://github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n\nimport os, pathlib\npathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True)\nimport os, subprocess, shutil, pathlib\n\nif not pathlib.Path(CLONE_DIR).exists():\n    !git clone {REPO_URL} {CLONE_DIR}\nelse:\n    # If the folder exists, just ensure it's a git repo and pull latest\n    os.chdir(CLONE_DIR)\n    # !git status\n    # !git pull --rebase # !git pull --ff-only\nos.chdir(CLONE_DIR)\nprint(\"Working dir:\", os.getcwd())\n\nWorking dir: /content/drive/MyDrive/dspt25/STAT4160\n!git status\n!git pull --rebase # !git pull --ff-only\n# Install Quarto CLI (one-time per Colab runtime)\n# !wget -q https://quarto.org/download/latest/quarto-linux-amd64.deb -O /tmp/quarto.deb\n# !dpkg -i /tmp/quarto.deb || apt-get -y -f install &gt;/dev/null && dpkg -i /tmp/quarto.deb\n# !quarto --version\n\n#Alternatively, save it to G-drive, and only need to download the first time. The size of  quarto-linux-amd64.deb is ~125Mb.\n# Path to store the deb package\ndeb_path = \"/content/drive/MyDrive/quarto-linux-amd64.deb\"\n\n# Download only if not already saved\n!test -f $deb_path || wget -q https://quarto.org/download/latest/quarto-linux-amd64.deb -O $deb_path\n\n# Install from Drive (fast, no re-download)\n!dpkg -i $deb_path || apt-get -y -f install &gt;/dev/null && dpkg -i $deb_path #-f: fix package dependency issues\n!quarto --version\n\nSelecting previously unselected package quarto.\n(Reading database ... 126371 files and directories currently installed.)\nPreparing to unpack .../MyDrive/quarto-linux-amd64.deb ...\nUnpacking quarto (1.7.33) ...\nSetting up quarto (1.7.33) ...\n(Reading database ... 130482 files and directories currently installed.)\nPreparing to unpack .../MyDrive/quarto-linux-amd64.deb ...\nUnpacking quarto (1.7.33) over (1.7.33) ...\nSetting up quarto (1.7.33) ...\n1.7.33\nRelated dpkg options\nfrom textwrap import dedent\nqproj = dedent(\"\"\"\\\nproject:\n  type: website\n  output-dir: docs1\n\nwebsite:\n  title: \"Unified Stocks — EDA\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: reports/eda.qmd\n        text: EDA (parametrized)\n\nformat:\n  html:\n    theme: cosmo\n    toc: true\n    code-fold: false\n\nexecute:\n  echo: true\n  warning: false\n  cache: true\n\"\"\")\nopen(\"_quarto.yml\",\"w\").write(qproj)\nprint(open(\"_quarto.yml\").read())\n\nproject:\n  type: website\n  output-dir: docs1\n\nwebsite:\n  title: \"Unified Stocks — EDA\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: reports/eda.qmd\n        text: EDA (parametrized)\n\nformat:\n  html:\n    theme: cosmo\n    toc: true\n    code-fold: false\n\nexecute:\n  echo: true\n  warning: false\n  cache: true\nindex = \"\"\"\\\n---\ntitle: \"Unified Stocks Project\"\n---\n\nWelcome! Use the navigation to view the EDA report.\n\n- **Stock set**: see `tickers_25.csv`\n- **Note**: Educational use only — no trading advice.\n\"\"\"\nopen(\"index.qmd\",\"w\").write(index)\nprint(open(\"index.qmd\").read())\n\n---\ntitle: \"Unified Stocks Project\"\n---\n\nWelcome! Use the navigation to view the EDA report.\n\n- **Stock set**: see `tickers_25.csv`\n- **Note**: Educational use only — no trading advice.\nimport os, pathlib\npathlib.Path(\"reports/figs\").mkdir(parents=True, exist_ok=True)\n# For Python\neda_qmd = \"\"\"\\\n---\ntitle: \"Stock EDA\"\nformat:\n  html:\n    toc: true\n    number-sections: false\nexecute:\n  echo: true\n  warning: false\n  cache: false     # keep off while testing params\njupyter: python3\n---\n\n::: callout-note\nThis report is parameterized. Example:\n`-P symbol:MSFT -P start_date:2019-01-01 -P end_date:2025-08-01 -P rolling:30`.\n:::\n\n## Setup\n\n```{python}\n#| tags: [parameters]\n# Default values (overridden by -P at render time)\nsymbol = \"AAPL\"\nstart_date = \"2018-01-01\"\nend_date = \"\"          # empty means \"open ended\"\nrolling = 20\n```\n\n```{python}\nimport pandas as pd\nstart = pd.to_datetime(start_date) if start_date else None\nend   = pd.to_datetime(end_date) if end_date else None\nroll  = int(rolling)\nprint(\"Using params:\", dict(symbol=symbol, start=start, end=end, rolling=roll))\n```\n\n## Price over time for `{python} symbol` (`{python} start_date` → `{python} end_date`)\n\n```{python}\n# TODO: fetch prices using `symbol`, `start`, `end`\n# df = ...\n# ax = df[\"Close\"].plot(title=f\"{symbol} closing price\")\n# ax.set_xlabel(\"\"); ax.set_ylabel(\"Price\")\n```\n\n## Daily log returns — histogram\n\n```{python}\n# TODO: compute returns from df and plot\n```\n\n## Rolling mean & volatility (window = `{python} roll`)\n\n```{python}\n# TODO: use `roll` for rolling stats\n```\n\n## Summary table\n\n```{python}\n# TODO: build a summary DataFrame and display\n```\n\"\"\"\nimport os, pathlib\npathlib.Path(\"reports/figs\").mkdir(parents=True, exist_ok=True)\n#\neda_qmd = \"\"\"\\\n---\ntitle: \"Stock EDA\"\nformat:\n  html:\n    toc: true\n    number-sections: false\nexecute-dir: \"/content/drive/MyDrive/dspt25/STAT4160/reports\"\nexecute:\n  echo: false\n  warning: false\n  cache: false     # keep off while testing params\n\njupyter: python3\nparams:\n  symbol: \"AAPL\"\n  start_date: \"2018-01-01\"\n  end_date: \"\"\n  rolling: 20\n---\n\n\n::: callout-note\nThis report is parameterized. To change inputs without editing code, pass\n`-P symbol:MSFT -P start_date:2019-01-01 -P end_date:2025-08-01 -P rolling:30` to `quarto render`.\n:::\n\n## Setup if using Python\n```{python}\n#| tags: [parameters]\n# Default values (overridden by -P at render time)\nSYMBOL = \"AAPL\"\nSTART  = \"2018-01-01\"\nEND    = \"\"\nROLL   =  20\n```\n\n``` {python}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yfinance as yf\nfrom pathlib import Path\nfrom datetime import datetime\n\n# Read parameters if using R\n# SYMBOL = params.get(\"symbol\", \"AAPL\")\n# START  = params.get(\"start_date\", \"2018-01-01\")\n# END    = params.get(\"end_date\", \"\")\n# ROLL   = int(params.get(\"rolling\", 20))\n\nif not END:\n    END = pd.Timestamp.today().strftime(\"%Y-%m-%d\")\n\nSYMBOL, START, END, ROLL\n```\n\n## Download and prepare data\n\n``` {python}\n# Fetch adjusted OHLCV\ntry:\n    data = yf.download(SYMBOL, start=START, end=END, auto_adjust=True, progress=False)\nexcept Exception as e:\n    print(\"yfinance failed, falling back to synthetic series:\", e)\n    idx = pd.bdate_range(START, END)\n    rng = np.random.default_rng(42)\n    ret = rng.normal(0, 0.01, len(idx))\n    price = 100 * np.exp(np.cumsum(ret))\n    vol = rng.integers(1e5, 5e6, len(idx))\n    data = pd.DataFrame({\"Close\": price, \"Volume\": vol}, index=idx)\n\n# Tidy & features\ndf = data.rename(columns=str.lower).copy()\ndf = df[[\"close\",\"volume\"]].dropna()\ndf[\"log_return\"] = np.log(df[\"close\"]).diff()\ndf[\"roll_mean\"]  = df[\"log_return\"].rolling(ROLL, min_periods=ROLL//2).mean()\ndf[\"roll_vol\"]   = df[\"log_return\"].rolling(ROLL, min_periods=ROLL//2).std()\ndf = df.dropna()\ndf.head()\n```\n\n## Price over time\n\n``` {python}\nfig, ax = plt.subplots(figsize=(8,3))\nax.plot(df.index, df[\"close\"])\nax.set_title(f\"{SYMBOL} — Adjusted Close\")\nax.set_xlabel(\"Date\"); ax.set_ylabel(\"Price\")\nfig.tight_layout()\n# figpath = Path(\"reports/figs\")/f\"{SYMBOL}_price.png\"\nfigpath = Path(\"figs\")/f\"{SYMBOL}_price.png\" #same changes for the rest of the figures\nfig.savefig(figpath, dpi=144)\nfigpath\n```\n\n## Daily log returns — histogram\n\n``` {python}\nfig, ax = plt.subplots(figsize=(6,3))\nax.hist(df[\"log_return\"], bins=50, alpha=0.8)\nax.set_title(f\"{SYMBOL} — Daily Log Return Distribution\")\nax.set_xlabel(\"log return\"); ax.set_ylabel(\"count\")\nfig.tight_layout()\nfigpath = Path(\"figs\")/f\"{SYMBOL}_hist.png\"\nfig.savefig(figpath, dpi=144)\nfigpath\n```\n\n## Rolling mean & volatility (window = {params.rolling})\n\n``` {python}\nfig, ax = plt.subplots(figsize=(8,3))\nax.plot(df.index, df[\"roll_mean\"], label=\"rolling mean\")\nax.plot(df.index, df[\"roll_vol\"],  label=\"rolling std\")\nax.set_title(f\"{SYMBOL} — Rolling Return Stats (window={ROLL})\")\nax.set_xlabel(\"Date\"); ax.set_ylabel(\"value\")\nax.legend()\nfig.tight_layout()\nfigpath = Path(\"figs\")/f\"{SYMBOL}_rolling.png\"\nfig.savefig(figpath, dpi=144)\nfigpath\n```\n\n## Summary table\n\n``` {python}\nsummary = pd.DataFrame({\n    \"n_days\": [len(df)],\n    \"start\": [df.index.min().date()],\n    \"end\":   [df.index.max().date()],\n    \"mean_daily_ret\": [df[\"log_return\"].mean()],\n    \"std_daily_ret\":  [df[\"log_return\"].std()],\n    \"ann_vol_approx\": [df[\"log_return\"].std()*np.sqrt(252)]\n})\nsummary\n```\n\n **Note**: Educational use only. This is not trading advice.\n\"\"\"\nopen(\"reports/eda.qmd\",\"w\").write(eda_qmd)\nprint(\"Wrote reports/eda.qmd\")\n\nWrote reports/eda.qmd\n# !pip install jupyter-cache # Run this cell if the package is missing\n# !pip install papermill   #Run this cell if papermill is passing.\n# Single render with defaults (AAPL)\n!quarto render reports/eda.qmd --output-dir docs1/\n\n\nExecuting 'eda.quarto_ipynb'\n\n  Cell 1/7: ''...Done\n\n  Cell 2/7: ''...Done\n\n  Cell 3/7: ''...Done\n\n  Cell 4/7: ''...Done\n\n  Cell 5/7: ''...Done\n\n  Cell 6/7: ''...Done\n\n  Cell 7/7: ''...Done\n\n\n\npandoc \n\n  to: html\n\n  output-file: eda.html\n\n  standalone: true\n\n  title-prefix: Unified Stocks — EDA\n\n  section-divs: true\n\n  html-math-method: mathjax\n\n  wrap: none\n\n  default-image-extension: png\n\n  toc: true\n\n  number-sections: false\n\n  variables: {}\n\n  \n\nmetadata\n\n  document-css: false\n\n  link-citations: true\n\n  date-format: long\n\n  lang: en\n\n  theme: cosmo\n\n  title: Stock EDA\n\n  execute-dir: /content/drive/MyDrive/dspt25/STAT4160/reports\n\n  jupyter: python3\n\n  \n\nOutput created: ../docs1/reports/eda.html\n# Render for MSFT with custom dates and rolling window\n# !quarto render reports/eda.qmd -P symbol:MSFT -P start_date:2019-01-01 -P end_date:2025-08-01 -P rolling:30 --output-dir docs1/\n!quarto render reports/eda.qmd -P SYMBOL:MSFT -P START:2019-01-01 -P END:2025-08-01 -P ROLL:30 --output-dir docs1/\n\n\n\nExecuting 'eda.quarto_ipynb'\n\n  Cell 1/8: ''...Done\n\n  Cell 2/8: ''...Done\n\n  Cell 3/8: ''...Done\n\n  Cell 4/8: ''...Done\n\n  Cell 5/8: ''...Done\n\n  Cell 6/8: ''...Done\n\n  Cell 7/8: ''...Done\n\n  Cell 8/8: ''...Done\n\n\n\npandoc \n\n  to: html\n\n  output-file: eda.html\n\n  standalone: true\n\n  title-prefix: Unified Stocks — EDA\n\n  section-divs: true\n\n  html-math-method: mathjax\n\n  wrap: none\n\n  default-image-extension: png\n\n  toc: true\n\n  number-sections: false\n\n  variables: {}\n\n  \n\nmetadata\n\n  document-css: false\n\n  link-citations: true\n\n  date-format: long\n\n  lang: en\n\n  theme: cosmo\n\n  title: Stock EDA\n\n  execute-dir: /content/drive/MyDrive/dspt25/STAT4160/reports\n\n  jupyter: python3\n\n  \n\nOutput created: ../docs1/reports/eda.html\n# Render for NVDA with a different window\n# !quarto render reports/eda.qmd -P symbol:NVDA -P start_date:2018-01-01 -P end_date:2025-08-01 -P rolling:60 --output-dir docs1/\n!quarto render reports/eda.qmd -P SYMBOL:NVDA -P START:2018-01-01 -P END:2025-08-01 -P ROLL:60 --output-dir docs1/\n\n\nExecuting 'eda.quarto_ipynb'\n\n  Cell 1/8: ''...Done\n\n  Cell 2/8: ''...Done\n\n  Cell 3/8: ''...Done\n\n  Cell 4/8: ''...Done\n\n  Cell 5/8: ''...Done\n\n  Cell 6/8: ''...Done\n\n  Cell 7/8: ''...Done\n\n  Cell 8/8: ''...Done\n\n\n\npandoc \n\n  to: html\n\n  output-file: eda.html\n\n  standalone: true\n\n  title-prefix: Unified Stocks — EDA\n\n  section-divs: true\n\n  html-math-method: mathjax\n\n  wrap: none\n\n  default-image-extension: png\n\n  toc: true\n\n  number-sections: false\n\n  variables: {}\n\n  \n\nmetadata\n\n  document-css: false\n\n  link-citations: true\n\n  date-format: long\n\n  lang: en\n\n  theme: cosmo\n\n  title: Stock EDA\n\n  execute-dir: /content/drive/MyDrive/dspt25/STAT4160/reports\n\n  jupyter: python3\n\n  \n\nOutput created: ../docs1/reports/eda.html\n# Example: write MSFT to docs/reports/eda-MSFT.html via project copy\nimport shutil, os\nshutil.copy(\"reports/eda.qmd\", \"reports/eda-MSFT.qmd\")\n!quarto render reports/eda-MSFT.qmd -P symbol:MSFT -P start_date:2019-01-01 -P end_date:2025-08-01 -P rolling:30 --output-dir docs1/\n\n\nStarting python3 kernel...Done\n\n\n\nExecuting 'eda-MSFT.quarto_ipynb'\n\n  Cell 1/8: ''...Done\n\n  Cell 2/8: ''...Done\n\n  Cell 3/8: ''...Done\n\n  Cell 4/8: ''...Done\n\n  Cell 5/8: ''...Done\n\n  Cell 6/8: ''...Done\n\n  Cell 7/8: ''...Done\n\n  Cell 8/8: ''...Done\n\n\n\npandoc \n\n  to: html\n\n  output-file: eda-MSFT.html\n\n  standalone: true\n\n  title-prefix: Unified Stocks — EDA\n\n  section-divs: true\n\n  html-math-method: mathjax\n\n  wrap: none\n\n  default-image-extension: png\n\n  toc: true\n\n  number-sections: false\n\n  variables: {}\n\n  \n\nmetadata\n\n  document-css: false\n\n  link-citations: true\n\n  date-format: long\n\n  lang: en\n\n  theme: cosmo\n\n  title: Stock EDA\n\n  execute-dir: /content/drive/MyDrive/dspt25/STAT4160/reports\n\n  jupyter: python3\n\n  \n\nOutput created: ../docs1/reports/eda-MSFT.html\nwith open('_quarto.yml') as f:\n    print(f.read())\n\nproject:\n  type: website\n  output-dir: docs1\n\nwebsite:\n  title: \"Unified Stocks — EDA\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: reports/eda.qmd\n        text: EDA (parametrized)\n\nformat:\n  html:\n    theme: cosmo\n    toc: true\n    code-fold: false\n\nexecute:\n  echo: true\n  warning: false\n  cache: true\n!pip install ruamel.yaml\n\n\nCollecting ruamel.yaml\n\n  Downloading ruamel.yaml-0.18.15-py3-none-any.whl.metadata (25 kB)\n\nCollecting ruamel.yaml.clib&gt;=0.2.7 (from ruamel.yaml)\n\n  Downloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n\nDownloading ruamel.yaml-0.18.15-py3-none-any.whl (119 kB)\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.7/119.7 kB 4.2 MB/s eta 0:00:00\n\nDownloading ruamel.yaml.clib-0.2.12-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (754 kB)\n\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 754.1/754.1 kB 22.8 MB/s eta 0:00:00\n\nInstalling collected packages: ruamel.yaml.clib, ruamel.yaml\n\nSuccessfully installed ruamel.yaml-0.18.15 ruamel.yaml.clib-0.2.12\n# Append MSFT page to navbar\nfrom ruamel.yaml import YAML\nyaml = YAML()\ncfg = yaml.load(open(\"_quarto.yml\"))\ncfg[\"website\"][\"navbar\"][\"left\"].append({\"href\": \"reports/eda-MSFT.qmd\", \"text\": \"MSFT EDA\"})\nwith open(\"_quarto.yml\",\"w\") as f:\n    yaml.dump(cfg, f)\n!quarto render --output-dir docs1/  # this will render all rendable files in the root directory and all subdirectories\n\n\n\n[ 1/10] reports/eda.qmd\n\n\n\nStarting python3 kernel...Done\n\n[ColabKernelApp] ERROR | No such comm target registered: quarto_kernel_setup\n\n\n\nExecuting 'eda.quarto_ipynb'\n\n  Cell 1/7: ''...Done\n\n  Cell 2/7: ''...Done\n\n  Cell 3/7: ''...Done\n\n  Cell 4/7: ''...Done\n\n  Cell 5/7: ''...Done\n\n  Cell 6/7: ''...Done\n\n  Cell 7/7: ''...Done\n\n\n\n[ 2/10] reports/system_check.md\n\n[ 3/10] reports/eda-MSFT.qmd\n\n\n\nStarting python3 kernel...Done\n\n[ColabKernelApp] ERROR | No such comm target registered: quarto_kernel_setup\n\n\n\nExecuting 'eda-MSFT.quarto_ipynb'\n\n  Cell 1/7: ''...Done\n\n  Cell 2/7: ''...Done\n\n  Cell 3/7: ''...Done\n\n  Cell 4/7: ''...Done\n\n  Cell 5/7: ''...Done\n\n  Cell 6/7: ''...Done\n\n  Cell 7/7: ''...Done\n\n\n\n[ 4/10] notebooks/testing.ipynb\n\n[ 5/10] notebooks/lec2_inclass.ipynb\n\n[ 6/10] notebooks/system_check.ipynb\n\n[ 7/10] notebooks/lec2-hw.ipynb\n\n[ 8/10] notebooks/lec2_hw.ipynb\n\n[ 9/10] notebooks/reproducibility_demo.ipynb\n\n[10/10] index.qmd\n\n\n\nOutput created: docs1/index.html"
  },
  {
    "objectID": "notebooks/lec3-inclass.html#homework",
    "href": "notebooks/lec3-inclass.html#homework",
    "title": "Unified Stocks — EDA",
    "section": "Homework",
    "text": "Homework\n\nimport shutil\nshutil.copy(\"reports/eda.qmd\", \"reports/eda-AAPL.qmd\")\nshutil.copy(\"reports/eda.qmd\", \"reports/eda-MSFT.qmd\")\nshutil.copy(\"reports/eda.qmd\", \"reports/eda-NVDA.qmd\")\n\n'reports/eda-NVDA.qmd'\n\n\n\nfrom ruamel.yaml import YAML\nyaml = YAML()\ncfg = yaml.load(open(\"_quarto.yml\"))\ncfg[\"website\"][\"navbar\"][\"left\"].extend([\n  {\"href\": \"reports/eda-AAPL.qmd\", \"text\": \"AAPL\"},\n  {\"href\": \"reports/eda-MSFT.qmd\", \"text\": \"MSFT\"},\n  {\"href\": \"reports/eda-NVDA.qmd\", \"text\": \"NVDA\"},\n])\nwith open(\"_quarto.yml\",\"w\") as f:\n    yaml.dump(cfg, f)\n!quarto render --output-dir docs1/\n\n\n[ 1/14] notebooks/lec3-inclass.ipynb\n\n[ 2/14] notebooks/lec2-hw.ipynb\n\n[ 3/14] notebooks/lec2_hw.ipynb\n\n[ 4/14] notebooks/testing.ipynb\n\n[ 5/14] notebooks/reproducibility_demo.ipynb\n\n[ 6/14] notebooks/system_check.ipynb\n\n[ 7/14] notebooks/lec2_inclass.ipynb\n\n[ 8/14] notebooks/lec3_code_inside_QMD_testing.ipynb\n\n[ 9/14] reports/system_check.md\n\n[10/14] reports/eda.qmd\n\n\n\nStarting python3 kernel...Done\n\n[ColabKernelApp] ERROR | No such comm target registered: quarto_kernel_setup\n\n\n\nExecuting 'eda.quarto_ipynb'\n\n  Cell 1/7: ''...Done\n\n  Cell 2/7: ''...Done\n\n  Cell 3/7: ''...Done\n\n  Cell 4/7: ''...Done\n\n  Cell 5/7: ''...Done\n\n  Cell 6/7: ''...Done\n\n  Cell 7/7: ''...Done"
  },
  {
    "objectID": "notebooks/lec2_hw.html",
    "href": "notebooks/lec2_hw.html",
    "title": "Unified Stocks — EDA",
    "section": "",
    "text": "# Colab cell\nfrom google.colab import drive\ndrive.mount('/content/drive', force_remount=True)\n\nMounted at /content/drive\n\n\n\n# Adjust these two for YOUR repo\nREPO_OWNER = \"ywanglab\"\nREPO_NAME  = \"STAT4160\"   # e.g., unified-stocks-team1\n\nBASE_DIR   = \"/content/drive/MyDrive/dspt25\"\nCLONE_DIR  = f\"{BASE_DIR}/{REPO_NAME}\"\nREPO_URL   = f\"https://github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n\nimport os, pathlib\npathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True)\n\n\nimport os, subprocess, shutil, pathlib\n\nif not pathlib.Path(CLONE_DIR).exists():\n    !git clone {REPO_URL} {CLONE_DIR}\nelse:\n    # If the folder exists, just ensure it's a git repo and pull latest\n    os.chdir(CLONE_DIR)\n    !git status\n    !git pull --ff-only\nos.chdir(CLONE_DIR)\nprint(\"Working dir:\", os.getcwd())\n\n\n# Run in your repo root\nimport os, pathlib, textwrap\npathlib.Path(\".github\").mkdir(exist_ok=True)\ntpl = textwrap.dedent(\"\"\"\\\n    ## Summary\n    What does this PR do and why?\n\n    ## Changes\n    -\n\n    ## How to test\n    - From a fresh clone: steps to run\n\n    ## Checklist\n    - [ ] Runs from a fresh clone (README steps)\n    - [ ] No secrets committed; `.env` only (and `.env.example` updated if needed)\n    - [ ] Large artifacts tracked by LFS (`git lfs ls-files` shows expected files)\n    - [ ] Clear, small diff; comments where useful\n\"\"\")\nopen(\".github/pull_request_template.md\",\"w\").write(tpl)\nprint(\"Wrote .github/pull_request_template.md\")\n\nWrote .github/pull_request_template.md\n\n\n\nowners = \"\"\"\\\n# Replace with your GitHub handles\n* @teammate1 @teammate2 @ywanglab\n\"\"\"\nopen(\".github/CODEOWNERS\",\"w\").write(owners)\nprint(\"Wrote .github/CODEOWNERS (edit handles!)\")\n\nWrote .github/CODEOWNERS (edit handles!)\n\n\n\n# tools/guard_large_files.py\nimport os, subprocess, sys\n\nLIMIT_MB = 10\nROOT = os.getcwd()\n\ndef lfs_tracked_paths(): # find files tracked by lfs\n    try:\n        out = subprocess.check_output([\"git\", \"lfs\", \"ls-files\"], text=True)\n        tracked = set()\n        for line in out.strip().splitlines():\n            # line format: \"&lt;oid&gt; &lt;path&gt;\" ex: line = \"3b2d8c7d53   data/processed/file.parquet\"\n            p = line.split(None, 1)[-1].strip() #split on whitespace at most once.\n            tracked.add(os.path.normpath(p)) # normpath(p): ensure consistent slashes (\\ vs /)\n        return tracked\n    except Exception:\n        return set()\n\ndef humanize(bytes_):\n    return f\"{bytes_/(1024*1024):.2f} MB\"\n\nlfs_set = lfs_tracked_paths()\nbad = []\nfor dirpath, dirnames, filenames in os.walk(ROOT):\n  #os.walk() is a generator that recursively traverses a directory tree.\n  # At each step it yields a tuple:(dirpath, subdirnames, filenames)\n\n    # skip .git directory\n    if \".git\" in dirpath.split(os.sep):#using os specific separator os.sep (/ for linus, \\ for windows)\n        continue\n    for fn in filenames:\n        path = os.path.normpath(os.path.join(dirpath, fn))\n        try:\n            size = os.path.getsize(path)\n        except FileNotFoundError:\n            continue\n        if size &gt;= LIMIT_MB * 1024 * 1024:\n            rel = os.path.relpath(path, ROOT)\n            if rel not in lfs_set:\n                bad.append((rel, size))\n\nif bad:\n    print(\"ERROR: Large non-LFS files found:\")\n    for rel, size in bad:\n        print(f\" - {rel} ({humanize(size)})\")\n    sys.exit(1)\nelse:\n    print(\"OK: No large non-LFS files detected.\")\n\nOK: No large non-LFS files detected.\n\n\n\n# Define the path to the tools directory\ntools_dir = Path(\"tools\")\n\n# Create it if it doesn't exist (including any parents)\ntools_dir.mkdir(parents=True, exist_ok=True)\n\nprint(f\"Directory '{tools_dir}' is ready.\")\n\nDirectory 'tools' is ready.\n\n\n\nfrom pathlib import Path\n\ntools_dir = Path(\"tools\")\ntools_dir.mkdir(parents=True, exist_ok=True)\n\nscript = tools_dir / \"guard_large_files.py\"\n\ncode = '''#!/usr/bin/env python3\nimport os\nimport sys\nimport subprocess\n\nLIMIT_MB = 10  # size threshold for LFS in megabytes\nROOT = os.path.abspath(os.path.dirname(__file__) + \"/..\")\n\ndef humanize(nbytes):\n    # format size in human-friendly units\n    for unit in ['B','KB','MB','GB','TB']:\n        if nbytes &lt; 1024:\n            return f\"{nbytes:.1f}{unit}\"\n        nbytes /= 1024\n    return f\"{nbytes:.1f}PB\"\n\ndef lfs_tracked_paths():\n    try:\n        out = subprocess.check_output([\"git\", \"lfs\", \"ls-files\"], text=True)\n        tracked = set()\n        for line in out.strip().splitlines():\n            # line format: \"&lt;oid&gt; &lt;path&gt;\"\n            p = line.split(None, 1)[-1].strip()\n            tracked.add(os.path.normpath(p))\n        return tracked\n    except Exception:\n        return set()\n\ndef main():\n    lfs_set = lfs_tracked_paths()\n    bad = []\n    for dirpath, dirnames, filenames in os.walk(ROOT):\n        # skip .git and other hidden dirs\n        if \".git\" in dirpath.split(os.sep):\n            continue\n        for fn in filenames:\n            path = os.path.normpath(os.path.join(dirpath, fn))\n            try:\n                size = os.path.getsize(path)\n            except FileNotFoundError:\n                continue\n            if size &gt;= LIMIT_MB * 1024 * 1024:\n                rel = os.path.relpath(path, ROOT)\n                if rel not in lfs_set:\n                    bad.append((rel, size))\n\n    if bad:\n        print(\"ERROR: Large non-LFS files found:\")\n        for rel, size in sorted(bad, key=lambda x: x[1], reverse=True):\n            print(f\" - {rel} ({humanize(size)})\")\n        sys.exit(1)\n    else:\n        print(f\"OK: No large non-LFS files detected (limit {LIMIT_MB} MB).\")\n\nif __name__ == \"__main__\":\n    main()\n'''\n\n# Write the file\nscript.write_text(code)\nscript.chmod(0o755)  # make it executable 0o means base-8. r:4, w: 2, x:1\n\nprint(f\"Created {script}\")\n\nCreated tools/guard_large_files.py\n\n\n\n# Create/append Makefile target\nfrom pathlib import Path\ntext = \"\\n\\nguard:\\n\\tpython tools/guard_large_files.py\\n\" # guard: Makefile target. \\t: tab required.\np = Path(\"Makefile\") # point to the Makefile\n# p.write_text(p.read_text() + text if p.exists() else text) # if p exists, read exising content and append text and overwrites.\n# the above code will append text everytime, casue error if repeatedly excute.\nif p.exists():\n    content = p.read_text()\n    if \"guard:\" not in content:\n        p.write_text(content + text)\nelse:\n    p.write_text(text)\n\nprint(\"Added 'guard' target to Makefile\")\n\nAdded 'guard' target to Makefile\n\n\n\n!python tools/guard_large_files.py\n\nOK: No large non-LFS files detected (limit 10 MB)."
  },
  {
    "objectID": "notebooks/reproducibility_demo.html",
    "href": "notebooks/reproducibility_demo.html",
    "title": "Unified Stocks — EDA",
    "section": "",
    "text": "# Colab cell\nfrom google.colab import drive\ndrive.mount('/content/drive', force_remount=True)\n\nMounted at /content/drive\n\n\n\n# Adjust these two for YOUR repo\nREPO_OWNER = \"ywanglab\"\nREPO_NAME  = \"STAT4160\"   # e.g., unified-stocks-team1\n\nBASE_DIR   = \"/content/drive/MyDrive/dspt25\"\nCLONE_DIR  = f\"{BASE_DIR}/{REPO_NAME}\"\nREPO_URL   = f\"https://github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n\nimport os, pathlib\npathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True)\n\n\nimport os, subprocess, shutil, pathlib\n\nif not pathlib.Path(CLONE_DIR).exists():\n    !git clone {REPO_URL} {CLONE_DIR}\nelse:\n    # If the folder exists, just ensure it's a git repo and pull latest\n    os.chdir(CLONE_DIR)\n    !git status\n    !git pull --ff-only\nos.chdir(CLONE_DIR)\nprint(\"Working dir:\", os.getcwd())\n\n\nRefresh index: 100% (47/47), done.\n\nOn branch main\n\nYour branch is up to date with 'origin/main'.\n\n\n\nChanges not staged for commit:\n\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   notebooks/reproducibility_demo.ipynb\n\n    modified:   notebooks/system_check.ipynb\n\n\n\nUntracked files:\n\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n\n    notebooks/testing.ipynb\n\n\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nAlready up to date.\n\nWorking dir: /content/drive/MyDrive/dspt25/STAT4160\n\n\n\n\n\n# Homework\n\n\n# Colab cell: freeze exact versions\n!pip freeze &gt; requirements-lock.txt\nprint(\"Wrote requirements-lock.txt with exact versions\")\n!head -n 20 requirements-lock.txt\n\nWrote requirements-lock.txt with exact versions\nabsl-py==1.4.0\naccelerate==1.10.0\naiofiles==24.1.0\naiohappyeyeballs==2.6.1\naiohttp==3.12.15\naiosignal==1.4.0\nalabaster==1.0.0\nalbucore==0.0.24\nalbumentations==2.0.8\nale-py==0.11.2\naltair==5.5.0\nannotated-types==0.7.0\nantlr4-python3-runtime==4.9.3\nanyio==4.10.0\nanywidget==0.9.18\nargon2-cffi==25.1.0\nargon2-cffi-bindings==25.1.0\narray_record==0.7.2\narviz==0.22.0\nastropy==7.1.0\n\n\n\nimport numpy as np, torch, random, json, os, time\n\ndef set_seed(seed=123):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    try:\n        torch.use_deterministic_algorithms(True)\n    except Exception:\n        pass\n\ndef make_toy(n=512, d=10, noise=0.1, seed=123):\n    set_seed(seed)\n    X = torch.randn(n, d)\n    true_w = torch.randn(d, 1)\n    y = X @ true_w + noise * torch.randn(n, 1)\n    return X, y, true_w\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nX, y, true_w = make_toy()\nX, y = X.to(device), y.to(device)\n\n\n# torch.use_deterministic_algorithms(False)\ndef train_once(lr=0.05, steps=300, seed=123):\n    set_seed(seed)\n    model = torch.nn.Linear(X.shape[1], 1, bias=False).to(device) #torch.nn.Linear(in_features, out_features, bias=False)\n    opt = torch.optim.SGD(model.parameters(), lr=lr)\n    loss_fn = torch.nn.MSELoss()\n    losses=[]\n    for t in range(steps):\n        opt.zero_grad(set_to_none=True) # set_to_none: slightly faster\n        yhat = model(X)\n        loss = loss_fn(yhat, y) # yhat must be in the first postion to have the correct gradient graph\n        loss.backward() # compute the loss\n        opt.step() # update weights\n        losses.append(loss.item())\n    return model.weight.detach().cpu().numpy(), losses[-1] #detatch from computing graph, moved to cpu to create np array\n\nw1, final_loss1 = train_once(seed=2025)\nw2, final_loss2 = train_once(seed=2025)\n\nprint(\"Final loss 1:\", round(final_loss1, 6))\nprint(\"Final loss 2:\", round(final_loss2, 6))\nprint(\"Weights equal:\", np.allclose(w1, w2, atol=1e-7))\n\nFinal loss 1: 0.01057\nFinal loss 2: 0.01057\nWeights equal: True\n\n\n\nos.makedirs(\"reports\", exist_ok=True)\nresult = {\n    \"device\": device,\n    \"final_loss1\": float(final_loss1),\n    \"final_loss2\": float(final_loss2),\n    \"weights_equal\": bool(np.allclose(w1, w2, atol=1e-7)),\n    \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n}\nwith open(\"reports/reproducibility_results.json\",\"w\") as f:\n    json.dump(result, f, indent=2)\nresult\n\n{'device': 'cpu',\n 'final_loss1': 0.010570256970822811,\n 'final_loss2': 0.010570256970822811,\n 'weights_equal': True,\n 'timestamp': '2025-08-15 21:10:06'}\n\n\n\nenv_example = \"\"\"\\\n# Example environment variables (do NOT commit a real .env with secrets)\nALPHA_VANTAGE_KEY=\nFRED_API_KEY=\n\"\"\"\nopen(\".env.example\", \"w\").write(env_example)\nprint(open(\".env.example\").read())\n\n# Example environment variables (do NOT commit a real .env with secrets)\nALPHA_VANTAGE_KEY=\nFRED_API_KEY="
  },
  {
    "objectID": "notebooks/lec2_inclass.html",
    "href": "notebooks/lec2_inclass.html",
    "title": "Unified Stocks — EDA",
    "section": "",
    "text": "# Colab cell\nfrom google.colab import drive\ndrive.mount('/content/drive', force_remount=True)\n\nMounted at /content/drive\n\n\n\n# Adjust these two for YOUR repo\nREPO_OWNER = \"ywanglab\"\nREPO_NAME  = \"STAT4160\"   # e.g., unified-stocks-team1\n\nBASE_DIR   = \"/content/drive/MyDrive/dspt25\"\nCLONE_DIR  = f\"{BASE_DIR}/{REPO_NAME}\"\nREPO_URL   = f\"https://github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n\nimport os, pathlib\npathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True)\n\n\nimport os, subprocess, shutil, pathlib\n\nif not pathlib.Path(CLONE_DIR).exists():\n    !git clone {REPO_URL} {CLONE_DIR}\nelse:\n    # If the folder exists, just ensure it's a git repo and pull latest\n    os.chdir(CLONE_DIR)\n    !git status\n    !git pull --ff-only\nos.chdir(CLONE_DIR)\nprint(\"Working dir:\", os.getcwd())\n\n\nRefresh index: 100% (48/48), done.\n\nOn branch main\n\nYour branch is up to date with 'origin/main'.\n\n\n\nChanges not staged for commit:\n\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   notebooks/lec2_inclass.ipynb\n\n\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n\nAlready up to date.\n\nWorking dir: /content/drive/MyDrive/dspt25/STAT4160\n\n\n\n\n\n# Replace with your name and school email\n!git config user.name \"Your name\"\n!git config user.email \"Your email\"\n\n!git config --get user.name\n!git config --get user.email\n\n\nBRANCH = \"setup/git-lfs\"\n!git checkout -b {BRANCH}\n!git branch --show-current\n\nSwitched to a new branch 'setup/git-lfs'\nsetup/git-lfs\n\n\n\ngitignore = \"\"\"\\\n_book/\n_freeze/\n.quarto/\n/.quarto/\n_quarto.yml\n/*.qmd\n/*.png\n/*.ipynb\n/*.html\n\n\n/*.log\n/*.aux\n/*.tex\n/*.toc\n\n\n# Byte-compiled / cache\n__pycache__/\n*.py[cod]\n\n# Jupyter checkpoints\n.ipynb_checkpoints/\n\n# OS/editor files\n.DS_Store\nThumbs.db\n.vscode/\n\n# Environments & secrets\n.env\n.env.*\n.venv/\n*.pem\n*.key\n\n# Data (raw & interim never committed)\ndata/raw/\ndata/interim/\n\n# Logs & caches\nlogs/\n.cache/\n\n# R / RStudio files\n.Rhistory\n.Rproj.user/\n\"\"\"\nopen(\".gitignore\", \"w\").write(gitignore)\nprint(open(\".gitignore\").read())\n\nbook/\n.quarto/\n/.quarto/\n\n# Byte-compiled / cache\n__pycache__/\n*.py[cod]\n\n# Jupyter checkpoints\n.ipynb_checkpoints/\n\n# OS/editor files\n.DS_Store\nThumbs.db\n.vscode/\n\n# Environments & secrets\n.env\n.env.*\n.venv/\n*.pem\n*.key\n\n# Data (raw & interim never committed)\ndata/raw/\ndata/interim/\n\n# Logs & caches\nlogs/\n.cache/\n\n\n\n\n# Install git-lfs on the Colab VM (one-time per runtime)\n!apt-get -y update &gt;/dev/null. # refresh available packages from the repositories\n!apt-get -y install git-lfs &gt;/dev/null\n!git lfs install\n!git lfs version\n\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nUpdated git hooks.\nGit LFS initialized.\ngit-lfs/3.0.2 (GitHub; linux amd64; go 1.18.1)\n\n\n\n# Add .gitattributes entries via git lfs track\n!git lfs track \"data/processed/*.parquet\"\n!git lfs track \"data/*.db\"\n!git lfs track \"models/*.pt\"\n!git lfs track \"reports/*.pdf\"\n\n# Show what LFS is tracking and verify .gitattributes created\n!git lfs track\nprint(\"\\n.gitattributes:\")\nprint(open(\".gitattributes\").read())\n\nTracking \"data/processed/*.parquet\"\nTracking \"data/*.db\"\nTracking \"models/*.pt\"\nTracking \"reports/*.pdf\"\nListing tracked patterns\n    data/processed/*.parquet (.gitattributes)\n    data/*.db (.gitattributes)\n    models/*.pt (.gitattributes)\n    reports/*.pdf (.gitattributes)\nListing excluded patterns\n\n.gitattributes:\ndata/processed/*.parquet filter=lfs diff=lfs merge=lfs -text\ndata/*.db filter=lfs diff=lfs merge=lfs -text\nmodels/*.pt filter=lfs diff=lfs merge=lfs -text\nreports/*.pdf filter=lfs diff=lfs merge=lfs -text\n\n\n\n\nimport pandas as pd, numpy as np, os, pathlib\n\npathlib.Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n\ntickers = pd.read_csv(\"tickers_25.csv\")[\"ticker\"].tolist() if os.path.exists(\"tickers_25.csv\") else [\n    \"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"NVDA\",\"TSLA\",\"JPM\",\"JNJ\",\"V\",\n    \"PG\",\"HD\",\"BAC\",\"XOM\",\"CVX\",\"PFE\",\"KO\",\"DIS\",\"NFLX\",\"INTC\",\"CSCO\",\"ORCL\",\"T\",\"VZ\",\"WMT\"\n]\n\n# 1000 business days x up to 25 tickers ~ 25k rows; a few MB as Parquet\ndates = pd.bdate_range(\"2018-01-01\", periods=1000)\ndf = (pd.MultiIndex.from_product([tickers, dates], names=[\"ticker\",\"date\"])\n      .to_frame(index=False))\nrng = np.random.default_rng(42)\ndf[\"r_1d\"] = rng.normal(0, 0.01, size=len(df))  # synthetic daily returns\ndf.to_parquet(\"data/processed/sample_returns.parquet\", index=False)\ndf.head()\n\n\n    \n\n\n\n\n\n\nticker\ndate\nr_1d\n\n\n\n\n0\nAAPL\n2018-01-01\n0.003047\n\n\n1\nAAPL\n2018-01-02\n-0.010400\n\n\n2\nAAPL\n2018-01-03\n0.007505\n\n\n3\nAAPL\n2018-01-04\n0.009406\n\n\n4\nAAPL\n2018-01-05\n-0.019510\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n      \n\n\n    \n        \n    \n\n      \n\n\n\n      \n    \n\n    \n  \n\n\n\n!git add .gitignore .gitattributes data/processed/sample_returns.parquet\n!git status\n\n!git commit -m \"feat: add .gitignore and git-lfs tracking; add sample Parquet\"\n!git log --oneline -n 2\n\n# if see the error of cannot run .git/hooks/post-commit: chmod +x .git/hooks/post-commit\n\n\nOn branch setup/git-lfs\n\nnothing to commit, working tree clean\n\nOn branch setup/git-lfs\n\nnothing to commit, working tree clean\n\nf839d76 (HEAD -&gt; setup/git-lfs) feat: add .gitignore and git-lfs tracking; add sample Parquet\n\n3c826a1 (origin/main, origin/HEAD, main) added lec2.html\n\n\n\n\n\n!chmod +x .git/hooks/* # run this to avoid errors\n\n\n# Colab cell: push using a temporary URL with token (not saved to git config)\nfrom getpass import getpass\ntoken = getpass(\"Enter your GitHub token (input hidden; not stored): \")\n\npush_url = f\"https://{token}@github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n!git push {push_url} {BRANCH}:{BRANCH} # local branch: remote branch\n\n# Optional: immediately clear the token variable\ndel token\n# if error:cannot exec '.git/hooks/pre-push': chmod +x .git/hooks/pre-push\n\nEnter your GitHub token (input hidden; not stored): ··········\nUploading LFS objects: 100% (1/1), 260 KB | 0 B/s, done.\nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 2 threads\nCompressing objects: 100% (7/7), done.\nWriting objects: 100% (7/7), 935 bytes | 44.00 KiB/s, done.\nTotal 7 (delta 1), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (1/1), completed with 1 local object.\nremote: \nremote: Create a pull request for 'setup/git-lfs' on GitHub by visiting:\nremote:      https://github.com/ywanglab/STAT4160/pull/new/setup/git-lfs\nremote: \nTo https://github.com/ywanglab/STAT4160.git\n * [new branch]      setup/git-lfs -&gt; setup/git-lfs\n\n\n\n# OPTIONAL: Create PR via GitHub API (requires token again)\nfrom getpass import getpass\nimport requests, json\n\ntoken = getpass(\"GitHub token (again, not stored): \")\nheaders = {\"Authorization\": f\"Bearer {token}\",\n           \"Accept\": \"application/vnd.github+json\"}\npayload = {\n    \"title\": \"Setup: .gitignore + Git-LFS + sample Parquet\",\n    \"head\": BRANCH,\n    \"base\": \"main\",\n    \"body\": \"Adds .gitignore, configures Git-LFS for parquet/db/pdf/model files, and commits a sample Parquet for verification.\"\n}\nr = requests.post(f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/pulls\",\n                  headers=headers, data=json.dumps(payload))\nprint(\"PR status:\", r.status_code)\ntry:\n    pr_url = r.json()[\"html_url\"]\n    print(\"PR URL:\", pr_url)\nexcept Exception as e:\n    print(\"Response:\", r.text)\ndel token\n\nGitHub token (again, not stored): ··········\nPR status: 422\nResponse: {\"message\":\"Validation Failed\",\"errors\":[{\"resource\":\"PullRequest\",\"field\":\"head\",\"code\":\"invalid\"}],\"documentation_url\":\"https://docs.github.com/rest/pulls/pulls#create-a-pull-request\",\"status\":\"422\"}\n\n\n\n!git lfs ls-files\n\ne87eb77993 * data/processed/sample_returns.parquet\n\n\n\n# List LFS-tracked files (shows their OIDs and sizes)\n!git lfs ls-files -l\n\ne87eb77993ba9e8a89e206b2623747f9c86b18fd9ccb6d12735f43da582b0720 * data/processed/sample_returns.parquet\n\n\n\n# Show the pointer text that’s in Git history\n!git cat-file -p HEAD:data/processed/sample_returns.parquet\n\nversion https://git-lfs.github.com/spec/v1\noid sha256:e87eb77993ba9e8a89e206b2623747f9c86b18fd9ccb6d12735f43da582b0720\nsize 259949\n\n\n\n# Ensure you have the actual binary downloaded\n# !git lfs fetch --include=\"data/processed/*.parquet\"\n# !git lfs checkout   # replaces pointers in your working tree with real files"
  },
  {
    "objectID": "reports/system_check.html",
    "href": "reports/system_check.html",
    "title": "System Check",
    "section": "",
    "text": "Timestamp: 2025-08-16 16:20:34\nPython: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\nOS: Linux-6.1.123+-x86_64-with-glibc2.35\npandas: 2.2.2 | numpy: 2.0.2 | torch: 2.6.0+cu124\nCUDA available: False | Device: CPU\n\n\n\n\nMatch on repeated seeds: True\nnumpy: [0.696469, 0.286139, 0.226851, 0.551315, 0.719469, 0.423106]\ntorch: [0.296112, 0.516562, 0.251671, 0.688557, 0.073972, 0.866522]"
  },
  {
    "objectID": "reports/system_check.html#rng-fingerprint",
    "href": "reports/system_check.html#rng-fingerprint",
    "title": "System Check",
    "section": "",
    "text": "Match on repeated seeds: True\nnumpy: [0.696469, 0.286139, 0.226851, 0.551315, 0.719469, 0.423106]\ntorch: [0.296112, 0.516562, 0.251671, 0.688557, 0.073972, 0.866522]"
  },
  {
    "objectID": "reports/eda-AAPL.html",
    "href": "reports/eda-AAPL.html",
    "title": "Stock EDA",
    "section": "",
    "text": "Note\n\n\n\nThis report is parameterized. To change inputs without editing code, pass -P symbol:MSFT -P start_date:2019-01-01 -P end_date:2025-08-01 -P rolling:30 to quarto render."
  },
  {
    "objectID": "reports/eda-AAPL.html#setup-if-using-python",
    "href": "reports/eda-AAPL.html#setup-if-using-python",
    "title": "Stock EDA",
    "section": "Setup if using Python",
    "text": "Setup if using Python\n\n\n('AAPL', '2018-01-01', '2025-08-22', 20)"
  },
  {
    "objectID": "reports/eda-AAPL.html#download-and-prepare-data",
    "href": "reports/eda-AAPL.html#download-and-prepare-data",
    "title": "Stock EDA",
    "section": "Download and prepare data",
    "text": "Download and prepare data\n\n\n\n    \n\n\n\n\n\nPrice\nclose\nvolume\nlog_return\nroll_mean\nroll_vol\n\n\nTicker\naapl\naapl\n\n\n\n\n\nDate\n\n\n\n\n\n\n\n\n\n2018-01-17\n41.984421\n137547200\n0.016381\n0.003894\n0.007023\n\n\n2018-01-18\n42.021919\n124773600\n0.000893\n0.003621\n0.006724\n\n\n2018-01-19\n41.834396\n129700400\n-0.004472\n0.002947\n0.006823\n\n\n2018-01-22\n41.492130\n108434400\n-0.008215\n0.002088\n0.007229\n\n\n2018-01-23\n41.501518\n130756400\n0.000226\n0.001955\n0.006963"
  },
  {
    "objectID": "reports/eda-AAPL.html#price-over-time",
    "href": "reports/eda-AAPL.html#price-over-time",
    "title": "Stock EDA",
    "section": "Price over time",
    "text": "Price over time\n\n\nPosixPath('figs/AAPL_price.png')"
  },
  {
    "objectID": "reports/eda-AAPL.html#daily-log-returns-histogram",
    "href": "reports/eda-AAPL.html#daily-log-returns-histogram",
    "title": "Stock EDA",
    "section": "Daily log returns — histogram",
    "text": "Daily log returns — histogram\n\n\nPosixPath('figs/AAPL_hist.png')"
  },
  {
    "objectID": "reports/eda-AAPL.html#rolling-mean-volatility-window-params.rolling",
    "href": "reports/eda-AAPL.html#rolling-mean-volatility-window-params.rolling",
    "title": "Stock EDA",
    "section": "Rolling mean & volatility (window = {params.rolling})",
    "text": "Rolling mean & volatility (window = {params.rolling})\n\n\nPosixPath('figs/AAPL_rolling.png')"
  },
  {
    "objectID": "reports/eda-AAPL.html#summary-table",
    "href": "reports/eda-AAPL.html#summary-table",
    "title": "Stock EDA",
    "section": "Summary table",
    "text": "Summary table\n\n\n\n    \n\n\n\n\n\n\nn_days\nstart\nend\nmean_daily_ret\nstd_daily_ret\nann_vol_approx\n\n\n\n\n0\n1910\n2018-01-17\n2025-08-21\n0.000887\n0.01968\n0.312412\n\n\n\n\n\n    \n      \n  \n    \n      \n  \n    \n  \n    \n    \n  \n\n    \n  \n  \n    \n  \n\n\nNote: Educational use only. This is not trading advice."
  },
  {
    "objectID": "reports/eda-NVDA.html",
    "href": "reports/eda-NVDA.html",
    "title": "Stock EDA",
    "section": "",
    "text": "Note\n\n\n\nThis report is parameterized. To change inputs without editing code, pass -P symbol:MSFT -P start_date:2019-01-01 -P end_date:2025-08-01 -P rolling:30 to quarto render."
  },
  {
    "objectID": "reports/eda-NVDA.html#setup-if-using-python",
    "href": "reports/eda-NVDA.html#setup-if-using-python",
    "title": "Stock EDA",
    "section": "Setup if using Python",
    "text": "Setup if using Python\n\n\n('AAPL', '2018-01-01', '2025-08-22', 20)"
  },
  {
    "objectID": "reports/eda-NVDA.html#download-and-prepare-data",
    "href": "reports/eda-NVDA.html#download-and-prepare-data",
    "title": "Stock EDA",
    "section": "Download and prepare data",
    "text": "Download and prepare data\n\n\n\n    \n\n\n\n\n\nPrice\nclose\nvolume\nlog_return\nroll_mean\nroll_vol\n\n\nTicker\naapl\naapl\n\n\n\n\n\nDate\n\n\n\n\n\n\n\n\n\n2018-01-17\n41.984417\n137547200\n0.016381\n0.003894\n0.007023\n\n\n2018-01-18\n42.021923\n124773600\n0.000893\n0.003621\n0.006724\n\n\n2018-01-19\n41.834389\n129700400\n-0.004473\n0.002947\n0.006823\n\n\n2018-01-22\n41.492149\n108434400\n-0.008214\n0.002088\n0.007229\n\n\n2018-01-23\n41.501518\n130756400\n0.000226\n0.001955\n0.006963"
  },
  {
    "objectID": "reports/eda-NVDA.html#price-over-time",
    "href": "reports/eda-NVDA.html#price-over-time",
    "title": "Stock EDA",
    "section": "Price over time",
    "text": "Price over time\n\n\nPosixPath('figs/AAPL_price.png')"
  },
  {
    "objectID": "reports/eda-NVDA.html#daily-log-returns-histogram",
    "href": "reports/eda-NVDA.html#daily-log-returns-histogram",
    "title": "Stock EDA",
    "section": "Daily log returns — histogram",
    "text": "Daily log returns — histogram\n\n\nPosixPath('figs/AAPL_hist.png')"
  },
  {
    "objectID": "reports/eda-NVDA.html#rolling-mean-volatility-window-params.rolling",
    "href": "reports/eda-NVDA.html#rolling-mean-volatility-window-params.rolling",
    "title": "Stock EDA",
    "section": "Rolling mean & volatility (window = {params.rolling})",
    "text": "Rolling mean & volatility (window = {params.rolling})\n\n\nPosixPath('figs/AAPL_rolling.png')"
  },
  {
    "objectID": "reports/eda-NVDA.html#summary-table",
    "href": "reports/eda-NVDA.html#summary-table",
    "title": "Stock EDA",
    "section": "Summary table",
    "text": "Summary table\n\n\n\n    \n\n\n\n\n\n\nn_days\nstart\nend\nmean_daily_ret\nstd_daily_ret\nann_vol_approx\n\n\n\n\n0\n1910\n2018-01-17\n2025-08-21\n0.000887\n0.01968\n0.312412\n\n\n\n\n\n    \n      \n  \n    \n      \n  \n    \n  \n    \n    \n  \n\n    \n  \n  \n    \n  \n\n\nNote: Educational use only. This is not trading advice."
  },
  {
    "objectID": "reports/eda.html#setup",
    "href": "reports/eda.html#setup",
    "title": "Stock EDA",
    "section": "Setup",
    "text": "Setup\n\n# Default values (overridden by -P at render time)\nsymbol = \"AAPL\"\nstart_date = \"2018-01-01\"\nend_date = \"\"          # empty means \"open ended\"\nrolling = 20\n\n\nimport pandas as pd\nstart = pd.to_datetime(start_date) if start_date else None\nend   = pd.to_datetime(end_date) if end_date else None\nroll  = int(rolling)\nprint(\"Using params:\", dict(symbol=symbol, start=start, end=end, rolling=roll))\n\nUsing params: {'symbol': 'AAPL', 'start': Timestamp('2018-01-01 00:00:00'), 'end': None, 'rolling': 20}"
  },
  {
    "objectID": "reports/eda.html#price-over-time-for-aapl-2018-01-01-python-end_date",
    "href": "reports/eda.html#price-over-time-for-aapl-2018-01-01-python-end_date",
    "title": "Stock EDA",
    "section": "Price over time for AAPL (2018-01-01 → {python} end_date)",
    "text": "Price over time for AAPL (2018-01-01 → {python} end_date)\n\n# TODO: fetch prices using `symbol`, `start`, `end`\n# df = ...\n# ax = df[\"Close\"].plot(title=f\"{symbol} closing price\")\n# ax.set_xlabel(\"\"); ax.set_ylabel(\"Price\")"
  },
  {
    "objectID": "reports/eda.html#rolling-mean-volatility-window-20",
    "href": "reports/eda.html#rolling-mean-volatility-window-20",
    "title": "Stock EDA",
    "section": "Rolling mean & volatility (window = 20)",
    "text": "Rolling mean & volatility (window = 20)\n\n# TODO: use `roll` for rolling stats"
  }
]