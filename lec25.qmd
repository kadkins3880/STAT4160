---
title: "Session 25 — Poster + Abstract Workshop"
---
Below is a complete lecture package for **Session 25 — Poster + Abstract Workshop** (75 minutes). It includes a timed agenda, instructor talking points (slides outline), a **Colab‑friendly in‑class lab with copy‑paste code** that generates three polished figures and a Quarto poster skeleton, plus **homework with copy‑paste code** to validate the abstract length and render a draft poster.

> **Educational use only — not trading advice.**
> Assumes your Drive‑mounted repo (e.g., `unified-stocks-teamX`), and that you have at least one set of predictions/metrics from earlier sessions (e.g., `reports/cli_linlags.csv`, `reports/unified_gru_split1_per_ticker.csv`, `reports/tsgpt_split1_metrics.csv`). All code includes **safe fallbacks** that synthesize minimal data so the lab runs even if files are missing.

---

## Session 25 — Poster + Abstract Workshop (75 min)

### Learning goals

By the end of class, students can:

1. Craft a concise **story arc** (Problem → Data → Method → Evaluation → Results → Limits → Takeaways).
2. Produce and polish **three key figures**:

   * **Model comparison** (baseline vs LSTM/GRU vs tiny‑Transformer/TS‑GPT).
   * **Regime breakdown** (errors by volatility regime).
   * **Ablation** (TS‑GPT hyperparam sweep).
3. Assemble a **one‑page poster** (Quarto HTML or PDF) and draft a **250‑word abstract**.

---

## Agenda (75 min)

* **(10 min)** Slides: poster anatomy, audience & narrative, figure design rules.
* **(10 min)** Slides: abstract structure, model‑card notes & caveats.
* **(40 min)** **In‑class lab**: generate three figures → create `reports/poster.qmd` → render draft.
* **(15 min)** Share & critique: 3‑minute lightning review per team; assign homework.

---

## Slides — talking points (drop into your deck)

### 1) Poster anatomy (for non‑experts)

* **Title** (problem & claim), **Authors/Affiliation**, **Contact**.
* **Left column:** Problem & Data (1–2 bullets each), **Method sketch** (one diagram).
* **Center:** **Key results** (3 figures), 1–2 sentences per figure (what/why it matters).
* **Right column:** **Limits** (leakage, data shifts), **Ethics & caveats**, **Takeaways**.

### 2) Figure design (fast rules)

* Use **clear labels/units**, readable fonts (≥ 11–12 pt on poster), concise legends.
* Order bars left→right by magnitude; add **error bars** where possible.
* Avoid clutter: minimal grid; **colorblind‑safe** if you pick colors; don’t rely only on color (shapes/line styles help).
* Always include a 10‑word **caption** and a one‑line **takeaway** near the figure.

### 3) Abstract (≈250 words, plain English)

* **Motivation** in 1–2 sentences; **data & setup** in 1–2; **methods** in 2–3; **results** with numbers; **limits** and **next steps**.
* No internal jargon; define acronyms (e.g., MAE = mean absolute error) on first use.

### 4) Model card essentials (1 small box on the poster)

* **Intended use** (educational baseline forecasting).
* **Data** (tickers & dates, pre‑processing, leakage controls).
* **Metrics** (MAE, sMAPE, by regime).
* **Limitations** (non‑stationarity, survivorship bias, no live trading).

---

## In‑class lab (40 min, Colab‑friendly)

> Run each block as its **own cell**. Change `REPO_NAME` if needed.

### 0) Setup & folders

```python
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

REPO_NAME = "unified-stocks-teamX"  # <- change to your repo name
BASE_DIR  = "/content/drive/MyDrive/dspt25"
REPO_DIR  = f"{BASE_DIR}/{REPO_NAME}"

import os, pathlib, sys, platform
pathlib.Path(REPO_DIR).mkdir(parents=True, exist_ok=True)
os.chdir(REPO_DIR)
for p in ["reports","docs/figs","scripts","tests"]:
    pathlib.Path(p).mkdir(parents=True, exist_ok=True)
print("Working dir:", os.getcwd(), "| Python:", sys.version.split()[0], "| OS:", platform.system())
```

### 1) Script to build poster figures (create `scripts/make_poster_figs.py`)

```python
%%bash
cat > scripts/make_poster_figs.py << 'PY'
#!/usr/bin/env python
from __future__ import annotations
import os, math, glob, json
from pathlib import Path
import numpy as np, pandas as pd
import matplotlib.pyplot as plt

FIGDIR = Path("docs/figs"); FIGDIR.mkdir(parents=True, exist_ok=True)
REPDIR = Path("reports"); REPDIR.mkdir(exist_ok=True)

def _safe_read_csv(path: str|Path) -> pd.DataFrame|None:
    p = Path(path)
    try:
        if p.exists():
            return pd.read_csv(p)
    except Exception as e:
        print("WARN cannot read", p, e)
    return None

def _synthesize_predictions(n=800, tickers=("AAPL","MSFT","GOOGL","AMZN","NVDA","META")):
    rng = np.random.default_rng(0)
    frames=[]
    for t in tickers:
        y = rng.normal(0, 0.012, size=n).astype("float32")
        e_lin = rng.normal(0, 0.009, size=n).astype("float32")
        df = pd.DataFrame({"ticker":t, "y_true":y, "yhat":y+e_lin})
        frames.append(df)
    out = pd.concat(frames, ignore_index=True)
    out["date"] = pd.date_range("2023-01-03", periods=len(out), freq="B")
    out["method"] = "lin_lags"
    return out

def _mae(y,yhat): return float(np.mean(np.abs(np.asarray(y)-np.asarray(yhat))))

def model_compare():
    """Build a bar chart comparing MAE across models (aggregate & per-ticker if available)."""
    # Load LIN_LAGS predictions from CLI
    lin = _safe_read_csv("reports/cli_linlags.csv")
    if lin is None or not {"y_true","yhat","ticker"}.issubset(lin.columns):
        print("Using synthetic LIN_LAGS predictions.")
        lin = _synthesize_predictions()
    lin["model"] = "lin_lags"
    m_lin = _mae(lin["y_true"], lin["yhat"])

    # GRU (per-ticker metrics if available)
    gru_pt = _safe_read_csv("reports/unified_gru_split1_per_ticker.csv")
    m_gru = gru_pt["mae"].mean() if (gru_pt is not None and "mae" in gru_pt.columns and len(gru_pt)>0) else None

    # TS-GPT (aggregate metrics)
    tsgpt = _safe_read_csv("reports/tsgpt_split1_metrics.csv")
    if tsgpt is not None and "val_mae" in tsgpt.columns and len(tsgpt)>0:
        m_tsgpt = float(tsgpt["val_mae"].iloc[-1])
    else:
        m_tsgpt = None

    rows=[{"model":"lin_lags","val_mae":m_lin}]
    if m_gru is not None:   rows.append({"model":"gru","val_mae":m_gru})
    if m_tsgpt is not None: rows.append({"model":"tsgpt","val_mae":m_tsgpt})
    comp = pd.DataFrame(rows).sort_values("val_mae")
    comp.to_csv(REPDIR/"model_compare.csv", index=False)

    # Bar plot
    plt.figure(figsize=(6,3.2))
    x = np.arange(len(comp))
    plt.bar(x, comp["val_mae"].values)
    plt.xticks(x, comp["model"].tolist())
    plt.ylabel("Validation MAE")
    plt.title("Model Comparison (lower is better)")
    plt.tight_layout()
    plt.savefig(FIGDIR/"model_compare.png", dpi=160)
    plt.close()
    print("Wrote", FIGDIR/"model_compare.png")

def regime_breakdown():
    """Compute MAE by volatility regime using LIN_LAGS predictions + returns variance proxy."""
    lin = _safe_read_csv("reports/cli_linlags.csv")
    base = None
    # Try to load a returns file to compute rolling volatility
    for cand in ["data/processed/features_v1.parquet","data/processed/returns.parquet"]:
        try:
            if Path(cand).exists():
                base = pd.read_parquet(cand)
                break
        except Exception: pass
    if lin is None:
        lin = _synthesize_predictions(n=400)
    if base is None or not {"ticker","date"}.issubset(base.columns):
        # fabricate a simple volatility proxy from y_true
        print("Volatility base missing — using synthetic regimes from residual std.")
        tmp = lin.copy()
        tmp["resid"] = lin["y_true"] - lin["yhat"]
        tmp["vol"] = tmp.groupby("ticker")["resid"].transform(lambda s: s.rolling(20, min_periods=20).std())
        base = tmp[["ticker","date","vol"]]
    else:
        base = base.sort_values(["ticker","date"]).copy()
        if "log_return" in base.columns:
            base["vol"] = base.groupby("ticker")["log_return"].rolling(20, min_periods=20).std().reset_index(level=0,drop=True)
        elif "r_1d" in base.columns:
            base["vol"] = base.groupby("ticker")["r_1d"].rolling(20, min_periods=20).std().reset_index(level=0,drop=True)
        else:
            base["vol"] = base.groupby("ticker").cumcount() * 0.0  # fallback
        base = base[["ticker","date","vol"]]
    # Merge
    df = lin.merge(base, on=["ticker","date"], how="left")
    q1, q2 = df["vol"].quantile([1/3, 2/3])
    def regime(v):
        if v<=q1: return "low"
        if v<=q2: return "med"
        return "high"
    df["regime"] = df["vol"].apply(regime)
    agg = df.groupby("regime").apply(lambda g: _mae(g["y_true"], g["yhat"])).reset_index(name="mae")
    agg = agg.sort_values("mae")
    agg.to_csv(REPDIR/"regime_breakdown.csv", index=False)

    # Bar plot
    plt.figure(figsize=(6,3.2))
    x = np.arange(len(agg))
    plt.bar(x, agg["mae"].values)
    plt.xticks(x, agg["regime"].tolist())
    plt.ylabel("MAE")
    plt.title("Error by Volatility Regime")
    plt.tight_layout()
    plt.savefig(FIGDIR/"regime_breakdown.png", dpi=160)
    plt.close()
    print("Wrote", FIGDIR/"regime_breakdown.png")

def ablation_plot():
    """Plot a simple heatmap for TS-GPT ablations if available; else synthesize."""
    paths = [p for p in ["reports/tsgpt_ablation_summary.csv","reports/tinygpt_ablation_summary.csv"] if Path(p).exists()]
    if paths:
        ab = pd.read_csv(paths[0])
    else:
        # synthesize small ablation grid
        rng = np.random.default_rng(1)
        ab = pd.DataFrame([
            {"ctx": c, "n_head": h, "dropout": d, "val_mae": 0.010 + rng.normal(0,0.0008)}
            for c in [32,64] for h in [2,4] for d in [0.0,0.1]
        ])
    # Prefer ctx vs n_head for each dropout (two panels by saving two images)
    for d in sorted(ab["dropout"].unique()):
        sub = ab[ab["dropout"]==d].copy()
        ctxs = sorted(sub["ctx"].unique())
        heads = sorted(sub["n_head"].unique())
        grid = np.full((len(ctxs), len(heads)), np.nan)
        for i,c in enumerate(ctxs):
            for j,h in enumerate(heads):
                rows = sub[(sub["ctx"]==c) & (sub["n_head"]==h)]
                if len(rows): grid[i,j] = float(rows.iloc[-1]["val_mae"])
        plt.figure(figsize=(5.2,3.8))
        plt.imshow(grid, aspect="auto", origin="lower")
        plt.colorbar(label="Val MAE")
        plt.xticks(np.arange(len(heads)), [str(h) for h in heads]); plt.xlabel("n_head")
        plt.yticks(np.arange(len(ctxs)), [str(c) for c in ctxs]);   plt.ylabel("context length")
        plt.title(f"TS-GPT Ablation (dropout={d})")
        plt.tight_layout()
        fn = FIGDIR/f"ablation_dropout_{str(d).replace('.','_')}.png"
        plt.savefig(fn, dpi=160)
        plt.close()
        print("Wrote", fn)
    ab.to_csv(REPDIR/"ablation_clean.csv", index=False)

def main():
    model_compare()
    regime_breakdown()
    ablation_plot()
    print("Done. Figures in", FIGDIR)

if __name__ == "__main__":
    main()
PY
chmod +x scripts/make_poster_figs.py
```

Run it:

```bash
%%bash
python scripts/make_poster_figs.py
ls -l docs/figs | head -n 10
```

### 2) Create a Quarto **poster skeleton** (`reports/poster.qmd`)

```python
%%bash
cat > reports/poster.qmd << 'QMD'
---
title: "Unified Stocks: Tiny Transformers vs Classical Baselines"
author: "Team — Data Science Productivity Tools"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
format:
  html:
    page-layout: full
    toc: false
    number-sections: false
    theme: default
    df-print: paged
    smooth-scroll: true
engine: knitr
editor: source
---

::: {.callout-note}
**Educational project (not trading advice).**  
Data and results are for demonstration of tools and methodology.
:::

## Problem
Short‑horizon return forecasting is noisy. We build a **unified model** across multiple tickers and compare **classical baselines** with a **tiny Transformer** under strict leakage controls.

## Data
- Daily prices for a static list of tickers.  
- Features: lags, rolling z‑scores, 20‑day volatility, calendar effects.  
- Splits: rolling‑origin with embargo; metrics reported on validation slices.

## Methods (1‑paragraph sketch)
- Baselines: **naive** (ŷ = return_t), **lin_lags** (per‑ticker linear regression).  
- Sequence models: **GRU** (multi‑asset with ticker IDs) and **TS‑GPT** (feature projection + causal attention).  
- Loss: MAE/Huber. No look‑ahead; scaler fit on TRAIN only.

## Results

### Model comparison (MAE)
![Comparison of validation MAE across models. Lower is better.](../docs/figs/model_compare.png){fig-alt="Bar chart: models vs MAE" width="70%"}

**Takeaway.** The unified sequence model improves over lin_lags on this split (magnitude varies by dataset).

### Error by volatility regime
![MAE by regime (low/med/high volatility).](../docs/figs/regime_breakdown.png){fig-alt="Bar chart: volatility regimes vs MAE" width="70%"}

**Takeaway.** Errors increase in high‑volatility regimes; compare models at equal regimes to avoid apples‑to‑oranges.

### TS‑GPT ablation (context × heads)
![Validation MAE heatmaps across context and heads (one per dropout).](../docs/figs/ablation_dropout_0_0.png){fig-alt="Heatmap: ctx vs n_head, dropout=0.0" width="45%"}
![Validation MAE heatmaps across context and heads (one per dropout).](../docs/figs/ablation_dropout_0_1.png){fig-alt="Heatmap: ctx vs n_head, dropout=0.1" width="45%"}

**Takeaway.** Longer context or more heads can help slightly, but returns are noisy—watch for overfitting.

## Limits & Ethics
- Non‑stationarity; survivorship bias minimized via static list and fixed history but not eliminated.  
- Not suitable for trading; missing costs/impact; academic metrics only.

## Model Card (short)
- **Intended use:** teaching pipeline/tools.  
- **Data:** daily OHLCV; engineered features; static ticker universe.  
- **Metrics:** MAE, sMAPE, regime‑wise MAE.  
- **Limitations:** no risk management; unstable out‑of‑sample.

## References
- Course repository and documentation; standard ML/TS texts.

## Contact
- Team GitHub and email here.
QMD
```

Render (HTML; PDF optional if LaTeX is available):

```bash
%%bash
quarto render reports/poster.qmd || echo "If Quarto not available here, render locally later."
```

### 3) Seed an **abstract draft** file and a **word‑count checker**

```python
%%bash
cat > reports/abstract.md << 'MD'
We study short‑horizon stock return forecasting as an educational exercise in reproducible data science tooling. Using a static set of equities and daily bars, we engineer causal features (lags, rolling volatility, calendar effects) and enforce time‑based splits with an embargo to prevent leakage. We compare per‑ticker linear baselines to unified sequence models, including a GRU with ticker embeddings and a tiny Transformer adapted for real‑valued time series (TS‑GPT).

Models are trained with MAE/Huber loss on expanding windows; evaluation uses MAE and sMAPE aggregated across tickers and by volatility regimes. On our validation split, the unified sequence model matches or modestly outperforms the linear baseline, especially in medium‑volatility regimes; effects shrink in high‑volatility periods. Ablations suggest small gains from longer context, with diminishing returns beyond 64 steps.

This course project emphasizes tools over profits: deterministic pipelines, tests, continuous integration, and a Typer CLI that reproduces results from a fresh clone. The work is limited by non‑stationarity, survivorship bias, and absence of transaction costs. Future work includes multi‑horizon forecasting, macro features, uncertainty estimates, and broader asset coverage. This is not trading advice.
MD

cat > scripts/check_abstract_length.py << 'PY'
#!/usr/bin/env python
import re, sys
from pathlib import Path

def count_words(text: str) -> int:
    text = re.sub(r"\s+", " ", text).strip()
    if not text: return 0
    return len(text.split(" "))

def main(path="reports/abstract.md"):
    p = Path(path)
    if not p.exists():
        print(f"Missing {p}", file=sys.stderr); sys.exit(2)
    words = count_words(p.read_text(encoding="utf-8"))
    print(f"{p}: {words} words")
    if not (200 <= words <= 300):
        print("Abstract must be between 200 and 300 words.", file=sys.stderr)
        sys.exit(2)

if __name__ == "__main__":
    main()
PY
chmod +x scripts/check_abstract_length.py
python scripts/check_abstract_length.py || true
```

### 4) Tiny test to ensure figures exist

```python
%%bash
cat > tests/test_poster_assets.py << 'PY'
from pathlib import Path

def test_poster_figs_exist():
    for fn in ["model_compare.png", "regime_breakdown.png"]:
        assert (Path("docs/figs")/fn).exists(), f"Missing {fn} — run scripts/make_poster_figs.py"
PY
pytest -q -k poster_assets || true
```

---

## Wrap‑up prompts (15 min)

* **Lightning critique**: Each team shows the **3 figures** (30–60 seconds each).
* Ask: “What is the **one sentence** the viewer should remember?”
* Confirm the poster **story arc** is visible from 6 feet away: bold headings; few words; figures big.

---

## Homework (due next session)

**Deliverables (push to repo):**

1. **`reports/poster.html`** (and `reports/poster.pdf` if you can render PDF) with the 3 figures embedded.
2. **`reports/abstract.md`** (200–300 words) that matches the poster’s story.
3. A short **commit message**: `docs: poster draft + abstract (v1)`.

### A. Makefile targets (append to `Makefile`)

```make
.PHONY: poster-figs poster render-poster abstract-check
poster-figs: ## Build all poster figures
\tpython scripts/make_poster_figs.py

poster: poster-figs ## Render HTML poster
\tquarto render reports/poster.qmd

render-poster: poster

abstract-check: ## Ensure abstract word count is 200-300
\tpython scripts/check_abstract_length.py
```

### B. Optional CI snippet (run only if Quarto available)

```yaml
# Append to .github/workflows/ci.yml
- name: Poster assets
  run: |
    python scripts/make_poster_figs.py
    python scripts/check_abstract_length.py
```

### C. (Optional) Extra figure (calibration / residuals)

Add this cell if you also saved predictions for GRU/TS‑GPT (e.g., `reports/tsgpt_preds_split1.csv` with `date,ticker,y_true,yhat`):

```python
import pandas as pd, numpy as np, matplotlib.pyplot as plt, pathlib
pred = None
for cand in ["reports/tsgpt_preds_split1.csv","reports/cli_linlags.csv"]:
    if pathlib.Path(cand).exists():
        pred = pd.read_csv(cand); break
if pred is not None and {"y_true","yhat"}.issubset(pred.columns):
    e = pred["y_true"] - pred["yhat"]
    plt.figure(figsize=(6,3.2))
    plt.hist(e.values, bins=50)
    plt.xlabel("Residual"); plt.ylabel("Count"); plt.title("Residual distribution")
    plt.tight_layout(); pathlib.Path("docs/figs").mkdir(parents=True, exist_ok=True)
    plt.savefig("docs/figs/residuals_hist.png", dpi=160); plt.close()
```

Then include in `poster.qmd`:

```markdown
![Residual distribution (optional).](../docs/figs/residuals_hist.png){width="55%"}
```

---

## Instructor notes / facilitation tips

* Encourage **big, legible figures**. Shrink text elsewhere, not the plots.
* If a figure doesn’t clearly answer a question, **cut it**.
* Remind to **state uncertainty/limits** explicitly (no trading claims).
* For the abstract, ban boilerplate like “significant improvement” without **numbers**.

---

## Grading (pass/revise)

* **Poster draft** builds from a **fresh clone** using `make poster` (figures present and render succeeds).
* **Three key figures** are present and readable, each with a concise takeaway.
* **Abstract** is 200–300 words and consistent with the figures.
* Repo contains `scripts/make_poster_figs.py` and `scripts/check_abstract_length.py`; optional test passes.

---

### Appendix — Figure caption starter lines (you can paste into the poster)

* **Model comparison:** “TS‑GPT reduces validation MAE vs lin\_lags on Split 1; improvements are modest and vary by ticker.”
* **Regime breakdown:** “All models degrade in high volatility; report metrics by regime to avoid overstating performance.”
* **Ablation:** “Context 64 and heads 4 are a reasonable sweet spot under tight budgets; gains diminish beyond this.”

This package gives you everything you need to run a productive **poster + abstract workshop** in 75 minutes and leave students with a tangible draft ready for polishing.
