% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={STAT 4160: Data Science Productivity Tools},
  pdfauthor={Yi Wang},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{STAT 4160: Data Science Productivity Tools}
\author{Yi Wang}
\date{2025-08-13}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

This is the lecture note for the course STAT 4160.

\bookmarksetup{startatroot}

\chapter*{Introduction}\label{introduction}
\addcontentsline{toc}{chapter}{Introduction}

\markboth{Introduction}{Introduction}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section*{13‑week plan (2 × 75‑min per
week)}\label{week-plan-2-75min-per-week}
\addcontentsline{toc}{section}{13‑week plan (2 × 75‑min per week)}

\markright{13‑week plan (2 × 75‑min per week)}

\textbf{Week 1 -- Setup, Colab, Git/GitHub}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} Local Python + VS Code; Colab basics (GPU, Drive mount,
  persistence limits), repo cloning in Colab, \texttt{requirements.txt},
  seeds.
\item
  \emph{Lec B:} Git essentials, branching, PRs, code review etiquette,
  \texttt{.gitignore}, \textbf{Git‑LFS} do's/don'ts (quota pitfalls).
\item
  \textbf{Deliverable:} Team repo with a Colab notebook that runs and
  logs environment info; one PR merged.
\end{itemize}

\textbf{Week 2 -- Reproducible reporting (Quarto) + RStudio cameo}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} Quarto for Python: parameters, caching, citations;
  publish to GitHub Pages.
\item
  \emph{Lec B (15--25 min cameo):} RStudio + Quarto rendering (so they
  can read R‑centric docs later), then back to Python.
\item
  \textbf{Deliverable:} Parameterized EDA report (symbol, date range as
  params).
\end{itemize}

\textbf{Week 3 -- Unix for data work + automation}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} Shell basics (pipes, redirects), \texttt{grep/sed/awk},
  \texttt{find/xargs}, regex.
\item
  \emph{Lec B:} Shell scripts, simple \textbf{Makefile/justfile}
  targets; \texttt{rsync}, quick SSH/tmux tour.
\item
  \textbf{Deliverable:} \texttt{make\ get-data} and
  \texttt{make\ report} run end‑to‑end.
\end{itemize}

\textbf{Week 4 -- SQL I (schemas, joins)}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} SQLite in repo; schema design for OHLCV + metadata;
  SELECT/JOIN/GROUP BY.
\item
  \emph{Lec B:} Window functions; indices; \texttt{pandas.read\_sql}
  pipelines.
\item
  \textbf{Deliverable:} SQL notebook producing a tidy table ready for
  modeling.
\end{itemize}

\textbf{Week 5 -- pandas for time series}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} Cleaning, types, missing, merges; \texttt{groupby},
  pivot; Parquet I/O.
\item
  \emph{Lec B:} Time‑series ops: resampling, rolling windows,
  shifting/lagging, calendar effects.
\item
  \textbf{Deliverable:} Cleaned Parquet dataset + feature snapshot.
\end{itemize}

\textbf{Week 6 -- APIs \& Web scraping (ethics + caching)}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} HTTP basics, \texttt{requests}, pagination, auth,
  retries, backoff; \textbf{don't hard‑code keys}
  (\texttt{python‑dotenv}).
\item
  \emph{Lec B:} BeautifulSoup, CSS selectors, robots.txt, throttling;
  \textbf{cache raw pulls}; persist to SQL/Parquet.
\item
  \textbf{Deliverable:} One external data source ingested with caching
  \& schema checks.
\end{itemize}

\textbf{Week 7 -- Quality: tests, lint, minimal CI}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} \texttt{pytest} (2--3 meaningful tests), data validation
  (light Pandera or custom checks), logging, type hints.
\item
  \emph{Lec B:} \textbf{Pre‑commit} (black, ruff, nbstripout),
  \textbf{GitHub Actions} to run tests + lint on PRs (fast jobs only).
\item
  \textbf{Deliverable:} CI badge green; failing test demonstrates
  leakage prevention or schema guard.
\end{itemize}

\textbf{Week 8 -- Time‑series baselines \& backtesting}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} Problem framing; horizon, step size; MAE/sMAPE/MASE;
  \textbf{rolling‑origin} evaluation.
\item
  \emph{Lec B:} Baselines: naive/seasonal‑naive; quick ARIMA/Prophet or
  sklearn regressor with lags.
\item
  \textbf{Deliverable:} Baseline model card + backtest plot in Quarto.
\end{itemize}

\textbf{Week 9 -- Finance‑specific evaluation \& leakage control}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} \textbf{Feature timing \& label definition} (t+1
  returns, multi‑step horizons), survivorship bias, look‑ahead traps,
  data snooping.
\item
  \emph{Lec B:} \textbf{Walk‑forward / expanding window}, embargoed
  splits, drift detection; error analysis by regime (volatility bins,
  bull/bear).
\item
  \textbf{Deliverable:} A robust evaluation plan + revised splits;
  leakage test added to \texttt{pytest}.
\end{itemize}

\textbf{Week 10 -- PyTorch fundamentals}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} Tensors, autograd, datasets/dataloaders for windows;
  training loop, early stopping; GPU in Colab; mixed precision.
\item
  \emph{Lec B:} A small \textbf{LSTM/TCN} baseline for forecasting;
  monitoring loss/metrics; save best weights.
\item
  \textbf{Deliverable:} PyTorch baseline surpasses classical baseline on
  at least one metric.
\end{itemize}

\textbf{Week 11 -- Transformers for sequences (tiny GPT)}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} Attention from scratch; \textbf{tiny char‑level GPT}
  (embeddings, positions, single head → multi‑head), sanity‑check
  overfitting on toy data.
\item
  \emph{Lec B:} Adapt to time series: window embedding, causal masking,
  regression head; ablation (context length, heads, dropout) within
  Colab budget.
\item
  \textbf{Deliverable:} Transformer results + one ablation figure; notes
  on compute/time.
\end{itemize}

\textbf{Week 12 -- Productivity at scale (lightweight)}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} Packaging a small library (\texttt{src/} layout,
  \texttt{pyproject.toml}), simple \textbf{CLI} (Typer) for batch
  inference; config via YAML.
\item
  \emph{Lec B:} \textbf{Optional FastAPI} endpoint demo (local only) +
  reproducibility audit (fresh‑clone run).
\item
  \textbf{Deliverable:} Tagged release \texttt{v1.0-rc}, CLI can score a
  held‑out period and write a report.
\end{itemize}

\textbf{Week 13 -- Communication \& showcase}

\begin{itemize}
\tightlist
\item
  \emph{Lec A:} Poster + abstract workshop; tell the error‑analysis
  story; figure polish; README \& model card.
\item
  \emph{Lec B:} In‑class presentations + final feedback; plan for
  continuing to the Spring symposium (next‑steps backlog).
\item
  \textbf{Deliverable:} Poster draft, 250‑word abstract, and a
  reproducible repo ready to extend.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section*{Project spine}\label{project-spine}
\addcontentsline{toc}{section}{Project spine}

\markright{Project spine}

\begin{itemize}
\tightlist
\item
  \textbf{Milestones:} W1 repo \& env → W3 automated data pipeline → W6
  external data → W7 CI green → W8 baselines → W9 robust eval plan → W10
  PyTorch baseline → W11 tiny Transformer → W12 release candidate → W13
  poster \& talk.
\item
  \textbf{Tracking (minimal):} log experiments to a simple CSV
  (\texttt{results/experiments.csv}) and keep a Quarto ``lab notebook.''
  If you're open to one extra tool, free \textbf{Weights \& Biases}
  makes ablations much easier---but the CSV+Quarto path is fine for two
  students.
\item
  \textbf{Data strategy:} keep raw data out of Git (use
  \texttt{make\ get-data}); store processed Parquet under 100MB if you
  must commit; otherwise regenerate. Use Git‑LFS only for small,
  immutable artifacts to avoid quota pain.
\item
  \textbf{Secrets:} \texttt{.env} with \texttt{python‑dotenv} +
  \texttt{.env} in \texttt{.gitignore}. For Colab, use environment
  variables or a JSON in Drive (not committed).
\end{itemize}

\bookmarksetup{startatroot}

\chapter{Session 1 --- Dev environment \& Colab
workflow}\label{session-1-dev-environment-colab-workflow}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 1 --- Dev environment \& Colab
workflow}\label{session-1-dev-environment-colab-workflow-1}

\subsection{Learning goals}\label{learning-goals}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Mount Google Drive in Colab and work in a persistent course folder.
\item
  Clone a GitHub repo into Drive (or create a project folder if no repo
  yet).
\item
  Create and install from a \textbf{soft‑pinned}
  \texttt{requirements.txt}.
\item
  Verify \textbf{environment info} (Python, OS, library versions) and
  \textbf{GPU availability}.
\item
  Use a \textbf{reproducibility seed} pattern (NumPy + PyTorch) and
  validate it.
\item
  Save a simple \textbf{system check report} to the repo.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min}

\begin{itemize}
\tightlist
\item
  \textbf{(5 min)} Course framing: how we'll work this semester
\item
  \textbf{(12 min)} Slides \& demo: Colab + Drive persistence; project
  folders; soft vs hard pins
\item
  \textbf{(8 min)} Slides \& demo: reproducibility basics (seeds, RNG,
  deterministic ops)
\item
  \textbf{(35 min)} \textbf{In‑class lab} (Colab): mount Drive →
  clone/create project → requirements → environment check →
  reproducibility check → write report
\item
  \textbf{(10 min)} Wrap‑up, troubleshooting, and homework briefing
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Main Points}\label{main-points}

\textbf{Why Colab + Drive}

\begin{itemize}
\tightlist
\item
  Colab gives you GPUs and a clean Python every session.
\item
  The runtime is \textbf{ephemeral}. Anything under \texttt{/content}
  disappears.
\item
  Mount \textbf{Drive} and work under
  \texttt{/content/drive/MyDrive/...} to persist code and outputs.
\end{itemize}

\textbf{Project layout (today's minimal)}

\begin{verbatim}
project/
  reports/
  notebooks/
  data/
  requirements.txt
  system_check.ipynb
\end{verbatim}

(We'll add \texttt{src/}, tests, CI in later sessions.)

\textbf{Pins: soft vs hard}

\begin{itemize}
\tightlist
\item
  \textbf{Soft pins} (e.g.,
  \texttt{pandas\textgreater{}=2.2,\textless{}3.0}) keep you compatible
  across machines.
\item
  \textbf{Hard pins} (exact versions) are for releases. Today we'll use
  \textbf{soft pins}, then \textbf{freeze} to
  \texttt{requirements-lock.txt} in homework.
\end{itemize}

\textbf{Reproducibility basics}

\begin{itemize}
\tightlist
\item
  Fix seeds for \textbf{random}, \textbf{NumPy}, \textbf{PyTorch} (and
  CUDA if present).
\item
  Disable nondeterministic cuDNN behavior for repeatability in simple
  models.
\item
  \textbf{Beware}: some ops remain nondeterministic on GPU; we'll use
  simple ones.
\end{itemize}

\textbf{Minimal Git today}

\begin{itemize}
\tightlist
\item
  If you already have a repo: clone it into G-Drive.
\item
  If not: create a folder; later you can upload the notebook via GitHub
  web UI.
\item
  Full Git workflow (branch/PR/CI) starts next session.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class Lab (35 min)}\label{inclass-lab-35-min}

\begin{quote}
\textbf{Instructor tip:} Put these as sequential Colab cells. Students
should run them top‑to‑bottom. Replace placeholders like
\texttt{YOUR\_USERNAME} / \texttt{YOUR\_REPO} before class if you
already created a starter repo. If not, tell them to use the ``no‑repo''
path in Step 3B.
\end{quote}

\subsection{1) Mount Google Drive and create a course
folder}\label{mount-google-drive-and-create-a-course-folder}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell}
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{COURSE\_DIR }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}  \CommentTok{\# change if you prefer another path}
\NormalTok{PROJECT\_NAME }\OperatorTok{=} \StringTok{"unified{-}stocks"}               \CommentTok{\# course project folder/repo name}
\end{Highlighting}
\end{Shaded}

Save it as \texttt{system\_check.ipynb}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: make directories and cd into project folder}
\ImportTok{import}\NormalTok{ os, pathlib}
\NormalTok{base }\OperatorTok{=}\NormalTok{ pathlib.Path(COURSE\_DIR)}
\NormalTok{proj }\OperatorTok{=}\NormalTok{ base }\OperatorTok{/}\NormalTok{ PROJECT\_NAME  }\CommentTok{\# / is overloaded to create the path}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [base, proj, proj}\OperatorTok{/}\StringTok{"reports"}\NormalTok{, proj}\OperatorTok{/}\StringTok{"notebooks"}\NormalTok{, proj}\OperatorTok{/}\StringTok{"data"}\NormalTok{]:}
\NormalTok{    p.mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\ImportTok{import}\NormalTok{ os}
\NormalTok{os.chdir(proj)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working in:"}\NormalTok{, os.getcwd())}
\end{Highlighting}
\end{Shaded}

\subsection{2) (Optional) If you already have a GitHub repo, clone it
into
Drive}\label{optional-if-you-already-have-a-github-repo-clone-it-into-drive}

\begin{quote}
\textbf{Pick A or B} (not both).
\end{quote}

\textbf{A. Clone an existing repo} (recommended if you created a starter
repo)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: clone via HTTPS (public or your private; for private, you can upload later instead of pushing from Colab) ONLY clone onetime. If run this notebook again, skip this cell. }
\NormalTok{REPO\_URL }\OperatorTok{=} \StringTok{"https://github.com/YOUR\_ORG\_OR\_USERNAME/YOUR\_REPO.git"}  \CommentTok{\# \textless{}{-} change me}
\ImportTok{import}\NormalTok{ subprocess, os}
\NormalTok{os.chdir(base)  }\CommentTok{\# clone next to your project folder}
\NormalTok{subprocess.run([}\StringTok{"git"}\NormalTok{, }\StringTok{"clone"}\NormalTok{, REPO\_URL], check}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\CommentTok{\# check if there is an error inseat of silent. }
\CommentTok{\# Optionally, use that cloned repo as the working directory:(uncomment the lines below if do this)}
\CommentTok{\# REPO\_NAME = REPO\_URL.split("/")[{-}1].replace(".git","")}
\CommentTok{\# os.chdir(base/REPO\_NAME)}
\CommentTok{\# print("Working in:", os.getcwd())}
\NormalTok{os.chdir(proj) }\CommentTok{\# change back to proj dir}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working in:"}\NormalTok{, os.getcwd())}
\end{Highlighting}
\end{Shaded}

\textbf{B. No repo yet? Stay with the folder we created.} You'll upload
files via GitHub web UI after class.

\subsection{\texorpdfstring{3) Create a soft‑pinned
\texttt{requirements.txt} and
install}{3) Create a soft‑pinned requirements.txt and install}}\label{create-a-softpinned-requirements.txt-and-install}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: write a soft{-}pinned requirements.txt}
\NormalTok{req }\OperatorTok{=} \StringTok{"""}\CharTok{\textbackslash{}}
\StringTok{pandas\textgreater{}=2.2,\textless{}3.0}
\StringTok{numpy\textgreater{}=2.0.0,\textless{}3.0}
\StringTok{pyarrow\textgreater{}=15,\textless{}17}
\StringTok{matplotlib\textgreater{}=3.8,\textless{}4.0}
\StringTok{scikit{-}learn\textgreater{}=1.6,\textless{}2.0}
\StringTok{yfinance\textgreater{}=0.2,\textless{}0.3}
\StringTok{python{-}dotenv\textgreater{}=1.0,\textless{}2.0}
\StringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{"requirements.txt"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(req)}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{"requirements.txt"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: install (quietly). Torch is usually preinstalled in Colab; we\textquotesingle{}ll check separately.}
\OperatorTok{!}\NormalTok{pip install }\OperatorTok{{-}}\NormalTok{q }\OperatorTok{{-}}\NormalTok{r requirements.txt}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: PyTorch check. If not available (rare in Colab), install CPU{-}only as a fallback.}
\ControlFlowTok{try}\NormalTok{:}
    \ImportTok{import}\NormalTok{ torch}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"PyTorch:"}\NormalTok{, torch.\_\_version\_\_)}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"PyTorch not found; installing CPU{-}only wheel as fallback..."}\NormalTok{)}
    \OperatorTok{!}\NormalTok{pip install }\OperatorTok{{-}}\NormalTok{q torch}
    \ImportTok{import}\NormalTok{ torch}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"PyTorch:"}\NormalTok{, torch.\_\_version\_\_)}
\end{Highlighting}
\end{Shaded}

\subsection{4) Environment report (Python/OS/lib versions, GPU
availability)}\label{environment-report-pythonoslib-versions-gpu-availability}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: environment info + GPU check}
\ImportTok{import}\NormalTok{ sys, platform, json, time}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{env }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"timestamp"}\NormalTok{: time.strftime(}\StringTok{"\%Y{-}\%m{-}}\SpecialCharTok{\%d}\StringTok{ \%H:\%M:\%S"}\NormalTok{),}
    \StringTok{"python"}\NormalTok{: sys.version,}
    \StringTok{"os"}\NormalTok{: platform.platform(),}
    \StringTok{"pandas"}\NormalTok{: pd.\_\_version\_\_,}
    \StringTok{"numpy"}\NormalTok{: np.\_\_version\_\_,}
\NormalTok{\}}

\ControlFlowTok{try}\NormalTok{:}
    \ImportTok{import}\NormalTok{ torch}
\NormalTok{    env[}\StringTok{"torch"}\NormalTok{] }\OperatorTok{=}\NormalTok{ torch.\_\_version\_\_}
\NormalTok{    env[}\StringTok{"cuda\_available"}\NormalTok{] }\OperatorTok{=} \BuiltInTok{bool}\NormalTok{(torch.cuda.is\_available())}
\NormalTok{    env[}\StringTok{"cuda\_device"}\NormalTok{] }\OperatorTok{=}\NormalTok{ torch.cuda.get\_device\_name(}\DecValTok{0}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"CPU"}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
\NormalTok{    env[}\StringTok{"torch"}\NormalTok{] }\OperatorTok{=} \StringTok{"not importable"}
\NormalTok{    env[}\StringTok{"cuda\_available"}\NormalTok{] }\OperatorTok{=} \VariableTok{False}
\NormalTok{    env[}\StringTok{"cuda\_device"}\NormalTok{] }\OperatorTok{=} \StringTok{"CPU"}

\BuiltInTok{print}\NormalTok{(env)}
\NormalTok{os.makedirs(}\StringTok{"reports"}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"reports/environment.json"}\NormalTok{,}\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    json.dump(env, f, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{5) Reproducibility seed utility + quick
validation}\label{reproducibility-seed-utility-quick-validation}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: reproducibility helpers}
\ImportTok{import}\NormalTok{ random}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\KeywordTok{def}\NormalTok{ set\_seed(seed: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{42}\NormalTok{, deterministic\_torch: }\BuiltInTok{bool} \OperatorTok{=} \VariableTok{True}\NormalTok{):}
\NormalTok{    random.seed(seed)}
\NormalTok{    np.random.seed(seed)}
    \ControlFlowTok{try}\NormalTok{:}
        \ImportTok{import}\NormalTok{ torch}
\NormalTok{        torch.manual\_seed(seed)}
\NormalTok{        torch.cuda.manual\_seed\_all(seed)}
        \ControlFlowTok{if}\NormalTok{ deterministic\_torch:}
\NormalTok{            torch.backends.cudnn.deterministic }\OperatorTok{=} \VariableTok{True}
\NormalTok{            torch.backends.cudnn.benchmark }\OperatorTok{=} \VariableTok{False}
            \ControlFlowTok{try}\NormalTok{:}
\NormalTok{                torch.use\_deterministic\_algorithms(}\VariableTok{True}\NormalTok{)}
            \ControlFlowTok{except} \PreprocessorTok{Exception}\NormalTok{:}
                \ControlFlowTok{pass}
    \ControlFlowTok{except} \PreprocessorTok{Exception}\NormalTok{:}
        \ControlFlowTok{pass}

\KeywordTok{def}\NormalTok{ sample\_rng\_fingerprint(n}\OperatorTok{=}\DecValTok{5}\NormalTok{, seed}\OperatorTok{=}\DecValTok{42}\NormalTok{):}
\NormalTok{    set\_seed(seed)}
\NormalTok{    a }\OperatorTok{=}\NormalTok{ np.random.rand(n).}\BuiltInTok{round}\NormalTok{(}\DecValTok{6}\NormalTok{).tolist()}
    \ControlFlowTok{try}\NormalTok{:}
        \ImportTok{import}\NormalTok{ torch}
\NormalTok{        b }\OperatorTok{=}\NormalTok{ torch.rand(n).tolist()}
\NormalTok{        b }\OperatorTok{=}\NormalTok{ [}\BuiltInTok{round}\NormalTok{(x,}\DecValTok{6}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ b]}
    \ControlFlowTok{except} \PreprocessorTok{Exception}\NormalTok{:}
\NormalTok{        b }\OperatorTok{=}\NormalTok{ [}\StringTok{"torch{-}missing"}\NormalTok{]}\OperatorTok{*}\NormalTok{n}
    \ControlFlowTok{return}\NormalTok{ \{}\StringTok{"numpy"}\NormalTok{: a, }\StringTok{"torch"}\NormalTok{: b\}}

\NormalTok{f1 }\OperatorTok{=}\NormalTok{ sample\_rng\_fingerprint(n}\OperatorTok{=}\DecValTok{6}\NormalTok{, seed}\OperatorTok{=}\DecValTok{123}\NormalTok{)}
\NormalTok{f2 }\OperatorTok{=}\NormalTok{ sample\_rng\_fingerprint(n}\OperatorTok{=}\DecValTok{6}\NormalTok{, seed}\OperatorTok{=}\DecValTok{123}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Fingerprint \#1:"}\NormalTok{, f1)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Fingerprint \#2:"}\NormalTok{, f2)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Match:"}\NormalTok{, f1 }\OperatorTok{==}\NormalTok{ f2)}

\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"reports/seed\_fingerprint.json"}\NormalTok{,}\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    json.dump(\{}\StringTok{"f1"}\NormalTok{: f1, }\StringTok{"f2"}\NormalTok{: f2, }\StringTok{"match"}\NormalTok{: f1}\OperatorTok{==}\NormalTok{f2\}, f, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{6) Create (or verify)
\texttt{tickers\_25.csv} for the
course}{6) Create (or verify) tickers\_25.csv for the course}}\label{create-or-verify-tickers_25.csv-for-the-course}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: create stock list if it doesn\textquotesingle{}t exist yet}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, os}
\NormalTok{tickers }\OperatorTok{=}\NormalTok{ [}
    \StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"META"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{,}\StringTok{"TSLA"}\NormalTok{,}\StringTok{"JPM"}\NormalTok{,}\StringTok{"JNJ"}\NormalTok{,}\StringTok{"V"}\NormalTok{,}
    \StringTok{"PG"}\NormalTok{,}\StringTok{"HD"}\NormalTok{,}\StringTok{"BAC"}\NormalTok{,}\StringTok{"XOM"}\NormalTok{,}\StringTok{"CVX"}\NormalTok{,}\StringTok{"PFE"}\NormalTok{,}\StringTok{"KO"}\NormalTok{,}\StringTok{"DIS"}\NormalTok{,}\StringTok{"NFLX"}\NormalTok{,}\StringTok{"INTC"}\NormalTok{,}
    \StringTok{"CSCO"}\NormalTok{,}\StringTok{"ORCL"}\NormalTok{,}\StringTok{"T"}\NormalTok{,}\StringTok{"VZ"}\NormalTok{,}\StringTok{"WMT"}
\NormalTok{]}
\NormalTok{path }\OperatorTok{=} \StringTok{"tickers\_25.csv"}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ os.path.exists(path):}
\NormalTok{    pd.DataFrame(\{}\StringTok{"ticker"}\NormalTok{: tickers\}).to\_csv(path, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{pd.read\_csv(path).head()}
\end{Highlighting}
\end{Shaded}

\subsection{7) (Optional) Prove GPU works by allocating a small
tensor}\label{optional-prove-gpu-works-by-allocating-a-small-tensor}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: tiny GPU smoke test (safe if CUDA available)}
\ImportTok{import}\NormalTok{ torch, time}

\CommentTok{\# change back to not use deterministic\_algorithm to do the matrix computation}
\CommentTok{\# torch.use\_deterministic\_algorithms(False)}

\NormalTok{device }\OperatorTok{=} \StringTok{"cuda"} \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"cpu"}
\NormalTok{x }\OperatorTok{=}\NormalTok{ torch.randn(}\DecValTok{1000}\NormalTok{, }\DecValTok{1000}\NormalTok{, device}\OperatorTok{=}\NormalTok{device)}
\NormalTok{y }\OperatorTok{=}\NormalTok{ x }\OperatorTok{@}\NormalTok{ x.T}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Device:"}\NormalTok{, device, }\StringTok{"| y shape:"}\NormalTok{, y.shape, }\StringTok{"| mean:"}\NormalTok{, y.}\BuiltInTok{float}\NormalTok{().mean().item())}
\end{Highlighting}
\end{Shaded}

\subsection{8) Save a short Markdown environment
report}\label{save-a-short-markdown-environment-report}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: write a small Markdown summary for humans}
\ImportTok{from}\NormalTok{ textwrap }\ImportTok{import}\NormalTok{ dedent}
\NormalTok{summary }\OperatorTok{=}\NormalTok{ dedent(}\SpecialStringTok{f"""}
\SpecialStringTok{\# System Check}

\SpecialStringTok{{-} Timestamp: }\SpecialCharTok{\{}\NormalTok{env[}\StringTok{\textquotesingle{}timestamp\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}
\SpecialStringTok{{-} Python: \textasciigrave{}}\SpecialCharTok{\{}\NormalTok{env[}\StringTok{\textquotesingle{}python\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{\textasciigrave{}}
\SpecialStringTok{{-} OS: \textasciigrave{}}\SpecialCharTok{\{}\NormalTok{env[}\StringTok{\textquotesingle{}os\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{\textasciigrave{}}
\SpecialStringTok{{-} pandas: \textasciigrave{}}\SpecialCharTok{\{}\NormalTok{env[}\StringTok{\textquotesingle{}pandas\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{\textasciigrave{} | numpy: \textasciigrave{}}\SpecialCharTok{\{}\NormalTok{env[}\StringTok{\textquotesingle{}numpy\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{\textasciigrave{} | torch: \textasciigrave{}}\SpecialCharTok{\{}\NormalTok{env[}\StringTok{\textquotesingle{}torch\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{\textasciigrave{}}
\SpecialStringTok{{-} CUDA available: \textasciigrave{}}\SpecialCharTok{\{}\NormalTok{env[}\StringTok{\textquotesingle{}cuda\_available\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{\textasciigrave{} | Device: \textasciigrave{}}\SpecialCharTok{\{}\NormalTok{env[}\StringTok{\textquotesingle{}cuda\_device\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{\textasciigrave{}}

\SpecialStringTok{\#\# RNG Fingerprint}
\SpecialStringTok{{-} Match on repeated seeds: \textasciigrave{}}\SpecialCharTok{\{}\NormalTok{f1 }\OperatorTok{==}\NormalTok{ f2}\SpecialCharTok{\}}\SpecialStringTok{\textasciigrave{}}
\SpecialStringTok{{-} numpy: \textasciigrave{}}\SpecialCharTok{\{}\NormalTok{f1[}\StringTok{\textquotesingle{}numpy\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{\textasciigrave{}}
\SpecialStringTok{{-} torch: \textasciigrave{}}\SpecialCharTok{\{}\NormalTok{f1[}\StringTok{\textquotesingle{}torch\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{\textasciigrave{}}
\SpecialStringTok{"""}\NormalTok{).strip()}

\BuiltInTok{open}\NormalTok{(}\StringTok{"reports/system\_check.md"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(summary)}
\BuiltInTok{print}\NormalTok{(summary)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Save the file as
\texttt{system\_check.ipynb}. To do it automatically, you can use the
following
code:}{Save the file as system\_check.ipynb. To do it automatically, you can use the following code:}}\label{save-the-file-as-system_check.ipynb.-to-do-it-automatically-you-can-use-the-following-code}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{\# Colab cell: save this notebook as system\_check.ipynb  }
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{  \_message}
\NormalTok{notebook\_name }\OperatorTok{=} \StringTok{"system\_check.ipynb"}
\CommentTok{\# Create the \textquotesingle{}notebooks\textquotesingle{} subdirectory path}
\NormalTok{out\_dir }\OperatorTok{=}\NormalTok{ proj }\OperatorTok{/} \StringTok{"notebooks"}
\NormalTok{out\_path }\OperatorTok{=}\NormalTok{ out\_dir }\OperatorTok{/}\NormalTok{ notebook\_name}

\CommentTok{\# Make sure the folder exists}
\NormalTok{out\_dir.mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Get the CURRENT notebook JSON from Colab}
\NormalTok{resp }\OperatorTok{=}\NormalTok{ \_message.blocking\_request(}\StringTok{\textquotesingle{}get\_ipynb\textquotesingle{}}\NormalTok{, timeout\_sec}\OperatorTok{=}\DecValTok{10}\NormalTok{)}
\NormalTok{nb }\OperatorTok{=}\NormalTok{ resp.get(}\StringTok{\textquotesingle{}ipynb\textquotesingle{}}\NormalTok{) }\ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(resp, }\BuiltInTok{dict}\NormalTok{) }\ControlFlowTok{else} \VariableTok{None}

\CommentTok{\# Basic sanity check: ensure there are cells}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ nb }\KeywordTok{or} \KeywordTok{not} \BuiltInTok{isinstance}\NormalTok{(nb, }\BuiltInTok{dict}\NormalTok{) }\KeywordTok{or} \KeywordTok{not}\NormalTok{ nb.get(}\StringTok{\textquotesingle{}cells\textquotesingle{}}\NormalTok{):}
    \ControlFlowTok{raise} \PreprocessorTok{RuntimeError}\NormalTok{(}\StringTok{"Could not capture the current notebook contents (no cells returned). "}
                       \StringTok{"Try running this cell again after a quick edit, or use File → Save a copy in Drive once."}\NormalTok{)}

\CommentTok{\# Write to Drive}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(out\_path, }\StringTok{\textquotesingle{}w\textquotesingle{}}\NormalTok{, encoding}\OperatorTok{=}\StringTok{\textquotesingle{}utf{-}8\textquotesingle{}}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    json.dump(nb, f, ensure\_ascii}\OperatorTok{=}\VariableTok{False}\NormalTok{, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Saved notebook to:"}\NormalTok{, out\_path)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{What to submit after class (if you already have a GitHub repo):}
For today, students may \textbf{upload} \texttt{system\_check.ipynb},
\texttt{reports/environment.json}, and \texttt{reports/system\_check.md}
via the GitHub web UI (Add file → Upload files). We'll do proper
pushes/PRs next session.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Troubleshooting notes (share in
class)}\label{troubleshooting-notes-share-in-class}

\begin{itemize}
\tightlist
\item
  \textbf{Drive won't mount}: Refresh the Colab tab, run the mount cell
  again, re‑authorize Google permissions.
\item
  \textbf{\texttt{pip\ install} hangs}: Rerun; if it persists, restart
  runtime (Runtime → Restart session) and re‑run from the top.
\item
  \textbf{PyTorch mismatch}: If Colab has Torch preinstalled, don't
  upgrade it. If you installed a CPU wheel by mistake and want GPU
  later, it's usually easiest to \textbf{restart runtime}.
\item
  \textbf{Path confusion}: Print \texttt{os.getcwd()} often; ensure
  you're inside your project folder under
  \texttt{/content/drive/MyDrive/...}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
2)}\label{homework-due-before-session-2}

\textbf{Goal:} Produce a \textbf{reproducible system snapshot} and a
\textbf{seed‑verified mini experiment}, then upload to your repo (via
GitHub web UI if you're not comfortable pushing yet).

\subsection{Part A --- Freeze your
environment}\label{part-a-freeze-your-environment}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  From the same Colab runtime (after installing), create a lock file:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: freeze exact versions}
\OperatorTok{!}\NormalTok{pip freeze }\OperatorTok{\textgreater{}}\NormalTok{ requirements}\OperatorTok{{-}}\NormalTok{lock.txt}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote requirements{-}lock.txt with exact versions"}\NormalTok{)}
\OperatorTok{!}\NormalTok{head }\OperatorTok{{-}}\NormalTok{n }\DecValTok{20}\NormalTok{ requirements}\OperatorTok{{-}}\NormalTok{lock.txt}
\end{Highlighting}
\end{Shaded}
\item
  Add a note to \texttt{README.md} explaining the difference between:

  \begin{itemize}
  \tightlist
  \item
    \texttt{requirements.txt} (soft pins for development) and
  \item
    \texttt{requirements-lock.txt} (exact versions used \textbf{today}).
  \end{itemize}
\end{enumerate}

\subsection{Part B --- Reproducibility
mini‑experiment}\label{part-b-reproducibility-miniexperiment}

Create \texttt{notebooks/reproducibility\_demo.ipynb} with the following
cells (students copy/paste):

\textbf{1) Setup \& data generation}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, torch, random, json, os, time}

\KeywordTok{def}\NormalTok{ set\_seed(seed}\OperatorTok{=}\DecValTok{123}\NormalTok{):}
\NormalTok{    random.seed(seed)}
\NormalTok{    np.random.seed(seed)}
\NormalTok{    torch.manual\_seed(seed)}
\NormalTok{    torch.cuda.manual\_seed\_all(seed)}
\NormalTok{    torch.backends.cudnn.deterministic }\OperatorTok{=} \VariableTok{True}
\NormalTok{    torch.backends.cudnn.benchmark }\OperatorTok{=} \VariableTok{False}
    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        torch.use\_deterministic\_algorithms(}\VariableTok{True}\NormalTok{)}
    \ControlFlowTok{except} \PreprocessorTok{Exception}\NormalTok{:}
        \ControlFlowTok{pass}

\KeywordTok{def}\NormalTok{ make\_toy(n}\OperatorTok{=}\DecValTok{512}\NormalTok{, d}\OperatorTok{=}\DecValTok{10}\NormalTok{, noise}\OperatorTok{=}\FloatTok{0.1}\NormalTok{, seed}\OperatorTok{=}\DecValTok{123}\NormalTok{):}
\NormalTok{    set\_seed(seed)}
\NormalTok{    X }\OperatorTok{=}\NormalTok{ torch.randn(n, d)}
\NormalTok{    true\_w }\OperatorTok{=}\NormalTok{ torch.randn(d, }\DecValTok{1}\NormalTok{)}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ X }\OperatorTok{@}\NormalTok{ true\_w }\OperatorTok{+}\NormalTok{ noise }\OperatorTok{*}\NormalTok{ torch.randn(n, }\DecValTok{1}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ X, y, true\_w}

\NormalTok{device }\OperatorTok{=} \StringTok{"cuda"} \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"cpu"}
\NormalTok{X, y, true\_w }\OperatorTok{=}\NormalTok{ make\_toy()}
\NormalTok{X, y }\OperatorTok{=}\NormalTok{ X.to(device), y.to(device)}
\end{Highlighting}
\end{Shaded}

\textbf{2) Minimal training loop (linear model)}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ train\_once(lr}\OperatorTok{=}\FloatTok{0.05}\NormalTok{, steps}\OperatorTok{=}\DecValTok{300}\NormalTok{, seed}\OperatorTok{=}\DecValTok{123}\NormalTok{):}
\NormalTok{    set\_seed(seed)}
\NormalTok{    model }\OperatorTok{=}\NormalTok{ torch.nn.Linear(X.shape[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{).to(device)}
\NormalTok{    opt }\OperatorTok{=}\NormalTok{ torch.optim.SGD(model.parameters(), lr}\OperatorTok{=}\NormalTok{lr)}
\NormalTok{    loss\_fn }\OperatorTok{=}\NormalTok{ torch.nn.MSELoss()}
\NormalTok{    losses}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(steps):}
\NormalTok{        opt.zero\_grad(set\_to\_none}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        yhat }\OperatorTok{=}\NormalTok{ model(X)}
\NormalTok{        loss }\OperatorTok{=}\NormalTok{ loss\_fn(yhat, y)}
\NormalTok{        loss.backward()}
\NormalTok{        opt.step()}
\NormalTok{        losses.append(loss.item())}
    \ControlFlowTok{return}\NormalTok{ model.weight.detach().cpu().numpy(), losses[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}

\NormalTok{w1, final\_loss1 }\OperatorTok{=}\NormalTok{ train\_once(seed}\OperatorTok{=}\DecValTok{2025}\NormalTok{)}
\NormalTok{w2, final\_loss2 }\OperatorTok{=}\NormalTok{ train\_once(seed}\OperatorTok{=}\DecValTok{2025}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Final loss 1:"}\NormalTok{, }\BuiltInTok{round}\NormalTok{(final\_loss1, }\DecValTok{6}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Final loss 2:"}\NormalTok{, }\BuiltInTok{round}\NormalTok{(final\_loss2, }\DecValTok{6}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Weights equal:"}\NormalTok{, np.allclose(w1, w2, atol}\OperatorTok{=}\FloatTok{1e{-}7}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\textbf{3) Save results JSON}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{os.makedirs(}\StringTok{"reports"}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{result }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"device"}\NormalTok{: device,}
    \StringTok{"final\_loss1"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(final\_loss1),}
    \StringTok{"final\_loss2"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(final\_loss2),}
    \StringTok{"weights\_equal"}\NormalTok{: }\BuiltInTok{bool}\NormalTok{(np.allclose(w1, w2, atol}\OperatorTok{=}\FloatTok{1e{-}7}\NormalTok{)),}
    \StringTok{"timestamp"}\NormalTok{: time.strftime(}\StringTok{"\%Y{-}\%m{-}}\SpecialCharTok{\%d}\StringTok{ \%H:\%M:\%S"}\NormalTok{)}
\NormalTok{\}}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"reports/reproducibility\_results.json"}\NormalTok{,}\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    json.dump(result, f, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{result}
\end{Highlighting}
\end{Shaded}

\textbf{Expected outcome:} the two runs with the same seed should
produce the \textbf{same final loss} and \textbf{identical weights}
(within tolerance). If on GPU, deterministic settings should keep this
stable for this simple model.

\subsection{\texorpdfstring{Part C --- Add a
\texttt{.env.example}}{Part C --- Add a .env.example}}\label{part-c-add-a-.env.example}

Create a placeholder for API keys we'll use later:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{env\_example }\OperatorTok{=} \StringTok{"""}\CharTok{\textbackslash{}}
\StringTok{\# Example environment variables (do NOT commit a real .env with secrets)}
\StringTok{ALPHA\_VANTAGE\_KEY=}
\StringTok{FRED\_API\_KEY=}
\StringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{".env.example"}\NormalTok{, }\StringTok{"w"}\NormalTok{).write(env\_example)}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{".env.example"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

\subsection{Part D --- Upload to GitHub}\label{part-d-upload-to-github}

Until we set up pushes/PRs next class, use the GitHub web UI:

\begin{itemize}
\tightlist
\item
  Upload: \texttt{system\_check.ipynb},
  \texttt{reports/environment.json}, \texttt{reports/system\_check.md},
  \texttt{requirements.txt}, \texttt{requirements-lock.txt},
  \texttt{notebooks/reproducibility\_demo.ipynb},
  \texttt{reports/reproducibility\_results.json}, \texttt{.env.example}.
\item
  If you already cloned a repo in class and are comfortable pushing, you
  may push from your laptop instead. \textbf{Do not paste tokens into
  notebooks.}
\end{itemize}

\subsection{Grading (pass/revise)}\label{grading-passrevise}

\begin{itemize}
\tightlist
\item
  \texttt{requirements.txt} present; \texttt{requirements-lock.txt}
  present and non‑empty.
\item
  \texttt{system\_check.ipynb} runs and writes
  \texttt{reports/system\_check.md} + \texttt{environment.json}.
\item
  \texttt{reproducibility\_demo.ipynb} demonstrates identical results
  across repeated runs with same seed and writes
  \texttt{reports/reproducibility\_results.json}.
\item
  \texttt{.env.example} present with placeholders.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{What to emphasize}\label{what-to-emphasize}

\begin{itemize}
\tightlist
\item
  ``Colab is \textbf{ephemeral}; persist to \textbf{Drive}.''
\item
  ``Soft pins now; \textbf{freeze} later.''
\item
  ``Seeds are necessary but not sufficient---watch for nondeterministic
  ops.''
\item
  ``Never store secrets (API keys) in the repo; use \texttt{.env} and
  keep a \texttt{.env.example}.''
\end{itemize}

That's it for Session 1. In Session 2 we'll set up \textbf{Git basics
and Git‑LFS} and move from uploading via web UI to \textbf{branch/PR}
workflows.

\bookmarksetup{startatroot}

\chapter{Session 2 --- Git essentials \&
Git‑LFS}\label{session-2-git-essentials-gitlfs}

\begin{quote}
\textbf{Security note:} Today we'll push from Colab using a
\textbf{short‑lived GitHub personal access token (PAT)} entered
interactively. \textbf{Never} hard‑code or commit tokens.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 2 --- Git essentials \& Git‑LFS (75
min)}\label{session-2-git-essentials-gitlfs-75-min}

\subsection{Learning goals}\label{learning-goals-1}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain Git's mental model: working directory → staging → commit;
  branches and remotes.
\item
  Create a feature branch, commit changes, and push to GitHub from Colab
  safely.
\item
  Use \textbf{.gitignore} to avoid committing generated artifacts and
  secrets.
\item
  Install and configure \textbf{Git‑LFS}, track large/binary files, and
  verify tracking.
\item
  Open a \textbf{pull request (PR)} and follow review etiquette.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 minutes)}\label{agenda-75-minutes}

\begin{itemize}
\tightlist
\item
  \textbf{(8 min)} Recap \& goals; overview of today's workflow
\item
  \textbf{(12 min)} Slides: Git mental model; branches; remotes; commit
  hygiene
\item
  \textbf{(10 min)} Slides: \texttt{.gitignore} must‑haves; Git‑LFS
  (when/why); LFS quotas \& pitfalls
\item
  \textbf{(35 min)} \textbf{In‑class lab}: clone → config → branch →
  \texttt{.gitignore} → LFS → sample Parquet → push → PR
\item
  \textbf{(10 min)} Wrap‑up; troubleshooting; homework briefing
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Main points}\label{main-points-1}

\subsection{Git mental model}\label{git-mental-model}

\begin{itemize}
\tightlist
\item
  \textbf{Working directory} (your files) → \texttt{git\ add} →
  \textbf{staging} → \texttt{git\ commit} → \textbf{local history}
\item
  \textbf{Remote}: GitHub hosts a copy. \texttt{git\ push} publishes
  commits; \texttt{git\ pull} brings others' changes.
\item
  \textbf{Branch}: a movable pointer to a chain of commits. Default is
  \texttt{main}. Create \textbf{feature branches} for each change.
\end{itemize}

\subsection{Branch \& PR etiquette}\label{branch-pr-etiquette}

\begin{itemize}
\item
  One feature/change per branch (small, reviewable diffs).
\item
  Commit messages: \emph{imperative mood}, short subject line (≤ 72
  chars), details in body if needed:

  \begin{itemize}
  \tightlist
  \item
    \texttt{feat:\ add\ git-lfs\ tracking\ for\ parquet}
  \item
    \texttt{docs:\ add\ README\ section\ on\ setup}
  \item
    \texttt{chore:\ ignore\ raw\ data\ directory}
  \end{itemize}
\item
  PR description: what/why, testing notes, checklist. Tag your teammate
  for review.
\end{itemize}

\subsection{\texorpdfstring{\texttt{.gitignore}
must‑haves}{.gitignore must‑haves}}\label{gitignore-musthaves}

\begin{itemize}
\tightlist
\item
  \textbf{Secrets}: \texttt{.env}, API keys (never commit).
\item
  \textbf{Large/derived artifacts}: raw/interim data, logs, cache,
  compiled assets.
\item
  \textbf{Notebooks' checkpoints}: \texttt{.ipynb\_checkpoints/}.
\item
  OS/editor cruft: \texttt{.DS\_Store}, \texttt{Thumbs.db},
  \texttt{.vscode/}.
\end{itemize}

\subsection{Git‑LFS}\label{gitlfs}

\begin{itemize}
\tightlist
\item
  Git‑LFS = Large File Storage. Keeps \textbf{pointers} in Git; binaries
  in LFS storage.
\item
  Track only what's necessary to version (e.g., \emph{small} processed
  Parquet samples, posters/PDFs, small models).
\item
  \textbf{Do not} LFS huge raw data you can re‑download
  (\texttt{make\ get-data}).
\item
  Quotas apply on Git hosting---be selective.
\end{itemize}

\subsection{Safe pushes from Colab}\label{safe-pushes-from-colab}

\begin{itemize}
\tightlist
\item
  Use a \textbf{fine‑grained PAT} limited to a single repo with
  \textbf{Contents: Read/Write} + \textbf{Pull requests: Read/Write}.
\item
  Enter token via \texttt{getpass} (not stored). Push using a
  \textbf{temporary URL} (token not saved in \texttt{git\ config}).
\item
  After push, \textbf{clear cell output}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min)}\label{inclass-lab-35-min-1}

\begin{quote}
\textbf{Instructor tip:} Students should have created a repo on GitHub
before this lab (e.g., \texttt{unified-stocks-teamX}). If not, give them
3 minutes to do so and add their partner as a collaborator.
\end{quote}

We'll:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Mount Drive \& clone the repo.
\item
  Configure Git identity.
\item
  Create a feature branch.
\item
  Add \texttt{.gitignore}.
\item
  Install and configure \textbf{Git‑LFS}.
\item
  Track Parquet \& DB files; generate a \textbf{sample Parquet}.
\item
  Commit \& \textbf{push from Colab} using a short‑lived PAT.
\item
  Open a PR (via web UI, optional API snippet included).
\end{enumerate}

\subsection{0) Mount Google Drive and set
variables}\label{mount-google-drive-and-set-variables}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell}
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Adjust these two for YOUR repo}
\NormalTok{REPO\_OWNER }\OperatorTok{=} \StringTok{"YOUR\_GITHUB\_USERNAME\_OR\_ORG"}
\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}   \CommentTok{\# e.g., unified{-}stocks{-}team1}

\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{CLONE\_DIR  }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}
\NormalTok{REPO\_URL   }\OperatorTok{=} \SpecialStringTok{f"https://github.com/}\SpecialCharTok{\{}\NormalTok{REPO\_OWNER}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{.git"}

\ImportTok{import}\NormalTok{ os, pathlib}
\NormalTok{pathlib.Path(BASE\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{1) Clone the repo (or pull latest if already
cloned)}\label{clone-the-repo-or-pull-latest-if-already-cloned}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ os, subprocess, shutil, pathlib}

\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ pathlib.Path(CLONE\_DIR).exists():}
    \OperatorTok{!}\NormalTok{git clone \{REPO\_URL\} \{CLONE\_DIR\}}
\ControlFlowTok{else}\NormalTok{:}
    \CommentTok{\# If the folder exists, just ensure it\textquotesingle{}s a git repo and pull latest}
\NormalTok{    os.chdir(CLONE\_DIR)}
    \OperatorTok{!}\NormalTok{git status}
    \OperatorTok{!}\NormalTok{git pull }\OperatorTok{{-}{-}}\NormalTok{ff}\OperatorTok{{-}}\NormalTok{only}
\NormalTok{os.chdir(CLONE\_DIR)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}
\end{Highlighting}
\end{Shaded}

\subsection{2) Configure Git identity (local to this
repo)}\label{configure-git-identity-local-to-this-repo}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Replace with your name and school email}
\OperatorTok{!}\NormalTok{git config user.name }\StringTok{"Your Name"}
\OperatorTok{!}\NormalTok{git config user.email }\StringTok{"you@example.edu"}

\OperatorTok{!}\NormalTok{git config }\OperatorTok{{-}{-}}\NormalTok{get user.name}
\OperatorTok{!}\NormalTok{git config }\OperatorTok{{-}{-}}\NormalTok{get user.email}
\end{Highlighting}
\end{Shaded}

\subsection{3) Create and switch to a feature
branch}\label{create-and-switch-to-a-feature-branch}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{BRANCH }\OperatorTok{=} \StringTok{"setup/git{-}lfs"}
\OperatorTok{!}\NormalTok{git checkout }\OperatorTok{{-}}\NormalTok{b \{BRANCH\}}
\OperatorTok{!}\NormalTok{git branch }\OperatorTok{{-}{-}}\NormalTok{show}\OperatorTok{{-}}\NormalTok{current}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) Add a robust
\texttt{.gitignore}}{4) Add a robust .gitignore}}\label{add-a-robust-.gitignore}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gitignore }\OperatorTok{=} \StringTok{"""}\CharTok{\textbackslash{}}
\StringTok{\# Byte{-}compiled / cache}
\StringTok{\_\_pycache\_\_/}
\StringTok{*.py[cod]}

\StringTok{\# Jupyter checkpoints}
\StringTok{.ipynb\_checkpoints/}

\StringTok{\# OS/editor files}
\StringTok{.DS\_Store}
\StringTok{Thumbs.db}
\StringTok{.vscode/}

\StringTok{\# Environments \& secrets}
\StringTok{.env}
\StringTok{.env.*}
\StringTok{.venv/}
\StringTok{*.pem}
\StringTok{*.key}

\StringTok{\# Data (raw \& interim never committed)}
\StringTok{data/raw/}
\StringTok{data/interim/}

\StringTok{\# Logs \& caches}
\StringTok{logs/}
\StringTok{.cache/}
\StringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{".gitignore"}\NormalTok{, }\StringTok{"w"}\NormalTok{).write(gitignore)}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{".gitignore"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

\subsection{5) Install and initialize Git‑LFS
(Colab)}\label{install-and-initialize-gitlfs-colab}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Install git{-}lfs on the Colab VM (one{-}time per runtime)}
\OperatorTok{!}\NormalTok{apt}\OperatorTok{{-}}\NormalTok{get }\OperatorTok{{-}}\NormalTok{y update }\OperatorTok{\textgreater{}/}\NormalTok{dev}\OperatorTok{/}\NormalTok{null}
\OperatorTok{!}\NormalTok{apt}\OperatorTok{{-}}\NormalTok{get }\OperatorTok{{-}}\NormalTok{y install git}\OperatorTok{{-}}\NormalTok{lfs }\OperatorTok{\textgreater{}/}\NormalTok{dev}\OperatorTok{/}\NormalTok{null}
\OperatorTok{!}\NormalTok{git lfs install}
\OperatorTok{!}\NormalTok{git lfs version}
\end{Highlighting}
\end{Shaded}

\subsection{6) Track Parquet/DB/PDF/model binaries with
LFS}\label{track-parquetdbpdfmodel-binaries-with-lfs}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Add .gitattributes entries via git lfs track}
\OperatorTok{!}\NormalTok{git lfs track }\StringTok{"data/processed/*.parquet"}
\OperatorTok{!}\NormalTok{git lfs track }\StringTok{"data/*.db"}
\OperatorTok{!}\NormalTok{git lfs track }\StringTok{"models/*.pt"}
\OperatorTok{!}\NormalTok{git lfs track }\StringTok{"reports/*.pdf"}

\CommentTok{\# Show what LFS is tracking and verify .gitattributes created}
\OperatorTok{!}\NormalTok{git lfs track}
\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{.gitattributes:"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{".gitattributes"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Why not LFS for raw?} Raw data should be
\textbf{re‑downloadable} with \texttt{make\ get-data} later; don't burn
LFS quota.
\end{quote}

\subsection{7) Create a small Parquet file to test
LFS}\label{create-a-small-parquet-file-to-test-lfs}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np, os, pathlib}

\NormalTok{pathlib.Path(}\StringTok{"data/processed"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{tickers }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"tickers\_25.csv"}\NormalTok{)[}\StringTok{"ticker"}\NormalTok{].tolist() }\ControlFlowTok{if}\NormalTok{ os.path.exists(}\StringTok{"tickers\_25.csv"}\NormalTok{) }\ControlFlowTok{else}\NormalTok{ [}
    \StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"META"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{,}\StringTok{"TSLA"}\NormalTok{,}\StringTok{"JPM"}\NormalTok{,}\StringTok{"JNJ"}\NormalTok{,}\StringTok{"V"}\NormalTok{,}
    \StringTok{"PG"}\NormalTok{,}\StringTok{"HD"}\NormalTok{,}\StringTok{"BAC"}\NormalTok{,}\StringTok{"XOM"}\NormalTok{,}\StringTok{"CVX"}\NormalTok{,}\StringTok{"PFE"}\NormalTok{,}\StringTok{"KO"}\NormalTok{,}\StringTok{"DIS"}\NormalTok{,}\StringTok{"NFLX"}\NormalTok{,}\StringTok{"INTC"}\NormalTok{,}\StringTok{"CSCO"}\NormalTok{,}\StringTok{"ORCL"}\NormalTok{,}\StringTok{"T"}\NormalTok{,}\StringTok{"VZ"}\NormalTok{,}\StringTok{"WMT"}
\NormalTok{]}

\CommentTok{\# 1000 business days x up to 25 tickers \textasciitilde{} 25k rows; a few MB as Parquet}
\NormalTok{dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2018{-}01{-}01"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{1000}\NormalTok{)}
\NormalTok{df }\OperatorTok{=}\NormalTok{ (pd.MultiIndex.from\_product([tickers, dates], names}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
\NormalTok{      .to\_frame(index}\OperatorTok{=}\VariableTok{False}\NormalTok{))}
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{42}\NormalTok{)}
\NormalTok{df[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.01}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(df))  }\CommentTok{\# synthetic daily returns}
\NormalTok{df.to\_parquet(}\StringTok{"data/processed/sample\_returns.parquet"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{df.head()}
\end{Highlighting}
\end{Shaded}

\subsection{8) Stage and commit changes}\label{stage-and-commit-changes}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{git add .gitignore .gitattributes data}\OperatorTok{/}\NormalTok{processed}\OperatorTok{/}\NormalTok{sample\_returns.parquet}
\OperatorTok{!}\NormalTok{git status}

\OperatorTok{!}\NormalTok{git commit }\OperatorTok{{-}}\NormalTok{m }\StringTok{"feat: add .gitignore and git{-}lfs tracking; add sample Parquet"}
\OperatorTok{!}\NormalTok{git log }\OperatorTok{{-}{-}}\NormalTok{oneline }\OperatorTok{{-}}\NormalTok{n }\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{9) \textbf{Push from Colab with a
short‑lived token (safe
method)}}{9) Push from Colab with a short‑lived token (safe method)}}\label{push-from-colab-with-a-shortlived-token-safe-method}

\begin{quote}
Create a \textbf{fine‑grained PAT} at GitHub → Settings → Developer
settings → \textbf{Fine‑grained tokens}

\begin{itemize}
\tightlist
\item
  Resource owner: your username/org
\item
  Repositories: select \textbf{this repo only}
\item
  Permissions: \textbf{Contents (Read/Write)}, \textbf{Pull requests
  (Read/Write)}
\item
  Expiration: short (e.g., 7 days)
\end{itemize}
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Colab cell: push using a temporary URL with token (not saved to git config)}
\ImportTok{from}\NormalTok{ getpass }\ImportTok{import}\NormalTok{ getpass}
\NormalTok{token }\OperatorTok{=}\NormalTok{ getpass(}\StringTok{"Enter your GitHub token (input hidden; not stored): "}\NormalTok{)}

\NormalTok{push\_url }\OperatorTok{=} \SpecialStringTok{f"https://}\SpecialCharTok{\{}\NormalTok{token}\SpecialCharTok{\}}\SpecialStringTok{@github.com/}\SpecialCharTok{\{}\NormalTok{REPO\_OWNER}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{.git"}
\OperatorTok{!}\NormalTok{git push \{push\_url\} \{BRANCH\}:\{BRANCH\}}

\CommentTok{\# Optional: immediately clear the token variable}
\KeywordTok{del}\NormalTok{ token}
\end{Highlighting}
\end{Shaded}

\begin{quote}
If the command prints the URL, \textbf{clear this cell's output} after a
successful push (Colab: ``⋮'' → ``Clear output'').
\end{quote}

\subsection{10) Open a Pull Request}\label{open-a-pull-request}

\begin{itemize}
\item
  \textbf{Recommended (web UI):} Navigate to your repo on GitHub →
  Compare \& pull request → base: \texttt{main}, compare:
  \texttt{setup/git-lfs}. Fill title/description, tag your partner, and
  create the PR.
\item
  \textbf{Optional (API):} open a PR programmatically from Colab:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# OPTIONAL: Create PR via GitHub API (requires token again)}
\ImportTok{from}\NormalTok{ getpass }\ImportTok{import}\NormalTok{ getpass}
\ImportTok{import}\NormalTok{ requests, json}

\NormalTok{token }\OperatorTok{=}\NormalTok{ getpass(}\StringTok{"GitHub token (again, not stored): "}\NormalTok{)}
\NormalTok{headers }\OperatorTok{=}\NormalTok{ \{}\StringTok{"Authorization"}\NormalTok{: }\SpecialStringTok{f"Bearer }\SpecialCharTok{\{}\NormalTok{token}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}
           \StringTok{"Accept"}\NormalTok{: }\StringTok{"application/vnd.github+json"}\NormalTok{\}}
\NormalTok{payload }\OperatorTok{=}\NormalTok{ \{}
    \StringTok{"title"}\NormalTok{: }\StringTok{"Setup: .gitignore + Git{-}LFS + sample Parquet"}\NormalTok{,}
    \StringTok{"head"}\NormalTok{: BRANCH,}
    \StringTok{"base"}\NormalTok{: }\StringTok{"main"}\NormalTok{,}
    \StringTok{"body"}\NormalTok{: }\StringTok{"Adds .gitignore, configures Git{-}LFS for parquet/db/pdf/model files, and commits a sample Parquet for verification."}
\NormalTok{\}}
\NormalTok{r }\OperatorTok{=}\NormalTok{ requests.post(}\SpecialStringTok{f"https://api.github.com/repos/}\SpecialCharTok{\{}\NormalTok{REPO\_OWNER}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{/pulls"}\NormalTok{,}
\NormalTok{                  headers}\OperatorTok{=}\NormalTok{headers, data}\OperatorTok{=}\NormalTok{json.dumps(payload))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"PR status:"}\NormalTok{, r.status\_code)}
\ControlFlowTok{try}\NormalTok{:}
\NormalTok{    pr\_url }\OperatorTok{=}\NormalTok{ r.json()[}\StringTok{"html\_url"}\NormalTok{]}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"PR URL:"}\NormalTok{, pr\_url)}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Response:"}\NormalTok{, r.text)}
\KeywordTok{del}\NormalTok{ token}
\end{Highlighting}
\end{Shaded}

\subsection{11) Quick verification
checklist}\label{quick-verification-checklist}

\begin{itemize}
\tightlist
\item
  \texttt{git\ lfs\ ls-files} shows
  \texttt{data/processed/sample\_returns.parquet}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{git lfs ls}\OperatorTok{{-}}\NormalTok{files}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  PR diff shows a small \textbf{pointer} for the Parquet, not raw binary
  content.
\item
  \texttt{.gitignore} present; no secrets or raw data committed.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (talking points, 10
min)}\label{wrapup-talking-points-10-min}

\begin{itemize}
\tightlist
\item
  Keep PRs small and focused; write helpful titles and descriptions.
\item
  Don't commit secrets or large data. Use \texttt{.env} +
  \texttt{.env.example}.
\item
  Use LFS \emph{selectively}---version only small, important binaries
  (e.g., sample processed sets, posters).
\item
  Next time: \textbf{Quarto} polish (already started) and \textbf{Unix}
  automation to fetch raw data reproducibly.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
3)}\label{homework-due-before-session-3}

\textbf{Goal:} Cement branch/PR hygiene, add review scaffolding, and add
a small guard against large files accidentally committed outside LFS.

\subsection{Part A --- Add a PR template and
CODEOWNERS}\label{part-a-add-a-pr-template-and-codeowners}

Create a PR template so every PR includes key info.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Run in your repo root}
\ImportTok{import}\NormalTok{ os, pathlib, textwrap}
\NormalTok{pathlib.Path(}\StringTok{".github"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{tpl }\OperatorTok{=}\NormalTok{ textwrap.dedent(}\StringTok{"""}\CharTok{\textbackslash{}}
\StringTok{    \#\# Summary}
\StringTok{    What does this PR do and why?}

\StringTok{    \#\# Changes}
\StringTok{    {-} }

\StringTok{    \#\# How to test}
\StringTok{    {-} From a fresh clone: steps to run}

\StringTok{    \#\# Checklist}
\StringTok{    {-} [ ] Runs from a fresh clone (README steps)}
\StringTok{    {-} [ ] No secrets committed; \textasciigrave{}.env\textasciigrave{} only (and \textasciigrave{}.env.example\textasciigrave{} updated if needed)}
\StringTok{    {-} [ ] Large artifacts tracked by LFS (\textasciigrave{}git lfs ls{-}files\textasciigrave{} shows expected files)}
\StringTok{    {-} [ ] Clear, small diff; comments where useful}
\StringTok{"""}\NormalTok{)}
\BuiltInTok{open}\NormalTok{(}\StringTok{".github/pull\_request\_template.md"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(tpl)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote .github/pull\_request\_template.md"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

(Optional) Require both teammates to review by setting
\textbf{CODEOWNERS} (edit handles):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{owners }\OperatorTok{=} \StringTok{"""}\CharTok{\textbackslash{}}
\StringTok{\# Replace with your GitHub handles}
\StringTok{* @teammate1 @teammate2}
\StringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{".github/CODEOWNERS"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(owners)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote .github/CODEOWNERS (edit handles!)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Commit and push on a new branch (example: \texttt{chore/pr-template}),
open a PR, and merge after review.

\subsection{Part B --- Add a large‑file guard (simple Python
script)}\label{part-b-add-a-largefile-guard-simple-python-script}

Create a small tool that \textbf{fails} if files \textgreater{} 10 MB
are found \textbf{and} aren't tracked by LFS. This will be used manually
for now (automation later in CI).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tools/guard\_large\_files.py}
\ImportTok{import}\NormalTok{ os, subprocess, sys}

\NormalTok{LIMIT\_MB }\OperatorTok{=} \DecValTok{10}
\NormalTok{ROOT }\OperatorTok{=}\NormalTok{ os.getcwd()}

\KeywordTok{def}\NormalTok{ lfs\_tracked\_paths():}
    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        out }\OperatorTok{=}\NormalTok{ subprocess.check\_output([}\StringTok{"git"}\NormalTok{, }\StringTok{"lfs"}\NormalTok{, }\StringTok{"ls{-}files"}\NormalTok{], text}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        tracked }\OperatorTok{=} \BuiltInTok{set}\NormalTok{()}
        \ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ out.strip().splitlines():}
            \CommentTok{\# line format: "\textless{}oid\textgreater{} \textless{}path\textgreater{}"}
\NormalTok{            p }\OperatorTok{=}\NormalTok{ line.split(}\VariableTok{None}\NormalTok{, }\DecValTok{1}\NormalTok{)[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].strip()}
\NormalTok{            tracked.add(os.path.normpath(p))}
        \ControlFlowTok{return}\NormalTok{ tracked}
    \ControlFlowTok{except} \PreprocessorTok{Exception}\NormalTok{:}
        \ControlFlowTok{return} \BuiltInTok{set}\NormalTok{()}

\KeywordTok{def}\NormalTok{ humanize(bytes\_):}
    \ControlFlowTok{return} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{bytes\_}\OperatorTok{/}\NormalTok{(}\DecValTok{1024}\OperatorTok{*}\DecValTok{1024}\NormalTok{)}\SpecialCharTok{:.2f\}}\SpecialStringTok{ MB"}

\NormalTok{lfs\_set }\OperatorTok{=}\NormalTok{ lfs\_tracked\_paths()}
\NormalTok{bad }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ dirpath, dirnames, filenames }\KeywordTok{in}\NormalTok{ os.walk(ROOT):}
    \CommentTok{\# skip .git directory}
    \ControlFlowTok{if} \StringTok{".git"} \KeywordTok{in}\NormalTok{ dirpath.split(os.sep):}
        \ControlFlowTok{continue}
    \ControlFlowTok{for}\NormalTok{ fn }\KeywordTok{in}\NormalTok{ filenames:}
\NormalTok{        path }\OperatorTok{=}\NormalTok{ os.path.normpath(os.path.join(dirpath, fn))}
        \ControlFlowTok{try}\NormalTok{:}
\NormalTok{            size }\OperatorTok{=}\NormalTok{ os.path.getsize(path)}
        \ControlFlowTok{except} \PreprocessorTok{FileNotFoundError}\NormalTok{:}
            \ControlFlowTok{continue}
        \ControlFlowTok{if}\NormalTok{ size }\OperatorTok{\textgreater{}=}\NormalTok{ LIMIT\_MB }\OperatorTok{*} \DecValTok{1024} \OperatorTok{*} \DecValTok{1024}\NormalTok{:}
\NormalTok{            rel }\OperatorTok{=}\NormalTok{ os.path.relpath(path, ROOT)}
            \ControlFlowTok{if}\NormalTok{ rel }\KeywordTok{not} \KeywordTok{in}\NormalTok{ lfs\_set:}
\NormalTok{                bad.append((rel, size))}

\ControlFlowTok{if}\NormalTok{ bad:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"ERROR: Large non{-}LFS files found:"}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ rel, size }\KeywordTok{in}\NormalTok{ bad:}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f" {-} }\SpecialCharTok{\{}\NormalTok{rel}\SpecialCharTok{\}}\SpecialStringTok{ (}\SpecialCharTok{\{}\NormalTok{humanize(size)}\SpecialCharTok{\}}\SpecialStringTok{)"}\NormalTok{)}
\NormalTok{    sys.exit(}\DecValTok{1}\NormalTok{)}
\ControlFlowTok{else}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"OK: No large non{-}LFS files detected."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Add a Makefile target to run it:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create/append Makefile target}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{text }\OperatorTok{=} \StringTok{"}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{guard:}\CharTok{\textbackslash{}n\textbackslash{}t}\StringTok{python tools/guard\_large\_files.py}\CharTok{\textbackslash{}n}\StringTok{"}
\NormalTok{p }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"Makefile"}\NormalTok{)}
\NormalTok{p.write\_text(p.read\_text() }\OperatorTok{+}\NormalTok{ text }\ControlFlowTok{if}\NormalTok{ p.exists() }\ControlFlowTok{else}\NormalTok{ text)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Added \textquotesingle{}guard\textquotesingle{} target to Makefile"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Run locally/Colab:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{python tools}\OperatorTok{/}\NormalTok{guard\_large\_files.py}
\end{Highlighting}
\end{Shaded}

Commit on a new branch (e.g., \texttt{chore/large-file-guard}), push,
open PR, and merge after review.

\subsection{Part C --- Branch/PR practice (each
student)}\label{part-c-branchpr-practice-each-student}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Each student creates \textbf{their own} branch (e.g.,
  \texttt{docs/readme-username}) and:

  \begin{itemize}
  \tightlist
  \item
    Adds a \textbf{``Development workflow''} section in
    \texttt{README.md} (1--2 paragraphs): how to clone, mount Drive in
    Colab, install requirements, and where outputs go.
  \item
    Adds themselves to \texttt{README.md} ``Contributors'' section with
    a GitHub handle link.
  \end{itemize}
\item
  Push branch and open a PR.
\item
  Partner reviews the PR:

  \begin{itemize}
  \tightlist
  \item
    Leave at least \textbf{2 useful comments} (nits vs blockers).
  \item
    Approve when ready; the author merges.
  \end{itemize}
\end{enumerate}

\textbf{Expected files touched:} \texttt{README.md},
\texttt{.github/pull\_request\_template.md}, optional
\texttt{.github/CODEOWNERS}, \texttt{tools/guard\_large\_files.py},
\texttt{Makefile}.

\subsection{Part D --- Prove LFS is
working}\label{part-d-prove-lfs-is-working}

\begin{itemize}
\tightlist
\item
  On \texttt{main}, run:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{git lfs ls}\OperatorTok{{-}}\NormalTok{files}
\end{Highlighting}
\end{Shaded}

\begin{itemize}
\tightlist
\item
  You should see \texttt{data/processed/sample\_returns.parquet} (and
  any other tracked binaries).
\item
  In the GitHub web UI, click the file to confirm it's an \textbf{LFS
  pointer}, not full binary contents.
\end{itemize}

\subsection{Submission checklist
(pass/revise)}\label{submission-checklist-passrevise}

\begin{itemize}
\tightlist
\item
  Two merged PRs (template + guard) with clear titles and descriptions.
\item
  README updated with development workflow and contributors.
\item
  \texttt{git\ lfs\ ls-files} shows expected files.
\item
  \texttt{tools/guard\_large\_files.py} present and passes (\texttt{OK})
  on \texttt{main}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class}

\begin{itemize}
\tightlist
\item
  Ensure students have or can create a GitHub repo and add
  collaborators.
\item
  Validate the lab sequence once in a fresh Colab runtime.
\item
  Have example screenshots of: PR diff, LFS pointer file, successful
  \texttt{git\ lfs\ ls-files}.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching}

\begin{itemize}
\tightlist
\item
  \textbf{Small PRs win.} Short diffs → fast, focused reviews.
\item
  \textbf{Don't commit secrets.} \texttt{.env} only; keep
  \texttt{.env.example} up to date.
\item
  \textbf{Use LFS sparingly} and purposefully---prefer regenerating big
  raw data.
\item
  \textbf{Colab pushes:} use a \textbf{short‑lived token}, and clear
  outputs after use.
\end{itemize}

Next session: \textbf{Quarto reporting} polish and pipeline hooks; soon
after, \textbf{Unix automation} so \texttt{make\ get-data} can
reproducibly fetch raw data for the unified‑stocks project.

\bookmarksetup{startatroot}

\chapter{Session 3 --- Quarto Reports
(Python)}\label{session-3-quarto-reports-python}

Below is a complete lecture package for \textbf{Session 3 --- Quarto
Reports (Python)} (75 minutes). It includes: timed agenda, key talking
points, an \textbf{in‑class lab with copy‑paste code cells
(Colab‑friendly)}, and \textbf{homework with copy‑paste code}. This
session produces a \textbf{parameterized EDA report} for multiple
tickers and publishes it to \textbf{GitHub Pages}.

\begin{quote}
Assumptions: Students already have (from Sessions 1--2) a repo like
\texttt{unified-stocks-teamX} in Drive (or they can create it now) and
basic Git push workflow with a short‑lived token. Today focuses on
Quarto.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 3 --- Quarto Reports (Python) --- 75
minutes}\label{session-3-quarto-reports-python-75-minutes}

\subsection{Learning goals}\label{learning-goals-2}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a \textbf{parameterized} Quarto report (\texttt{.qmd}) that
  runs Python code.
\item
  Render a report from \textbf{Colab} using the \textbf{Quarto CLI}
  (with caching).
\item
  Pass parameters on the command line to re‑render for different
  tickers/date ranges.
\item
  Configure a minimal Quarto \textbf{website} that builds to
  \texttt{docs/} and publish it via \textbf{GitHub Pages}.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-1}

\begin{itemize}
\tightlist
\item
  \textbf{(8 min)} Why Quarto for DS: literate programming, parameters,
  caching, publishing
\item
  \textbf{(12 min)} Anatomy of a \texttt{.qmd}: YAML front matter,
  \texttt{params:}, code chunks, \texttt{execute:} options, figures
\item
  \textbf{(35 min)} \textbf{In‑class lab}: install Quarto in Colab →
  create \texttt{\_quarto.yml} → write \texttt{reports/eda.qmd} → render
  for AAPL/MSFT → output to \texttt{docs/}
\item
  \textbf{(10 min)} GitHub Pages walkthrough + troubleshooting +
  homework briefing
\item
  \textbf{(10 min)} Buffer for hiccups (first Quarto install/render
  often needs a minute)
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Talking points (for your
slides)}\label{talking-points-for-your-slides}

\textbf{Why Quarto}

\begin{itemize}
\tightlist
\item
  One source of truth for code + prose + figures → reproducibility and
  explainability.
\item
  Parameterization = fast re‑runs with different inputs
  (ticker/horizon).
\item
  Publishing to GitHub Pages gives a permanent, shareable artifact.
\end{itemize}

\textbf{Key concepts}

\begin{itemize}
\item
  \textbf{Front matter}:

  \begin{itemize}
  \tightlist
  \item
    \texttt{format:} controls HTML/PDF/RevealJS (we'll use HTML).
  \item
    \texttt{execute:} controls caching, echo, warnings.
  \item
    \texttt{params:} defines inputs; accessed as \texttt{params} dict in
    Python cells.
  \end{itemize}
\item
  \textbf{Performance}: enable \texttt{execute.cache:\ true} to avoid
  refetching/recomputing.
\item
  \textbf{Publishing}: write to \texttt{docs/} then enable GitHub Pages
  (Settings → Pages → ``Deploy from a branch'' → \texttt{main} /
  \texttt{/docs}).
\end{itemize}

\textbf{Ethics/footnote}

\begin{itemize}
\tightlist
\item
  Financial data EDA here is \textbf{educational} only; not trading
  advice.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min)}\label{inclass-lab-35-min-2}

\begin{quote}
\textbf{Instructor tip}: Ask students to follow step‑by‑step. If they
didn't complete Session 2's clone, they can create a fresh folder under
Drive and initialize a new GitHub repo afterward.
\end{quote}

\subsection{0) Mount Drive and set repo
paths}\label{mount-drive-and-set-repo-paths}

Run each block as a separate Colab cell.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_OWNER }\OperatorTok{=} \StringTok{"YOUR\_GITHUB\_USERNAME\_OR\_ORG"}  \CommentTok{\# \textless{}{-} change}
\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}         \CommentTok{\# \textless{}{-} change}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}
\NormalTok{REPO\_URL   }\OperatorTok{=} \SpecialStringTok{f"https://github.com/}\SpecialCharTok{\{}\NormalTok{REPO\_OWNER}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{.git"}

\ImportTok{import}\NormalTok{ pathlib, os, subprocess}
\NormalTok{pathlib.Path(BASE\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ pathlib.Path(REPO\_DIR).exists():}
    \OperatorTok{!}\NormalTok{git clone \{REPO\_URL\} \{REPO\_DIR\}}
\ControlFlowTok{else}\NormalTok{:}
    \OperatorTok{\%}\NormalTok{cd \{REPO\_DIR\}}
    \OperatorTok{!}\NormalTok{git pull }\OperatorTok{{-}{-}}\NormalTok{ff}\OperatorTok{{-}}\NormalTok{only}
\OperatorTok{\%}\NormalTok{cd \{REPO\_DIR\}}
\end{Highlighting}
\end{Shaded}

\subsection{1) Install Quarto CLI on Colab and
verify}\label{install-quarto-cli-on-colab-and-verify}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Install Quarto CLI (one{-}time per Colab runtime)}
\OperatorTok{!}\NormalTok{wget }\OperatorTok{{-}}\NormalTok{q https:}\OperatorTok{//}\NormalTok{quarto.org}\OperatorTok{/}\NormalTok{download}\OperatorTok{/}\NormalTok{latest}\OperatorTok{/}\NormalTok{quarto}\OperatorTok{{-}}\NormalTok{linux}\OperatorTok{{-}}\NormalTok{amd64.deb }\OperatorTok{{-}}\NormalTok{O }\OperatorTok{/}\NormalTok{tmp}\OperatorTok{/}\NormalTok{quarto.deb}
\OperatorTok{!}\NormalTok{dpkg }\OperatorTok{{-}}\NormalTok{i }\OperatorTok{/}\NormalTok{tmp}\OperatorTok{/}\NormalTok{quarto.deb }\OperatorTok{||}\NormalTok{ apt}\OperatorTok{{-}}\NormalTok{get }\OperatorTok{{-}}\NormalTok{y }\OperatorTok{{-}}\NormalTok{f install }\OperatorTok{\textgreater{}/}\NormalTok{dev}\OperatorTok{/}\NormalTok{null }\OperatorTok{\&\&}\NormalTok{ dpkg }\OperatorTok{{-}}\NormalTok{i }\OperatorTok{/}\NormalTok{tmp}\OperatorTok{/}\NormalTok{quarto.deb}
\OperatorTok{!}\NormalTok{quarto }\OperatorTok{{-}{-}}\NormalTok{version}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Minimal project config:
\texttt{\_quarto.yml} (website to
\texttt{docs/})}{2) Minimal project config: \_quarto.yml (website to docs/)}}\label{minimal-project-config-_quarto.yml-website-to-docs}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ textwrap }\ImportTok{import}\NormalTok{ dedent}
\NormalTok{qproj }\OperatorTok{=}\NormalTok{ dedent(}\StringTok{"""}\CharTok{\textbackslash{}}
\StringTok{project:}
\StringTok{  type: website}
\StringTok{  output{-}dir: docs}

\StringTok{website:}
\StringTok{  title: "Unified Stocks — EDA"}
\StringTok{  navbar:}
\StringTok{    left:}
\StringTok{      {-} href: index.qmd}
\StringTok{        text: Home}
\StringTok{      {-} href: reports/eda.qmd}
\StringTok{        text: EDA (parametrized)}

\StringTok{format:}
\StringTok{  html:}
\StringTok{    theme: cosmo}
\StringTok{    toc: true}
\StringTok{    code{-}fold: false}

\StringTok{execute:}
\StringTok{  echo: true}
\StringTok{  warning: false}
\StringTok{  cache: true}
\StringTok{"""}\NormalTok{)}
\BuiltInTok{open}\NormalTok{(}\StringTok{"\_quarto.yml"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(qproj)}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{"\_quarto.yml"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

Create a simple homepage:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{index }\OperatorTok{=} \StringTok{"""}\CharTok{\textbackslash{}}
\StringTok{{-}{-}{-}}
\StringTok{title: "Unified Stocks Project"}
\StringTok{{-}{-}{-}}

\StringTok{Welcome! Use the navigation to view the EDA report.}

\StringTok{{-} **Stock set**: see \textasciigrave{}tickers\_25.csv\textasciigrave{}}
\StringTok{{-} **Note**: Educational use only — no trading advice.}
\StringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{"index.qmd"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(index)}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{"index.qmd"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Create the parameterized EDA report:
\texttt{reports/eda.qmd}}{3) Create the parameterized EDA report: reports/eda.qmd}}\label{create-the-parameterized-eda-report-reportseda.qmd}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ os, pathlib}
\NormalTok{pathlib.Path(}\StringTok{"reports/figs"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{eda\_qmd }\OperatorTok{=} \StringTok{"""}\CharTok{\textbackslash{}}
\StringTok{{-}{-}{-}}
\StringTok{title: "Stock EDA"}
\StringTok{format:}
\StringTok{  html:}
\StringTok{    toc: true}
\StringTok{    number{-}sections: false}
\StringTok{execute:}
\StringTok{  echo: true}
\StringTok{  warning: false}
\StringTok{  cache: true}
\StringTok{params:}
\StringTok{  symbol: "AAPL"}
\StringTok{  start\_date: "2018{-}01{-}01"}
\StringTok{  end\_date: ""}
\StringTok{  rolling: 20}
\StringTok{{-}{-}{-}}

\StringTok{::: callout{-}note}
\StringTok{This report is parameterized. To change inputs without editing code, pass}
\StringTok{\textasciigrave{}{-}P symbol:MSFT {-}P start\_date:2019{-}01{-}01 {-}P end\_date:2025{-}08{-}01 {-}P rolling:30\textasciigrave{} to \textasciigrave{}quarto render\textasciigrave{}.}
\StringTok{:::}

\StringTok{\#\# Setup}



\StringTok{\#\# Price over time}



\StringTok{\#\# Daily log returns — histogram}



\StringTok{\#\# Rolling mean \& volatility (window = }\SpecialCharTok{\{params.rolling\}}\StringTok{)}



\StringTok{\#\# Summary table}



\StringTok{\textgreater{} **Note**: Educational use only. This is not trading advice.}
\StringTok{\textgreater{} """}
\OperatorTok{\textgreater{}} \BuiltInTok{open}\NormalTok{(}\StringTok{"reports/eda.qmd"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(eda\textbackslash{}\_qmd)}
\OperatorTok{\textgreater{}} \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote reports/eda.qmd"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) Render the report for one ticker (AAPL)
and put outputs in
\texttt{docs/}}{4) Render the report for one ticker (AAPL) and put outputs in docs/}}\label{render-the-report-for-one-ticker-aapl-and-put-outputs-in-docs}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Single render with defaults (AAPL)}
\OperatorTok{!}\NormalTok{quarto render reports}\OperatorTok{/}\NormalTok{eda.qmd }\OperatorTok{{-}{-}}\NormalTok{output}\OperatorTok{{-}}\BuiltInTok{dir}\NormalTok{ docs}\OperatorTok{/}
\end{Highlighting}
\end{Shaded}

Open the produced HTML (Colab file browser →
\texttt{docs/reports/eda.html}). If the HTML is under
\texttt{docs/reports/eda.html}, that's expected (Quarto keeps layout
mirroring source folders).

\subsection{5) Render for multiple tickers by passing
parameters}\label{render-for-multiple-tickers-by-passing-parameters}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Render for MSFT with custom dates and rolling window}
\OperatorTok{!}\NormalTok{quarto render reports}\OperatorTok{/}\NormalTok{eda.qmd }\OperatorTok{{-}}\NormalTok{P symbol:MSFT }\OperatorTok{{-}}\NormalTok{P start\_date:}\DecValTok{2019}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P end\_date:}\DecValTok{2025}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{8}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P rolling:}\DecValTok{30} \OperatorTok{{-}{-}}\NormalTok{output}\OperatorTok{{-}}\BuiltInTok{dir}\NormalTok{ docs}\OperatorTok{/}

\CommentTok{\# Render for NVDA with a different window}
\OperatorTok{!}\NormalTok{quarto render reports}\OperatorTok{/}\NormalTok{eda.qmd }\OperatorTok{{-}}\NormalTok{P symbol:NVDA }\OperatorTok{{-}}\NormalTok{P start\_date:}\DecValTok{2018}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P end\_date:}\DecValTok{2025}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{8}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P rolling:}\DecValTok{60} \OperatorTok{{-}{-}}\NormalTok{output}\OperatorTok{{-}}\BuiltInTok{dir}\NormalTok{ docs}\OperatorTok{/}
\end{Highlighting}
\end{Shaded}

This will create \texttt{docs/reports/eda.html} for the last render
(Quarto overwrites the same output path by default). If you want
\textbf{separate pages per ticker}, render to different filenames:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Example: write MSFT to docs/reports/eda{-}MSFT.html via project copy}
\ImportTok{import}\NormalTok{ shutil, os}
\NormalTok{shutil.copy(}\StringTok{"reports/eda.qmd"}\NormalTok{, }\StringTok{"reports/eda{-}MSFT.qmd"}\NormalTok{)}
\OperatorTok{!}\NormalTok{quarto render reports}\OperatorTok{/}\NormalTok{eda}\OperatorTok{{-}}\NormalTok{MSFT.qmd }\OperatorTok{{-}}\NormalTok{P symbol:MSFT }\OperatorTok{{-}}\NormalTok{P start\_date:}\DecValTok{2019}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P end\_date:}\DecValTok{2025}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{8}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P rolling:}\DecValTok{30} \OperatorTok{{-}{-}}\NormalTok{output}\OperatorTok{{-}}\BuiltInTok{dir}\NormalTok{ docs}\OperatorTok{/}
\end{Highlighting}
\end{Shaded}

\subsection{6) Add nav links to specific ticker pages
(optional)}\label{add-nav-links-to-specific-ticker-pages-optional}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Append MSFT page to navbar}
\ImportTok{from}\NormalTok{ ruamel.yaml }\ImportTok{import}\NormalTok{ YAML}
\NormalTok{yaml }\OperatorTok{=}\NormalTok{ YAML()}
\NormalTok{cfg }\OperatorTok{=}\NormalTok{ yaml.load(}\BuiltInTok{open}\NormalTok{(}\StringTok{"\_quarto.yml"}\NormalTok{))}
\NormalTok{cfg[}\StringTok{"website"}\NormalTok{][}\StringTok{"navbar"}\NormalTok{][}\StringTok{"left"}\NormalTok{].append(\{}\StringTok{"href"}\NormalTok{: }\StringTok{"reports/eda{-}MSFT.qmd"}\NormalTok{, }\StringTok{"text"}\NormalTok{: }\StringTok{"MSFT EDA"}\NormalTok{\})}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"\_quarto.yml"}\NormalTok{,}\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    yaml.dump(cfg, f)}
\OperatorTok{!}\NormalTok{quarto render }\OperatorTok{{-}{-}}\NormalTok{output}\OperatorTok{{-}}\BuiltInTok{dir}\NormalTok{ docs}\OperatorTok{/}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{7) Commit and push site to GitHub (so Pages
can serve
\texttt{docs/})}{7) Commit and push site to GitHub (so Pages can serve docs/)}}\label{commit-and-push-site-to-github-so-pages-can-serve-docs}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{git add \_quarto.yml index.qmd reports}\OperatorTok{/}\NormalTok{eda}\OperatorTok{*}\NormalTok{.qmd reports}\OperatorTok{/}\NormalTok{figs docs}
\OperatorTok{!}\NormalTok{git status}
\OperatorTok{!}\NormalTok{git commit }\OperatorTok{{-}}\NormalTok{m }\StringTok{"feat: add parameterized Quarto EDA and publish to docs/"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Push using a short{-}lived fine{-}grained token (as in Session 2)}
\ImportTok{from}\NormalTok{ getpass }\ImportTok{import}\NormalTok{ getpass}
\NormalTok{token }\OperatorTok{=}\NormalTok{ getpass(}\StringTok{"GitHub token (not stored): "}\NormalTok{)}
\NormalTok{push\_url }\OperatorTok{=} \SpecialStringTok{f"https://}\SpecialCharTok{\{}\NormalTok{token}\SpecialCharTok{\}}\SpecialStringTok{@github.com/}\SpecialCharTok{\{}\NormalTok{REPO\_OWNER}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{.git"}
\OperatorTok{!}\NormalTok{git push \{push\_url\} HEAD:main}
\KeywordTok{del}\NormalTok{ token}
\end{Highlighting}
\end{Shaded}

\subsection{8) Enable GitHub Pages (one-time,
UI)}\label{enable-github-pages-one-time-ui}

\begin{itemize}
\item
  On GitHub: \textbf{Settings → Pages}

  \begin{itemize}
  \tightlist
  \item
    Source: \textbf{Deploy from a branch}
  \item
    Branch: \texttt{main}
  \item
    Folder: \texttt{/docs}
  \end{itemize}
\item
  Save. Wait \textasciitilde1--3 minutes. Your site will be live at the
  URL GitHub shows (usually
  \texttt{https://\textless{}owner\textgreater{}.github.io/\textless{}repo\textgreater{}/}).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min}

\begin{itemize}
\tightlist
\item
  Re‑rendering with \texttt{-P} lets you build many variants quickly.
\item
  Keep \textbf{data fetches cached} and/or saved to files to speed up
  renders.
\item
  Your team can add more pages (e.g., \emph{Methodology},
  \emph{Results}, \emph{Model Card}) and link them via
  \texttt{\_quarto.yml}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
4)}\label{homework-due-before-session-4}

\textbf{Goal:} Enhance the EDA report with two features and publish
distinct pages for \textbf{three} tickers from \texttt{tickers\_25.csv}.

\subsection{Part A --- Add drawdown \& simple regime
shading}\label{part-a-add-drawdown-simple-regime-shading}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Edit \texttt{reports/eda.qmd}. After computing
  \texttt{df{[}"log\_return"{]}}, compute:

  \begin{itemize}
  \tightlist
  \item
    \texttt{cum\_return} and \textbf{drawdown}
  \item
    A simple \textbf{volatility regime} indicator (e.g., rolling std
    quantiles)
  \end{itemize}
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Add to the "Tidy \& features" section in eda.qmd}
\NormalTok{df[}\StringTok{"cum\_return"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"log\_return"}\NormalTok{].cumsum().fillna(}\FloatTok{0.0}\NormalTok{)}
\NormalTok{peak }\OperatorTok{=}\NormalTok{ df[}\StringTok{"cum\_return"}\NormalTok{].cummax()}
\NormalTok{df[}\StringTok{"drawdown"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"cum\_return"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ peak}

\CommentTok{\# Regime via rolling volatility terciles}
\NormalTok{vol }\OperatorTok{=}\NormalTok{ df[}\StringTok{"log\_return"}\NormalTok{].rolling(ROLL, min\_periods}\OperatorTok{=}\NormalTok{ROLL}\OperatorTok{//}\DecValTok{2}\NormalTok{).std()}
\NormalTok{q1, q2 }\OperatorTok{=}\NormalTok{ vol.quantile([}\FloatTok{0.33}\NormalTok{, }\FloatTok{0.66}\NormalTok{])}
\KeywordTok{def}\NormalTok{ regime(v):}
    \ControlFlowTok{if}\NormalTok{ np.isnan(v): }\ControlFlowTok{return} \StringTok{"mid"}
    \ControlFlowTok{return} \StringTok{"low"} \ControlFlowTok{if}\NormalTok{ v }\OperatorTok{\textless{}}\NormalTok{ q1 }\ControlFlowTok{else}\NormalTok{ (}\StringTok{"high"} \ControlFlowTok{if}\NormalTok{ v }\OperatorTok{\textgreater{}}\NormalTok{ q2 }\ControlFlowTok{else} \StringTok{"mid"}\NormalTok{)}
\NormalTok{df[}\StringTok{"regime"}\NormalTok{] }\OperatorTok{=}\NormalTok{ [regime(v) }\ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ vol]}
\NormalTok{df[}\StringTok{"regime"}\NormalTok{].value\_counts().to\_frame(}\StringTok{"days"}\NormalTok{).T}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Add a \textbf{drawdown plot} and shade high‑volatility regimes:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Drawdown plot}
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\NormalTok{ax.plot(df.index, df[}\StringTok{"drawdown"}\NormalTok{])}
\NormalTok{ax.set\_title(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{SYMBOL}\SpecialCharTok{\}}\SpecialStringTok{ — Drawdown (log{-}return cumulative)"}\NormalTok{)}
\NormalTok{ax.set\_xlabel(}\StringTok{"Date"}\NormalTok{)}\OperatorTok{;}\NormalTok{ ax.set\_ylabel(}\StringTok{"drawdown"}\NormalTok{)}
\NormalTok{fig.tight\_layout()}
\NormalTok{figpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"reports/figs"}\NormalTok{)}\OperatorTok{/}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{SYMBOL}\SpecialCharTok{\}}\SpecialStringTok{\_drawdown.png"}
\NormalTok{fig.savefig(figpath, dpi}\OperatorTok{=}\DecValTok{144}\NormalTok{)}
\NormalTok{figpath}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Price with regime shading (simple)}
\NormalTok{fig, ax }\OperatorTok{=}\NormalTok{ plt.subplots(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\NormalTok{ax.plot(df.index, df[}\StringTok{"close"}\NormalTok{])}
\NormalTok{ax.set\_title(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{SYMBOL}\SpecialCharTok{\}}\SpecialStringTok{ — Price with High{-}Volatility Shading"}\NormalTok{)}
\NormalTok{ax.set\_xlabel(}\StringTok{"Date"}\NormalTok{)}\OperatorTok{;}\NormalTok{ ax.set\_ylabel(}\StringTok{"Price"}\NormalTok{)}

\CommentTok{\# Shade where regime == \textquotesingle{}high\textquotesingle{}}
\NormalTok{mask }\OperatorTok{=}\NormalTok{ (df[}\StringTok{"regime"}\NormalTok{] }\OperatorTok{==} \StringTok{"high"}\NormalTok{)}
\CommentTok{\# merge contiguous regions}
\NormalTok{in\_region }\OperatorTok{=} \VariableTok{False}
\NormalTok{start }\OperatorTok{=} \VariableTok{None}
\ControlFlowTok{for}\NormalTok{ i, (ts, is\_high) }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(}\BuiltInTok{zip}\NormalTok{(df.index, mask)):}
    \ControlFlowTok{if}\NormalTok{ is\_high }\KeywordTok{and} \KeywordTok{not}\NormalTok{ in\_region:}
\NormalTok{        in\_region }\OperatorTok{=} \VariableTok{True}
\NormalTok{        start }\OperatorTok{=}\NormalTok{ ts}
    \ControlFlowTok{if}\NormalTok{ in\_region }\KeywordTok{and}\NormalTok{ (}\KeywordTok{not}\NormalTok{ is\_high }\KeywordTok{or}\NormalTok{ i }\OperatorTok{==} \BuiltInTok{len}\NormalTok{(df)}\OperatorTok{{-}}\DecValTok{1}\NormalTok{):}
\NormalTok{        end }\OperatorTok{=}\NormalTok{ df.index[i}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ is\_high }\ControlFlowTok{else}\NormalTok{ ts}
\NormalTok{        ax.axvspan(start, end, alpha}\OperatorTok{=}\FloatTok{0.15}\NormalTok{)  }\CommentTok{\# shaded band}
\NormalTok{        in\_region }\OperatorTok{=} \VariableTok{False}
\NormalTok{fig.tight\_layout()}
\NormalTok{figpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"reports/figs"}\NormalTok{)}\OperatorTok{/}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{SYMBOL}\SpecialCharTok{\}}\SpecialStringTok{\_price\_regimes.png"}
\NormalTok{fig.savefig(figpath, dpi}\OperatorTok{=}\DecValTok{144}\NormalTok{)}
\NormalTok{figpath}
\end{Highlighting}
\end{Shaded}

\subsection{Part B --- Render three separate pages and link them in the
navbar}\label{part-b-render-three-separate-pages-and-link-them-in-the-navbar}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Make copies of the report source so each produces its own page:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ shutil}
\NormalTok{shutil.copy(}\StringTok{"reports/eda.qmd"}\NormalTok{, }\StringTok{"reports/eda{-}AAPL.qmd"}\NormalTok{)}
\NormalTok{shutil.copy(}\StringTok{"reports/eda.qmd"}\NormalTok{, }\StringTok{"reports/eda{-}MSFT.qmd"}\NormalTok{)}
\NormalTok{shutil.copy(}\StringTok{"reports/eda.qmd"}\NormalTok{, }\StringTok{"reports/eda{-}NVDA.qmd"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Render each with different parameters:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{quarto render reports}\OperatorTok{/}\NormalTok{eda}\OperatorTok{{-}}\NormalTok{AAPL.qmd }\OperatorTok{{-}}\NormalTok{P symbol:AAPL }\OperatorTok{{-}}\NormalTok{P start\_date:}\DecValTok{2018}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P end\_date:}\DecValTok{2025}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{8}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P rolling:}\DecValTok{30} \OperatorTok{{-}{-}}\NormalTok{output}\OperatorTok{{-}}\BuiltInTok{dir}\NormalTok{ docs}\OperatorTok{/}
\OperatorTok{!}\NormalTok{quarto render reports}\OperatorTok{/}\NormalTok{eda}\OperatorTok{{-}}\NormalTok{MSFT.qmd }\OperatorTok{{-}}\NormalTok{P symbol:MSFT }\OperatorTok{{-}}\NormalTok{P start\_date:}\DecValTok{2018}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P end\_date:}\DecValTok{2025}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{8}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P rolling:}\DecValTok{30} \OperatorTok{{-}{-}}\NormalTok{output}\OperatorTok{{-}}\BuiltInTok{dir}\NormalTok{ docs}\OperatorTok{/}
\OperatorTok{!}\NormalTok{quarto render reports}\OperatorTok{/}\NormalTok{eda}\OperatorTok{{-}}\NormalTok{NVDA.qmd }\OperatorTok{{-}}\NormalTok{P symbol:NVDA }\OperatorTok{{-}}\NormalTok{P start\_date:}\DecValTok{2018}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P end\_date:}\DecValTok{2025}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{8}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}}\NormalTok{P rolling:}\DecValTok{30} \OperatorTok{{-}{-}}\NormalTok{output}\OperatorTok{{-}}\BuiltInTok{dir}\NormalTok{ docs}\OperatorTok{/}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Add to the navbar in \texttt{\_quarto.yml} and rebuild site:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ ruamel.yaml }\ImportTok{import}\NormalTok{ YAML}
\NormalTok{yaml }\OperatorTok{=}\NormalTok{ YAML()}
\NormalTok{cfg }\OperatorTok{=}\NormalTok{ yaml.load(}\BuiltInTok{open}\NormalTok{(}\StringTok{"\_quarto.yml"}\NormalTok{))}
\NormalTok{cfg[}\StringTok{"website"}\NormalTok{][}\StringTok{"navbar"}\NormalTok{][}\StringTok{"left"}\NormalTok{].extend([}
\NormalTok{  \{}\StringTok{"href"}\NormalTok{: }\StringTok{"reports/eda{-}AAPL.qmd"}\NormalTok{, }\StringTok{"text"}\NormalTok{: }\StringTok{"AAPL"}\NormalTok{\},}
\NormalTok{  \{}\StringTok{"href"}\NormalTok{: }\StringTok{"reports/eda{-}MSFT.qmd"}\NormalTok{, }\StringTok{"text"}\NormalTok{: }\StringTok{"MSFT"}\NormalTok{\},}
\NormalTok{  \{}\StringTok{"href"}\NormalTok{: }\StringTok{"reports/eda{-}NVDA.qmd"}\NormalTok{, }\StringTok{"text"}\NormalTok{: }\StringTok{"NVDA"}\NormalTok{\},}
\NormalTok{])}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"\_quarto.yml"}\NormalTok{,}\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    yaml.dump(cfg, f)}
\OperatorTok{!}\NormalTok{quarto render }\OperatorTok{{-}{-}}\NormalTok{output}\OperatorTok{{-}}\BuiltInTok{dir}\NormalTok{ docs}\OperatorTok{/}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Commit \& push (use your short‑lived token as before):
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{git add reports}\OperatorTok{/}\NormalTok{eda}\OperatorTok{{-}*}\NormalTok{.qmd reports}\OperatorTok{/}\NormalTok{figs \_quarto.yml docs}
\OperatorTok{!}\NormalTok{git commit }\OperatorTok{{-}}\NormalTok{m }\StringTok{"feat: EDA enhancements (drawdown/regimes) and pages for AAPL/MSFT/NVDA"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ getpass }\ImportTok{import}\NormalTok{ getpass}
\NormalTok{token }\OperatorTok{=}\NormalTok{ getpass(}\StringTok{"GitHub token (not stored): "}\NormalTok{)}
\NormalTok{push\_url }\OperatorTok{=} \SpecialStringTok{f"https://}\SpecialCharTok{\{}\NormalTok{token}\SpecialCharTok{\}}\SpecialStringTok{@github.com/}\SpecialCharTok{\{}\NormalTok{REPO\_OWNER}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{.git"}
\OperatorTok{!}\NormalTok{git push \{push\_url\} HEAD:main}
\KeywordTok{del}\NormalTok{ token}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Verify \textbf{GitHub Pages} shows navbar links and pages load.
\end{enumerate}

\subsection{Part C --- Makefile convenience
targets}\label{part-c-makefile-convenience-targets}

Append these to your project \texttt{Makefile}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{report:}
\NormalTok{\textbackslash{}tquarto render reports/eda.qmd {-}{-}output{-}dir docs/}

\NormalTok{reports{-}trio:}
\NormalTok{\textbackslash{}tquarto render reports/eda{-}AAPL.qmd {-}P symbol:AAPL {-}P start\_date:2018{-}01{-}01 {-}P end\_date:2025{-}08{-}01 {-}{-}output{-}dir docs/}
\NormalTok{\textbackslash{}tquarto render reports/eda{-}MSFT.qmd {-}P symbol:MSFT {-}P start\_date:2018{-}01{-}01 {-}P end\_date:2025{-}08{-}01 {-}{-}output{-}dir docs/}
\NormalTok{\textbackslash{}tquarto render reports/eda{-}NVDA.qmd {-}P symbol:NVDA {-}P start\_date:2018{-}01{-}01 {-}P end\_date:2025{-}08{-}01 {-}{-}output{-}dir docs/}
\end{Highlighting}
\end{Shaded}

\begin{quote}
On Colab, running \texttt{make} requires \texttt{make} to be available
(it is). Otherwise, keep using \texttt{quarto\ render} commands.
\end{quote}

\subsection{Grading (pass/revise)}\label{grading-passrevise-1}

\begin{itemize}
\tightlist
\item
  \texttt{reports/eda.qmd} renders with parameters and caching enabled.
\item
  At least \textbf{three} ticker pages rendered and linked in navbar.
\item
  Drawdown and simple regime shading working on the EDA page(s).
\item
  Site published via GitHub Pages (\texttt{docs/} present on
  \texttt{main} and live).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-1}

\begin{itemize}
\tightlist
\item
  Test the Quarto install/render flow once in a fresh Colab runtime.
\item
  Have a screenshot of: \texttt{\_quarto.yml}, rendered \texttt{docs/}
  tree, GitHub Pages settings.
\item
  Remind students: if \texttt{yfinance} rate‑limits, re‑run or wait; the
  synthetic fallback ensures the page renders.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-1}

\begin{itemize}
\tightlist
\item
  \textbf{Parameters} make reports reusable; don't copy‑paste notebooks
  for each ticker.
\item
  \textbf{Cache} for speed; \textbf{docs/} for Pages.
\item
  Keep figures saved under \texttt{reports/figs/} and referenced in the
  report.
\item
  Keep secrets out of the repo; EDA uses public data only.
\end{itemize}

Next time (Session 4): a quick \textbf{RStudio Quarto cameo} and more
\textbf{report hygiene} (citations, figure captions, alt text), then
into \textbf{Unix automation}.

\bookmarksetup{startatroot}

\chapter{Session 4 --- RStudio Quarto cameo + Report
Hygiene}\label{session-4-rstudio-quarto-cameo-report-hygiene}

Below is a complete lecture package for \textbf{Session 4 --- RStudio
Quarto cameo + Report Hygiene} (75 minutes). It includes: a timed
agenda, slide talking points, a \textbf{Colab‑friendly in‑class lab with
copy‑paste code}, and \textbf{homework with copy‑paste code}. The goal
is to make your Quarto site \textbf{clean, citable, accessible, and
reproducible}---and to show (briefly) that \textbf{RStudio can render
your Python‑based Quarto project}.

\begin{quote}
\textbf{Assumptions:}

\begin{itemize}
\tightlist
\item
  Students already have a repo (e.g., \texttt{unified-stocks-teamX})
  with the Quarto site scaffolding from Sessions 2--3.
\item
  Python‑first course; the \textbf{RStudio cameo} demonstrates that
  Quarto is editor‑agnostic (no R coding required).
\end{itemize}
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 4 --- RStudio cameo + Report Hygiene (75
min)}\label{session-4-rstudio-cameo-report-hygiene-75-min}

\subsection{Learning goals}\label{learning-goals-3}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Render a \textbf{Python‑only} Quarto report from \textbf{RStudio} (or
  RStudio Cloud) as a proof that Quarto is editor‑agnostic.
\item
  Add \textbf{hygiene features} to the project: citations
  (\texttt{references.bib}), figure/table \textbf{captions +
  cross‑references}, \textbf{alt text}, better site navigation, custom
  CSS, and \textbf{freeze/caching} for reproducibility.
\item
  Produce a \textbf{Data Dictionary} section that documents columns and
  dtypes, and reference it from the EDA page.
\item
  Render \& publish the cleaned site to \textbf{GitHub Pages}.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-2}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Why report hygiene matters (credibility,
  accessibility, reusability)
\item
  \textbf{(15 min)} \textbf{RStudio cameo}: Render the Python‑based
  Quarto report in RStudio
\item
  \textbf{(30 min)} \textbf{In‑class lab} (Colab): add citations,
  cross‑refs, alt text, freeze/caching, CSS, data dictionary, rebuild
  site
\item
  \textbf{(10 min)} Wrap‑up + troubleshooting + homework briefing
\item
  \textbf{(10 min)} Buffer (for first‑time installs or Git pushes)
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points}\label{slides-talking-points}

\subsection{Why hygiene?}\label{why-hygiene}

\begin{itemize}
\tightlist
\item
  \textbf{Credibility:} citations + model/report lineage
\item
  \textbf{Accessibility:} alt text, readable fonts, color‑safe figures
\item
  \textbf{Reusability:} parameters, freeze/caching, stable page links
\item
  \textbf{Assessability:} clear captions, labeled figures \& tables,
  cross‑references
\end{itemize}

\subsection{Quarto features we'll use}\label{quarto-features-well-use}

\begin{itemize}
\tightlist
\item
  \textbf{Captions \& labels}: \texttt{\#\textbar{}\ label:\ fig-price},
  \texttt{\#\textbar{}\ fig-cap:\ "Price\ over\ time"} → reference in
  text with \texttt{@fig-price}
\item
  \textbf{Tables}: \texttt{\#\textbar{}\ label:\ tbl-summary},
  \texttt{\#\textbar{}\ tbl-cap:\ "Summary\ statistics"} → reference
  with \texttt{@tbl-summary}
\item
  \textbf{Alt text}:
  \texttt{\#\textbar{}\ fig-alt:\ "One‑sentence\ description\ of\ the\ figure"}
\item
  \textbf{Citations}: add \texttt{bibliography:\ references.bib} and
  cite with \texttt{{[}@key{]}}
\item
  \textbf{Freeze}: project‑level \texttt{freeze:\ auto} for
  deterministic rebuilds
\item
  \textbf{Cache}: \texttt{execute:\ cache:\ true} to avoid redoing
  expensive steps
\item
  \textbf{CSS}: small tweaks to readability (font size, code block
  width)
\end{itemize}

\subsection{RStudio cameo (no R
required)}\label{rstudio-cameo-no-r-required}

\begin{itemize}
\tightlist
\item
  RStudio integrates Quarto; the \textbf{Render} button runs
  \texttt{quarto\ render} under the hood.
\item
  Your \texttt{.qmd} can be Python‑only; RStudio is just the IDE.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{RStudio cameo (15 min, live demo
steps)}\label{rstudio-cameo-15-min-live-demo-steps}

\begin{quote}
Do this on the projector. Students observe; they can try later on their
machines or RStudio Cloud.
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Open RStudio} (Desktop or Cloud).
\item
  \textbf{File → Open Project} and select your repo folder
  (\texttt{unified-stocks-teamX}).
\item
  Confirm Quarto: \textbf{Help → About Quarto} (or run
  \texttt{quarto\ -\/-version} in the RStudio terminal).
\item
  Open \texttt{reports/eda.qmd}. Click \textbf{Render} (or run
  \texttt{quarto\ render\ reports/eda.qmd}).
\item
  Show the generated HTML preview. Note: no R code, just Python chunks.
\item
  Mention that \textbf{RMarkdown} is the predecessor; \textbf{Quarto}
  unifies Python \& R (and more). We use \textbf{Quarto}.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (30 min,
Colab‑friendly)}\label{inclass-lab-30-min-colabfriendly}

\begin{quote}
We'll: ensure Quarto CLI is present, upgrade \texttt{\_quarto.yml}
(freeze, bibliography, CSS), add \texttt{references.bib},
\textbf{rewrite EDA with captions/labels/alt text}, generate a
\textbf{Data Dictionary}, re‑render, and push to GitHub.
\end{quote}

\subsection{0) Mount Drive, set repo path, and ensure Quarto
CLI}\label{mount-drive-set-repo-path-and-ensure-quarto-cli}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_OWNER }\OperatorTok{=} \StringTok{"YOUR\_GITHUB\_USERNAME\_OR\_ORG"}  \CommentTok{\# \textless{}{-} change}
\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}         \CommentTok{\# \textless{}{-} change}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}
\NormalTok{REPO\_URL   }\OperatorTok{=} \SpecialStringTok{f"https://github.com/}\SpecialCharTok{\{}\NormalTok{REPO\_OWNER}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{.git"}

\ImportTok{import}\NormalTok{ pathlib, os}
\NormalTok{pathlib.Path(BASE\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ pathlib.Path(REPO\_DIR).exists():}
    \OperatorTok{!}\NormalTok{git clone \{REPO\_URL\} \{REPO\_DIR\}}
\OperatorTok{\%}\NormalTok{cd \{REPO\_DIR\}}

\CommentTok{\# Ensure Quarto CLI}
\OperatorTok{!}\NormalTok{quarto }\OperatorTok{{-}{-}}\NormalTok{version }\OperatorTok{||}\NormalTok{ (wget }\OperatorTok{{-}}\NormalTok{q https:}\OperatorTok{//}\NormalTok{quarto.org}\OperatorTok{/}\NormalTok{download}\OperatorTok{/}\NormalTok{latest}\OperatorTok{/}\NormalTok{quarto}\OperatorTok{{-}}\NormalTok{linux}\OperatorTok{{-}}\NormalTok{amd64.deb }\OperatorTok{{-}}\NormalTok{O }\OperatorTok{/}\NormalTok{tmp}\OperatorTok{/}\NormalTok{quarto.deb }\OperatorTok{\&\&}\NormalTok{ dpkg }\OperatorTok{{-}}\NormalTok{i }\OperatorTok{/}\NormalTok{tmp}\OperatorTok{/}\NormalTok{quarto.deb }\OperatorTok{||}\NormalTok{ (apt}\OperatorTok{{-}}\NormalTok{get }\OperatorTok{{-}}\NormalTok{y }\OperatorTok{{-}}\NormalTok{f install }\OperatorTok{\textgreater{}/}\NormalTok{dev}\OperatorTok{/}\NormalTok{null }\OperatorTok{\&\&}\NormalTok{ dpkg }\OperatorTok{{-}}\NormalTok{i }\OperatorTok{/}\NormalTok{tmp}\OperatorTok{/}\NormalTok{quarto.deb))}
\OperatorTok{!}\NormalTok{quarto }\OperatorTok{{-}{-}}\NormalTok{version}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{1) Upgrade \texttt{\_quarto.yml}: freeze,
bibliography, CSS, nav
polish}{1) Upgrade \_quarto.yml: freeze, bibliography, CSS, nav polish}}\label{upgrade-_quarto.yml-freeze-bibliography-css-nav-polish}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Install ruamel.yaml for safe YAML edits}
\OperatorTok{!}\NormalTok{pip }\OperatorTok{{-}}\NormalTok{q install ruamel.yaml}

\ImportTok{from}\NormalTok{ ruamel.yaml }\ImportTok{import}\NormalTok{ YAML}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\NormalTok{yaml }\OperatorTok{=}\NormalTok{ YAML()}
\NormalTok{cfg\_path }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"\_quarto.yml"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ cfg\_path.exists():}
\NormalTok{    cfg }\OperatorTok{=}\NormalTok{ yaml.load(cfg\_path.read\_text())}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    cfg }\OperatorTok{=}\NormalTok{ \{}\StringTok{"project"}\NormalTok{: \{}\StringTok{"type"}\NormalTok{: }\StringTok{"website"}\NormalTok{, }\StringTok{"output{-}dir"}\NormalTok{: }\StringTok{"docs"}\NormalTok{\},}
           \StringTok{"website"}\NormalTok{: \{}\StringTok{"title"}\NormalTok{: }\StringTok{"Unified Stocks"}\NormalTok{, }\StringTok{"navbar"}\NormalTok{: \{}\StringTok{"left"}\NormalTok{: [\{}\StringTok{"href"}\NormalTok{:}\StringTok{"index.qmd"}\NormalTok{,}\StringTok{"text"}\NormalTok{:}\StringTok{"Home"}\NormalTok{\}]\}\},}
           \StringTok{"format"}\NormalTok{:\{}\StringTok{"html"}\NormalTok{:\{}\StringTok{"theme"}\NormalTok{:}\StringTok{"cosmo"}\NormalTok{,}\StringTok{"toc"}\NormalTok{:}\VariableTok{True}\NormalTok{\}\}\}}

\CommentTok{\# Add/ensure features}
\NormalTok{cfg.setdefault(}\StringTok{"format"}\NormalTok{, \{\}).setdefault(}\StringTok{"html"}\NormalTok{, \{\})}
\NormalTok{cfg[}\StringTok{"format"}\NormalTok{][}\StringTok{"html"}\NormalTok{][}\StringTok{"toc"}\NormalTok{] }\OperatorTok{=} \VariableTok{True}
\NormalTok{cfg[}\StringTok{"format"}\NormalTok{][}\StringTok{"html"}\NormalTok{][}\StringTok{"code{-}fold"}\NormalTok{] }\OperatorTok{=} \VariableTok{False}
\NormalTok{cfg[}\StringTok{"format"}\NormalTok{][}\StringTok{"html"}\NormalTok{][}\StringTok{"toc{-}depth"}\NormalTok{] }\OperatorTok{=} \DecValTok{2}
\NormalTok{cfg[}\StringTok{"format"}\NormalTok{][}\StringTok{"html"}\NormalTok{][}\StringTok{"page{-}navigation"}\NormalTok{] }\OperatorTok{=} \VariableTok{True}
\NormalTok{cfg[}\StringTok{"format"}\NormalTok{][}\StringTok{"html"}\NormalTok{][}\StringTok{"code{-}tools"}\NormalTok{] }\OperatorTok{=} \VariableTok{True}
\NormalTok{cfg[}\StringTok{"format"}\NormalTok{][}\StringTok{"html"}\NormalTok{][}\StringTok{"fig{-}cap{-}location"}\NormalTok{] }\OperatorTok{=} \StringTok{"bottom"}
\NormalTok{cfg[}\StringTok{"format"}\NormalTok{][}\StringTok{"html"}\NormalTok{][}\StringTok{"tbl{-}cap{-}location"}\NormalTok{] }\OperatorTok{=} \StringTok{"top"}
\NormalTok{cfg[}\StringTok{"format"}\NormalTok{][}\StringTok{"html"}\NormalTok{][}\StringTok{"css"}\NormalTok{] }\OperatorTok{=} \StringTok{"docs/style.css"}

\NormalTok{cfg.setdefault(}\StringTok{"execute"}\NormalTok{, \{\})}
\NormalTok{cfg[}\StringTok{"execute"}\NormalTok{][}\StringTok{"echo"}\NormalTok{] }\OperatorTok{=} \VariableTok{True}
\NormalTok{cfg[}\StringTok{"execute"}\NormalTok{][}\StringTok{"warning"}\NormalTok{] }\OperatorTok{=} \VariableTok{False}
\NormalTok{cfg[}\StringTok{"execute"}\NormalTok{][}\StringTok{"cache"}\NormalTok{] }\OperatorTok{=} \VariableTok{True}

\CommentTok{\# Freeze: deterministic rebuilds until the source changes}
\NormalTok{cfg[}\StringTok{"project"}\NormalTok{][}\StringTok{"freeze"}\NormalTok{] }\OperatorTok{=} \StringTok{"auto"}

\CommentTok{\# Bibliography}
\NormalTok{cfg[}\StringTok{"bibliography"}\NormalTok{] }\OperatorTok{=} \StringTok{"references.bib"}

\CommentTok{\# Ensure navbar has EDA link}
\NormalTok{nav }\OperatorTok{=}\NormalTok{ cfg.setdefault(}\StringTok{"website"}\NormalTok{, \{\}).setdefault(}\StringTok{"navbar"}\NormalTok{, \{\}).setdefault(}\StringTok{"left"}\NormalTok{, [])}
\ControlFlowTok{if} \KeywordTok{not} \BuiltInTok{any}\NormalTok{(item.get(}\StringTok{"href"}\NormalTok{) }\OperatorTok{==} \StringTok{"reports/eda.qmd"} \ControlFlowTok{for}\NormalTok{ item }\KeywordTok{in}\NormalTok{ nav }\ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(item, }\BuiltInTok{dict}\NormalTok{)):}
\NormalTok{    nav.append(\{}\StringTok{"href"}\NormalTok{: }\StringTok{"reports/eda.qmd"}\NormalTok{, }\StringTok{"text"}\NormalTok{: }\StringTok{"EDA"}\NormalTok{\})}

\NormalTok{yaml.dump(cfg, }\BuiltInTok{open}\NormalTok{(}\StringTok{"\_quarto.yml"}\NormalTok{,}\StringTok{"w"}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{"\_quarto.yml"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Add \texttt{references.bib} (sample
entries; students will refine
later)}{2) Add references.bib (sample entries; students will refine later)}}\label{add-references.bib-sample-entries-students-will-refine-later}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{refs }\OperatorTok{=} \VerbatimStringTok{r"""@book\{hyndman{-}fpp3,}
\VerbatimStringTok{  title = \{Forecasting: Principles and Practice\},}
\VerbatimStringTok{  author = \{Hyndman, Rob J. and Athanasopoulos, George\},}
\VerbatimStringTok{  edition = }\SpecialCharTok{\{3\}}\VerbatimStringTok{,}
\VerbatimStringTok{  year = }\SpecialCharTok{\{2021\}}\VerbatimStringTok{,}
\VerbatimStringTok{  url = \{https://otexts.com/fpp3/\}}
\VerbatimStringTok{\}}
\VerbatimStringTok{@misc\{quarto{-}docs,}
\VerbatimStringTok{  title = \{Quarto Documentation\},}
\VerbatimStringTok{  author = }\SpecialCharTok{\{\{}\VerbatimStringTok{Posit}\SpecialCharTok{\}\}}\VerbatimStringTok{,}
\VerbatimStringTok{  year = }\SpecialCharTok{\{2025\}}\VerbatimStringTok{,}
\VerbatimStringTok{  url = \{https://quarto.org/\}}
\VerbatimStringTok{\}}
\VerbatimStringTok{@misc\{yfinance,}
\VerbatimStringTok{  title = \{yfinance: Yahoo! Finance market data downloader\},}
\VerbatimStringTok{  author = \{Ran Aroussi\},}
\VerbatimStringTok{  year = }\SpecialCharTok{\{2024\}}\VerbatimStringTok{,}
\VerbatimStringTok{  url = \{https://github.com/ranaroussi/yfinance\}}
\VerbatimStringTok{\}}
\VerbatimStringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{"references.bib"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(refs)}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{"references.bib"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Overwrite \texttt{reports/eda.qmd} with
captions, labels, alt text, citations, and
cross‑refs}{3) Overwrite reports/eda.qmd with captions, labels, alt text, citations, and cross‑refs}}\label{overwrite-reportseda.qmd-with-captions-labels-alt-text-citations-and-crossrefs}

\begin{quote}
This replaces the earlier EDA with a hygienic version. Feel free to
adjust wording later.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ textwrap }\ImportTok{import}\NormalTok{ dedent}
\NormalTok{eda }\OperatorTok{=}\NormalTok{ dedent(}\StringTok{"""}\CharTok{\textbackslash{}}
\StringTok{{-}{-}{-}}
\StringTok{title: "Stock EDA"}
\StringTok{format:}
\StringTok{  html:}
\StringTok{    toc: true}
\StringTok{    number{-}sections: false}
\StringTok{execute:}
\StringTok{  echo: true}
\StringTok{  warning: false}
\StringTok{  cache: true}
\StringTok{params:}
\StringTok{  symbol: "AAPL"}
\StringTok{  start\_date: "2018{-}01{-}01"}
\StringTok{  end\_date: ""}
\StringTok{  rolling: 20}
\StringTok{{-}{-}{-}}

\StringTok{\textgreater{} *Educational use only — not trading advice.* Data pulled via **yfinance** [@yfinance].}

\StringTok{This page is **parameterized**; see the **Parameters** section for usage.}

\StringTok{\#\# Setup}

\StringTok{::: \{.cell execution\_count=1\}}
\StringTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{} \{.python .cell{-}code\}}
\StringTok{import pandas as pd}
\StringTok{import numpy as np}
\StringTok{import matplotlib.pyplot as plt}
\StringTok{import yfinance as yf}
\StringTok{from pathlib import Path}

\StringTok{SYMBOL = params.get("symbol", "AAPL")}
\StringTok{START  = params.get("start\_date", "2018{-}01{-}01")}
\StringTok{END    = params.get("end\_date", "")}
\StringTok{ROLL   = int(params.get("rolling", 20))}
\StringTok{if not END:}
\StringTok{  END = pd.Timestamp.today().strftime("\%Y{-}\%m{-}}\SpecialCharTok{\%d}\StringTok{")}
\end{Highlighting}
\end{Shaded}

\section{Download and tidy}\label{download-and-tidy}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\#| echo: true}
\NormalTok{try:}
\NormalTok{  data = yf.download(SYMBOL, start=START, end=END, auto\_adjust=True, progress=False)}
\NormalTok{except Exception as e:}
\NormalTok{  \# Synthetic fallback}
\NormalTok{  idx = pd.bdate\_range(START, END)}
\NormalTok{  rng = np.random.default\_rng(42)}
\NormalTok{  ret = rng.normal(0, 0.01, len(idx))}
\NormalTok{  price = 100 * np.exp(np.cumsum(ret))}
\NormalTok{  vol = rng.integers(1e5, 5e6, len(idx))}
\NormalTok{  data = pd.DataFrame(\{"Close": price, "Volume": vol\}, index=idx)}

\NormalTok{df = (data.rename(columns=str.lower)[["close","volume"]]}
\NormalTok{        .dropna()}
\NormalTok{        .assign(log\_return=lambda d: np.log(d["close"]).diff()))}
\NormalTok{df["roll\_mean"] = df["log\_return"].rolling(ROLL, min\_periods=ROLL//2).mean()}
\NormalTok{df["roll\_vol"]  = df["log\_return"].rolling(ROLL, min\_periods=ROLL//2).std()}
\NormalTok{df = df.dropna()}
\end{Highlighting}
\end{Shaded}

:::

\section{Price over time}\label{price-over-time}

As shown in \textbf{Figure \textbf{?@fig-price}}, prices vary over time
with changing volatility.

\section{Return distribution}\label{return-distribution}

\textbf{Figure \textbf{?@fig-hist}} shows the return distribution; many
assets exhibit heavy tails {[}(\textbf{hyndman-fpp3?}), pp.~20--21{]}.

\section{Rolling statistics (window =
\{params.rolling\})}\label{rolling-statistics-window-params.rolling}

\section{Summary table}\label{summary-table}

See \textbf{Table \textbf{?@tbl-summary}} for overall statistics.

\section{Data dictionary}\label{data-dictionary}

\section{Parameters}\label{parameters}

This page accepts parameters: \texttt{symbol}, \texttt{start\_date},
\texttt{end\_date}, and \texttt{rolling}. You can re‑render with:

\begin{verbatim}

quarto render reports/eda.qmd \\
  -P symbol:MSFT -P start_date:2019-01-01 -P end_date:2025-08-01 -P rolling:30
\end{verbatim}

\section{References}\label{references}

``\,``\,``) open(''reports/eda.qmd'',``w'').write(eda) print(``Wrote
reports/eda.qmd with hygiene features.'')

\begin{verbatim}

### 4) Add a minimal CSS for readability
```python
from pathlib import Path
Path("docs").mkdir(exist_ok=True)
css = """\
/* Increase base font and widen code blocks slightly */
body { font-size: 1.02rem; }
pre code { white-space: pre-wrap; }
img { max-width: 100%; height: auto; }
"""
open("docs/style.css","w").write(css)
print("Wrote docs/style.css")
\end{verbatim}

\subsection{\texorpdfstring{5) Render site to \texttt{docs/} and
preview}{5) Render site to docs/ and preview}}\label{render-site-to-docs-and-preview}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{quarto render }\OperatorTok{{-}{-}}\NormalTok{output}\OperatorTok{{-}}\BuiltInTok{dir}\NormalTok{ docs}\OperatorTok{/}
\end{Highlighting}
\end{Shaded}

Open \texttt{docs/reports/eda.html} in the Colab file browser to
preview. Confirm:

\begin{itemize}
\tightlist
\item
  Captions under figures, tables titled at top
\item
  Cross‑refs like ``Figure 1''/``Table 1'' clickable
\item
  ``References'' section at bottom with your 2--3 entries
\end{itemize}

\subsection{6) Commit and push (short‑lived token
method)}\label{commit-and-push-shortlived-token-method}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{git add \_quarto.yml references.bib reports}\OperatorTok{/}\NormalTok{eda.qmd docs}\OperatorTok{/}\NormalTok{style.css docs}\OperatorTok{/}
\OperatorTok{!}\NormalTok{git commit }\OperatorTok{{-}}\NormalTok{m }\StringTok{"chore: report hygiene (captions, cross{-}refs, alt text, freeze, bibliography, CSS)"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ getpass }\ImportTok{import}\NormalTok{ getpass}
\NormalTok{token }\OperatorTok{=}\NormalTok{ getpass(}\StringTok{"GitHub token (not stored): "}\NormalTok{)}
\NormalTok{push\_url }\OperatorTok{=} \SpecialStringTok{f"https://}\SpecialCharTok{\{}\NormalTok{token}\SpecialCharTok{\}}\SpecialStringTok{@github.com/}\SpecialCharTok{\{}\NormalTok{REPO\_OWNER}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{.git"}
\OperatorTok{!}\NormalTok{git push \{push\_url\} HEAD:main}
\KeywordTok{del}\NormalTok{ token}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-1}

\begin{itemize}
\tightlist
\item
  Your report now has \textbf{citations}, \textbf{captions},
  \textbf{cross‑refs}, \textbf{alt text}, and \textbf{frozen} outputs
  for stable rebuilds.
\item
  RStudio can render the exact same Python‑based \texttt{.qmd}. Teams
  can mix editors without friction.
\item
  Next: Unix automation and Makefile targets to run reports end‑to‑end.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
5)}\label{homework-due-before-session-5}

\textbf{Goal:} Extend hygiene and add one analytic section---\textbf{ACF
plot}---with proper captions/labels/alt text/citations.

\subsection{Part A --- Add an ACF figure with cross‑ref + alt
text}\label{part-a-add-an-acf-figure-with-crossref-alt-text}

Append this code chunk to \texttt{reports/eda.qmd} after the ``Rolling
statistics'' section:

\begin{Shaded}
\begin{Highlighting}[]



\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}python}
\ImportTok{from}\NormalTok{ getpass }\ImportTok{import}\NormalTok{ getpass}
\NormalTok{token }\OperatorTok{=}\NormalTok{ getpass(}\StringTok{"GitHub token (not stored): "}\NormalTok{)}
\NormalTok{push\_url }\OperatorTok{=} \SpecialStringTok{f"https://}\SpecialCharTok{\{}\NormalTok{token}\SpecialCharTok{\}}\SpecialStringTok{@github.com/}\SpecialCharTok{\{}\NormalTok{REPO\_OWNER}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{.git"}
\OperatorTok{!}\NormalTok{git push \{push\_url\} HEAD:main}
\KeywordTok{del}\NormalTok{ token}
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\CommentTok{\#\#\# Grading (pass/revise)}

\OperatorTok{*}\NormalTok{ EDA page includes }\OperatorTok{**}\NormalTok{ACF figure}\OperatorTok{**} \ControlFlowTok{with}\NormalTok{ caption, label, }\KeywordTok{and}\NormalTok{ alt text}\OperatorTok{;}\NormalTok{ cross‑referenced }\KeywordTok{in}\NormalTok{ text.}
\OperatorTok{*} \OperatorTok{**}\NormalTok{Monthly returns}\OperatorTok{**}\NormalTok{ table present }\ControlFlowTok{with}\NormalTok{ caption}\OperatorTok{/}\NormalTok{label}\OperatorTok{;}\NormalTok{ referenced }\KeywordTok{in}\NormalTok{ text.}
\OperatorTok{*} \OperatorTok{**}\NormalTok{At least two}\OperatorTok{**}\NormalTok{ new, relevant citations included }\KeywordTok{and}\NormalTok{ rendered under References.}
\OperatorTok{*}\NormalTok{ \textasciigrave{}freeze\textasciigrave{} }\KeywordTok{and}\NormalTok{ \textasciigrave{}cache\textasciigrave{} enabled}\OperatorTok{;}\NormalTok{ site renders to \textasciigrave{}docs}\OperatorTok{/}\NormalTok{\textasciigrave{} }\KeywordTok{and}\NormalTok{ loads on GitHub Pages.}

\OperatorTok{{-}{-}{-}}

\CommentTok{\#\# Instructor checklist (before class)}

\OperatorTok{*}\NormalTok{ Confirm Quarto CLI install on your demo environment.}
\OperatorTok{*}\NormalTok{ Ensure you can }\BuiltInTok{open}\NormalTok{ an existing Python‑only \textasciigrave{}.qmd\textasciigrave{} }\KeywordTok{in}\NormalTok{ RStudio }\KeywordTok{and}\NormalTok{ click }\OperatorTok{**}\NormalTok{Render}\OperatorTok{**}\NormalTok{ successfully.}
\OperatorTok{*}\NormalTok{ Have a GitHub Pages site ready to show before}\OperatorTok{/}\NormalTok{after hygiene improvements.}

\CommentTok{\#\# Emphasize while teaching}

\OperatorTok{*} \OperatorTok{**}\NormalTok{Accessibility}\OperatorTok{**} \KeywordTok{is}\NormalTok{ part of professionalism: always write }\OperatorTok{**}\NormalTok{alt text}\OperatorTok{**}\NormalTok{, don’t rely on color alone, }\KeywordTok{and}\NormalTok{ keep captions informative.}
\OperatorTok{*} \OperatorTok{**}\NormalTok{Citations}\OperatorTok{**}\NormalTok{ are }\KeywordTok{not}\NormalTok{ optional }\ControlFlowTok{for}\NormalTok{ serious work}\OperatorTok{;}\NormalTok{ treat the report like a short paper.}
\OperatorTok{*} \OperatorTok{**}\NormalTok{Freeze }\OperatorTok{+}\NormalTok{ cache}\OperatorTok{**}\NormalTok{ save time }\KeywordTok{and}\NormalTok{ prevent accidental drift.}
\OperatorTok{*}\NormalTok{ RStudio }\KeywordTok{is}\NormalTok{ a }\OperatorTok{**}\NormalTok{comfortable alternative editor}\OperatorTok{**} \ControlFlowTok{for}\NormalTok{ Quarto even }\KeywordTok{in}\NormalTok{ a Python‑only workflow.}

\NormalTok{Next up (Session }\DecValTok{5}\NormalTok{): }\OperatorTok{**}\NormalTok{Unix }\ControlFlowTok{for}\NormalTok{ data work}\OperatorTok{**}\NormalTok{—shell power tools }\KeywordTok{and}\NormalTok{ Make automation to glue everything together.}



\NormalTok{\textasciigrave{}}\OperatorTok{\textless{}!{-}{-}}\NormalTok{ quarto}\OperatorTok{{-}}\BuiltInTok{file}\OperatorTok{{-}}\NormalTok{metadata: eyJyZXNvdXJjZURpciI6Ii4ifQ}\OperatorTok{==} \OperatorTok{{-}{-}\textgreater{}}\NormalTok{\textasciigrave{}\{}\OperatorTok{=}\NormalTok{html\}}

\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{}\OperatorTok{=}\NormalTok{html\}}
\OperatorTok{\textless{}!{-}{-}}\NormalTok{ quarto}\OperatorTok{{-}}\BuiltInTok{file}\OperatorTok{{-}}\NormalTok{metadata: eyJyZXNvdXJjZURpciI6Ii4iLCJib29rSXRlbVR5cGUiOiJjaGFwdGVyIiwiYm9va0l0ZW1OdW1iZXIiOjUsImJvb2tJdGVtRmlsZSI6ImxlYzUucW1kIiwiYm9va0l0ZW1EZXB0aCI6MH0}\OperatorTok{=} \OperatorTok{{-}{-}\textgreater{}}
\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}}

\CommentTok{\# Session 5 — Unix/Shell Essentials for Data Work }

\NormalTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\{.quarto}\OperatorTok{{-}}\NormalTok{title}\OperatorTok{{-}}\NormalTok{block template}\OperatorTok{=}\StringTok{\textquotesingle{}/Users/yiwang/Applications/quarto/share/projects/book/pandoc/title{-}block.md\textquotesingle{}}\NormalTok{\}}
\OperatorTok{{-}{-}{-}}
\NormalTok{title: Session }\DecValTok{5}\NormalTok{ — Unix}\OperatorTok{/}\NormalTok{Shell Essentials }\ControlFlowTok{for}\NormalTok{ Data Work}

\OperatorTok{{-}{-}{-}}
\end{Highlighting}
\end{Shaded}

Below is a complete lecture package for \textbf{Session 5 --- Unix/Shell
Essentials for Data Work} (75 minutes). It includes: timed agenda, slide
talking points, a \textbf{Colab‑friendly in‑class lab with copy‑paste
code cells}, and \textbf{homework with copy‑paste code}. The lab works
entirely in \textbf{Google Colab} using \textbf{Bash} commands and your
course repo in \textbf{Google Drive}.

\begin{quote}
\textbf{Scope today:} Filesystem navigation, pipes/redirects,
\texttt{grep}/\texttt{sed}/\texttt{awk},
\texttt{sort\textbar{}uniq\textbar{}wc\textbar{}cut\textbar{}tr\textbar{}head\textbar{}tail\textbar{}tee},
\texttt{find\textbar{}xargs}, regex basics, and a small \textbf{shell QA
script} for CSV health checks.
\end{quote}

\section{Session 5 --- Unix for Data Work (75
min)}\label{session-5-unix-for-data-work-75-min}

\subsection{Learning goals}\label{learning-goals-4}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
\item
  Navigate and manipulate files safely from the shell (relative vs
  absolute paths, quoting).
\item
\item
  Use \textbf{pipes} and \textbf{redirection} to build composable
  mini‑pipelines.
\item
\item
  Filter and transform text/CSV data with \textbf{\texttt{grep}},
  \textbf{\texttt{sed}}, \textbf{\texttt{awk}}, and friends.
\item
\item
  Find files with \textbf{\texttt{find}} and operate on them with
  \textbf{\texttt{xargs} / \texttt{-exec}} safely.
\item
\item
  Write a small, \textbf{defensive Bash script}
  (\texttt{set\ -euo\ pipefail}) that performs data QA checks and
  returns a \textbf{non‑zero exit code on failure}.
\item
\end{enumerate}

\section{Agenda (75 min)}\label{agenda-75-min-3}

\begin{itemize}
\item
\item
  \textbf{(8 min)} Why shell for data science; mental model of pipelines
\item
\item
  \textbf{(12 min)} Core commands \& patterns: pipes/redirects, quoting,
  regex, \texttt{grep}/\texttt{sed}/\texttt{awk}
\item
\item
  \textbf{(35 min)} \textbf{In‑class lab} (Colab): filesystem → CSV
  pipelines → find/xargs → QA shell script
\item
\item
  \textbf{(10 min)} Wrap‑up, troubleshooting, and homework briefing
\item
\item
  \textbf{(10 min)} Buffer for slow installs / student issues
\item
\end{itemize}

\section{Slides / talking points (put these bullets on your
slides)}\label{slides-talking-points-put-these-bullets-on-your-slides}

\textbf{Why shell?}

\begin{itemize}
\item
\item
  Fast iteration for \textbf{data plumbing} (ETL glue) and
  \textbf{repeatable} ops.
\item
\item
  Works on any POSIX host (your laptop, Colab VM, servers).
\item
\item
  Lets you \textbf{compose} small tools with pipes:
  \texttt{producer\ \textbar{}\ filter\ \textbar{}\ summarize\ \textgreater{}\ report.txt}.
\item
\end{itemize}

\textbf{Mental model}

\begin{itemize}
\item
\item
  \textbf{Stream text} through commands. Each command reads
  \textbf{STDIN}, writes \textbf{STDOUT}; \texttt{\textbar{}} connects
  them.
\item
\item
  \textbf{Redirection}: \texttt{\textgreater{}} (truncate to file),
  \texttt{\textgreater{}\textgreater{}} (append), \texttt{\textless{}}
  (read from file), \texttt{2\textgreater{}} (errors).
\item
\item
  \textbf{Exit code}: \texttt{0} success; non‑zero = error. Use
  \texttt{\&\&} (only if success) and \texttt{\textbar{}\textbar{}} (if
  failure).
\item
\end{itemize}

\textbf{Quoting}

\begin{itemize}
\item
\item
  \texttt{"double\ quotes"} expand variables and backslashes;
\item
\item
  \texttt{\textquotesingle{}single\ quotes\textquotesingle{}} are
  \textbf{literal} (best for regex/cut/sed patterns);
\item
\item
  Always \textbf{quote paths} that might contain spaces:
  \texttt{"\$FILE"}.
\item
\end{itemize}

\textbf{Regex quick guide}

\begin{itemize}
\item
\item
  \texttt{\^{}} start, \texttt{\$} end, \texttt{.} any char, \texttt{*}
  0+, \texttt{+} 1+, \texttt{?} 0/1, \texttt{{[}A-Z{]}} class,
  \texttt{(foo\textbar{}bar)} alt.
\item
\item
  Use \textbf{\texttt{grep\ -E}} (ERE) for \texttt{+} and
  \texttt{\textbar{}}. Plain \texttt{grep} is basic (BRE).
\item
\end{itemize}

\textbf{CSV caution}

\begin{itemize}
\item
\item
  Unix tools are \textbf{line‑oriented}. They're fine for simple CSVs
  (no embedded commas/quotes).
\item
\item
  For tricky CSVs, prefer Python/pandas. Today's examples are
  \textbf{simple CSVs}.
\item
\end{itemize}

\section{In‑class lab (35 min)}\label{inclass-lab-35-min-3}

\begin{quote}
\textbf{Instructor tip:} Have students run these \emph{as separate Colab
cells}. Cells labeled ``Bash'' use \texttt{\%\%bash}. Cells labeled
``Python'' are only used to \textbf{generate a small synthetic CSV} we
can play with offline (no API keys needed).
\end{quote}

\subsection{0) Mount Drive, set repo paths, and cd into the
repo}\label{mount-drive-set-repo-paths-and-cd-into-the-repo}

\textbf{Python (Colab)}

\begin{verbatim}
from google.colab import drive drive.mount('/content/drive', force_remount=True)  REPO_OWNER = "YOUR_GITHUB_USERNAME_OR_ORG"   # <- change for your class REPO_NAME  = "unified-stocks-teamX"          # <- change BASE_DIR   = "/content/drive/MyDrive/dspt25" REPO_DIR   = f"{BASE_DIR}/{REPO_NAME}"  import pathlib, os, subprocess pathlib.Path(BASE_DIR).mkdir(parents=True, exist_ok=True) if not pathlib.Path(REPO_DIR).exists():     print("Repo not found in Drive; please clone it in Session 2/3 or adjust REPO_DIR.") else:     os.chdir(REPO_DIR)     print("Working dir:", os.getcwd()) 
\end{verbatim}

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX" pwd ls -la 
\end{verbatim}

\subsection{\texorpdfstring{1) Create a small \textbf{synthetic} prices
CSV to work with (safe \&
reproducible)}{1) Create a small synthetic prices CSV to work with (safe \& reproducible)}}\label{create-a-small-synthetic-prices-csv-to-work-with-safe-reproducible}

\textbf{Python}

\begin{verbatim}
# Generates data/raw/prices.csv with columns: ticker,date,adj_close,volume,log_return import pandas as pd, numpy as np, os from pathlib import Path  Path("data/raw").mkdir(parents=True, exist_ok=True) tickers = pd.read_csv("tickers_25.csv")["ticker"].tolist() if os.path.exists("tickers_25.csv") else [     "AAPL","MSFT","AMZN","GOOGL","META","NVDA","TSLA","JPM","JNJ","V",     "PG","HD","BAC","XOM","CVX","PFE","KO","DIS","NFLX","INTC","CSCO","ORCL","T","VZ","WMT" ] dates = pd.bdate_range("2020-01-01", periods=180)  # ~ 9 months rng = np.random.default_rng(7)  frames=[] for t in tickers:     r = rng.normal(0, 0.01, len(dates))     price = 100*np.exp(np.cumsum(r))     vol = rng.integers(1e5, 5e6, len(dates))     df = pd.DataFrame({"ticker": t, "date": dates, "adj_close": price, "volume": vol})     df["log_return"] = np.log(df["adj_close"]).diff().fillna(0)     frames.append(df)  out = pd.concat(frames, ignore_index=True) out.to_csv("data/raw/prices.csv", index=False) out.head() 
\end{verbatim}

\subsection{\texorpdfstring{2) \textbf{Pipes \& redirects}
warm‑up}{2) Pipes \& redirects warm‑up}}\label{pipes-redirects-warmup}

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX"  # How many lines? (including header) wc -l data/raw/prices.csv | tee reports/prices_wc.txt  # First 5 lines, save to a sample head -n 5 data/raw/prices.csv | tee data/raw/prices_sample.csv  # Show ticker column only (field 1), excluding header cut -d, -f1 data/raw/prices.csv | tail -n +2 | head -n 10 
\end{verbatim}

\subsection{\texorpdfstring{3) \textbf{\texttt{grep}} filters (basic and
extended) +
\textbf{regex}}{3) grep filters (basic and extended) + regex}}\label{grep-filters-basic-and-extended-regex}

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX"  # All rows for NVDA OR MSFT (extended regex with alternation) grep -E '^(NVDA|MSFT),' data/raw/prices.csv | head -n 3  # Rows where ticker starts with a vowel (A, E, I, O, U) grep -E '^(A|E|I|O|U)[A-Z]*,' data/raw/prices.csv | head -n 3  # Count rows per ticker quickly (just for demo) cut -d, -f1 data/raw/prices.csv | tail -n +2 | sort | uniq -c | head 
\end{verbatim}

\begin{quote}
\textbf{Note:} We anchor \texttt{\^{}} to the start of the line so
\texttt{grep} doesn't match commas later in the row.
\end{quote}

\subsection{\texorpdfstring{4) \textbf{\texttt{sed}} transformations
(search/replace; in‑place
edits)}{4) sed transformations (search/replace; in‑place edits)}}\label{sed-transformations-searchreplace-inplace-edits}

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX"  # Make a copy so we don't touch the raw file cp data/raw/prices.csv data/interim || mkdir -p data/interim && cp data/raw/prices.csv data/interim cp data/interim/prices.csv data/interim/prices_copy.csv  # Replace ISO date dashes with slashes (2020-01-02 -> 2020/01/02) in-place sed -i '1!s/\([0-9]\{4\}\)-\([0-9]\{2\}\)-\([0-9]\{2\}\)/\1\/\2\/\3/g' data/interim/prices_copy.csv  # Normalize ticker to lowercase (first column) using sed's capture groups and tolower via awk (hybrid example) head -n 1 data/interim/prices_copy.csv > data/interim/prices_lower.csv tail -n +2 data/interim/prices_copy.csv | awk -F, 'BEGIN{OFS=","}{ $1=tolower($1); print }' >> data/interim/prices_lower.csv  head -n 3 data/interim/prices_lower.csv 
\end{verbatim}

\subsection{\texorpdfstring{5) \textbf{\texttt{awk}} for CSV
summarization}{5) awk for CSV summarization}}\label{awk-for-csv-summarization}

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX"  # Compute mean log_return per ticker (skip header). -F, sets comma as field separator. awk -F, 'NR>1 { sum[$1]+=$5; n[$1]++ } END { OFS=","; print "ticker","mean_log_return"; for (t in sum) print t, sum[t]/n[t] }' data/raw/prices.csv \ | sort -t, -k2,2nr | head  # Top 5 dates with highest absolute log_return for NVDA awk -F, 'NR>1 && $1=="NVDA" { print $2, $5 }' data/raw/prices.csv \ | awk '{ if ($2<0) s=-$2; else s=$2; print $1","$2","s }' \ | sort -t, -k3,3nr | head -n 5 
\end{verbatim}

\textbf{Explanation for students}

\begin{itemize}
\item
\item
  \texttt{NR\textgreater{}1} skips header.
\item
\item
  \texttt{sum{[}\$1{]}} and \texttt{n{[}\$1{]}} are associative arrays
  keyed by \textbf{ticker}.
\item
\item
  We sort numerically on column 2 (mean) with \texttt{-k2,2n} or
  \texttt{nr} for descending.
\item
\end{itemize}

\subsection{\texorpdfstring{6) \texttt{sort\ \textbar{}\ uniq} deduping
and \textbf{\texttt{comm}} to compare
lists}{6) sort \textbar{} uniq deduping and comm to compare lists}}\label{sort-uniq-deduping-and-comm-to-compare-lists}

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX"  # Unique tickers actually present in the file cut -d, -f1 data/raw/prices.csv | tail -n +2 | sort | uniq > data/interim/tickers_in_data.txt  # Compare to our canonical list from tickers_25.csv cut -d, -f1 tickers_25.csv | tail -n +2 | sort > data/interim/tickers_25.txt  echo "Only in data:"; comm -23 data/interim/tickers_in_data.txt data/interim/tickers_25.txt | sed 's/^/  /' echo "Only in canonical:"; comm -13 data/interim/tickers_in_data.txt data/interim/tickers_25.txt | sed 's/^/  /' 
\end{verbatim}

\subsection{\texorpdfstring{7) \textbf{\texttt{find}} and
\textbf{\texttt{xargs}} (safe,
null‑terminated)}{7) find and xargs (safe, null‑terminated)}}\label{find-and-xargs-safe-nullterminated}

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX"  # Show all CSVs under data/, printing sizes find data -type f -name "*.csv" -printf "%p,%s bytes\n" | sort | head  # Count lines in each CSV (null-safe for weird filenames) find data -type f -name "*.csv" -print0 | xargs -0 -I{} sh -c 'echo -n "{},"; wc -l < "{}"'  # Gzip-compress any CSV larger than ~1MB (demo threshold: 1e6 bytes) find data -type f -name "*.csv" -size +1000k -print0 | xargs -0 -I{} gzip -kf "{}"  # -k keeps original 
\end{verbatim}

\begin{quote}
\textbf{Pattern:} prefer \texttt{-print0\ \textbar{}\ xargs\ -0} to
safely handle spaces/newlines in filenames.
\end{quote}

\subsection{\texorpdfstring{8) Build a \textbf{defensive CSV QA script}
and run
it}{8) Build a defensive CSV QA script and run it}}\label{build-a-defensive-csv-qa-script-and-run-it}

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX" mkdir -p scripts  cat > scripts/qa_csv.sh << 'EOF' #!/usr/bin/env bash # Simple CSV health check # Usage: scripts/qa_csv.sh path/to/file.csv required_columns_csv set -euo pipefail IFS=$'\n\t'  FILE="${1:-}" REQUIRED="${2:-ticker,date,adj_close,volume,log_return}"  err() { echo "ERROR: $*" >&2; exit 1; } [[ -z "$FILE" ]] && err "No CSV file provided." [[ ! -f "$FILE" ]] && err "File not found: $FILE"  # 1) Non-empty and header present LINES=$(wc -l < "$FILE" || true) [[ "${LINES:-0}" -lt 2 ]] && err "File has <2 lines (missing data?): $FILE"  HEADER=$(head -n 1 "$FILE") # 2) All required columns present IFS=',' read -r -a req <<< "$REQUIRED" for col in "${req[@]}"; do   echo "$HEADER" | grep -q -E "(^|,)${col}(,|$)" || err "Missing required column: $col" done  # 3) No obvious NA/blank values in required numeric cols (basic check) NUMERIC="adj_close,volume,log_return" IFS=',' read -r -a nums <<< "$NUMERIC" for col in "${nums[@]}"; do   # find column index   idx=$(awk -F, -v COL="$col" 'NR==1{for(i=1;i<=NF;i++) if($i==COL) print i}' "$FILE")   [[ -z "${idx:-}" ]] && err "Column not found: $col"   # check any blank values from row 2 onward   bad=$(awk -F, -v I="$idx" 'NR>1 && ($I=="" || $I=="NA") {c++} END{print c+0}' "$FILE")   [[ "$bad" -gt 0 ]] && err "Found $bad blank/NA in column: $col" done  echo "OK: $FILE passed basic CSV QA ($LINES lines)." EOF  chmod +x scripts/qa_csv.sh 
\end{verbatim}

\textbf{Run the QA script}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX" scripts/qa_csv.sh data/raw/prices.csv 
\end{verbatim}

\begin{quote}
Intentionally break it (optional): open \texttt{data/raw/prices.csv},
blank out a value, and re‑run to watch it fail with non‑zero exit code.
\end{quote}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-2}

\begin{itemize}
\item
\item
  Shell is about \textbf{composable building blocks}. Learn 15 commands
  deeply; combine them fluently.
\item
\item
  Prefer \textbf{null‑safe}
  \texttt{find\ …\ -print0\ \textbar{}\ xargs\ -0} patterns; always
  quote variables: \texttt{"\$FILE"}.
\item
\item
  For complex CSV logic, \textbf{fall back to Python}; but shell shines
  for \textbf{quick filters and QA}.
\item
\item
  We'll hook these into \textbf{Make} next session so one command runs
  your whole pipeline.
\item
\end{itemize}

\section{Homework (due before Session
6)}\label{homework-due-before-session-6}

\textbf{Goal:} Practice and codify shell workflows into your project:\\
(1) a \emph{data stats} pipeline, (2) a \emph{per‑ticker split} utility,
(3) a Makefile target, and (4) a short \textbf{shell‑only EDA} text
report.

\subsection{Part A --- Data stats pipeline (one‑liners saved to
files)}\label{part-a-data-stats-pipeline-oneliners-saved-to-files}

\textbf{Bash (Colab)}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX" mkdir -p reports data/interim  # 1) Count lines and unique tickers {    echo "Lines (incl header): $(wc -l < data/raw/prices.csv)";   echo "Unique tickers: $(cut -d, -f1 data/raw/prices.csv | tail -n +2 | sort | uniq | wc -l)"; } | tee reports/data_counts.txt  # 2) Top-10 days by absolute log_return across all tickers tail -n +2 data/raw/prices.csv \ | awk -F, '{a=$5; if(a<0) a=-a; print $1","$2","$5","a}' \ | sort -t, -k4,4nr | head -n 10 \ | tee reports/top10_abs_moves.csv  # 3) Mean log_return per ticker (CSV) awk -F, 'NR>1 { s[$1]+=$5; n[$1]++ } END { OFS=","; print "ticker,mean_log_return"; for(t in s) print t, s[t]/n[t] }' \   data/raw/prices.csv | sort -t, -k2,2nr | tee reports/mean_return_by_ticker.csv 
\end{verbatim}

\subsection{\texorpdfstring{Part B --- Split per‑ticker CSVs into
\texttt{data/interim/ticker=XYZ/}
directories}{Part B --- Split per‑ticker CSVs into data/interim/ticker=XYZ/ directories}}\label{part-b-split-perticker-csvs-into-datainterimtickerxyz-directories}

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX" mkdir -p data/interim  # Extract header once HEADER=$(head -n 1 data/raw/prices.csv)  # Create per-ticker files with header + rows (null-safe not necessary here) cut -d, -f1 data/raw/prices.csv | tail -n +2 | sort | uniq | while read -r T; do   mkdir -p "data/interim/ticker=${T}"   {     echo "$HEADER"     awk -F, -v TK="$T" 'NR==1 || $1==TK' data/raw/prices.csv   } > "data/interim/ticker=${T}/prices_${T}.csv" done  # Verify one example ls -la data/interim/ticker=AAPL | head 
\end{verbatim}

\subsection{\texorpdfstring{Part C --- Add \textbf{Makefile} targets for
QA and per‑ticker
split}{Part C --- Add Makefile targets for QA and per‑ticker split}}\label{part-c-add-makefile-targets-for-qa-and-perticker-split}

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX"  # Append or create a Makefile {   echo ""   echo "qa:"   echo "\tscripts/qa_csv.sh data/raw/prices.csv"   echo ""   echo "split-by-ticker:"   echo "\tbash -c 'HEADER=\$(head -n 1 data/raw/prices.csv); cut -d, -f1 data/raw/prices.csv | tail -n +2 | sort | uniq | while read -r T; do mkdir -p data/interim/ticker=\$\$T; { echo \"\$\$HEADER\"; awk -F, -v TK=\"\$\$T\" '\"'NR==1 || \$1==TK'\"' data/raw/prices.csv; } > data/interim/ticker=\$\$T/prices_\$\$T.csv; done'" } >> Makefile  cat Makefile 
\end{verbatim}

\textbf{Run the targets}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX" make qa make split-by-ticker 
\end{verbatim}

\subsection{Part D --- Shell‑only mini EDA
report}\label{part-d-shellonly-mini-eda-report}

Create \texttt{reports/mini\_eda.txt} with \textbf{three sections}:
counts, top moves, mean returns.

\textbf{Bash}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX"  {   echo "# Mini EDA (shell-only)"   echo "Generated: $(date)"   echo   echo "## Counts"   echo "Lines (incl header): $(wc -l < data/raw/prices.csv)"   echo "Unique tickers: $(cut -d, -f1 data/raw/prices.csv | tail -n +2 | sort | uniq | wc -l)"   echo   echo "## Top 5 absolute daily moves"   tail -n +2 data/raw/prices.csv \   | awk -F, '{a=$5; if(a<0) a=-a; print $1","$2","$5","a}' \   | sort -t, -k4,4nr | head -n 5   echo   echo "## Mean log_return by ticker (top 10)"   awk -F, 'NR>1 { s[$1]+=$5; n[$1]++ } END { for(t in s) printf "%s,%.6f\n", t, s[t]/n[t] }' \     data/raw/prices.csv | sort -t, -k2,2nr | head -n 10 } | tee reports/mini_eda.txt 
\end{verbatim}

\subsection{Part E --- Commit \& push your changes (use your short‑lived
token as in Session
2)}\label{part-e-commit-push-your-changes-use-your-shortlived-token-as-in-session-2}

\textbf{Bash + Python (getpass)}

\begin{verbatim}
%%bash set -euo pipefail cd "/content/drive/MyDrive/dspt25/unified-stocks-teamX" git add scripts/qa_csv.sh data/raw/prices.csv data/interim reports/*.txt reports/*.csv Makefile git status git commit -m "feat(shell): data QA script, per-ticker split, shell mini-EDA, Make targets" 
\end{verbatim}

\begin{verbatim}
from getpass import getpass import os, subprocess token = getpass("GitHub token (not stored): ") REPO_OWNER = "YOUR_GITHUB_USERNAME_OR_ORG" REPO_NAME  = "unified-stocks-teamX" push_url = f"https://{token}@github.com/{REPO_OWNER}/{REPO_NAME}.git" # Push current HEAD to main (adjust if you prefer a branch + PR) subprocess.run(["git", "push", push_url, "HEAD:main"], check=True) del token 
\end{verbatim}

\subsection{Grading (pass/revise)}\label{grading-passrevise-2}

\begin{itemize}
\item
\item
  \texttt{scripts/qa\_csv.sh} exists, is executable, and \textbf{fails}
  on malformed CSV, \textbf{passes} on clean CSV.
\item
\item
  \texttt{reports/data\_counts.txt},
  \texttt{reports/top10\_abs\_moves.csv},
  \texttt{reports/mean\_return\_by\_ticker.csv}, and
  \texttt{reports/mini\_eda.txt} generated.
\item
\item
  \texttt{make\ qa} and \texttt{make\ split-by-ticker} run successfully.
\item
\item
  Per‑ticker CSVs created under \texttt{data/interim/ticker=XYZ/}.
\item
\end{itemize}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-2}

\begin{itemize}
\item
\item
  Test the lab in a fresh Colab runtime; ensure Drive path matches.
\item
\item
  Prepare a one‑slide ``cheat sheet'' of \texttt{grep/sed/awk} flags
  used today.
\item
\item
  (Optional) Verify \texttt{gzip} is available (it is on Colab).
\item
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-2}

\begin{itemize}
\item
\item
  \textbf{Quote} variables and paths. Prefer
  \texttt{-print0\ \textbar{}\ xargs\ -0} with \texttt{find}.
\item
\item
  \textbf{Fail fast} in scripts (\texttt{set\ -euo\ pipefail}) and
  return \textbf{non‑zero} exit codes for CI.
\item
\item
  Shell is for \textbf{plumbing}---it complements, not replaces, Python.
\item
\end{itemize}

\textbf{Next session (6):} ``Make/just, rsync, ssh/tmux (survey)'' and
we'll wire \texttt{make\ get-data} and \texttt{make\ report} into a
reproducible one‑command pipeline.

\bookmarksetup{startatroot}

\chapter{Session 6 --- Make/Automation + rsync + ssh/tmux
(survey)}\label{session-6-makeautomation-rsync-sshtmux-survey}

Below is a complete lecture package for \textbf{Session 6 ---
Make/Automation + rsync + ssh/tmux (survey)} (75 minutes). It includes:
a timed agenda, slide talking points, a \textbf{Colab‑friendly in‑class
lab with copy‑paste code}, and \textbf{homework with copy‑paste code}.
By the end, students will have a \textbf{one‑command pipeline}
(\texttt{make\ all}) to fetch data, build features, render the Quarto
EDA, and back up artifacts---plus practical notes on \texttt{rsync},
\texttt{ssh}, and \texttt{tmux}.

\begin{quote}
\textbf{Assumptions:} You're using the same Drive‑mounted repo from
prior sessions (e.g., \texttt{unified-stocks-teamX}). The course remains
Python‑first, Colab‑first. No trading advice---this is educational.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 6 --- Make/Automation + rsync + ssh/tmux (75
min)}\label{session-6-makeautomation-rsync-sshtmux-75-min}

\subsection{Learning goals}\label{learning-goals-5}

Students will be able to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain how \textbf{Make} turns scripts into a \textbf{reproducible
  pipeline} via \textbf{targets, dependencies,} and \textbf{incremental
  builds}.
\item
  Create and use a \textbf{Makefile} with helpful defaults, variables,
  and a \texttt{help} target.
\item
  Use \textbf{rsync} to back up project artifacts and understand
  \texttt{-\/-delete} and exclude patterns.
\item
  Understand the \textbf{ssh} key flow and a \textbf{tmux} workflow for
  long‑running jobs (survey).
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-4}

\begin{itemize}
\tightlist
\item
  \textbf{(12 min)} Slides: Why automation? How Make models dependencies
  \& incremental builds; best practices
\item
  \textbf{(10 min)} Slides: rsync fundamentals; \texttt{ssh} keys \&
  config; \texttt{tmux} workflow (survey)
\item
  \textbf{(33 min)} \textbf{In‑class lab} (Colab): create scripts →
  author Makefile → run \texttt{make\ all} → rsync backup
\item
  \textbf{(10 min)} Wrap‑up \& troubleshooting
\item
  \textbf{(10 min)} Buffer
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points (drop these bullets into your
deck)}\label{slides-talking-points-drop-these-bullets-into-your-deck}

\subsection{Why Make for DS pipelines?}\label{why-make-for-ds-pipelines}

\begin{itemize}
\tightlist
\item
  Encodes your workflow as \textbf{targets} that depend on
  \textbf{files} or other targets.
\item
  \textbf{Incremental}: only rebuilds what changed.
\item
  Plays nicely with CI (\texttt{make\ all} from a clean clone).
\item
  Stable across OSes; no new runtime to learn.
\end{itemize}

\textbf{Core syntax}

\begin{verbatim}
target: dependencies
<TAB> recipe commands
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Use variables: \texttt{PY\ :=\ python}, \texttt{QUARTO\ :=\ quarto}.
\item
  Use \textbf{PHONY} for meta‑targets that don't produce files.
\item
  Prefer \textbf{deterministic} outputs: fixed seeds, pinned versions,
  stable paths.
\end{itemize}

\subsection{rsync basics}\label{rsync-basics}

\begin{itemize}
\tightlist
\item
  \texttt{rsync\ -avh\ SRC/\ DST/} → syncs directory trees, preserving
  metadata.
\item
  \texttt{-\/-delete} makes DST exactly match SRC (removes files not in
  SRC).
\item
  \texttt{-\/-exclude} to skip folders
  (\texttt{-\/-exclude\ \textquotesingle{}raw/\textquotesingle{}}).
\item
  Remote with SSH:
  \texttt{rsync\ -avz\ -e\ ssh\ SRC/\ user@host:/path/}.
\end{itemize}

\subsection{ssh keys \& tmux (survey)}\label{ssh-keys-tmux-survey}

\begin{itemize}
\tightlist
\item
  \textbf{Keys}: \texttt{ssh-keygen\ -t\ ed25519\ -C\ "you@school.edu"};
  add the \textbf{public} key to servers/GitHub; keep private key
  private.
\item
  \texttt{\textasciitilde{}/.ssh/config} holds named hosts;
  \texttt{ssh\ myhpc} uses that stanza.
\item
  \textbf{tmux}: start \texttt{tmux\ new\ -s\ train}; detach
  (\texttt{Ctrl-b\ d}); list (\texttt{tmux\ ls}); reattach
  (\texttt{tmux\ attach\ -t\ train}). Keeps jobs alive on remote shells.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (33 min)}\label{inclass-lab-33-min}

We'll create \textbf{three tiny scripts} and a \textbf{Makefile} that
ties them together:

\begin{itemize}
\tightlist
\item
  \texttt{scripts/get\_prices.py} → \texttt{data/raw/prices.csv} (Yahoo
  via \texttt{yfinance}, with synthetic fallback)
\item
  \texttt{scripts/build\_features.py} →
  \texttt{data/processed/features.parquet}
\item
  \texttt{scripts/backup.sh} → rsync your artifacts to
  \texttt{backups/\textless{}timestamp\textgreater{}/}
\item
  \texttt{Makefile} → \texttt{make\ all} runs end‑to‑end;
  \texttt{make\ report} renders Quarto; \texttt{make\ backup} syncs
  artifacts.
\end{itemize}

\begin{quote}
\textbf{Instructor tip:} Have everyone run each block as a separate
Colab cell.
\end{quote}

\subsection{0) Mount Drive and set repo
path}\label{mount-drive-and-set-repo-path}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_OWNER }\OperatorTok{=} \StringTok{"YOUR\_GITHUB\_USERNAME\_OR\_ORG"}  \CommentTok{\# \textless{}{-} change}
\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}         \CommentTok{\# \textless{}{-} change}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ pathlib, os, subprocess}
\NormalTok{pathlib.Path(BASE\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ pathlib.Path(REPO\_DIR).exists():}
    \ControlFlowTok{raise} \PreprocessorTok{SystemExit}\NormalTok{(}\StringTok{"Repo not found in Drive. Clone it first (see Session 2/3)."}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}
\end{Highlighting}
\end{Shaded}

\subsection{1) Quick tool checks (Make, rsync,
Quarto)}\label{quick-tool-checks-make-rsync-quarto}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ subprocess, shutil}
\KeywordTok{def}\NormalTok{ check(cmd):}
    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        out }\OperatorTok{=}\NormalTok{ subprocess.check\_output(cmd, text}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
        \BuiltInTok{print}\NormalTok{(cmd[}\DecValTok{0}\NormalTok{], }\StringTok{"OK"}\NormalTok{)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \BuiltInTok{print}\NormalTok{(cmd[}\DecValTok{0}\NormalTok{], }\StringTok{"NOT FOUND"}\NormalTok{)}
\NormalTok{check([}\StringTok{"make"}\NormalTok{, }\StringTok{"{-}{-}version"}\NormalTok{])}
\NormalTok{check([}\StringTok{"rsync"}\NormalTok{, }\StringTok{"{-}{-}version"}\NormalTok{])}
\NormalTok{check([}\StringTok{"quarto"}\NormalTok{, }\StringTok{"{-}{-}version"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

If Quarto is missing, re-run the installer from Session 3 before
\texttt{make\ report}.

\subsection{\texorpdfstring{2) Script:
\texttt{scripts/get\_prices.py}}{2) Script: scripts/get\_prices.py}}\label{script-scriptsget_prices.py}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{Path(}\StringTok{"scripts"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{get\_py }\OperatorTok{=} \VerbatimStringTok{r"""\#!/usr/bin/env python}
\VerbatimStringTok{import argparse, sys, time}
\VerbatimStringTok{from pathlib import Path}
\VerbatimStringTok{import pandas as pd, numpy as np}

\VerbatimStringTok{def fetch\_yf(ticker, start, end):}
\VerbatimStringTok{    import yfinance as yf}
\VerbatimStringTok{    df = yf.download(ticker, start=start, end=end, auto\_adjust=True, progress=False)}
\VerbatimStringTok{    if df is None or df.empty:}
\VerbatimStringTok{        raise RuntimeError("empty")}
\VerbatimStringTok{    df = df.rename(columns=str.lower)[["close","volume"]]}
\VerbatimStringTok{    df.index.name = "date"}
\VerbatimStringTok{    df = df.reset\_index()}
\VerbatimStringTok{    df["ticker"] = ticker}
\VerbatimStringTok{    return df[["ticker","date","close","volume"]]}

\VerbatimStringTok{def main():}
\VerbatimStringTok{    ap = argparse.ArgumentParser()}
\VerbatimStringTok{    ap.add\_argument("{-}{-}tickers", default="tickers\_25.csv")}
\VerbatimStringTok{    ap.add\_argument("{-}{-}start", default="2020{-}01{-}01")}
\VerbatimStringTok{    ap.add\_argument("{-}{-}end", default="")}
\VerbatimStringTok{    ap.add\_argument("{-}{-}out", default="data/raw/prices.csv")}
\VerbatimStringTok{    args = ap.parse\_args()}

\VerbatimStringTok{    out = Path(args.out)}
\VerbatimStringTok{    out.parent.mkdir(parents=True, exist\_ok=True)}
\VerbatimStringTok{    tickers = pd.read\_csv(args.tickers)["ticker"].dropna().unique().tolist()}

\VerbatimStringTok{    rows = []}
\VerbatimStringTok{    for t in tickers:}
\VerbatimStringTok{        try:}
\VerbatimStringTok{            df = fetch\_yf(t, args.start, args.end or None)}
\VerbatimStringTok{        except Exception:}
\VerbatimStringTok{            \# synthetic fallback}
\VerbatimStringTok{            idx = pd.bdate\_range(args.start, args.end or pd.Timestamp.today().date())}
\VerbatimStringTok{            rng = np.random.default\_rng(42 + hash(t)\%1000)}
\VerbatimStringTok{            r = rng.normal(0, 0.01, len(idx))}
\VerbatimStringTok{            price = 100*np.exp(np.cumsum(r))}
\VerbatimStringTok{            vol = rng.integers(1e5, 5e6, len(idx))}
\VerbatimStringTok{            df = pd.DataFrame(\{"ticker": t, "date": idx, "close": price, "volume": vol\})}
\VerbatimStringTok{        df["date"] = pd.to\_datetime(df["date"]).dt.date}
\VerbatimStringTok{        df["adj\_close"] = df["close"]}
\VerbatimStringTok{        df = df.drop(columns=["close"])}
\VerbatimStringTok{        df["log\_return"] = np.log(df["adj\_close"]).diff().fillna(0.0)}
\VerbatimStringTok{        rows.append(df)}

\VerbatimStringTok{    allp = pd.concat(rows, ignore\_index=True)}
\VerbatimStringTok{    allp = allp[["ticker","date","adj\_close","volume","log\_return"]]}
\VerbatimStringTok{    allp.to\_csv(out, index=False)}
\VerbatimStringTok{    print("Wrote", out, "rows:", len(allp))}

\VerbatimStringTok{if \_\_name\_\_ == "\_\_main\_\_":}
\VerbatimStringTok{    sys.exit(main())}
\VerbatimStringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{"scripts/get\_prices.py"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(get\_py)}
\ImportTok{import}\NormalTok{ os, stat}
\NormalTok{os.chmod(}\StringTok{"scripts/get\_prices.py"}\NormalTok{, os.stat(}\StringTok{"scripts/get\_prices.py"}\NormalTok{).st\_mode }\OperatorTok{|}\NormalTok{ stat.S\_IEXEC)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Created scripts/get\_prices.py"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Script:
\texttt{scripts/build\_features.py}}{3) Script: scripts/build\_features.py}}\label{script-scriptsbuild_features.py}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{feat\_py }\OperatorTok{=} \VerbatimStringTok{r"""\#!/usr/bin/env python}
\VerbatimStringTok{import argparse}
\VerbatimStringTok{from pathlib import Path}
\VerbatimStringTok{import pandas as pd, numpy as np}

\VerbatimStringTok{def main():}
\VerbatimStringTok{    ap = argparse.ArgumentParser()}
\VerbatimStringTok{    ap.add\_argument("{-}{-}input", default="data/raw/prices.csv")}
\VerbatimStringTok{    ap.add\_argument("{-}{-}out", default="data/processed/features.parquet")}
\VerbatimStringTok{    ap.add\_argument("{-}{-}roll", type=int, default=20)}
\VerbatimStringTok{    args = ap.parse\_args()}

\VerbatimStringTok{    df = pd.read\_csv(args.input, parse\_dates=["date"])}
\VerbatimStringTok{    df = df.sort\_values(["ticker","date"])}
\VerbatimStringTok{    \# groupwise lags}
\VerbatimStringTok{    df["r\_1d"] = df["log\_return"]}
\VerbatimStringTok{    for k in (1,2,3):}
\VerbatimStringTok{        df[f"lag}\SpecialCharTok{\{k\}}\VerbatimStringTok{"] = df.groupby("ticker")["r\_1d"].shift(k)}
\VerbatimStringTok{    df["roll\_mean"] = (df.groupby("ticker")["r\_1d"]}
\VerbatimStringTok{                         .rolling(args.roll, min\_periods=args.roll//2).mean()}
\VerbatimStringTok{                         .reset\_index(level=0, drop=True))}
\VerbatimStringTok{    df["roll\_std"]  = (df.groupby("ticker")["r\_1d"]}
\VerbatimStringTok{                         .rolling(args.roll, min\_periods=args.roll//2).std()}
\VerbatimStringTok{                         .reset\_index(level=0, drop=True))}
\VerbatimStringTok{    out = Path(args.out)}
\VerbatimStringTok{    out.parent.mkdir(parents=True, exist\_ok=True)}
\VerbatimStringTok{    \# Save compactly}
\VerbatimStringTok{    df.to\_parquet(out, index=False)}
\VerbatimStringTok{    print("Wrote", out, "rows:", len(df))}

\VerbatimStringTok{if \_\_name\_\_ == "\_\_main\_\_":}
\VerbatimStringTok{    main()}
\VerbatimStringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{"scripts/build\_features.py"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(feat\_py)}
\ImportTok{import}\NormalTok{ os, stat}
\NormalTok{os.chmod(}\StringTok{"scripts/build\_features.py"}\NormalTok{, os.stat(}\StringTok{"scripts/build\_features.py"}\NormalTok{).st\_mode }\OperatorTok{|}\NormalTok{ stat.S\_IEXEC)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Created scripts/build\_features.py"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) Script: \texttt{scripts/backup.sh}
(rsync)}{4) Script: scripts/backup.sh (rsync)}}\label{script-scriptsbackup.sh-rsync}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{backup\_sh }\OperatorTok{=} \VerbatimStringTok{r"""\#!/usr/bin/env bash}
\VerbatimStringTok{\# Sync selected artifacts to backups/\textless{}timestamp\textgreater{} using rsync.}
\VerbatimStringTok{\# Usage: scripts/backup.sh [DEST\_ROOT]}
\VerbatimStringTok{set {-}euo pipefail}
\VerbatimStringTok{ROOT="$\{1:{-}backups\}"}
\VerbatimStringTok{STAMP="$(date +\%Y\%m}\SpecialCharTok{\%d}\VerbatimStringTok{{-}\%H\%M\%S)"}
\VerbatimStringTok{DEST="$}\SpecialCharTok{\{ROOT\}}\VerbatimStringTok{/run{-}$}\SpecialCharTok{\{STAMP\}}\VerbatimStringTok{"}
\VerbatimStringTok{mkdir {-}p "$DEST"}

\VerbatimStringTok{\# What to back up (adjust as needed)}
\VerbatimStringTok{INCLUDE=("data/processed" "reports" "docs")}

\VerbatimStringTok{for src in "$}\SpecialCharTok{\{INCLUDE[@]\}}\VerbatimStringTok{"; do}
\VerbatimStringTok{  if [[ {-}d "$src" ]]; then}
\VerbatimStringTok{    echo "Syncing $src {-}\textgreater{} $DEST/$src"}
\VerbatimStringTok{    rsync {-}avh {-}{-}delete {-}{-}exclude \textquotesingle{}raw/\textquotesingle{} {-}{-}exclude \textquotesingle{}interim/\textquotesingle{} "$src"/ "$DEST/$src"/}
\VerbatimStringTok{  fi}
\VerbatimStringTok{done}

\VerbatimStringTok{echo "Backup complete at $DEST"}
\VerbatimStringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{"scripts/backup.sh"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(backup\_sh)}
\ImportTok{import}\NormalTok{ os, stat}
\NormalTok{os.chmod(}\StringTok{"scripts/backup.sh"}\NormalTok{, os.stat(}\StringTok{"scripts/backup.sh"}\NormalTok{).st\_mode }\OperatorTok{|}\NormalTok{ stat.S\_IEXEC)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Created scripts/backup.sh"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{5) Makefile (robust, with variables and
\texttt{help})}{5) Makefile (robust, with variables and help)}}\label{makefile-robust-with-variables-and-help}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{makefile }\OperatorTok{=} \VerbatimStringTok{r"""\# Makefile — unified{-}stocks}
\VerbatimStringTok{SHELL := /bin/bash}
\VerbatimStringTok{.SHELLFLAGS := {-}eu {-}o pipefail {-}c}

\VerbatimStringTok{PY := python}
\VerbatimStringTok{QUARTO := quarto}

\VerbatimStringTok{START ?= 2020{-}01{-}01}
\VerbatimStringTok{END   ?= 2025{-}08{-}01}
\VerbatimStringTok{ROLL  ?= 30}

\VerbatimStringTok{DATA\_RAW := data/raw/prices.csv}
\VerbatimStringTok{FEATS    := data/processed/features.parquet}
\VerbatimStringTok{REPORT   := docs/reports/eda.html}

\VerbatimStringTok{\# Default target}
\VerbatimStringTok{.DEFAULT\_GOAL := help}

\VerbatimStringTok{.PHONY: help all clean clobber qa report backup}

\VerbatimStringTok{help: \#\# Show help for each target}
\VerbatimStringTok{    @awk \textquotesingle{}BEGIN \{FS = ":.*\#\#"; printf "Available targets:\textbackslash{}n"\} /\^{}[a{-}zA{-}Z0{-}9\_\textbackslash{}{-}]+:.*\#\#/ \{printf "  \textbackslash{}033[36m}\SpecialCharTok{\%{-}18s}\VerbatimStringTok{\textbackslash{}033[0m }\SpecialCharTok{\%s}\VerbatimStringTok{\textbackslash{}n", $$1, $$2\}\textquotesingle{} $(MAKEFILE\_LIST)}

\VerbatimStringTok{all: $(DATA\_RAW) $(FEATS) report backup \#\# Run the full pipeline and back up artifacts}

\VerbatimStringTok{$(DATA\_RAW): scripts/get\_prices.py tickers\_25.csv}
\VerbatimStringTok{    $(PY) scripts/get\_prices.py {-}{-}tickers tickers\_25.csv {-}{-}start $(START) {-}{-}end $(END) {-}{-}out $(DATA\_RAW)}

\VerbatimStringTok{$(FEATS): scripts/build\_features.py $(DATA\_RAW) scripts/qa\_csv.sh}
\VerbatimStringTok{    \# Basic QA first}
\VerbatimStringTok{    scripts/qa\_csv.sh $(DATA\_RAW)}
\VerbatimStringTok{    $(PY) scripts/build\_features.py {-}{-}input $(DATA\_RAW) {-}{-}out $(FEATS) {-}{-}roll $(ROLL)}

\VerbatimStringTok{report: $(REPORT) \#\# Render Quarto EDA to docs/}
\VerbatimStringTok{$(REPORT): reports/eda.qmd \_quarto.yml docs/style.css}
\VerbatimStringTok{    $(QUARTO) render reports/eda.qmd {-}P symbol:AAPL {-}P start\_date=$(START) {-}P end\_date=$(END) {-}P rolling=$(ROLL) {-}{-}output{-}dir docs/}
\VerbatimStringTok{    @test {-}f $(REPORT) || (echo "Report not generated." \&\& exit 1)}

\VerbatimStringTok{backup: \#\# Rsync selected artifacts to backups/\textless{}timestamp\textgreater{}/}
\VerbatimStringTok{    ./scripts/backup.sh}

\VerbatimStringTok{clean: \#\# Remove intermediate artifacts (safe)}
\VerbatimStringTok{    rm {-}rf data/interim}
\VerbatimStringTok{    rm {-}rf data/processed/*.parquet || true}

\VerbatimStringTok{clobber: clean \#\# Remove generated reports and backups (dangerous)}
\VerbatimStringTok{    rm {-}rf docs/reports || true}
\VerbatimStringTok{    rm {-}rf backups || true}
\VerbatimStringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{"Makefile"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(makefile)}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{"Makefile"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

\begin{quote}
Note: The Makefile expects \texttt{scripts/qa\_csv.sh} from Session 5.
If a student missed it, set \texttt{scripts/qa\_csv.sh} to a no‑op or
remove that dependency temporarily.
\end{quote}

\subsection{6) Try the pipeline}\label{try-the-pipeline}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ subprocess, os, textwrap, sys}
\BuiltInTok{print}\NormalTok{(subprocess.check\_output([}\StringTok{"make"}\NormalTok{, }\StringTok{"help"}\NormalTok{], text}\OperatorTok{=}\VariableTok{True}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Fetch raw, build features, render report, back up artifacts}
\ImportTok{import}\NormalTok{ subprocess}
\BuiltInTok{print}\NormalTok{(subprocess.check\_output([}\StringTok{"make"}\NormalTok{, }\StringTok{"all"}\NormalTok{], text}\OperatorTok{=}\VariableTok{True}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Confirm:

\begin{itemize}
\tightlist
\item
  \texttt{data/raw/prices.csv} exists
\item
  \texttt{data/processed/features.parquet} exists
\item
  \texttt{docs/reports/eda.html} renders
\item
  \texttt{backups/run-\textless{}timestamp\textgreater{}/} contains
  synced folders
\end{itemize}

\subsection{\texorpdfstring{7) (Optional) \texttt{just}
command‑runner}{7) (Optional) just command‑runner}}\label{optional-just-commandrunner}

\begin{quote}
\textbf{Optional}: If \texttt{just} is available on your system, create
a \texttt{justfile} that mirrors common Make targets. On Colab,
installation may or may not be available; this is just for reference.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\BuiltInTok{set} \AttributeTok{{-}e}
\ControlFlowTok{if} \OtherTok{! }\BuiltInTok{command} \AttributeTok{{-}v}\NormalTok{ just }\OperatorTok{\textgreater{}}\NormalTok{/dev/null }\DecValTok{2}\OperatorTok{\textgreater{}\&}\DecValTok{1}\KeywordTok{;} \ControlFlowTok{then}
  \BuiltInTok{echo} \StringTok{"just not found; skipping optional step."}
  \BuiltInTok{exit}\NormalTok{ 0}
\ControlFlowTok{fi}
\FunctionTok{cat} \OperatorTok{\textgreater{}}\NormalTok{ justfile }\OperatorTok{\textless{}\textless{} \textquotesingle{}EOF\textquotesingle{}}
\StringTok{\# justfile — optional convenience recipes}
\StringTok{set shell := ["bash", "{-}eu", "{-}o", "pipefail", "{-}c"]}

\StringTok{start := "2020{-}01{-}01"}
\StringTok{end   := "2025{-}08{-}01"}
\StringTok{roll  := "30"}

\StringTok{help:}
\StringTok{\textbackslash{}t@echo "Recipes: get{-}data, features, report, all, backup"}

\StringTok{get{-}data:}
\StringTok{\textbackslash{}tpython scripts/get\_prices.py {-}{-}tickers tickers\_25.csv {-}{-}start \{\{start\}\} {-}{-}end \{\{end\}\} {-}{-}out data/raw/prices.csv}

\StringTok{features:}
\StringTok{\textbackslash{}tbash {-}lc \textquotesingle{}scripts/qa\_csv.sh data/raw/prices.csv\textquotesingle{}}
\StringTok{\textbackslash{}tpython scripts/build\_features.py {-}{-}input data/raw/prices.csv {-}{-}out data/processed/features.parquet {-}{-}roll \{\{roll\}\}}

\StringTok{report:}
\StringTok{\textbackslash{}tquarto render reports/eda.qmd {-}P symbol:AAPL {-}P start\_date=\{\{start\}\} {-}P end\_date=\{\{end\}\} {-}P rolling:\{\{roll\}\} {-}{-}output{-}dir docs/}

\StringTok{all: get{-}data features report}

\StringTok{backup:}
\StringTok{\textbackslash{}t./scripts/backup.sh}
\OperatorTok{EOF}
\BuiltInTok{echo} \StringTok{"Wrote justfile (optional)."}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{8) ssh \& tmux quickstarts (survey, run
\textbf{locally}, not in
Colab)}{8) ssh \& tmux quickstarts (survey, run locally, not in Colab)}}\label{ssh-tmux-quickstarts-survey-run-locally-not-in-colab}

\textbf{ssh key generation (local terminal):}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ssh{-}keygen} \AttributeTok{{-}t}\NormalTok{ ed25519 }\AttributeTok{{-}C} \StringTok{"you@school.edu"}
\CommentTok{\# Press enter to accept default path (\textasciitilde{}/.ssh/id\_ed25519), set a passphrase (recommended)}
\FunctionTok{cat}\NormalTok{ \textasciitilde{}/.ssh/id\_ed25519.pub   }\CommentTok{\# copy this PUBLIC key where needed (GitHub/servers)}
\end{Highlighting}
\end{Shaded}

\textbf{SSH config (\texttt{\textasciitilde{}/.ssh/config}, local):}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{Host}\NormalTok{ github}
  \ExtensionTok{HostName}\NormalTok{ github.com}
  \ExtensionTok{User}\NormalTok{ git}
  \ExtensionTok{IdentityFile}\NormalTok{ \textasciitilde{}/.ssh/id\_ed25519}
  \ExtensionTok{AddKeysToAgent}\NormalTok{ yes}
  \ExtensionTok{IdentitiesOnly}\NormalTok{ yes}

\ExtensionTok{Host}\NormalTok{ myhpc}
  \ExtensionTok{HostName}\NormalTok{ login.hpc.university.edu}
  \ExtensionTok{User}\NormalTok{ your\_netid}
  \ExtensionTok{IdentityFile}\NormalTok{ \textasciitilde{}/.ssh/id\_ed25519}
\end{Highlighting}
\end{Shaded}

\textbf{Test GitHub SSH (local):}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ssh} \AttributeTok{{-}T}\NormalTok{ git@github.com}
\end{Highlighting}
\end{Shaded}

\textbf{tmux essentials (remote or local):}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{tmux}\NormalTok{ new }\AttributeTok{{-}s}\NormalTok{ train              }\CommentTok{\# start session "train"}
\CommentTok{\# ... run your long job ...}
\CommentTok{\# detach: press Ctrl{-}b then d}
\ExtensionTok{tmux}\NormalTok{ ls                        }\CommentTok{\# list sessions}
\ExtensionTok{tmux}\NormalTok{ attach }\AttributeTok{{-}t}\NormalTok{ train           }\CommentTok{\# reattach}
\ExtensionTok{tmux}\NormalTok{ kill{-}session }\AttributeTok{{-}t}\NormalTok{ train     }\CommentTok{\# end session}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-3}

\begin{itemize}
\tightlist
\item
  \textbf{Make} codifies your pipeline; the file graph serves as your
  dependency DAG.
\item
  \textbf{Incremental} builds save time: edit one script → only
  downstream targets rebuild.
\item
  \textbf{rsync} is your friend for backups/snapshots; be deliberate
  with \texttt{-\/-delete}.
\item
  \textbf{ssh/tmux}: you don't need them in Colab, but you will on
  campus servers/HPC.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
7)}\label{homework-due-before-session-7}

\textbf{Goal:} Extend your automation with a tiny baseline training \&
evaluation step and polish your Makefile.

\subsection{Part A --- Add a minimal baseline
trainer}\label{part-a-add-a-minimal-baseline-trainer}

Create \texttt{scripts/train\_baseline.py} that learns a \textbf{linear
regression} on lagged returns (toy baseline) and writes metrics.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_py }\OperatorTok{=} \VerbatimStringTok{r"""\#!/usr/bin/env python}
\VerbatimStringTok{import argparse, json}
\VerbatimStringTok{from pathlib import Path}
\VerbatimStringTok{import pandas as pd}
\VerbatimStringTok{from sklearn.linear\_model import LinearRegression}
\VerbatimStringTok{from sklearn.metrics import mean\_absolute\_error}

\VerbatimStringTok{def main():}
\VerbatimStringTok{    ap = argparse.ArgumentParser()}
\VerbatimStringTok{    ap.add\_argument("{-}{-}features", default="data/processed/features.parquet")}
\VerbatimStringTok{    ap.add\_argument("{-}{-}out{-}metrics", default="reports/baseline\_metrics.json")}
\VerbatimStringTok{    args = ap.parse\_args()}

\VerbatimStringTok{    df = pd.read\_parquet(args.features)}
\VerbatimStringTok{    \# Train/test split by date (last 20}\SpecialCharTok{\% f}\VerbatimStringTok{or test)}
\VerbatimStringTok{    df = df.dropna(subset=["lag1","lag2","lag3","r\_1d"])}
\VerbatimStringTok{    n = len(df)}
\VerbatimStringTok{    split = int(n*0.8)}
\VerbatimStringTok{    Xtr = df[["lag1","lag2","lag3"]].iloc[:split].values}
\VerbatimStringTok{    ytr = df["r\_1d"].iloc[:split].values}
\VerbatimStringTok{    Xte = df[["lag1","lag2","lag3"]].iloc[split:].values}
\VerbatimStringTok{    yte = df["r\_1d"].iloc[split:].values}

\VerbatimStringTok{    model = LinearRegression().fit(Xtr, ytr)}
\VerbatimStringTok{    pred = model.predict(Xte)}
\VerbatimStringTok{    mae = float(mean\_absolute\_error(yte, pred))}

\VerbatimStringTok{    Path("reports").mkdir(exist\_ok=True)}
\VerbatimStringTok{    with open(args.out\_metrics, "w") as f:}
\VerbatimStringTok{        json.dump(\{"model":"linear(lag1,lag2,lag3)","test\_mae":mae,"n\_test":len(yte)\}, f, indent=2)}
\VerbatimStringTok{    print("Wrote", args.out\_metrics, "MAE:", mae)}

\VerbatimStringTok{if \_\_name\_\_ == "\_\_main\_\_":}
\VerbatimStringTok{    main()}
\VerbatimStringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{"scripts/train\_baseline.py"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(train\_py)}
\ImportTok{import}\NormalTok{ os, stat}
\NormalTok{os.chmod(}\StringTok{"scripts/train\_baseline.py"}\NormalTok{, os.stat(}\StringTok{"scripts/train\_baseline.py"}\NormalTok{).st\_mode }\OperatorTok{|}\NormalTok{ stat.S\_IEXEC)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Created scripts/train\_baseline.py"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Part B --- Extend your Makefile with
\texttt{train} and
\texttt{all}}{Part B --- Extend your Makefile with train and all}}\label{part-b-extend-your-makefile-with-train-and-all}

Append these to your \texttt{Makefile}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\# {-}{-}{-} add after FEATS definition, near other targets {-}{-}{-}}

\NormalTok{TRAIN\_METRICS := reports/baseline\_metrics.json}

\NormalTok{.PHONY: train}
\NormalTok{train: $(TRAIN\_METRICS) \#\# Train toy baseline and write metrics}

\NormalTok{$(TRAIN\_METRICS): scripts/train\_baseline.py $(FEATS)}
\NormalTok{    $(PY) scripts/train\_baseline.py {-}{-}features $(FEATS) {-}{-}out{-}metrics $(TRAIN\_METRICS)}

\NormalTok{\# Update \textquotesingle{}all\textquotesingle{} to include \textquotesingle{}train\textquotesingle{}}
\NormalTok{\# all: $(DATA\_RAW) $(FEATS) report backup   \# OLD}
\NormalTok{\# Replace with:}
\NormalTok{\# all: $(DATA\_RAW) $(FEATS) report train backup}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\BuiltInTok{set} \AttributeTok{{-}euo}\NormalTok{ pipefail}
\BuiltInTok{cd} \StringTok{"/content/drive/MyDrive/dspt25/unified{-}stocks{-}teamX"}
\FunctionTok{make}\NormalTok{ train}
\FunctionTok{cat}\NormalTok{ reports/baseline\_metrics.json}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Part C --- Add a \texttt{help} description
to every target and verify
\texttt{make\ help}}{Part C --- Add a help description to every target and verify make help}}\label{part-c-add-a-help-description-to-every-target-and-verify-make-help}

Ensure each target in your \texttt{Makefile} has a \texttt{\#\#}
comment. Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\BuiltInTok{set} \AttributeTok{{-}euo}\NormalTok{ pipefail}
\BuiltInTok{cd} \StringTok{"/content/drive/MyDrive/dspt25/unified{-}stocks{-}teamX"}
\FunctionTok{make}\NormalTok{ help}
\end{Highlighting}
\end{Shaded}

\subsection{Part D --- (Optional) Track small models/metrics with
Git‑LFS}\label{part-d-optional-track-small-modelsmetrics-with-gitlfs}

If you decide to save model artifacts (e.g.,
\texttt{models/baseline.pkl}), track them:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\BuiltInTok{set} \AttributeTok{{-}euo}\NormalTok{ pipefail}
\BuiltInTok{cd} \StringTok{"/content/drive/MyDrive/dspt25/unified{-}stocks{-}teamX"}
\FunctionTok{git}\NormalTok{ lfs track }\StringTok{"models/*.pkl"}
\FunctionTok{git}\NormalTok{ add .gitattributes}
\FunctionTok{git}\NormalTok{ commit }\AttributeTok{{-}m} \StringTok{"chore: track small model files via LFS"}
\end{Highlighting}
\end{Shaded}

\emph{(You can extend \texttt{train\_baseline.py} to save
\texttt{models/baseline.pkl} using \texttt{joblib}.)}

\subsection{Part E --- Commit \& push}\label{part-e-commit-push}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\BuiltInTok{set} \AttributeTok{{-}euo}\NormalTok{ pipefail}
\BuiltInTok{cd} \StringTok{"/content/drive/MyDrive/dspt25/unified{-}stocks{-}teamX"}
\FunctionTok{git}\NormalTok{ add scripts/}\PreprocessorTok{*}\NormalTok{.py scripts/backup.sh Makefile reports/baseline\_metrics.json}
\FunctionTok{git}\NormalTok{ status}
\FunctionTok{git}\NormalTok{ commit }\AttributeTok{{-}m} \StringTok{"feat: automated pipeline with Make (data{-}\textgreater{}features{-}\textgreater{}report{-}\textgreater{}train) and rsync backup"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ getpass }\ImportTok{import}\NormalTok{ getpass}
\ImportTok{import}\NormalTok{ subprocess}
\NormalTok{token }\OperatorTok{=}\NormalTok{ getpass(}\StringTok{"GitHub token (not stored): "}\NormalTok{)}
\NormalTok{REPO\_OWNER }\OperatorTok{=} \StringTok{"YOUR\_GITHUB\_USERNAME\_OR\_ORG"}
\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}
\NormalTok{push\_url }\OperatorTok{=} \SpecialStringTok{f"https://}\SpecialCharTok{\{}\NormalTok{token}\SpecialCharTok{\}}\SpecialStringTok{@github.com/}\SpecialCharTok{\{}\NormalTok{REPO\_OWNER}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{.git"}
\NormalTok{subprocess.run([}\StringTok{"git"}\NormalTok{, }\StringTok{"push"}\NormalTok{, push\_url, }\StringTok{"HEAD:main"}\NormalTok{], check}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\KeywordTok{del}\NormalTok{ token}
\end{Highlighting}
\end{Shaded}

\subsection{Grading (pass/revise)}\label{grading-passrevise-3}

\begin{itemize}
\tightlist
\item
  \texttt{make\ all} runs from a fresh clone (with minimal edits for
  tokens/Quarto install) and produces: \texttt{data/raw/prices.csv},
  \texttt{data/processed/features.parquet},
  \texttt{docs/reports/eda.html},
  \texttt{reports/baseline\_metrics.json}, and a \texttt{backups/run-*/}
  snapshot.
\item
  \texttt{Makefile} has \textbf{helpful \texttt{help} output} and
  \textbf{variables} (\texttt{START}, \texttt{END}, \texttt{ROLL}).
\item
  \texttt{scripts/backup.sh} uses \texttt{rsync\ -avh\ -\/-delete} and
  excludes \texttt{raw/} \& \texttt{interim/}.
\item
  (Optional) LFS tracking updated for models.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-3}

\begin{itemize}
\tightlist
\item
  Test the full lab in a fresh Colab runtime (data fetch, feature build,
  report render, backup).
\item
  Have one slide that visually shows the \textbf{dependency graph}:
  \texttt{prices.csv\ →\ features.parquet\ →\ report/train}.
\item
  Prepare a one‑pager cheat sheet for \texttt{rsync} flags and
  \texttt{tmux} keystrokes.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-3}

\begin{itemize}
\tightlist
\item
  \textbf{Make} is a thin layer over shell commands---it doesn't replace
  Python; it orchestrates it.
\item
  Keep targets \textbf{idempotent}: running twice shouldn't break; only
  rebuild on changes.
\item
  Use \texttt{rsync} with care: \texttt{-\/-delete} is
  powerful---double‑check DEST paths.
\item
  \textbf{ssh/tmux}: you'll want this the first time you run a long
  model on a remote machine.
\end{itemize}

\bookmarksetup{startatroot}

\chapter{Session 7 --- SQL I: SQLite Schemas \&
Joins}\label{session-7-sql-i-sqlite-schemas-joins}

Below is a complete lecture package for \textbf{Session 7 --- SQL I:
SQLite Schemas \& Joins} (75 minutes). It includes: a timed agenda,
slide talking points, a \textbf{Colab‑friendly in‑class lab with
copy‑paste code}, and \textbf{homework with copy‑paste code}. By the
end, students will have a \textbf{SQLite database} with a clean schema,
constraints, indexes, and several \textbf{SELECT/JOIN} queries they can
reuse from Python.

\begin{quote}
\textbf{Assumptions:} You're continuing in the same Drive‑mounted repo
(e.g., \texttt{unified-stocks-teamX}). You have
\texttt{data/raw/prices.csv} from prior sessions. If not, the lab
includes a fallback generator.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 7 --- SQL I: SQLite Schemas \& Joins (75
min)}\label{session-7-sql-i-sqlite-schemas-joins-75-min}

\subsection{Learning goals}\label{learning-goals-6}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a \textbf{SQLite database} with proper \textbf{tables, primary
  keys, constraints,} and \textbf{indexes}.
\item
  Load CSV data into SQLite safely (parameterized inserts or
  \texttt{pandas.to\_sql}), avoiding duplicates.
\item
  Write \textbf{SELECT} queries with \textbf{WHERE/ORDER/LIMIT} and
  basic \textbf{JOINs}.
\item
  Use \textbf{parameterized queries from Python} to avoid SQL injection.
\item
  Build a small \textbf{SQL I/O helper} to streamline queries from
  Python.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 minutes)}\label{agenda-75-minutes-1}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Why relational databases for DS; SQLite types;
  PK/constraints; indexes
\item
  \textbf{(10 min)} DDL overview (CREATE TABLE/INDEX); transactions;
  parameterized queries
\item
  \textbf{(35 min)} \textbf{In‑class lab} (Colab): create
  \texttt{prices.db} → load \texttt{prices} + \texttt{meta} → write
  joins
\item
  \textbf{(10 min)} Wrap‑up \& homework briefing
\item
  \textbf{(10 min)} Buffer
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points (add to your
deck)}\label{slides-talking-points-add-to-your-deck}

\textbf{Why SQLite for DS}

\begin{itemize}
\tightlist
\item
  Single file DB → easy to version, ship, query; no server admin.
\item
  Stronger \textbf{guarantees} than loose CSVs: types,
  \textbf{constraints}, \textbf{unique keys}, \textbf{foreign keys}.
\item
  Fast \textbf{filters/joins} with \textbf{indexes}; JIT queries from
  Python, R, or CLI.
\end{itemize}

\textbf{SQLite types \& constraints}

\begin{itemize}
\tightlist
\item
  SQLite uses \textbf{dynamic typing} but honors affinities:
  \texttt{INTEGER}, \texttt{REAL}, \texttt{TEXT}, \texttt{BLOB}.
\item
  Use \textbf{PRIMARY KEY} (uniqueness + index), \textbf{NOT NULL}, and
  \textbf{CHECK} (e.g., volume ≥ 0).
\item
  Turn on \textbf{foreign keys}: \texttt{PRAGMA\ foreign\_keys\ =\ ON;}
\end{itemize}

\textbf{Indexes \& performance}

\begin{itemize}
\tightlist
\item
  Index columns used in \textbf{joins} and \textbf{filters}.
\item
  Composite PK \texttt{(ticker,\ date)} makes common lookups fast.
\end{itemize}

\textbf{What NOT to commit}

\begin{itemize}
\tightlist
\item
  Large \texttt{.db} files. Keep DB small or regenerate from CSV with a
  script.
\item
  If you must version a small DB, ensure \textbf{Git‑LFS} tracks
  \texttt{data/*.db} (we set this in Session 2).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min)}\label{inclass-lab-35-min-4}

\begin{quote}
\textbf{Instructor tip:} Have students run each block as its own Colab
cell. Commands that start with \texttt{!} run in the Colab shell; the
rest are Python.
\end{quote}

\subsection{0) Mount Drive \& enter repo}\label{mount-drive-enter-repo}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_OWNER }\OperatorTok{=} \StringTok{"YOUR\_GITHUB\_USERNAME\_OR\_ORG"}   \CommentTok{\# \textless{}{-} change}
\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}          \CommentTok{\# \textless{}{-} change}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{pathlib.Path(BASE\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{assert}\NormalTok{ pathlib.Path(REPO\_DIR).exists(), }\StringTok{"Repo not found in Drive. Clone it first."}
\NormalTok{os.chdir(REPO\_DIR)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{1) Ensure prerequisites \& create a small
\texttt{prices.csv} if
missing}{1) Ensure prerequisites \& create a small prices.csv if missing}}\label{ensure-prerequisites-create-a-small-prices.csv-if-missing}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Ensure pandas and sqlite3 are available (sqlite3 is in stdlib)}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, sqlite3, numpy }\ImportTok{as}\NormalTok{ np, os}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\NormalTok{Path(}\StringTok{"data/raw"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ Path(}\StringTok{"data/raw/prices.csv"}\NormalTok{).exists():}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"No prices.csv found; generating a small synthetic one."}\NormalTok{)}
\NormalTok{    tickers }\OperatorTok{=}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{]}
\NormalTok{    dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{120}\NormalTok{)}
\NormalTok{    rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{7}\NormalTok{)}
\NormalTok{    frames}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ tickers:}
\NormalTok{        r }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\BuiltInTok{len}\NormalTok{(dates))}
\NormalTok{        price }\OperatorTok{=} \DecValTok{100}\OperatorTok{*}\NormalTok{np.exp(np.cumsum(r))}
\NormalTok{        vol }\OperatorTok{=}\NormalTok{ rng.integers(}\FloatTok{1e5}\NormalTok{, }\FloatTok{5e6}\NormalTok{, }\BuiltInTok{len}\NormalTok{(dates))}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{"ticker"}\NormalTok{: t, }\StringTok{"date"}\NormalTok{: dates, }\StringTok{"adj\_close"}\NormalTok{: price, }\StringTok{"volume"}\NormalTok{: vol\})}
\NormalTok{        df[}\StringTok{"log\_return"}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(df[}\StringTok{"adj\_close"}\NormalTok{]).diff().fillna(}\DecValTok{0}\NormalTok{)}
\NormalTok{        frames.append(df)}
\NormalTok{    pd.concat(frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).to\_csv(}\StringTok{"data/raw/prices.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\CommentTok{\# Show a peek}
\NormalTok{pd.read\_csv(}\StringTok{"data/raw/prices.csv"}\NormalTok{).head()}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Design schema \& create the database
\texttt{data/prices.db}}{2) Design schema \& create the database data/prices.db}}\label{design-schema-create-the-database-dataprices.db}

We'll use two tables:

\begin{itemize}
\tightlist
\item
  \texttt{meta(ticker\ TEXT\ PRIMARY\ KEY,\ name\ TEXT,\ sector\ TEXT\ NOT\ NULL)}
\item
  \texttt{prices(ticker\ TEXT\ NOT\ NULL,\ date\ TEXT\ NOT\ NULL,\ adj\_close\ REAL\ NOT\ NULL,\ volume\ INTEGER\ NOT\ NULL,\ log\_return\ REAL\ NOT\ NULL,\ PRIMARY\ KEY\ (ticker,date),\ FOREIGN\ KEY\ (ticker)\ REFERENCES\ meta(ticker))}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sqlite3, textwrap, os}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\NormalTok{db\_path }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/prices.db"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ db\_path.exists(): db\_path.unlink()  }\CommentTok{\# start fresh for class; remove this in real life}
\NormalTok{con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(db\_path)}
\NormalTok{cur }\OperatorTok{=}\NormalTok{ con.cursor()}

\CommentTok{\# Turn on foreign keys}
\NormalTok{cur.execute(}\StringTok{"PRAGMA foreign\_keys = ON;"}\NormalTok{)}
\CommentTok{\# (Optional) WAL can help concurrency; not critical here}
\NormalTok{cur.execute(}\StringTok{"PRAGMA journal\_mode = WAL;"}\NormalTok{)}

\NormalTok{ddl }\OperatorTok{=}\NormalTok{ textwrap.dedent(}\StringTok{"""}
\StringTok{CREATE TABLE meta (}
\StringTok{  ticker TEXT PRIMARY KEY,}
\StringTok{  name   TEXT,}
\StringTok{  sector TEXT NOT NULL}
\StringTok{);}

\StringTok{CREATE TABLE prices (}
\StringTok{  ticker     TEXT NOT NULL,}
\StringTok{  date       TEXT NOT NULL,               {-}{-} ISO \textquotesingle{}YYYY{-}MM{-}DD\textquotesingle{}}
\StringTok{  adj\_close  REAL NOT NULL CHECK (adj\_close \textgreater{}= 0),}
\StringTok{  volume     INTEGER NOT NULL CHECK (volume \textgreater{}= 0),}
\StringTok{  log\_return REAL NOT NULL,}
\StringTok{  PRIMARY KEY (ticker, date),}
\StringTok{  FOREIGN KEY (ticker) REFERENCES meta(ticker)}
\StringTok{);}

\StringTok{{-}{-} Index to speed up date{-}range scans across all tickers}
\StringTok{CREATE INDEX IF NOT EXISTS idx\_prices\_date ON prices(date);}
\StringTok{"""}\NormalTok{)}
\NormalTok{cur.executescript(ddl)}
\NormalTok{con.commit()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Created:"}\NormalTok{, db\_path)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Populate \texttt{meta} (try yfinance
sector; fallback to
synthetic)}{3) Populate meta (try yfinance sector; fallback to synthetic)}}\label{populate-meta-try-yfinance-sector-fallback-to-synthetic}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ warnings}
\NormalTok{warnings.filterwarnings(}\StringTok{"ignore"}\NormalTok{)}

\CommentTok{\# Read tickers (from existing CSV or fallback)}
\ControlFlowTok{if}\NormalTok{ Path(}\StringTok{"tickers\_25.csv"}\NormalTok{).exists():}
\NormalTok{    tickers }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"tickers\_25.csv"}\NormalTok{)[}\StringTok{"ticker"}\NormalTok{].dropna().unique().tolist()}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    tickers }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"data/raw/prices.csv"}\NormalTok{)[}\StringTok{"ticker"}\NormalTok{].dropna().unique().tolist()}

\KeywordTok{def}\NormalTok{ fetch\_sector\_map(tickers):}
    \ControlFlowTok{try}\NormalTok{:}
        \ImportTok{import}\NormalTok{ yfinance }\ImportTok{as}\NormalTok{ yf}
\NormalTok{        out}\OperatorTok{=}\NormalTok{[]}
        \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ tickers:}
\NormalTok{            info }\OperatorTok{=}\NormalTok{ yf.Ticker(t).info }\KeywordTok{or}\NormalTok{ \{\}}
\NormalTok{            name  }\OperatorTok{=}\NormalTok{ info.get(}\StringTok{"shortName"}\NormalTok{) }\KeywordTok{or}\NormalTok{ info.get(}\StringTok{"longName"}\NormalTok{) }\KeywordTok{or}\NormalTok{ t}
\NormalTok{            sector}\OperatorTok{=}\NormalTok{ info.get(}\StringTok{"sector"}\NormalTok{) }\KeywordTok{or} \StringTok{"Unknown"}
\NormalTok{            out.append(\{}\StringTok{"ticker"}\NormalTok{: t, }\StringTok{"name"}\NormalTok{: name, }\StringTok{"sector"}\NormalTok{: sector\})}
        \ControlFlowTok{return}\NormalTok{ pd.DataFrame(out)}
    \ControlFlowTok{except} \PreprocessorTok{Exception}\NormalTok{:}
        \ControlFlowTok{pass}
    \CommentTok{\# Fallback: deterministic synthetic sectors}
\NormalTok{    sectors }\OperatorTok{=}\NormalTok{ [}\StringTok{"Technology"}\NormalTok{,}\StringTok{"Financials"}\NormalTok{,}\StringTok{"Healthcare"}\NormalTok{,}\StringTok{"Energy"}\NormalTok{,}\StringTok{"Consumer"}\NormalTok{]}
\NormalTok{    rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{42}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ pd.DataFrame(\{}
        \StringTok{"ticker"}\NormalTok{: tickers,}
        \StringTok{"name"}\NormalTok{: tickers,}
        \StringTok{"sector"}\NormalTok{: [sectors[i }\OperatorTok{\%} \BuiltInTok{len}\NormalTok{(sectors)] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(tickers))]}
\NormalTok{    \})}

\NormalTok{meta\_df }\OperatorTok{=}\NormalTok{ fetch\_sector\_map(tickers)}
\NormalTok{meta\_df.head()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Insert meta with parameterized query}
\ControlFlowTok{with}\NormalTok{ con:}
\NormalTok{    con.executemany(}
        \StringTok{"INSERT INTO meta(ticker, name, sector) VALUES(?, ?, ?)"}\NormalTok{,}
\NormalTok{        meta\_df[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"name"}\NormalTok{,}\StringTok{"sector"}\NormalTok{]].itertuples(index}\OperatorTok{=}\VariableTok{False}\NormalTok{, name}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\NormalTok{    )}
\BuiltInTok{print}\NormalTok{(pd.read\_sql\_query(}\StringTok{"SELECT * FROM meta LIMIT 5;"}\NormalTok{, con))}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) Load \texttt{data/raw/prices.csv} into a
staging DataFrame and insert into
\texttt{prices}}{4) Load data/raw/prices.csv into a staging DataFrame and insert into prices}}\label{load-datarawprices.csv-into-a-staging-dataframe-and-insert-into-prices}

We'll use \textbf{parameterized bulk insert} (\texttt{executemany})
which is fast and safe.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prices }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"data/raw/prices.csv"}\NormalTok{, parse\_dates}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{])}
\CommentTok{\# Normalize date to ISO text}
\NormalTok{prices[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ prices[}\StringTok{"date"}\NormalTok{].dt.strftime(}\StringTok{"\%Y{-}\%m{-}}\SpecialCharTok{\%d}\StringTok{"}\NormalTok{)}
\CommentTok{\# Keep only needed columns and ensure order matches table}
\NormalTok{prices }\OperatorTok{=}\NormalTok{ prices[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{]]}

\CommentTok{\# Optional: drop duplicates to respect PK before insert}
\NormalTok{prices }\OperatorTok{=}\NormalTok{ prices.drop\_duplicates(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{len}\NormalTok{(prices)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Bulk insert inside one transaction; ignore rows violating FK or PK (e.g., duplicates)}
\ControlFlowTok{with}\NormalTok{ con:}
\NormalTok{    con.executemany(}
        \StringTok{"INSERT OR IGNORE INTO prices(ticker,date,adj\_close,volume,log\_return) VALUES(?,?,?,?,?)"}\NormalTok{,}
\NormalTok{        prices.itertuples(index}\OperatorTok{=}\VariableTok{False}\NormalTok{, name}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\NormalTok{    )}

\CommentTok{\# Quick counts}
\BuiltInTok{print}\NormalTok{(pd.read\_sql\_query(}\StringTok{"SELECT COUNT(*) AS nrows FROM prices;"}\NormalTok{, con))}
\BuiltInTok{print}\NormalTok{(pd.read\_sql\_query(}\StringTok{"SELECT ticker, COUNT(*) AS n FROM prices GROUP BY ticker ORDER BY n DESC LIMIT 5;"}\NormalTok{, con))}
\end{Highlighting}
\end{Shaded}

\subsection{5) Sanity queries (filters, order,
limit)}\label{sanity-queries-filters-order-limit}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{q1 }\OperatorTok{=} \StringTok{"""}
\StringTok{SELECT ticker, date, adj\_close, volume}
\StringTok{FROM prices}
\StringTok{WHERE ticker = ? AND date BETWEEN ? AND ?}
\StringTok{ORDER BY date ASC}
\StringTok{LIMIT 5;}
\StringTok{"""}
\BuiltInTok{print}\NormalTok{(pd.read\_sql\_query(q1, con, params}\OperatorTok{=}\NormalTok{[}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"2022{-}03{-}01"}\NormalTok{,}\StringTok{"2022{-}06{-}30"}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Top 10 absolute daily moves for a chosen ticker}
\NormalTok{q2 }\OperatorTok{=} \StringTok{"""}
\StringTok{SELECT p.ticker, p.date, p.log\_return, ABS(p.log\_return) AS abs\_move}
\StringTok{FROM prices AS p}
\StringTok{WHERE p.ticker = ?}
\StringTok{ORDER BY abs\_move DESC}
\StringTok{LIMIT 10;}
\StringTok{"""}
\BuiltInTok{print}\NormalTok{(pd.read\_sql\_query(q2, con, params}\OperatorTok{=}\NormalTok{[}\StringTok{"NVDA"}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{6) JOIN with \texttt{meta} (per‑sector
summaries)}{6) JOIN with meta (per‑sector summaries)}}\label{join-with-meta-persector-summaries}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Mean |std| of daily returns per sector over a date range}
\NormalTok{q3 }\OperatorTok{=} \StringTok{"""}
\StringTok{SELECT m.sector,}
\StringTok{       AVG(ABS(p.log\_return)) AS mean\_abs\_return,}
\StringTok{       AVG(p.log\_return)      AS mean\_return,}
\StringTok{       STDDEV(p.log\_return)   AS std\_return}
\StringTok{FROM prices p}
\StringTok{JOIN meta   m ON p.ticker = m.ticker}
\StringTok{WHERE p.date BETWEEN ? AND ?}
\StringTok{GROUP BY m.sector}
\StringTok{ORDER BY mean\_abs\_return DESC;}
\StringTok{"""}
\CommentTok{\# SQLite doesn\textquotesingle{}t have STDDEV by default; fallback using variance formula via window? We\textquotesingle{}ll compute in pandas:}
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(}\StringTok{"""}
\StringTok{SELECT m.sector, p.log\_return}
\StringTok{FROM prices p JOIN meta m ON p.ticker = m.ticker}
\StringTok{WHERE p.date BETWEEN ? AND ?;}
\StringTok{"""}\NormalTok{, con, params}\OperatorTok{=}\NormalTok{[}\StringTok{"2022{-}01{-}01"}\NormalTok{,}\StringTok{"2025{-}08{-}01"}\NormalTok{])}
\NormalTok{agg }\OperatorTok{=}\NormalTok{ (df.assign(}\BuiltInTok{abs}\OperatorTok{=}\KeywordTok{lambda}\NormalTok{ d: d[}\StringTok{"log\_return"}\NormalTok{].}\BuiltInTok{abs}\NormalTok{())}
\NormalTok{         .groupby(}\StringTok{"sector"}\NormalTok{)}
\NormalTok{         .agg(mean\_abs\_return}\OperatorTok{=}\NormalTok{(}\StringTok{"abs"}\NormalTok{,}\StringTok{"mean"}\NormalTok{),}
\NormalTok{              mean\_return}\OperatorTok{=}\NormalTok{(}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"mean"}\NormalTok{),}
\NormalTok{              std\_return}\OperatorTok{=}\NormalTok{(}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"std"}\NormalTok{))}
\NormalTok{         .sort\_values(}\StringTok{"mean\_abs\_return"}\NormalTok{, ascending}\OperatorTok{=}\VariableTok{False}\NormalTok{))}
\NormalTok{agg}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{7) Create a \textbf{view} for convenience \&
test uniqueness
constraint}{7) Create a view for convenience \& test uniqueness constraint}}\label{create-a-view-for-convenience-test-uniqueness-constraint}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# View: latest available date per ticker}
\ControlFlowTok{with}\NormalTok{ con:}
\NormalTok{    con.execute(}\StringTok{"""}
\StringTok{    CREATE VIEW IF NOT EXISTS latest\_prices AS}
\StringTok{    SELECT p.*}
\StringTok{    FROM prices p}
\StringTok{    JOIN (}
\StringTok{      SELECT ticker, MAX(date) AS max\_date}
\StringTok{      FROM prices}
\StringTok{      GROUP BY ticker}
\StringTok{    ) t ON p.ticker = t.ticker AND p.date = t.max\_date;}
\StringTok{    """}\NormalTok{)}
\NormalTok{pd.read\_sql\_query(}\StringTok{"SELECT * FROM latest\_prices ORDER BY ticker LIMIT 10;"}\NormalTok{, con)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Demonstrate the UNIQUE/PK constraint: inserting a duplicate row should be ignored or fail}
\ImportTok{import}\NormalTok{ sqlite3}
\NormalTok{row }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(}\StringTok{"SELECT * FROM prices LIMIT 1;"}\NormalTok{, con).iloc[}\DecValTok{0}\NormalTok{].to\_dict()}
\ControlFlowTok{try}\NormalTok{:}
    \ControlFlowTok{with}\NormalTok{ con:}
\NormalTok{        con.execute(}
            \StringTok{"INSERT INTO prices(ticker,date,adj\_close,volume,log\_return) VALUES(?,?,?,?,?)"}\NormalTok{,}
\NormalTok{            (row[}\StringTok{"ticker"}\NormalTok{], row[}\StringTok{"date"}\NormalTok{], row[}\StringTok{"adj\_close"}\NormalTok{], row[}\StringTok{"volume"}\NormalTok{], row[}\StringTok{"log\_return"}\NormalTok{])}
\NormalTok{        )}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Unexpected: duplicate insert succeeded (should not)."}\NormalTok{)}
\ControlFlowTok{except}\NormalTok{ sqlite3.IntegrityError }\ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"IntegrityError as expected:"}\NormalTok{, e)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{8) A tiny \textbf{SQL I/O helper} for your
project}{8) A tiny SQL I/O helper for your project}}\label{a-tiny-sql-io-helper-for-your-project}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{Path(}\StringTok{"src"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{Path(}\StringTok{"src/projectname"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{sqlio\_py }\OperatorTok{=} \StringTok{"""}\CharTok{\textbackslash{}}
\StringTok{from \_\_future\_\_ import annotations}
\StringTok{import sqlite3}
\StringTok{import pandas as pd}
\StringTok{from contextlib import contextmanager}
\StringTok{from pathlib import Path}

\StringTok{DB\_PATH = Path("data/prices.db")}

\StringTok{@contextmanager}
\StringTok{def connect(db\_path: str | Path = DB\_PATH):}
\StringTok{    con = sqlite3.connect(str(db\_path))}
\StringTok{    con.execute("PRAGMA foreign\_keys = ON;")}
\StringTok{    try:}
\StringTok{        yield con}
\StringTok{    finally:}
\StringTok{        con.close()}

\StringTok{def query\_df(sql: str, params: tuple | list | None = None, db\_path: str | Path = DB\_PATH) {-}\textgreater{} pd.DataFrame:}
\StringTok{    with connect(db\_path) as con:}
\StringTok{        return pd.read\_sql\_query(sql, con, params=params)}

\StringTok{def sector\_summary(start: str, end: str, db\_path: str | Path = DB\_PATH) {-}\textgreater{} pd.DataFrame:}
\StringTok{    sql = \textquotesingle{}\textquotesingle{}\textquotesingle{}}
\StringTok{    SELECT m.sector, p.log\_return}
\StringTok{    FROM prices p JOIN meta m ON p.ticker = m.ticker}
\StringTok{    WHERE p.date BETWEEN ? AND ?;}
\StringTok{    \textquotesingle{}\textquotesingle{}\textquotesingle{}}
\StringTok{    df = query\_df(sql, [start, end], db\_path)}
\StringTok{    if df.empty:}
\StringTok{        return df}
\StringTok{    g = df.assign(abs=lambda d: d["log\_return"].abs()).groupby("sector")}
\StringTok{    return g.agg(mean\_abs\_return=("abs","mean"),}
\StringTok{                 mean\_return=("log\_return","mean"),}
\StringTok{                 std\_return=("log\_return","std")).reset\_index()}
\StringTok{"""}
\BuiltInTok{open}\NormalTok{(}\StringTok{"src/projectname/sqlio.py"}\NormalTok{,}\StringTok{"w"}\NormalTok{).write(sqlio\_py)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote src/projectname/sqlio.py"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Quick test:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ src.projectname.sqlio }\ImportTok{import}\NormalTok{ sector\_summary}
\NormalTok{sector\_summary(}\StringTok{"2022{-}01{-}01"}\NormalTok{,}\StringTok{"2025{-}08{-}01"}\NormalTok{).head()}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Note on versioning:} If \texttt{data/prices.db} stays small (a
few MB), you may commit it via \textbf{Git‑LFS} (we tracked
\texttt{data/*.db} in Session 2). Otherwise, \textbf{do not
commit}---rebuild from CSV with a script (homework).
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-4}

\begin{itemize}
\tightlist
\item
  You now have a \textbf{relational core} for the project.
\item
  Use \textbf{PK + constraints} to prevent silent data corruption.
\item
  Use \textbf{parameterized queries} from Python.
\item
  Next session: \textbf{SQL II --- Window functions \&
  \texttt{pandas.read\_sql} workflows} (rolling stats, LAG/LEAD).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
8)}\label{homework-due-before-session-8}

\textbf{Goal:} Make database creation reproducible, add metadata, write
joins you'll reuse later, and hook it into your Makefile.

\subsection{Part A --- Script to (re)build the
DB}\label{part-a-script-to-rebuild-the-db}

Create \texttt{scripts/build\_db.py} that \textbf{creates tables} and
\textbf{loads CSVs} deterministically.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scripts/build\_db.py}
\CommentTok{\#!/usr/bin/env python}
\ImportTok{import}\NormalTok{ argparse, sys, textwrap, sqlite3}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{DDL }\OperatorTok{=}\NormalTok{ textwrap.dedent(}\StringTok{"""}
\StringTok{PRAGMA foreign\_keys = ON;}
\StringTok{CREATE TABLE IF NOT EXISTS meta (}
\StringTok{  ticker TEXT PRIMARY KEY,}
\StringTok{  name   TEXT,}
\StringTok{  sector TEXT NOT NULL}
\StringTok{);}
\StringTok{CREATE TABLE IF NOT EXISTS prices (}
\StringTok{  ticker     TEXT NOT NULL,}
\StringTok{  date       TEXT NOT NULL,}
\StringTok{  adj\_close  REAL NOT NULL CHECK (adj\_close \textgreater{}= 0),}
\StringTok{  volume     INTEGER NOT NULL CHECK (volume \textgreater{}= 0),}
\StringTok{  log\_return REAL NOT NULL,}
\StringTok{  PRIMARY KEY (ticker,date),}
\StringTok{  FOREIGN KEY (ticker) REFERENCES meta(ticker)}
\StringTok{);}
\StringTok{CREATE INDEX IF NOT EXISTS idx\_prices\_date ON prices(date);}
\StringTok{"""}\NormalTok{)}

\KeywordTok{def}\NormalTok{ load\_meta(con, tickers\_csv: Path):}
    \ControlFlowTok{if}\NormalTok{ tickers\_csv.exists():}
\NormalTok{        tks }\OperatorTok{=}\NormalTok{ pd.read\_csv(tickers\_csv)[}\StringTok{"ticker"}\NormalTok{].dropna().unique().tolist()}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{raise} \PreprocessorTok{SystemExit}\NormalTok{(}\SpecialStringTok{f"tickers CSV not found: }\SpecialCharTok{\{}\NormalTok{tickers\_csv}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    sectors }\OperatorTok{=}\NormalTok{ [}\StringTok{"Technology"}\NormalTok{,}\StringTok{"Financials"}\NormalTok{,}\StringTok{"Healthcare"}\NormalTok{,}\StringTok{"Energy"}\NormalTok{,}\StringTok{"Consumer"}\NormalTok{]}
\NormalTok{    meta }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
        \StringTok{"ticker"}\NormalTok{: tks,}
        \StringTok{"name"}\NormalTok{: tks,}
        \StringTok{"sector"}\NormalTok{: [sectors[i }\OperatorTok{\%} \BuiltInTok{len}\NormalTok{(sectors)] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(tks))]}
\NormalTok{    \})}
    \ControlFlowTok{with}\NormalTok{ con:}
\NormalTok{        con.executemany(}\StringTok{"INSERT OR REPLACE INTO meta(ticker,name,sector) VALUES(?,?,?)"}\NormalTok{,}
\NormalTok{                        meta.itertuples(index}\OperatorTok{=}\VariableTok{False}\NormalTok{, name}\OperatorTok{=}\VariableTok{None}\NormalTok{))}

\KeywordTok{def}\NormalTok{ load\_prices(con, prices\_csv: Path):}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_csv(prices\_csv, parse\_dates}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{])}
\NormalTok{    df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.strftime(}\StringTok{"\%Y{-}\%m{-}}\SpecialCharTok{\%d}\StringTok{"}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ df[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{]].drop\_duplicates([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
    \ControlFlowTok{with}\NormalTok{ con:}
\NormalTok{        con.executemany(}
            \StringTok{"INSERT OR REPLACE INTO prices(ticker,date,adj\_close,volume,log\_return) VALUES(?,?,?,?,?)"}\NormalTok{,}
\NormalTok{            df.itertuples(index}\OperatorTok{=}\VariableTok{False}\NormalTok{, name}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\NormalTok{        )}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    ap }\OperatorTok{=}\NormalTok{ argparse.ArgumentParser()}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}db"}\NormalTok{, default}\OperatorTok{=}\StringTok{"data/prices.db"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}tickers"}\NormalTok{, default}\OperatorTok{=}\StringTok{"tickers\_25.csv"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}prices"}\NormalTok{, default}\OperatorTok{=}\StringTok{"data/raw/prices.csv"}\NormalTok{)}
\NormalTok{    args }\OperatorTok{=}\NormalTok{ ap.parse\_args()}

\NormalTok{    Path(args.db).parent.mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(args.db)}
\NormalTok{    con.executescript(DDL)}
\NormalTok{    load\_meta(con, Path(args.tickers))}
\NormalTok{    load\_prices(con, Path(args.prices))}
\NormalTok{    con.close()}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Built DB:"}\NormalTok{, args.db)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    sys.exit(main())}
\end{Highlighting}
\end{Shaded}

Make it executable:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ os, stat, pathlib}
\NormalTok{p }\OperatorTok{=}\NormalTok{ pathlib.Path(}\StringTok{"scripts/build\_db.py"}\NormalTok{)}
\NormalTok{os.chmod(p, os.stat(p).st\_mode }\OperatorTok{|}\NormalTok{ stat.S\_IEXEC)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Ready:"}\NormalTok{, p)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Part B --- Add Makefile target \texttt{db}
and a small SQL
report}{Part B --- Add Makefile target db and a small SQL report}}\label{part-b-add-makefile-target-db-and-a-small-sql-report}

Append to your \texttt{Makefile}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{DB := data/prices.db}

\NormalTok{.PHONY: db sql{-}report}
\NormalTok{db: \#\# Build/refresh SQLite database from CSVs}
\NormalTok{\textbackslash{}tpython scripts/build\_db.py {-}{-}db $(DB) {-}{-}tickers tickers\_25.csv {-}{-}prices data/raw/prices.csv}

\NormalTok{sql{-}report: db \#\# Generate a simple SQL{-}driven CSV summary}
\NormalTok{\textbackslash{}tpython {-} \textless{}\textless{} \textquotesingle{}PY\textquotesingle{}}
\NormalTok{import pandas as pd, sqlite3, os}
\NormalTok{con = sqlite3.connect("data/prices.db")}
\NormalTok{df = pd.read\_sql\_query(\textbackslash{}"\textbackslash{}"\textbackslash{}"\textbackslash{}nSELECT m.sector, COUNT(*) AS n\_obs, AVG(ABS(p.log\_return)) AS mean\_abs\_return\textbackslash{}nFROM prices p JOIN meta m ON p.ticker=m.ticker\textbackslash{}nGROUP BY m.sector ORDER BY n\_obs DESC;\textbackslash{}n\textbackslash{}"\textbackslash{}"\textbackslash{}", con)}
\NormalTok{os.makedirs("reports", exist\_ok=True)}
\NormalTok{df.to\_csv("reports/sql\_sector\_summary.csv", index=False)}
\NormalTok{print(df.head())}
\NormalTok{con.close()}
\NormalTok{PY}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\BuiltInTok{set} \AttributeTok{{-}euo}\NormalTok{ pipefail}
\BuiltInTok{cd} \StringTok{"/content/drive/MyDrive/dspt25/unified{-}stocks{-}teamX"}
\FunctionTok{make}\NormalTok{ db}
\FunctionTok{make}\NormalTok{ sql{-}report}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Part C --- Write 3 JOIN queries (save as
\texttt{.sql} under
\texttt{sql/})}{Part C --- Write 3 JOIN queries (save as .sql under sql/)}}\label{part-c-write-3-join-queries-save-as-.sql-under-sql}

Create a folder \texttt{sql/} and add:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{sector\_top\_moves.sql}: top 10 absolute daily moves per
  sector (date, ticker, abs\_move).
\item
  \texttt{ticker\_activity.sql}: per‑ticker counts, min/max date.
\item
  \texttt{range\_summary.sql}: for a given date range (use
  placeholders), mean/std of returns by ticker and sector.
\end{enumerate}

Example (1):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} sql/sector\_top\_moves.sql}
\KeywordTok{SELECT}\NormalTok{ m.sector, p.ticker, p.}\DataTypeTok{date}\NormalTok{, p.log\_return, }\FunctionTok{ABS}\NormalTok{(p.log\_return) }\KeywordTok{AS}\NormalTok{ abs\_move}
\KeywordTok{FROM}\NormalTok{ prices p }\KeywordTok{JOIN}\NormalTok{ meta m }\KeywordTok{ON}\NormalTok{ p.ticker }\OperatorTok{=}\NormalTok{ m.ticker}
\KeywordTok{ORDER} \KeywordTok{BY}\NormalTok{ abs\_move }\KeywordTok{DESC}
\KeywordTok{LIMIT} \DecValTok{10}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

Then a small Python launcher to run any \texttt{.sql} file with optional
parameters:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scripts/run\_sql.py}
\CommentTok{\#!/usr/bin/env python}
\ImportTok{import}\NormalTok{ argparse, sqlite3, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    ap }\OperatorTok{=}\NormalTok{ argparse.ArgumentParser()}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}db"}\NormalTok{, default}\OperatorTok{=}\StringTok{"data/prices.db"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}sqlfile"}\NormalTok{, required}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}params"}\NormalTok{, nargs}\OperatorTok{=}\StringTok{"*"}\NormalTok{, default}\OperatorTok{=}\NormalTok{[])}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}out"}\NormalTok{, default}\OperatorTok{=}\StringTok{""}\NormalTok{)}
\NormalTok{    args }\OperatorTok{=}\NormalTok{ ap.parse\_args()}

\NormalTok{    sql }\OperatorTok{=}\NormalTok{ Path(args.sqlfile).read\_text()}
\NormalTok{    con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(args.db)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(sql, con, params}\OperatorTok{=}\NormalTok{args.params }\KeywordTok{or} \VariableTok{None}\NormalTok{)}
\NormalTok{    con.close()}
    \ControlFlowTok{if}\NormalTok{ args.out:}
\NormalTok{        Path(args.out).parent.mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        df.to\_csv(args.out, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(df.head())}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Run a demo:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\BuiltInTok{set} \AttributeTok{{-}euo}\NormalTok{ pipefail}
\BuiltInTok{cd} \StringTok{"/content/drive/MyDrive/dspt25/unified{-}stocks{-}teamX"}
\ExtensionTok{python}\NormalTok{ scripts/run\_sql.py }\AttributeTok{{-}{-}sqlfile}\NormalTok{ sql/sector\_top\_moves.sql }\AttributeTok{{-}{-}out}\NormalTok{ reports/sector\_top\_moves.csv}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Part D --- (Stretch) Create a
\textbf{calendar} table \& missing‑day
check}{Part D --- (Stretch) Create a calendar table \& missing‑day check}}\label{part-d-stretch-create-a-calendar-table-missingday-check}

Create \texttt{calendar(date\ TEXT\ PRIMARY\ KEY)} covering min→max date
in \texttt{prices}, and write a query that counts \textbf{missing
business days} per ticker (join \texttt{calendar} LEFT JOIN
\texttt{prices}). Save result to \texttt{reports/missing\_days.csv}.

\emph{Hint: build the calendar in Python with
\texttt{pd.bdate\_range()}; insert into \texttt{calendar}; then
\texttt{SELECT\ c.date,\ p.ticker\ FROM\ calendar\ c\ LEFT\ JOIN\ prices\ p\ ...\ WHERE\ p.date\ IS\ NULL}.}

\subsection{Part E --- Commit \& push (use the short‑lived token flow
from Session
2)}\label{part-e-commit-push-use-the-shortlived-token-flow-from-session-2}

Recommended files to add:

\begin{itemize}
\tightlist
\item
  \texttt{scripts/build\_db.py}, \texttt{scripts/run\_sql.py},
  \texttt{sql/*.sql}, updated \texttt{Makefile},
  \texttt{reports/sql\_sector\_summary.csv}
\item
  Optionally \textbf{do not} commit \texttt{data/prices.db} if large; if
  small and you must commit, ensure LFS is tracking \texttt{data/*.db}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Grading (pass/revise)}\label{grading-passrevise-4}

\begin{itemize}
\tightlist
\item
  \texttt{data/prices.db} builds from \texttt{make\ db} and contains
  \textbf{meta} + \textbf{prices} with PK \texttt{(ticker,date)} and FK
  to \texttt{meta}.
\item
  \texttt{reports/sql\_sector\_summary.csv} generated by
  \texttt{make\ sql-report}.
\item
  \texttt{sql/sector\_top\_moves.sql},
  \texttt{sql/ticker\_activity.sql}, \texttt{sql/range\_summary.sql}
  present and runnable via \texttt{scripts/run\_sql.py}.
\item
  If stretch completed: \texttt{calendar} table +
  \texttt{reports/missing\_days.csv}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-4}

\begin{itemize}
\tightlist
\item
  Run the entire lab once in a fresh Colab runtime with a small
  synthetic \texttt{prices.csv} to ensure speed.
\item
  Prepare a one‑slide schema diagram (\texttt{meta\ ⟷\ prices}) and a
  slide showing an index scan vs table scan (EXPLAIN output optional).
\item
  Remind students: \textbf{don't commit big DBs}; keep
  \texttt{build\_db.py} as the source of truth.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-4}

\begin{itemize}
\tightlist
\item
  \textbf{Schema first}: clean DDL prevents downstream headaches.
\item
  \textbf{Constraints} are your guardrails; test them (we did with a
  duplicate insert).
\item
  \textbf{Parameterize} queries; never string‑concat user inputs into
  SQL.
\item
  Keep SQLite for \textbf{analysis}; push heavy analytics to
  Python/Polars when needed.
\end{itemize}

Next time (Session 8): \textbf{SQL II --- Window functions \&
\texttt{pandas.read\_sql} workflows} (LAG/LEAD, rolling stats, and
SQL↔pandas round‑trips).

\bookmarksetup{startatroot}

\chapter{\texorpdfstring{Session 8 --- SQL II: Window Functions \&
\texttt{pandas.read\_sql}
Workflows}{Session 8 --- SQL II: Window Functions \& pandas.read\_sql Workflows}}\label{session-8-sql-ii-window-functions-pandas.read_sql-workflows}

Below is a complete lecture package for \textbf{Session 8 --- SQL II:
Window Functions \& \texttt{pandas.read\_sql} Workflows} (75 minutes).
It includes: a timed agenda, slides/talking points, a
\textbf{Colab‑friendly in‑class lab with copy‑paste code}, and
\textbf{homework with copy‑paste code}. Today you'll compute
\textbf{lags, leads, rolling stats, and top‑k queries} in SQLite using
\textbf{window functions}, then pull results into pandas for downstream
use.

\begin{quote}
\textbf{Assumptions:}

\begin{itemize}
\tightlist
\item
  You're in the same Drive‑mounted repo (e.g.,
  \texttt{unified-stocks-teamX}).
\item
  You have \texttt{data/prices.db} from Session 7. If not, the lab
  includes a small fallback to build it from
  \texttt{data/raw/prices.csv}.
\item
  Educational use only --- not trading advice.
\end{itemize}
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{\texorpdfstring{Session 8 --- SQL II: Window Functions \&
\texttt{pandas.read\_sql} (75
min)}{Session 8 --- SQL II: Window Functions \& pandas.read\_sql (75 min)}}\label{session-8-sql-ii-window-functions-pandas.read_sql-75-min}

\subsection{Learning goals}\label{learning-goals-7}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain and use \textbf{window functions}: \texttt{LAG},
  \texttt{LEAD}, \texttt{ROW\_NUMBER}, and aggregates with
  \texttt{OVER\ (PARTITION\ BY\ …\ ORDER\ BY\ …\ ROWS\ …)}.
\item
  Compute \textbf{rolling means/variance} and \textbf{multi‑lag
  features} per ticker \textbf{without leakage}.
\item
  Use \texttt{WINDOW} named frames to avoid repetition and errors.
\item
  Run parameterized SQL from Python with
  \texttt{pandas.read\_sql\_query}, and optionally register a custom SQL
  function (e.g., \texttt{SQRT}).
\item
  Evaluate query performance basics with \texttt{EXPLAIN\ QUERY\ PLAN}.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-5}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Window functions: mental model \& syntax
  (\texttt{PARTITION\ BY}, \texttt{ORDER\ BY}, \texttt{ROWS} frames)
\item
  \textbf{(10 min)} Patterns for time series: lags, leads, rolling
  stats, top‑k per group
\item
  \textbf{(35 min)} \textbf{In‑class lab} (Colab): lags/leads → rolling
  mean/variance → z‑scores → top days per ticker → pull into pandas and
  save features
\item
  \textbf{(10 min)} Wrap‑up, performance notes
  (\texttt{EXPLAIN\ QUERY\ PLAN}), homework briefing
\item
  \textbf{(10 min)} Buffer
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points}\label{slides-talking-points-1}

\textbf{What's a window?}

\begin{itemize}
\item
  A \textbf{window} lets an aggregate or analytic function see a
  \textbf{row + its neighbors} without collapsing rows.
\item
  Template:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{func(expr) }\KeywordTok{OVER}\NormalTok{ (}
   \KeywordTok{PARTITION} \KeywordTok{BY} \KeywordTok{key}
   \KeywordTok{ORDER} \KeywordTok{BY} \DataTypeTok{time}
   \KeywordTok{ROWS} \KeywordTok{BETWEEN}\NormalTok{ N }\KeywordTok{PRECEDING} \KeywordTok{AND} \KeywordTok{CURRENT} \KeywordTok{ROW}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}
\item
  \textbf{\texttt{PARTITION\ BY}} = per‑group window;
  \textbf{\texttt{ORDER\ BY}} = sequence; \textbf{\texttt{ROWS}} = how
  many rows to include.
\end{itemize}

\textbf{Window vs GROUP BY}

\begin{itemize}
\tightlist
\item
  \texttt{GROUP\ BY} returns \textbf{one row per group};
  \texttt{OVER\ (…)} returns \textbf{one row per input row} with extra
  columns.
\end{itemize}

\textbf{Time‑series patterns}

\begin{itemize}
\tightlist
\item
  \textbf{Lags:} \texttt{LAG(x,\ k)} → previous \texttt{k} rows ⇒
  features at \emph{t} that use only info ≤ \emph{t}.
\item
  \textbf{Leads:} \texttt{LEAD(x,\ k)} → future \texttt{k} rows ⇒
  \emph{labels} (don't leak into features).
\item
  \textbf{Rolling stats:}
  \texttt{AVG(x)\ OVER\ (…\ ROWS\ BETWEEN\ w-1\ PRECEDING\ AND\ CURRENT\ ROW)};
  rolling variance via \texttt{AVG(x*x)\ -\ AVG(x)\^{}2}.
\item
  \textbf{Top‑k per group:} compute
  \texttt{ROW\_NUMBER()\ OVER\ (PARTITION\ BY\ key\ ORDER\ BY\ score\ DESC)}
  and filter \texttt{WHERE\ rn\textless{}=k}.
\end{itemize}

\textbf{ROWS vs RANGE}

\begin{itemize}
\tightlist
\item
  Use \textbf{\texttt{ROWS}} for fixed‑length windows on ordered rows
  (what we need).
\item
  \textbf{Time‑based windows} (e.g., last 30 calendar days) require
  different techniques in SQLite (correlated subquery); we'll note but
  not use today.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min)}\label{inclass-lab-35-min-5}

\begin{quote}
Run each block as its own Colab cell. Adjust
\texttt{REPO\_OWNER/REPO\_NAME} first.
\end{quote}

\subsection{0) Mount Drive, open DB, and ensure it
exists}\label{mount-drive-open-db-and-ensure-it-exists}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_OWNER }\OperatorTok{=} \StringTok{"YOUR\_GITHUB\_USERNAME\_OR\_ORG"}     \CommentTok{\# \textless{}{-} change}
\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}            \CommentTok{\# \textless{}{-} change}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, sqlite3, pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np, math, textwrap}
\NormalTok{pathlib.Path(BASE\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{assert}\NormalTok{ pathlib.Path(REPO\_DIR).exists(), }\StringTok{"Repo not found; clone it first."}
\NormalTok{os.chdir(REPO\_DIR)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}

\CommentTok{\# Ensure DB exists (fallback: build from CSV)}
\NormalTok{db\_path }\OperatorTok{=}\NormalTok{ pathlib.Path(}\StringTok{"data/prices.db"}\NormalTok{)}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ db\_path.exists():}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"prices.db not found; attempting minimal build from data/raw/prices.csv …"}\NormalTok{)}
\NormalTok{    pathlib.Path(}\StringTok{"data"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(db\_path)}
\NormalTok{    con.execute(}\StringTok{"PRAGMA foreign\_keys = ON;"}\NormalTok{)}
\NormalTok{    con.executescript(}\StringTok{"""}
\StringTok{    CREATE TABLE IF NOT EXISTS meta (}
\StringTok{      ticker TEXT PRIMARY KEY,}
\StringTok{      name   TEXT,}
\StringTok{      sector TEXT NOT NULL}
\StringTok{    );}
\StringTok{    CREATE TABLE IF NOT EXISTS prices (}
\StringTok{      ticker     TEXT NOT NULL,}
\StringTok{      date       TEXT NOT NULL,}
\StringTok{      adj\_close  REAL NOT NULL CHECK (adj\_close \textgreater{}= 0),}
\StringTok{      volume     INTEGER NOT NULL CHECK (volume \textgreater{}= 0),}
\StringTok{      log\_return REAL NOT NULL,}
\StringTok{      PRIMARY KEY (ticker,date),}
\StringTok{      FOREIGN KEY (ticker) REFERENCES meta(ticker)}
\StringTok{    );}
\StringTok{    CREATE INDEX IF NOT EXISTS idx\_prices\_date ON prices(date);}
\StringTok{    """}\NormalTok{)}
    \CommentTok{\# Minimal meta from tickers\_25 or from CSV}
    \ControlFlowTok{if}\NormalTok{ pathlib.Path(}\StringTok{"tickers\_25.csv"}\NormalTok{).exists():}
\NormalTok{        tks }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"tickers\_25.csv"}\NormalTok{)[}\StringTok{"ticker"}\NormalTok{].dropna().unique().tolist()}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        raw }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"data/raw/prices.csv"}\NormalTok{)}
\NormalTok{        tks }\OperatorTok{=}\NormalTok{ raw[}\StringTok{"ticker"}\NormalTok{].dropna().unique().tolist()}
\NormalTok{    meta }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{"ticker"}\NormalTok{: tks, }\StringTok{"name"}\NormalTok{: tks, }\StringTok{"sector"}\NormalTok{: [}\StringTok{"Unknown"}\NormalTok{]}\OperatorTok{*}\BuiltInTok{len}\NormalTok{(tks)\})}
\NormalTok{    con.executemany(}\StringTok{"INSERT OR IGNORE INTO meta(ticker,name,sector) VALUES(?,?,?)"}\NormalTok{,}
\NormalTok{                    meta.itertuples(index}\OperatorTok{=}\VariableTok{False}\NormalTok{, name}\OperatorTok{=}\VariableTok{None}\NormalTok{))}
    \CommentTok{\# Load prices.csv if present; otherwise synthesize small sample}
    \ControlFlowTok{if}\NormalTok{ pathlib.Path(}\StringTok{"data/raw/prices.csv"}\NormalTok{).exists():}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"data/raw/prices.csv"}\NormalTok{, parse\_dates}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{]).copy()}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{90}\NormalTok{)}
\NormalTok{        rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{7}\NormalTok{)}
\NormalTok{        frames}\OperatorTok{=}\NormalTok{[]}
        \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ tks[:}\DecValTok{5}\NormalTok{]:}
\NormalTok{            r }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\BuiltInTok{len}\NormalTok{(dates))}
\NormalTok{            price }\OperatorTok{=} \DecValTok{100}\OperatorTok{*}\NormalTok{np.exp(np.cumsum(r))}
\NormalTok{            vol }\OperatorTok{=}\NormalTok{ rng.integers(}\FloatTok{1e5}\NormalTok{, }\FloatTok{5e6}\NormalTok{, }\BuiltInTok{len}\NormalTok{(dates))}
\NormalTok{            frames.append(pd.DataFrame(\{}\StringTok{"ticker"}\NormalTok{: t, }\StringTok{"date"}\NormalTok{: dates,}
                                        \StringTok{"adj\_close"}\NormalTok{: price, }\StringTok{"volume"}\NormalTok{: vol\}))}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.concat(frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        df[}\StringTok{"log\_return"}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(df[}\StringTok{"adj\_close"}\NormalTok{]).diff().fillna(}\DecValTok{0}\NormalTok{)}
\NormalTok{    df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{]).dt.strftime(}\StringTok{"\%Y{-}\%m{-}}\SpecialCharTok{\%d}\StringTok{"}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ df[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{]].drop\_duplicates([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
\NormalTok{    con.executemany(}\StringTok{"INSERT OR REPLACE INTO prices(ticker,date,adj\_close,volume,log\_return) VALUES(?,?,?,?,?)"}\NormalTok{,}
\NormalTok{                    df.itertuples(index}\OperatorTok{=}\VariableTok{False}\NormalTok{, name}\OperatorTok{=}\VariableTok{None}\NormalTok{))}
\NormalTok{    con.commit()}
\NormalTok{    con.close()}

\CommentTok{\# Connect and register SQRT (SQLite lacks STDDEV; we’ll compute var and take sqrt)}
\NormalTok{con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(db\_path)}
\NormalTok{con.create\_function(}\StringTok{"SQRT"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\KeywordTok{lambda}\NormalTok{ x: math.sqrt(x) }\ControlFlowTok{if}\NormalTok{ x }\KeywordTok{is} \KeywordTok{not} \VariableTok{None} \KeywordTok{and}\NormalTok{ x}\OperatorTok{\textgreater{}=}\DecValTok{0} \ControlFlowTok{else} \VariableTok{None}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"SQLite version:"}\NormalTok{, sqlite3.sqlite\_version)}
\end{Highlighting}
\end{Shaded}

\subsection{1) LAG \& LEAD (no leakage in
features)}\label{lag-lead-no-leakage-in-features}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\NormalTok{sql }\OperatorTok{=} \StringTok{"""}
\StringTok{SELECT ticker, date,}
\StringTok{       log\_return AS r,}
\StringTok{       LAG(log\_return,1) OVER (PARTITION BY ticker ORDER BY date) AS lag1,}
\StringTok{       LAG(log\_return,2) OVER (PARTITION BY ticker ORDER BY date) AS lag2,}
\StringTok{       LEAD(log\_return,1) OVER (PARTITION BY ticker ORDER BY date) AS r\_tplus1  {-}{-} label candidate}
\StringTok{FROM prices}
\StringTok{WHERE date BETWEEN ? AND ?}
\StringTok{ORDER BY ticker, date}
\StringTok{LIMIT 20;}
\StringTok{"""}
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(sql, con, params}\OperatorTok{=}\NormalTok{[}\StringTok{"2022{-}03{-}01"}\NormalTok{,}\StringTok{"2022{-}06{-}30"}\NormalTok{])}
\NormalTok{df.head(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Teaching notes:}

\begin{itemize}
\tightlist
\item
  \texttt{lag1/lag2} are \textbf{safe features at time \emph{t}} (depend
  on ≤ \emph{t-1}).
\item
  \texttt{r\_tplus1} is a \textbf{label}; never include in features.
\end{itemize}
\end{quote}

\subsection{\texorpdfstring{2) Named \texttt{WINDOW} + rolling
mean/variance (20‑row
window)}{2) Named WINDOW + rolling mean/variance (20‑row window)}}\label{named-window-rolling-meanvariance-20row-window}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sql }\OperatorTok{=} \StringTok{"""}
\StringTok{SELECT}
\StringTok{  ticker, date, log\_return AS r,}
\StringTok{  AVG(log\_return) OVER w AS roll\_mean\_20,}
\StringTok{  AVG(log\_return*log\_return) OVER w}
\StringTok{    {-} (AVG(log\_return) OVER w)*(AVG(log\_return) OVER w) AS roll\_var\_20}
\StringTok{FROM prices}
\StringTok{WINDOW w AS (}
\StringTok{  PARTITION BY ticker}
\StringTok{  ORDER BY date}
\StringTok{  ROWS BETWEEN 19 PRECEDING AND CURRENT ROW}
\StringTok{)}
\StringTok{WHERE date BETWEEN ? AND ?}
\StringTok{ORDER BY ticker, date}
\StringTok{LIMIT 20;}
\StringTok{"""}
\NormalTok{roll }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(sql, con, params}\OperatorTok{=}\NormalTok{[}\StringTok{"2022{-}03{-}01"}\NormalTok{,}\StringTok{"2022{-}06{-}30"}\NormalTok{])}
\NormalTok{roll.head(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Compute rolling \textbf{std} and \textbf{z‑score} in pandas (since we
registered \texttt{SQRT}, we could also do it in SQL; here we'll do it
in pandas for clarity):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roll[}\StringTok{"roll\_std\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (roll[}\StringTok{"roll\_var\_20"}\NormalTok{].clip(lower}\OperatorTok{=}\DecValTok{0}\NormalTok{)).}\BuiltInTok{pow}\NormalTok{(}\FloatTok{0.5}\NormalTok{)}
\NormalTok{roll[}\StringTok{"zscore\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (roll[}\StringTok{"r"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ roll[}\StringTok{"roll\_mean\_20"}\NormalTok{]) }\OperatorTok{/}\NormalTok{ roll[}\StringTok{"roll\_std\_20"}\NormalTok{].replace(}\DecValTok{0}\NormalTok{, pd.NA)}
\NormalTok{roll.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Top‑k absolute moves \textbf{per ticker}
with
\texttt{ROW\_NUMBER}}{3) Top‑k absolute moves per ticker with ROW\_NUMBER}}\label{topk-absolute-moves-per-ticker-with-row_number}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sql }\OperatorTok{=} \StringTok{"""}
\StringTok{WITH ranked AS (}
\StringTok{  SELECT}
\StringTok{    ticker, date, log\_return,}
\StringTok{    ABS(log\_return) AS abs\_move,}
\StringTok{    ROW\_NUMBER() OVER (}
\StringTok{      PARTITION BY ticker}
\StringTok{      ORDER BY ABS(log\_return) DESC}
\StringTok{    ) AS rn}
\StringTok{  FROM prices}
\StringTok{  WHERE date BETWEEN ? AND ?}
\StringTok{)}
\StringTok{SELECT * FROM ranked WHERE rn \textless{}= 3}
\StringTok{ORDER BY ticker, rn;}
\StringTok{"""}
\NormalTok{topk }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(sql, con, params}\OperatorTok{=}\NormalTok{[}\StringTok{"2022{-}01{-}01"}\NormalTok{,}\StringTok{"2025{-}08{-}01"}\NormalTok{])}
\NormalTok{topk.head(}\DecValTok{15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) Build a \textbf{features} DataFrame
directly from SQL and save to
Parquet}{4) Build a features DataFrame directly from SQL and save to Parquet}}\label{build-a-features-dataframe-directly-from-sql-and-save-to-parquet}

We'll assemble lags and rolling stats in one query using a named window
\texttt{w20}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sql }\OperatorTok{=} \StringTok{"""}
\StringTok{SELECT}
\StringTok{  ticker, date,}
\StringTok{  log\_return AS r\_1d,}
\StringTok{  LAG(log\_return,1) OVER (PARTITION BY ticker ORDER BY date) AS lag1,}
\StringTok{  LAG(log\_return,2) OVER (PARTITION BY ticker ORDER BY date) AS lag2,}
\StringTok{  LAG(log\_return,3) OVER (PARTITION BY ticker ORDER BY date) AS lag3,}
\StringTok{  AVG(log\_return) OVER w20 AS roll\_mean\_20,}
\StringTok{  AVG(log\_return*log\_return) OVER w20}
\StringTok{    {-} (AVG(log\_return) OVER w20)*(AVG(log\_return) OVER w20) AS roll\_var\_20}
\StringTok{FROM prices}
\StringTok{WINDOW w20 AS (}
\StringTok{  PARTITION BY ticker}
\StringTok{  ORDER BY date}
\StringTok{  ROWS BETWEEN 19 PRECEDING AND CURRENT ROW}
\StringTok{)}
\StringTok{WHERE date BETWEEN ? AND ?}
\StringTok{ORDER BY ticker, date;}
\StringTok{"""}
\NormalTok{features\_sql }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(sql, con, params}\OperatorTok{=}\NormalTok{[}\StringTok{"2019{-}01{-}01"}\NormalTok{,}\StringTok{"2025{-}08{-}01"}\NormalTok{])}
\NormalTok{features\_sql[}\StringTok{"roll\_std\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (features\_sql[}\StringTok{"roll\_var\_20"}\NormalTok{].clip(lower}\OperatorTok{=}\DecValTok{0}\NormalTok{)).}\BuiltInTok{pow}\NormalTok{(}\FloatTok{0.5}\NormalTok{)}
\NormalTok{features\_sql[}\StringTok{"zscore\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (features\_sql[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ features\_sql[}\StringTok{"roll\_mean\_20"}\NormalTok{]) }\OperatorTok{/}\NormalTok{ features\_sql[}\StringTok{"roll\_std\_20"}\NormalTok{].replace(}\DecValTok{0}\NormalTok{, pd.NA)}

\CommentTok{\# Drop first 2–3 rows per ticker where lags are null}
\NormalTok{features\_sql }\OperatorTok{=}\NormalTok{ (features\_sql}
\NormalTok{                .sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
\NormalTok{                .groupby(}\StringTok{"ticker"}\NormalTok{, group\_keys}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{                .}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ g: g.iloc[}\DecValTok{3}\NormalTok{:]))}

\CommentTok{\# Save}
\NormalTok{pathlib.Path(}\StringTok{"data/processed"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{features\_sql.to\_parquet(}\StringTok{"data/processed/features\_sql.parquet"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{features\_sql.head()}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{5) \texttt{EXPLAIN\ QUERY\ PLAN} sanity \&
index
usage}{5) EXPLAIN QUERY PLAN sanity \& index usage}}\label{explain-query-plan-sanity-index-usage}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plan }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(}\StringTok{"""}
\StringTok{EXPLAIN QUERY PLAN}
\StringTok{SELECT ticker, date,}
\StringTok{       LAG(log\_return,1) OVER (PARTITION BY ticker ORDER BY date) AS lag1}
\StringTok{FROM prices}
\StringTok{WHERE date BETWEEN ? AND ?}
\StringTok{ORDER BY ticker, date;}
\StringTok{"""}\NormalTok{, con, params}\OperatorTok{=}\NormalTok{[}\StringTok{"2022{-}01{-}01"}\NormalTok{,}\StringTok{"2025{-}08{-}01"}\NormalTok{])}
\NormalTok{plan}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Interpretation tip:} You should see use of the
\texttt{idx\_prices\_date} or \texttt{PRIMARY\ KEY} (depending on the
optimizer). If you often filter by \texttt{(ticker,\ date)}, consider a
composite index:
\texttt{CREATE\ INDEX\ IF\ NOT\ EXISTS\ idx\_prices\_ticker\_date\ ON\ prices(ticker,\ date);}
(We'll include that in homework.)
\end{quote}

\subsection{6) Save lab outputs}\label{save-lab-outputs}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pathlib.Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{features\_sql.head(}\DecValTok{100}\NormalTok{).to\_csv(}\StringTok{"reports/sql\_window\_demo.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{topk.to\_csv(}\StringTok{"reports/top3\_abs\_moves\_per\_ticker.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote reports/sql\_window\_demo.csv and reports/top3\_abs\_moves\_per\_ticker.csv"}\NormalTok{)}
\NormalTok{con.close()}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-5}

\begin{itemize}
\tightlist
\item
  Window functions = \textbf{per‑row context} (lags, rolling stats,
  top‑k per group) with \textbf{no row collapse}.
\item
  Prefer
  \textbf{\texttt{ROWS\ BETWEEN\ N\ PRECEDING\ AND\ CURRENT\ ROW}} to
  express true rolling windows.
\item
  \textbf{No leakage}: only use \texttt{LAG} for features; \texttt{LEAD}
  is for labels.
\item
  Use \texttt{pandas.read\_sql\_query} to \textbf{push computation into
  SQL} and bring back tidy frames.
\item
  Indexes matter; check \texttt{EXPLAIN\ QUERY\ PLAN}, and add
  \texttt{(ticker,\ date)} index when filtering by both.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
9)}\label{homework-due-before-session-9}

\textbf{Goal:} Productionize SQL‑side feature engineering and
performance basics. You will (A) create a reusable SQL file that defines
features using windows, (B) write a small Python runner that writes
\textbf{\texttt{data/processed/features\_sql.parquet}}, (C) add a
composite index, and (D) produce two small reports.

\subsection{\texorpdfstring{Part A --- \texttt{sql/features\_window.sql}
(reusable)}{Part A --- sql/features\_window.sql (reusable)}}\label{part-a-sqlfeatures_window.sql-reusable}

Create \texttt{sql/features\_window.sql}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} sql/features\_window.sql}
\CommentTok{{-}{-} Rolling features and lags built with window functions.}
\KeywordTok{WITH}\NormalTok{ base }\KeywordTok{AS}\NormalTok{ (}
  \KeywordTok{SELECT}
\NormalTok{    ticker, }\DataTypeTok{date}\NormalTok{, log\_return }\KeywordTok{AS}\NormalTok{ r\_1d}
  \KeywordTok{FROM}\NormalTok{ prices}
  \KeywordTok{WHERE} \DataTypeTok{date} \KeywordTok{BETWEEN}\NormalTok{ ? }\KeywordTok{AND}\NormalTok{ ?  }\CommentTok{{-}{-} placeholders: start, end}
\NormalTok{)}
\KeywordTok{SELECT}
\NormalTok{  ticker, }\DataTypeTok{date}\NormalTok{, r\_1d,}
  \FunctionTok{LAG}\NormalTok{(r\_1d,}\DecValTok{1}\NormalTok{) }\KeywordTok{OVER}\NormalTok{ (}\KeywordTok{PARTITION} \KeywordTok{BY}\NormalTok{ ticker }\KeywordTok{ORDER} \KeywordTok{BY} \DataTypeTok{date}\NormalTok{) }\KeywordTok{AS}\NormalTok{ lag1,}
  \FunctionTok{LAG}\NormalTok{(r\_1d,}\DecValTok{2}\NormalTok{) }\KeywordTok{OVER}\NormalTok{ (}\KeywordTok{PARTITION} \KeywordTok{BY}\NormalTok{ ticker }\KeywordTok{ORDER} \KeywordTok{BY} \DataTypeTok{date}\NormalTok{) }\KeywordTok{AS}\NormalTok{ lag2,}
  \FunctionTok{LAG}\NormalTok{(r\_1d,}\DecValTok{3}\NormalTok{) }\KeywordTok{OVER}\NormalTok{ (}\KeywordTok{PARTITION} \KeywordTok{BY}\NormalTok{ ticker }\KeywordTok{ORDER} \KeywordTok{BY} \DataTypeTok{date}\NormalTok{) }\KeywordTok{AS}\NormalTok{ lag3,}
  \FunctionTok{AVG}\NormalTok{(r\_1d) }\KeywordTok{OVER}\NormalTok{ w20 }\KeywordTok{AS}\NormalTok{ roll\_mean\_20,}
  \FunctionTok{AVG}\NormalTok{(r\_1d}\OperatorTok{*}\NormalTok{r\_1d) }\KeywordTok{OVER}\NormalTok{ w20 }\OperatorTok{{-}}\NormalTok{ (}\FunctionTok{AVG}\NormalTok{(r\_1d) }\KeywordTok{OVER}\NormalTok{ w20)}\OperatorTok{*}\NormalTok{(}\FunctionTok{AVG}\NormalTok{(r\_1d) }\KeywordTok{OVER}\NormalTok{ w20) }\KeywordTok{AS}\NormalTok{ roll\_var\_20}
\KeywordTok{FROM}\NormalTok{ base}
\NormalTok{WINDOW w20 }\KeywordTok{AS}\NormalTok{ (}
  \KeywordTok{PARTITION} \KeywordTok{BY}\NormalTok{ ticker}
  \KeywordTok{ORDER} \KeywordTok{BY} \DataTypeTok{date}
  \KeywordTok{ROWS} \KeywordTok{BETWEEN} \DecValTok{19} \KeywordTok{PRECEDING} \KeywordTok{AND} \KeywordTok{CURRENT} \KeywordTok{ROW}
\NormalTok{)}
\KeywordTok{ORDER} \KeywordTok{BY}\NormalTok{ ticker, }\DataTypeTok{date}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Part B --- Runner:
\texttt{scripts/build\_features\_sql.py}}{Part B --- Runner: scripts/build\_features\_sql.py}}\label{part-b-runner-scriptsbuild_features_sql.py}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scripts/build\_features\_sql.py}
\CommentTok{\#!/usr/bin/env python}
\ImportTok{import}\NormalTok{ argparse, sqlite3, pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np, math}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    ap }\OperatorTok{=}\NormalTok{ argparse.ArgumentParser()}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}db"}\NormalTok{, default}\OperatorTok{=}\StringTok{"data/prices.db"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}sqlfile"}\NormalTok{, default}\OperatorTok{=}\StringTok{"sql/features\_window.sql"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}start"}\NormalTok{, default}\OperatorTok{=}\StringTok{"2019{-}01{-}01"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}end"}\NormalTok{,   default}\OperatorTok{=}\StringTok{"2025{-}08{-}01"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}out"}\NormalTok{,   default}\OperatorTok{=}\StringTok{"data/processed/features\_sql.parquet"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}drop{-}head"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{3}\NormalTok{, }\BuiltInTok{help}\OperatorTok{=}\StringTok{"Drop first N rows per ticker (due to lags)"}\NormalTok{)}
\NormalTok{    args }\OperatorTok{=}\NormalTok{ ap.parse\_args()}

\NormalTok{    Path(args.out).parent.mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(args.db)}
\NormalTok{    con.create\_function(}\StringTok{"SQRT"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\KeywordTok{lambda}\NormalTok{ x: math.sqrt(x) }\ControlFlowTok{if}\NormalTok{ x }\KeywordTok{is} \KeywordTok{not} \VariableTok{None} \KeywordTok{and}\NormalTok{ x}\OperatorTok{\textgreater{}=}\DecValTok{0} \ControlFlowTok{else} \VariableTok{None}\NormalTok{)}

\NormalTok{    sql }\OperatorTok{=}\NormalTok{ Path(args.sqlfile).read\_text()}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(sql, con, params}\OperatorTok{=}\NormalTok{[args.start, args.end])}

    \CommentTok{\# Finish std \& z{-}score in pandas}
\NormalTok{    df[}\StringTok{"roll\_std\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (df[}\StringTok{"roll\_var\_20"}\NormalTok{].clip(lower}\OperatorTok{=}\DecValTok{0}\NormalTok{)).}\BuiltInTok{pow}\NormalTok{(}\FloatTok{0.5}\NormalTok{)}
\NormalTok{    df[}\StringTok{"zscore\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (df[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ df[}\StringTok{"roll\_mean\_20"}\NormalTok{]) }\OperatorTok{/}\NormalTok{ df[}\StringTok{"roll\_std\_20"}\NormalTok{].replace(}\DecValTok{0}\NormalTok{, pd.NA)}

    \CommentTok{\# Drop first N rows per ticker where lags are NaN}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ (df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
\NormalTok{            .groupby(}\StringTok{"ticker"}\NormalTok{, group\_keys}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{            .}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ g: g.iloc[args.drop\_head:]))}

\NormalTok{    df.to\_parquet(args.out, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, args.out, }\StringTok{"rows:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(df))}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Make it executable:

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ os, stat, pathlib}
\NormalTok{p }\OperatorTok{=}\NormalTok{ pathlib.Path(}\StringTok{"scripts/build\_features\_sql.py"}\NormalTok{)}
\NormalTok{os.chmod(p, os.stat(p).st\_mode }\OperatorTok{|}\NormalTok{ stat.S\_IEXEC)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Ready:"}\NormalTok{, p)}
\end{Highlighting}
\end{Shaded}

\subsection{Part C --- Add a composite index and verify
plan}\label{part-c-add-a-composite-index-and-verify-plan}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create \texttt{sql/add\_index\_ticker\_date.sql}:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-} sql/add\_index\_ticker\_date.sql}
\KeywordTok{CREATE} \KeywordTok{INDEX} \ControlFlowTok{IF} \KeywordTok{NOT} \KeywordTok{EXISTS}\NormalTok{ idx\_prices\_ticker\_date }\KeywordTok{ON}\NormalTok{ prices(ticker, }\DataTypeTok{date}\NormalTok{);}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Runner to apply it (or just execute once in a notebook):
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sqlite3, pathlib}
\NormalTok{con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(}\StringTok{"data/prices.db"}\NormalTok{)}
\NormalTok{con.executescript(pathlib.Path(}\StringTok{"sql/add\_index\_ticker\_date.sql"}\NormalTok{).read\_text())}
\NormalTok{con.close()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Index created: idx\_prices\_ticker\_date"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Capture the query plan to a text file:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sqlite3, pandas }\ImportTok{as}\NormalTok{ pd, pathlib}
\NormalTok{con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(}\StringTok{"data/prices.db"}\NormalTok{)}
\NormalTok{plan }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(}\StringTok{"""}
\StringTok{EXPLAIN QUERY PLAN}
\StringTok{SELECT ticker, date, LAG(log\_return,1) OVER (PARTITION BY ticker ORDER BY date)}
\StringTok{FROM prices}
\StringTok{WHERE ticker = ? AND date BETWEEN ? AND ?}
\StringTok{ORDER BY date;}
\StringTok{"""}\NormalTok{, con, params}\OperatorTok{=}\NormalTok{[}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"2022{-}01{-}01"}\NormalTok{,}\StringTok{"2025{-}08{-}01"}\NormalTok{])}
\NormalTok{pathlib.Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{plan.to\_csv(}\StringTok{"reports/query\_plan\_lag1.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{con.close()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote reports/query\_plan\_lag1.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{Part D --- Produce two small
reports}\label{part-d-produce-two-small-reports}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Top‑k per ticker} (k=5) as CSV:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ sqlite3, pandas }\ImportTok{as}\NormalTok{ pd, pathlib}
\NormalTok{con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(}\StringTok{"data/prices.db"}\NormalTok{)}
\NormalTok{sql }\OperatorTok{=} \StringTok{"""}
\StringTok{WITH ranked AS (}
\StringTok{  SELECT ticker, date, log\_return, ABS(log\_return) AS abs\_move,}
\StringTok{         ROW\_NUMBER() OVER (PARTITION BY ticker ORDER BY ABS(log\_return) DESC) AS rn}
\StringTok{  FROM prices}
\StringTok{  WHERE date BETWEEN ? AND ?}
\StringTok{)}
\StringTok{SELECT * FROM ranked WHERE rn \textless{}= 5 ORDER BY ticker, rn;}
\StringTok{"""}
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(sql, con, params}\OperatorTok{=}\NormalTok{[}\StringTok{"2019{-}01{-}01"}\NormalTok{,}\StringTok{"2025{-}08{-}01"}\NormalTok{])}
\NormalTok{pathlib.Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{df.to\_csv(}\StringTok{"reports/top5\_abs\_moves\_per\_ticker.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{con.close()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote reports/top5\_abs\_moves\_per\_ticker.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Features via SQL} saved to Parquet:
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{python scripts}\OperatorTok{/}\NormalTok{build\_features\_sql.py }\OperatorTok{{-}{-}}\NormalTok{start }\DecValTok{2019}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}{-}}\NormalTok{end }\DecValTok{2025}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{8}\OperatorTok{{-}}\DecValTok{0}\ErrorTok{1} \OperatorTok{{-}{-}}\NormalTok{out data}\OperatorTok{/}\NormalTok{processed}\OperatorTok{/}\NormalTok{features\_sql.parquet}
\end{Highlighting}
\end{Shaded}

\subsection{Part E --- Makefile targets (optional but
recommended)}\label{part-e-makefile-targets-optional-but-recommended}

Append to your \texttt{Makefile}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{DB := data/prices.db}
\NormalTok{FEATS\_SQL := data/processed/features\_sql.parquet}

\NormalTok{.PHONY: features{-}sql add{-}index plan}
\NormalTok{features{-}sql: $(FEATS\_SQL) \#\# Build features using SQL windows}
\NormalTok{$(FEATS\_SQL): scripts/build\_features\_sql.py sql/features\_window.sql $(DB)}
\NormalTok{\textbackslash{}tpython scripts/build\_features\_sql.py {-}{-}db $(DB) {-}{-}sqlfile sql/features\_window.sql {-}{-}start $(START) {-}{-}end $(END) {-}{-}out $(FEATS\_SQL)}

\NormalTok{add{-}index: \#\# Create composite (ticker,date) index}
\NormalTok{\textbackslash{}tsqlite3 $(DB) \textless{} sql/add\_index\_ticker\_date.sql}

\NormalTok{plan: \#\# Save a sample EXPLAIN QUERY PLAN to reports/}
\NormalTok{\textbackslash{}tpython {-} \textless{}\textless{} \textquotesingle{}PY\textquotesingle{}}
\NormalTok{import sqlite3, pandas as pd, os}
\NormalTok{con = sqlite3.connect("data/prices.db")}
\NormalTok{df = pd.read\_sql\_query(\textbackslash{}"\textbackslash{}"\textbackslash{}"\textbackslash{}nEXPLAIN QUERY PLAN\textbackslash{}nSELECT ticker, date, LAG(log\_return,1) OVER (PARTITION BY ticker ORDER BY date)\textbackslash{}nFROM prices WHERE ticker=? AND date BETWEEN ? AND ? ORDER BY date;\textbackslash{}n\textbackslash{}"\textbackslash{}"\textbackslash{}", con, params=["AAPL","2022{-}01{-}01","2025{-}08{-}01"])}
\NormalTok{os.makedirs("reports", exist\_ok=True)}
\NormalTok{df.to\_csv("reports/query\_plan\_lag1.csv", index=False)}
\NormalTok{con.close()}
\NormalTok{print("Wrote reports/query\_plan\_lag1.csv")}
\NormalTok{PY}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\BuiltInTok{set} \AttributeTok{{-}euo}\NormalTok{ pipefail}
\BuiltInTok{cd} \StringTok{"/content/drive/MyDrive/dspt25/unified{-}stocks{-}teamX"}
\FunctionTok{make}\NormalTok{ add{-}index}
\FunctionTok{make}\NormalTok{ features{-}sql}
\FunctionTok{make}\NormalTok{ plan}
\end{Highlighting}
\end{Shaded}

\subsection{Submission checklist
(pass/revise)}\label{submission-checklist-passrevise-1}

\begin{itemize}
\tightlist
\item
  \texttt{sql/features\_window.sql} present; uses \texttt{WINDOW\ w20}
  and \texttt{LAG} for 1--3 lags.
\item
  \texttt{scripts/build\_features\_sql.py} runs and writes
  \texttt{data/processed/features\_sql.parquet}.
\item
  Composite index created (\texttt{idx\_prices\_ticker\_date}).
\item
  \texttt{reports/top5\_abs\_moves\_per\_ticker.csv} and
  \texttt{reports/query\_plan\_lag1.csv} generated.
\item
  (Optional) \texttt{Makefile} updated with \texttt{features-sql},
  \texttt{add-index}, \texttt{plan}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-5}

\begin{itemize}
\tightlist
\item
  Test the in‑class lab once in a fresh Colab runtime; ensure SQLite
  version ≥ 3.25 (window functions).
\item
  If a student's runtime is older (rare), advise upgrading Colab or
  running the Python fallback path.
\item
  Keep one slide showing the difference between
  \textbf{\texttt{ROWS\ BETWEEN\ 19\ PRECEDING\ AND\ CURRENT\ ROW}} and
  off‑by‑one mistakes.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-5}

\begin{itemize}
\tightlist
\item
  \textbf{No leakage}: features must come from \textbf{\texttt{LAG}},
  not \texttt{LEAD}.
\item
  Rolling stats with windows are \textbf{declarative and fast}; avoid
  reinventing in pandas unless needed.
\item
  Use \texttt{WINDOW} names to reduce errors and duplication.
\item
  Check query plans and add indexes purposefully.
\end{itemize}

\textbf{Next up (Session 9):} Finance‑specific evaluation \& leakage
control --- walk‑forward splits, embargo, and regime‑aware error
analysis.

\bookmarksetup{startatroot}

\chapter{Session 9 --- Cleaning, Joins, and
Parquet}\label{session-9-cleaning-joins-and-parquet}

Below is a complete lecture package for \textbf{Session 9 --- Cleaning,
Joins, and Parquet} (75 minutes). It includes a timed agenda, slide
talking points, a \textbf{Colab‑friendly in‑class lab with copy‑paste
code}, and \textbf{homework with copy‑paste code}. You'll clean \& merge
multi‑ticker data, standardize dtypes (including \textbf{pandas nullable
ints} and \textbf{categoricals}), and write tidy
\textbf{Parquet}---including a partitioned‑by‑ticker dataset.

\begin{quote}
\textbf{Assumptions:} Same Drive‑mounted repo (e.g.,
\texttt{unified-stocks-teamX}) as prior sessions. Your raw prices live
under \texttt{data/raw/} (either a single \texttt{prices.csv} or
multiple CSVs). The lab includes a safe fallback (small synthetic
dataset) if raw files are missing.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 9 --- Cleaning, Joins, Parquet (75
min)}\label{session-9-cleaning-joins-parquet-75-min}

\subsection{Learning goals}\label{learning-goals-8}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use \texttt{merge}, \texttt{assign}, and \texttt{pipe} to write clean,
  testable data‑wrangling code.
\item
  Choose \textbf{sensible dtypes} for analytics and storage:
  \texttt{category}, pandas \textbf{nullable integers} (\texttt{Int64},
  \texttt{Int32}, \ldots), and \texttt{string}.
\item
  Write \textbf{Parquet} with compression and \textbf{read it back};
  understand \textbf{partitioning by ticker} and how to filter
  efficiently.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-6}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: tidy schema; joins (\texttt{merge}),
  \texttt{assign}, \texttt{pipe} patterns
\item
  \textbf{(10 min)} Slides: dtypes---\texttt{category}, \texttt{string},
  \textbf{nullable ints} (\texttt{Int64}), \texttt{float32} vs
  \texttt{float64}
\item
  \textbf{(10 min)} Slides: Parquet vs CSV; compression; partitioning;
  schema preservation
\item
  \textbf{(35 min)} \textbf{In‑class lab}: clean \& join → set dtypes →
  write \texttt{data/processed/prices.parquet} and \textbf{partitioned}
  dataset by ticker
\item
  \textbf{(10 min)} Wrap‑up \& homework briefing
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points (paste these bullets into your
deck)}\label{slides-talking-points-paste-these-bullets-into-your-deck}

\subsection{Tidy schema for price
data}\label{tidy-schema-for-price-data}

\begin{itemize}
\tightlist
\item
  \textbf{One row = one ticker‑day}.
\item
  Minimal columns (snake\_case): \texttt{date\ (datetime64{[}ns{]})},
  \texttt{ticker\ (category)},
  \texttt{open/high/low/close/adj\_close\ (float32/64)},
  \texttt{volume\ (Int64)}.
\item
  Optional metadata (from a separate table): \texttt{name\ (string)},
  \texttt{sector\ (category)}.
\end{itemize}

\subsection{\texorpdfstring{Idiomatic pandas: \texttt{merge},
\texttt{assign},
\texttt{pipe}}{Idiomatic pandas: merge, assign, pipe}}\label{idiomatic-pandas-merge-assign-pipe}

\begin{itemize}
\tightlist
\item
  \textbf{\texttt{merge}}: combine frames by keys (e.g., \texttt{prices}
  ⟵left join⟶ \texttt{tickers}).
\item
  \textbf{\texttt{assign}}: add/transform columns without breaking the
  chain:
  \texttt{df\ =\ df.assign(adj\_close=lambda\ d:\ d{[}\textquotesingle{}adj\_close\textquotesingle{}{]}.fillna(d{[}\textquotesingle{}close\textquotesingle{}{]}))}.
\item
  \textbf{\texttt{pipe}}: compose small, testable transforms:
  \texttt{df\ =\ (raw.pipe(standardize\_columns).pipe(clean\_prices).pipe(join\_meta,\ meta=meta))}.
\end{itemize}

\subsection{Dtypes that help}\label{dtypes-that-help}

\begin{itemize}
\tightlist
\item
  \textbf{Categorical} (\texttt{category}): compact \& fast for
  low‑cardinality strings (\texttt{ticker}, \texttt{sector}).
\item
  \textbf{Nullable integers} (\texttt{Int64}, \texttt{Int32}): keep
  \textbf{missing values} and integer semantics (\texttt{volume}).
\item
  \textbf{String} (\texttt{string{[}python{]}}): consistent string
  semantics (avoid \texttt{object}).
\item
  \textbf{Floats}: \texttt{float32} can halve memory, but consider
  numeric precision.
\end{itemize}

\subsection{Parquet: why \& how}\label{parquet-why-how}

\begin{itemize}
\tightlist
\item
  \textbf{Columnar}, compressed, preserves schema better than CSV.
\item
  \textbf{Filters \& projection}: read only needed columns/rows
  (esp.~with \textbf{partitioned datasets}).
\item
  Partitioning by \textbf{\texttt{ticker/}} yields fast reads of a
  subset (e.g., a single ticker).
\item
  Typical settings: engine=\texttt{pyarrow}, compression=\texttt{zstd}
  or \texttt{snappy}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min)}\label{inclass-lab-35-min-6}

\begin{quote}
Run each block as its \textbf{own Colab cell}. Replace
\texttt{REPO\_NAME} to match your repo.
\end{quote}

\subsection{0) Setup: mount Drive, cd into repo, ensure
folders}\label{setup-mount-drive-cd-into-repo-ensure-folders}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# ✏️ Change this to your repo folder name}
\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, sys, glob, pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{pathlib.Path(BASE\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{assert}\NormalTok{ pathlib.Path(REPO\_DIR).exists(), }\StringTok{"Repo not found. Clone it first (Session 2/3)."}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/raw"}\NormalTok{, }\StringTok{"data/static"}\NormalTok{, }\StringTok{"data/processed"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}
\end{Highlighting}
\end{Shaded}

\subsection{1) Locate raw price files (CSV) or create a
fallback}\label{locate-raw-price-files-csv-or-create-a-fallback}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np, datetime }\ImportTok{as}\NormalTok{ dt}

\NormalTok{raw\_candidates }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{if}\NormalTok{ Path(}\StringTok{"data/raw/prices.csv"}\NormalTok{).exists():}
\NormalTok{    raw\_candidates }\OperatorTok{=}\NormalTok{ [}\StringTok{"data/raw/prices.csv"}\NormalTok{]}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    raw\_candidates }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(glob.glob(}\StringTok{"data/raw/prices*.csv"}\NormalTok{)) }\KeywordTok{or} \BuiltInTok{sorted}\NormalTok{(glob.glob(}\StringTok{"data/raw/prices/*.csv"}\NormalTok{))}

\KeywordTok{def}\NormalTok{ \_make\_synthetic\_prices():}
    \CommentTok{\# Small 2{-}year synthetic daily prices for AAPL/MSFT/GOOGL}
\NormalTok{    tickers }\OperatorTok{=}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{]}
\NormalTok{    dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{520}\NormalTok{, freq}\OperatorTok{=}\StringTok{"B"}\NormalTok{)}
\NormalTok{    rows }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ tickers:}
\NormalTok{        price }\OperatorTok{=} \DecValTok{100} \OperatorTok{+}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{).cumsum()}
\NormalTok{        price }\OperatorTok{=}\NormalTok{ np.maximum(price, }\FloatTok{1.0}\NormalTok{)}
\NormalTok{        vol }\OperatorTok{=}\NormalTok{ rng.integers(}\FloatTok{5e6}\NormalTok{, }\FloatTok{2e7}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates))}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
            \StringTok{"date"}\NormalTok{: dates,}
            \StringTok{"ticker"}\NormalTok{: t,}
            \StringTok{"open"}\NormalTok{: price }\OperatorTok{*}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.002}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates))),}
            \StringTok{"high"}\NormalTok{: price }\OperatorTok{*}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ rng.normal(}\FloatTok{0.003}\NormalTok{, }\FloatTok{0.003}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates))).clip(}\BuiltInTok{min}\OperatorTok{=}\DecValTok{1}\NormalTok{),}
            \StringTok{"low"}\NormalTok{:  price }\OperatorTok{*}\NormalTok{ (}\DecValTok{1} \OperatorTok{{-}}\NormalTok{ np.}\BuiltInTok{abs}\NormalTok{(rng.normal(}\FloatTok{0.003}\NormalTok{, }\FloatTok{0.003}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)))),}
            \StringTok{"close"}\NormalTok{: price,}
            \StringTok{"adj\_close"}\NormalTok{: price }\OperatorTok{*}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.0005}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates))),}
            \StringTok{"volume"}\NormalTok{: vol}
\NormalTok{        \})}
\NormalTok{        rows.append(df)}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ pd.concat(rows, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    Path(}\StringTok{"data/raw"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    out.to\_csv(}\StringTok{"data/raw/prices.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ [}\StringTok{"data/raw/prices.csv"}\NormalTok{]}

\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ raw\_candidates:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"No raw prices found; creating a small synthetic dataset..."}\NormalTok{)}
\NormalTok{    raw\_candidates }\OperatorTok{=}\NormalTok{ \_make\_synthetic\_prices()}

\NormalTok{raw\_candidates}
\end{Highlighting}
\end{Shaded}

\subsection{2) Optional metadata (tickers table), or create a minimal
one}\label{optional-metadata-tickers-table-or-create-a-minimal-one}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{meta\_path }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/static/tickers.csv"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ meta\_path.exists():}
\NormalTok{    meta }\OperatorTok{=}\NormalTok{ pd.read\_csv(meta\_path)}
\ControlFlowTok{else}\NormalTok{:}
    \CommentTok{\# Build a minimal metadata table from raw tickers}
\NormalTok{    tmp }\OperatorTok{=}\NormalTok{ pd.read\_csv(raw\_candidates[}\DecValTok{0}\NormalTok{])}
\NormalTok{    tickers }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(pd.unique(tmp[}\StringTok{"ticker"}\NormalTok{]))}
\NormalTok{    meta }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{"ticker"}\NormalTok{: tickers,}
                         \StringTok{"name"}\NormalTok{: tickers,}
                         \StringTok{"sector"}\NormalTok{: [}\StringTok{"Unknown"}\NormalTok{]}\OperatorTok{*}\BuiltInTok{len}\NormalTok{(tickers)\})}
\NormalTok{    Path(}\StringTok{"data/static"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    meta.to\_csv(meta\_path, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{meta.head()}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Helpers: \texttt{standardize\_columns},
\texttt{clean\_prices}, \texttt{join\_meta} (showing
\texttt{merge}/\texttt{assign}/\texttt{pipe})}{3) Helpers: standardize\_columns, clean\_prices, join\_meta (showing merge/assign/pipe)}}\label{helpers-standardize_columns-clean_prices-join_meta-showing-mergeassignpipe}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ re}

\KeywordTok{def}\NormalTok{ standardize\_columns(df: pd.DataFrame) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame:}
    \CommentTok{"""Lowercase snake\_case; repair common price column name variants."""}
    \KeywordTok{def}\NormalTok{ snake(s):}
\NormalTok{        s }\OperatorTok{=}\NormalTok{ re.sub(}\VerbatimStringTok{r"[\^{}\textbackslash{}w\textbackslash{}s]"}\NormalTok{, }\StringTok{"\_"}\NormalTok{, s)}
\NormalTok{        s }\OperatorTok{=}\NormalTok{ re.sub(}\VerbatimStringTok{r"\textbackslash{}s+"}\NormalTok{, }\StringTok{"\_"}\NormalTok{, s.strip().lower())}
\NormalTok{        s }\OperatorTok{=}\NormalTok{ re.sub(}\VerbatimStringTok{r"\_+"}\NormalTok{, }\StringTok{"\_"}\NormalTok{, s)}
        \ControlFlowTok{return}\NormalTok{ s}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    out.columns }\OperatorTok{=}\NormalTok{ [snake(c) }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ out.columns]}
    \CommentTok{\# Normalize known variants}
\NormalTok{    ren }\OperatorTok{=}\NormalTok{ \{}
        \StringTok{"adjclose"}\NormalTok{:}\StringTok{"adj\_close"}\NormalTok{, }\StringTok{"adj\_close\_"}\NormalTok{:}\StringTok{"adj\_close"}\NormalTok{,}
        \StringTok{"close\_adj"}\NormalTok{:}\StringTok{"adj\_close"}\NormalTok{, }\StringTok{"adj\_close\_close"}\NormalTok{:}\StringTok{"adj\_close"}
\NormalTok{    \}}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ out.rename(columns}\OperatorTok{=}\NormalTok{\{k:v }\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ ren.items() }\ControlFlowTok{if}\NormalTok{ k }\KeywordTok{in}\NormalTok{ out.columns\})}
    \CommentTok{\# If no adj\_close but close exists, create it}
    \ControlFlowTok{if} \StringTok{"adj\_close"} \KeywordTok{not} \KeywordTok{in}\NormalTok{ out }\KeywordTok{and} \StringTok{"close"} \KeywordTok{in}\NormalTok{ out:}
\NormalTok{        out }\OperatorTok{=}\NormalTok{ out.assign(adj\_close}\OperatorTok{=}\NormalTok{out[}\StringTok{"close"}\NormalTok{])}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ clean\_prices(df: pd.DataFrame) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame:}
    \CommentTok{"""Coerce dtypes, drop dupes, basic sanity checks; add minor derived fields."""}
\NormalTok{    cols }\OperatorTok{=}\NormalTok{ [}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"open"}\NormalTok{,}\StringTok{"high"}\NormalTok{,}\StringTok{"low"}\NormalTok{,}\StringTok{"close"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{]}
\NormalTok{    keep }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ cols }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ df.columns]}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df.loc[:, keep].copy()}

    \CommentTok{\# Parse date, coerce numerics}
\NormalTok{    out[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(out[}\StringTok{"date"}\NormalTok{], errors}\OperatorTok{=}\StringTok{"coerce"}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ [}\StringTok{"open"}\NormalTok{,}\StringTok{"high"}\NormalTok{,}\StringTok{"low"}\NormalTok{,}\StringTok{"close"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{]:}
        \ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ out: out[c] }\OperatorTok{=}\NormalTok{ pd.to\_numeric(out[c], errors}\OperatorTok{=}\StringTok{"coerce"}\NormalTok{)}
    \ControlFlowTok{if} \StringTok{"volume"} \KeywordTok{in}\NormalTok{ out: out[}\StringTok{"volume"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_numeric(out[}\StringTok{"volume"}\NormalTok{], errors}\OperatorTok{=}\StringTok{"coerce"}\NormalTok{)}

    \CommentTok{\# Drop bad rows}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ out.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{])}
    \CommentTok{\# Deduplicate by (ticker, date)}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ out.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ out.drop\_duplicates(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{], keep}\OperatorTok{=}\StringTok{"last"}\NormalTok{)}

    \CommentTok{\# Enforce dtypes}
    \ControlFlowTok{if} \StringTok{"volume"} \KeywordTok{in}\NormalTok{ out:}
\NormalTok{        out[}\StringTok{"volume"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out[}\StringTok{"volume"}\NormalTok{].}\BuiltInTok{round}\NormalTok{().astype(}\StringTok{"Int64"}\NormalTok{)  }\CommentTok{\# nullable int}
\NormalTok{        out.loc[out[}\StringTok{"volume"}\NormalTok{] }\OperatorTok{\textless{}} \DecValTok{0}\NormalTok{, }\StringTok{"volume"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.NA}
    \CommentTok{\# Use category for low{-}cardinality strings}
\NormalTok{    out[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
    \CommentTok{\# Use consistent float dtype}
    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ [}\StringTok{"open"}\NormalTok{,}\StringTok{"high"}\NormalTok{,}\StringTok{"low"}\NormalTok{,}\StringTok{"close"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{]:}
        \ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ out: out[c] }\OperatorTok{=}\NormalTok{ out[c].astype(}\StringTok{"float32"}\NormalTok{)  }\CommentTok{\# ok for teaching; change to float64 if you need more precision}

    \CommentTok{\# Quick sanity checks}
    \ControlFlowTok{assert}\NormalTok{ out[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]].duplicated().}\BuiltInTok{sum}\NormalTok{() }\OperatorTok{==} \DecValTok{0}\NormalTok{, }\StringTok{"Duplicates remain"}
    \ControlFlowTok{assert}\NormalTok{ pd.api.types.is\_datetime64\_any\_dtype(out[}\StringTok{"date"}\NormalTok{]), }\StringTok{"date not datetime"}
    \ControlFlowTok{return}\NormalTok{ out.reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\KeywordTok{def}\NormalTok{ join\_meta(prices: pd.DataFrame, meta: pd.DataFrame) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame:}
    \CommentTok{"""Left join metadata; keep minimal meta columns; set dtypes."""}
\NormalTok{    keep\_meta }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ [}\StringTok{"ticker"}\NormalTok{,}\StringTok{"name"}\NormalTok{,}\StringTok{"sector"}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ meta.columns]}
\NormalTok{    meta2 }\OperatorTok{=}\NormalTok{ meta.loc[:, keep\_meta].copy()}
    \CommentTok{\# Make strings consistent and compact}
    \ControlFlowTok{if} \StringTok{"name"} \KeywordTok{in}\NormalTok{ meta2:   meta2[}\StringTok{"name"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ meta2[}\StringTok{"name"}\NormalTok{].astype(}\StringTok{"string"}\NormalTok{)}
    \ControlFlowTok{if} \StringTok{"sector"} \KeywordTok{in}\NormalTok{ meta2: meta2[}\StringTok{"sector"}\NormalTok{] }\OperatorTok{=}\NormalTok{ meta2[}\StringTok{"sector"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ prices.merge(meta2, on}\OperatorTok{=}\StringTok{"ticker"}\NormalTok{, how}\OperatorTok{=}\StringTok{"left"}\NormalTok{, validate}\OperatorTok{=}\StringTok{"many\_to\_one"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ out}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) Read, clean, and join all raw files using
a
\textbf{pipeline}}{4) Read, clean, and join all raw files using a pipeline}}\label{read-clean-and-join-all-raw-files-using-a-pipeline}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfs }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ path }\KeywordTok{in}\NormalTok{ raw\_candidates:}
\NormalTok{    raw }\OperatorTok{=}\NormalTok{ pd.read\_csv(path)}
\NormalTok{    tidy }\OperatorTok{=}\NormalTok{ (raw}
\NormalTok{            .pipe(standardize\_columns)  }\CommentTok{\# \textless{}{-} consistent names}
\NormalTok{            .pipe(clean\_prices))        }\CommentTok{\# \textless{}{-} dtypes and sanity checks}
\NormalTok{    dfs.append(tidy)}

\NormalTok{prices }\OperatorTok{=}\NormalTok{ pd.concat(dfs, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{prices }\OperatorTok{=}\NormalTok{ prices.pipe(join\_meta, meta}\OperatorTok{=}\NormalTok{meta)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Preview:"}\NormalTok{)}
\NormalTok{display(prices.head(}\DecValTok{3}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{Info:"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(prices.info(memory\_usage}\OperatorTok{=}\StringTok{"deep"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{5) Save clean data to \textbf{Parquet}
(single file) and \textbf{partitioned by
ticker}}{5) Save clean data to Parquet (single file) and partitioned by ticker}}\label{save-clean-data-to-parquet-single-file-and-partitioned-by-ticker}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Single{-}file Parquet}
\NormalTok{single\_path }\OperatorTok{=} \StringTok{"data/processed/prices.parquet"}
\NormalTok{prices.to\_parquet(single\_path, engine}\OperatorTok{=}\StringTok{"pyarrow"}\NormalTok{, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote:"}\NormalTok{, single\_path)}

\CommentTok{\# Partitioned dataset by ticker (directory with /ticker=.../)}
\NormalTok{part\_dir }\OperatorTok{=} \StringTok{"data/processed/prices\_by\_ticker"}
\CommentTok{\# pandas to\_parquet supports partition\_cols with pyarrow engine}
\ControlFlowTok{try}\NormalTok{:}
\NormalTok{    prices.to\_parquet(part\_dir, engine}\OperatorTok{=}\StringTok{"pyarrow"}\NormalTok{, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{,}
\NormalTok{                      index}\OperatorTok{=}\VariableTok{False}\NormalTok{, partition\_cols}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{])}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote partitioned dataset:"}\NormalTok{, part\_dir)}
\ControlFlowTok{except} \PreprocessorTok{TypeError}\NormalTok{:}
    \CommentTok{\# Fallback via pyarrow dataset API}
    \ImportTok{import}\NormalTok{ pyarrow }\ImportTok{as}\NormalTok{ pa, pyarrow.parquet }\ImportTok{as}\NormalTok{ pq}
\NormalTok{    pa\_tbl }\OperatorTok{=}\NormalTok{ pa.Table.from\_pandas(prices, preserve\_index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{    pq.write\_to\_dataset(pa\_tbl, root\_path}\OperatorTok{=}\NormalTok{part\_dir, partition\_cols}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{], compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote (fallback) partitioned dataset:"}\NormalTok{, part\_dir)}
\end{Highlighting}
\end{Shaded}

\subsection{6) Read back efficiently: projection + simple
filters}\label{read-back-efficiently-projection-simple-filters}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 6a) Read a few columns from single{-}file Parquet}
\NormalTok{cols }\OperatorTok{=}\NormalTok{ [}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{]}
\NormalTok{df\_small }\OperatorTok{=}\NormalTok{ pd.read\_parquet(}\StringTok{"data/processed/prices.parquet"}\NormalTok{, columns}\OperatorTok{=}\NormalTok{cols)}
\NormalTok{df\_small.head()}

\CommentTok{\# 6b) Read one ticker from the partitioned dataset using pyarrow.dataset}
\ImportTok{import}\NormalTok{ pyarrow.dataset }\ImportTok{as}\NormalTok{ ds}
\NormalTok{dataset }\OperatorTok{=}\NormalTok{ ds.dataset(}\StringTok{"data/processed/prices\_by\_ticker"}\NormalTok{, }\BuiltInTok{format}\OperatorTok{=}\StringTok{"parquet"}\NormalTok{, partitioning}\OperatorTok{=}\StringTok{"hive"}\NormalTok{)}
\CommentTok{\# Choose a ticker present in the data}
\NormalTok{one\_ticker }\OperatorTok{=} \BuiltInTok{str}\NormalTok{(prices[}\StringTok{"ticker"}\NormalTok{].cat.categories[}\DecValTok{0}\NormalTok{])}
\NormalTok{flt }\OperatorTok{=}\NormalTok{ (ds.field(}\StringTok{"ticker"}\NormalTok{) }\OperatorTok{==}\NormalTok{ one\_ticker)}
\NormalTok{tbl }\OperatorTok{=}\NormalTok{ dataset.to\_table(}\BuiltInTok{filter}\OperatorTok{=}\NormalTok{flt, columns}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{])}
\NormalTok{df\_one }\OperatorTok{=}\NormalTok{ tbl.to\_pandas()}
\NormalTok{df\_one.head()}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{7) Persist a simple \textbf{schema record}
for
reproducibility}{7) Persist a simple schema record for reproducibility}}\label{persist-a-simple-schema-record-for-reproducibility}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ json, pathlib}
\NormalTok{schema }\OperatorTok{=}\NormalTok{ \{c: }\BuiltInTok{str}\NormalTok{(t) }\ControlFlowTok{for}\NormalTok{ c,t }\KeywordTok{in}\NormalTok{ prices.dtypes.items()\}}
\NormalTok{pathlib.Path(}\StringTok{"data/processed"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"data/processed/prices\_schema.json"}\NormalTok{,}\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
\NormalTok{    json.dump(schema, f, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote data/processed/prices\_schema.json"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min) --- points to
emphasize}\label{wrapup-10-min-points-to-emphasize}

\begin{itemize}
\tightlist
\item
  A \textbf{tidy schema} makes life easier downstream.
\item
  Prefer \textbf{\texttt{category}} for \texttt{ticker},
  \textbf{nullable ints} for \texttt{volume}.
\item
  Use \textbf{\texttt{merge}} (left join) to attach metadata; use
  \textbf{\texttt{assign}} for clear column creation; compose steps with
  \textbf{\texttt{pipe}}.
\item
  \textbf{Parquet} is compact and fast; \textbf{partition by
  \texttt{ticker}} for selective reads.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
10)}\label{homework-due-before-session-10}

\textbf{Deliverable:} \texttt{data/processed/returns.parquet} (and
optionally partitioned by ticker) containing:

\begin{itemize}
\tightlist
\item
  \texttt{date}, \texttt{ticker}
\item
  \texttt{log\_return} --- daily log return
  \(\log(\frac{\text{adj\_close}_t}{\text{adj\_close}_{t-1}})\)
\item
  \texttt{r\_1d} --- \textbf{next‑day} log return (lead of
  \texttt{log\_return})
\item
  \texttt{weekday} (0=Mon..6=Sun), \texttt{month} (1..12) --- choose
  compact dtypes
\end{itemize}

\subsection{Step‑by‑step code
(Colab‑friendly)}\label{stepbystep-code-colabfriendly}

\begin{quote}
Run in your repo root after finishing the in‑class lab.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np, pathlib}

\CommentTok{\# 1) Read the single{-}file Parquet you wrote in class}
\NormalTok{prices\_path }\OperatorTok{=} \StringTok{"data/processed/prices.parquet"}
\ControlFlowTok{assert}\NormalTok{ pathlib.Path(prices\_path).exists(), }\StringTok{"Missing processed/prices.parquet — finish the lab first."}

\NormalTok{prices }\OperatorTok{=}\NormalTok{ pd.read\_parquet(prices\_path)}
\CommentTok{\# If ticker was written as object, you can re{-}cast to category:}
\ControlFlowTok{if}\NormalTok{ prices[}\StringTok{"ticker"}\NormalTok{].dtype }\OperatorTok{!=} \StringTok{"category"}\NormalTok{:}
\NormalTok{    prices[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ prices[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}

\CommentTok{\# 2) Sort and compute returns per ticker (no leakage)}
\NormalTok{prices }\OperatorTok{=}\NormalTok{ prices.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Daily log return: log(adj\_close\_t / adj\_close\_\{t{-}1\})}
\NormalTok{prices[}\StringTok{"log\_return"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (prices.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"adj\_close"}\NormalTok{]}
\NormalTok{                        .}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ s: np.log(s }\OperatorTok{/}\NormalTok{ s.shift(}\DecValTok{1}\NormalTok{))).reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{))}

\CommentTok{\# Next{-}day return label r\_1d = lead(log\_return, 1)}
\NormalTok{prices[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (prices.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{]}
\NormalTok{                  .shift(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{))}

\CommentTok{\# 3) Calendar features}
\NormalTok{prices[}\StringTok{"weekday"}\NormalTok{] }\OperatorTok{=}\NormalTok{ prices[}\StringTok{"date"}\NormalTok{].dt.weekday.astype(}\StringTok{"int8"}\NormalTok{)  }\CommentTok{\# 0..6}
\NormalTok{prices[}\StringTok{"month"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ prices[}\StringTok{"date"}\NormalTok{].dt.month.astype(}\StringTok{"int8"}\NormalTok{)    }\CommentTok{\# 1..12}

\CommentTok{\# 4) Select output columns \& dtypes}
\NormalTok{out }\OperatorTok{=}\NormalTok{ prices[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"weekday"}\NormalTok{,}\StringTok{"month"}\NormalTok{]].copy()}
\NormalTok{out[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}

\CommentTok{\# 5) Save to Parquet}
\NormalTok{out\_path }\OperatorTok{=} \StringTok{"data/processed/returns.parquet"}
\NormalTok{out.to\_parquet(out\_path, engine}\OperatorTok{=}\StringTok{"pyarrow"}\NormalTok{, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote:"}\NormalTok{, out\_path)}

\CommentTok{\# 6) (Optional) also write a partitioned dataset by ticker}
\NormalTok{part\_dir }\OperatorTok{=} \StringTok{"data/processed/returns\_by\_ticker"}
\ControlFlowTok{try}\NormalTok{:}
\NormalTok{    out.to\_parquet(part\_dir, engine}\OperatorTok{=}\StringTok{"pyarrow"}\NormalTok{, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{,}
\NormalTok{                   index}\OperatorTok{=}\VariableTok{False}\NormalTok{, partition\_cols}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{])}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote partitioned dataset:"}\NormalTok{, part\_dir)}
\ControlFlowTok{except} \PreprocessorTok{TypeError}\NormalTok{:}
    \ImportTok{import}\NormalTok{ pyarrow }\ImportTok{as}\NormalTok{ pa, pyarrow.parquet }\ImportTok{as}\NormalTok{ pq}
\NormalTok{    pq.write\_to\_dataset(pa.Table.from\_pandas(out, preserve\_index}\OperatorTok{=}\VariableTok{False}\NormalTok{),}
\NormalTok{                        root\_path}\OperatorTok{=}\NormalTok{part\_dir, partition\_cols}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{], compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote (fallback) partitioned dataset:"}\NormalTok{, part\_dir)}
\end{Highlighting}
\end{Shaded}

\subsection{Quick self‑check (run after
saving)}\label{quick-selfcheck-run-after-saving}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{r }\OperatorTok{=}\NormalTok{ pd.read\_parquet(}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}
\ControlFlowTok{assert}\NormalTok{ \{}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"weekday"}\NormalTok{,}\StringTok{"month"}\NormalTok{\}.issubset(r.columns)}
\ControlFlowTok{assert}\NormalTok{ r[}\StringTok{"ticker"}\NormalTok{].dtype.name }\KeywordTok{in}\NormalTok{ (}\StringTok{"category"}\NormalTok{,}\StringTok{"CategoricalDtype"}\NormalTok{), }\StringTok{"ticker should be categorical"}
\BuiltInTok{print}\NormalTok{(}\StringTok{"rows:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(r), }\StringTok{"| tickers:"}\NormalTok{, r[}\StringTok{"ticker"}\NormalTok{].nunique())}
\NormalTok{r.head()}
\end{Highlighting}
\end{Shaded}

\subsection{(Optional) Extra credit}\label{optional-extra-credit}

\begin{itemize}
\tightlist
\item
  Add \textbf{\texttt{year}} (Int16) and
  \textbf{\texttt{is\_month\_end}} (BooleanDtype):
  \texttt{r{[}"year"{]}\ =\ r{[}"date"{]}.dt.year.astype("Int16")}
  \texttt{r{[}"is\_month\_end"{]}\ =\ r{[}"date"{]}.dt.is\_month\_end.astype("boolean")}
\item
  Compare file sizes: CSV vs Parquet vs Parquet (\texttt{zstd} vs
  \texttt{snappy}).
\end{itemize}

\subsection{Submission checklist
(pass/revise)}\label{submission-checklist-passrevise-2}

\begin{itemize}
\tightlist
\item
  \texttt{data/processed/returns.parquet} exists and contains the
  required columns.
\item
  \texttt{ticker} is \textbf{categorical};
  \texttt{weekday}/\texttt{month} are compact ints.
\item
  \texttt{r\_1d} is a \textbf{lead} of \texttt{log\_return} (next‑day),
  not the same‑day return.
\item
  You can read it back without errors.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor notes / gotchas to watch
for}\label{instructor-notes-gotchas-to-watch-for}

\begin{itemize}
\tightlist
\item
  \textbf{Nullable ints}: \texttt{astype("Int64")} keeps NAs; plain
  \texttt{int64} will fail if NAs exist.
\item
  \textbf{Categoricals \& partitions}: When reading partitioned Parquet,
  \texttt{ticker} may come back as \texttt{object}. Re‑cast to
  \texttt{category} after read if needed.
\item
  \textbf{Compression choice}: \texttt{zstd} gives good ratio/speed;
  \texttt{snappy} is more ubiquitous.
\item
  \textbf{Precision}: \texttt{float32} is fine for teaching; for
  production finance, consider \texttt{float64} and explicit rounding.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Optional (for your Makefile
later)}\label{optional-for-your-makefile-later}

Add quick targets:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.PHONY: prices{-}parquet returns{-}parquet}
\NormalTok{prices{-}parquet:  \#\# Clean raw prices and save processed Parquet(s)}
\NormalTok{\textbackslash{}tpython {-} \textless{}\textless{}\textquotesingle{}PY\textquotesingle{}}
\NormalTok{import pandas as pd, glob, pathlib, numpy as np, re, json}
\NormalTok{from pathlib import Path}
\NormalTok{\# (Paste the functions from the lab: standardize\_columns, clean\_prices, join\_meta)}
\NormalTok{\# Then read raw {-}\textgreater{} clean {-}\textgreater{} write parquet as in the lab}
\NormalTok{PY}

\NormalTok{returns{-}parquet: \#\# Build returns.parquet with r\_1d + calendar features}
\NormalTok{\textbackslash{}tpython {-} \textless{}\textless{}\textquotesingle{}PY\textquotesingle{}}
\NormalTok{import pandas as pd, numpy as np}
\NormalTok{p="data/processed/prices.parquet"; r=pd.read\_parquet(p).sort\_values(["ticker","date"])}
\NormalTok{r["log\_return"]=r.groupby("ticker")["adj\_close"].apply(lambda s: np.log(s/s.shift(1))).reset\_index(level=0, drop=True)}
\NormalTok{r["r\_1d"]=r.groupby("ticker")["log\_return"].shift({-}1)}
\NormalTok{r["weekday"]=r["date"].dt.weekday.astype("int8"); r["month"]=r["date"].dt.month.astype("int8")}
\NormalTok{r[["date","ticker","log\_return","r\_1d","weekday","month"]].to\_parquet("data/processed/returns.parquet", compression="zstd", index=False)}
\NormalTok{print("Wrote data/processed/returns.parquet")}
\NormalTok{PY}
\end{Highlighting}
\end{Shaded}

You now have a clean, tidy Parquet foundation the later sessions
(evaluation \& modeling) can rely on.

\bookmarksetup{startatroot}

\chapter{Rolling Windows, Resampling, and Leakage‑Safe
Features}\label{rolling-windows-resampling-and-leakagesafe-features}

Fantastic---thanks for pasting the full course plan. Below are
\textbf{three complete 75‑minute lecture packages} for \textbf{Sessions
10, 11, and 12}, each with: a timed agenda, slide talking points, a
\textbf{Colab‑friendly in‑class lab with copy‑paste code}, and
\textbf{homework with copy‑paste code}. They assume you completed
Session 9 and have \texttt{data/processed/prices.parquet} and
\texttt{data/processed/returns.parquet}. Every lab includes fallbacks so
you can run them even if files are missing.

\begin{quote}
\textbf{Educational use only --- not trading advice.} Python‑only. Colab
+ Drive assumed. If you don't already have the repo and folders used
below, the first cells create them.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\bookmarksetup{startatroot}

\chapter{\texorpdfstring{\textbf{Session 10 --- Rolling Windows,
Resampling, and Leakage‑Safe Features (75
min)}}{Session 10 --- Rolling Windows, Resampling, and Leakage‑Safe Features (75 min)}}\label{session-10-rolling-windows-resampling-and-leakagesafe-features-75-min}

\subsection{Learning goals}\label{learning-goals-9}

By the end of class students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use \texttt{groupby(\textquotesingle{}ticker\textquotesingle{})} with
  \texttt{shift}, \texttt{rolling}, \texttt{expanding}, and \texttt{ewm}
  to engineer features \textbf{without leakage}.
\item
  Resample safely (daily → weekly/monthly) and understand how to
  aggregate OHLC + volume.
\item
  Produce a tidy \texttt{features\_v1.parquet} with sensible dtypes.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-7}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: leakage‑free features; lags vs rolling;
  resampling patterns
\item
  \textbf{(10 min)} Slides: common pitfalls (min\_periods, alignment,
  mixed frequencies)
\item
  \textbf{(35 min)} \textbf{In‑class lab}: load returns → build features
  → (optional) weekly aggregates → write \texttt{features\_v1.parquet}
\item
  \textbf{(10 min)} Wrap‑up + homework brief
\item
  \textbf{(10 min)} Buffer
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slide talking points}\label{slide-talking-points}

\textbf{Feature timing = everything}

\begin{itemize}
\tightlist
\item
  Predict \(r_{t+1}\) using info up to and including \textbf{time t}.
\item
  \textbf{Rule:} compute any rolling stat at \(t\) from data \(\le t\),
  then \textbf{shift by 1} if that stat includes the current target
  variable.
\end{itemize}

\textbf{Core pandas patterns}

\begin{itemize}
\tightlist
\item
  \textbf{Lags:} \texttt{s.shift(k)} (past), never negative shifts.
\item
  \textbf{Rolling:} \texttt{s.rolling(W,\ min\_periods=W).agg(...)} and
  then \textbf{no extra shift} if the rolling window ends at \(t\).
\item
  \textbf{Expanding:} long‑memory features (e.g., expanding mean).
\item
  \textbf{EWM:} \texttt{s.ewm(span=W,\ adjust=False).mean()} for decayed
  memory.
\end{itemize}

\textbf{Resampling safely}

\begin{itemize}
\item
  Use
  \texttt{groupby(\textquotesingle{}ticker\textquotesingle{}).resample(\textquotesingle{}W-FRI\textquotesingle{},\ on=\textquotesingle{}date\textquotesingle{})}
  then aggregate:

  \begin{itemize}
  \tightlist
  \item
    OHLC: \texttt{first/open}, \texttt{max/high}, \texttt{min/low},
    \texttt{last/adj\_close}
  \item
    Volume: \texttt{sum}
  \item
    Returns: compound via \texttt{np.log(prod(1+r))} or sum of log
    returns.
  \end{itemize}
\end{itemize}

\textbf{Dtypes}

\begin{itemize}
\tightlist
\item
  \texttt{ticker} = \texttt{category}; calendar ints \texttt{int8};
  features \texttt{float32} (fine for class).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (Colab‑friendly)}\label{inclass-lab-colabfriendly}

\begin{quote}
Run each block as its own cell. Adjust \texttt{REPO\_NAME} as needed.
\end{quote}

\subsection{0) Setup}\label{setup}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}   \CommentTok{\# \textless{}{-} change if needed}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/raw"}\NormalTok{,}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"reports"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}
\end{Highlighting}
\end{Shaded}

\subsection{1) Load inputs or build small
fallbacks}\label{load-inputs-or-build-small-fallbacks}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}

\CommentTok{\# Fallback synthetic if missing}
\KeywordTok{def}\NormalTok{ make\_synth\_prices():}
\NormalTok{    dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{300}\NormalTok{)}
\NormalTok{    frames}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ tkr }\KeywordTok{in}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{]:}
\NormalTok{        base }\OperatorTok{=} \DecValTok{100} \OperatorTok{+}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)).cumsum()}
\NormalTok{        d }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
            \StringTok{"date"}\NormalTok{: dates, }\StringTok{"ticker"}\NormalTok{: tkr,}
            \StringTok{"adj\_close"}\NormalTok{: np.maximum(base, }\FloatTok{1.0}\NormalTok{).astype(}\StringTok{"float32"}\NormalTok{),}
            \StringTok{"volume"}\NormalTok{: rng.integers(}\FloatTok{1e6}\NormalTok{, }\FloatTok{5e6}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)).astype(}\StringTok{"int64"}\NormalTok{)}
\NormalTok{        \})}
\NormalTok{        frames.append(d)}
\NormalTok{    prices }\OperatorTok{=}\NormalTok{ pd.concat(frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    prices[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ prices[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{    prices.to\_parquet(}\StringTok{"data/processed/prices.parquet"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ prices}

\NormalTok{ppath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/prices.parquet"}\NormalTok{)}
\NormalTok{rpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}

\ControlFlowTok{if}\NormalTok{ ppath.exists():}
\NormalTok{    prices }\OperatorTok{=}\NormalTok{ pd.read\_parquet(ppath)}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    prices }\OperatorTok{=}\NormalTok{ make\_synth\_prices()}

\CommentTok{\# Build returns if missing (from Session 9 logic)}
\ControlFlowTok{if}\NormalTok{ rpath.exists():}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ pd.read\_parquet(rpath)}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ prices.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).copy()}
\NormalTok{    df[}\StringTok{"log\_return"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"adj\_close"}\NormalTok{]}
\NormalTok{                        .}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ s: np.log(s}\OperatorTok{/}\NormalTok{s.shift(}\DecValTok{1}\NormalTok{))).reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{))}
\NormalTok{    df[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].shift(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{    df[}\StringTok{"weekday"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.weekday.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{    df[}\StringTok{"month"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.month.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ df[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"weekday"}\NormalTok{,}\StringTok{"month"}\NormalTok{]].copy()}
\NormalTok{    returns[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ returns[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{    returns.to\_parquet(}\StringTok{"data/processed/returns.parquet"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\NormalTok{prices.head(}\DecValTok{3}\NormalTok{), returns.head(}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{2) Rolling, lag, expanding, ewm features (no
leakage)}\label{rolling-lag-expanding-ewm-features-no-leakage}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ build\_features(ret: pd.DataFrame, windows}\OperatorTok{=}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{), add\_rsi}\OperatorTok{=}\VariableTok{True}\NormalTok{):}
\NormalTok{    g }\OperatorTok{=}\NormalTok{ ret.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).groupby(}\StringTok{"ticker"}\NormalTok{, group\_keys}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ ret.copy()}

    \CommentTok{\# Lags of log\_return (past info)}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]:}
\NormalTok{        out[}\SpecialStringTok{f"lag}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].shift(k)}

    \CommentTok{\# Rolling mean/std and z{-}score of returns using past W days **including today**,}
    \CommentTok{\# which is fine because target is r\_\{t+1\}. No extra shift needed.}
    \ControlFlowTok{for}\NormalTok{ W }\KeywordTok{in}\NormalTok{ windows:}
\NormalTok{        rm }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].rolling(W, min\_periods}\OperatorTok{=}\NormalTok{W).mean()}
\NormalTok{        rsd}\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].rolling(W, min\_periods}\OperatorTok{=}\NormalTok{W).std()}
\NormalTok{        out[}\SpecialStringTok{f"roll\_mean\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{=}\NormalTok{ rm.reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        out[}\SpecialStringTok{f"roll\_std\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ rsd.reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        out[}\SpecialStringTok{f"zscore\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{]    }\OperatorTok{=}\NormalTok{ (out[}\StringTok{"log\_return"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ out[}\SpecialStringTok{f"roll\_mean\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{]) }\OperatorTok{/}\NormalTok{ (out[}\SpecialStringTok{f"roll\_std\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{+} \FloatTok{1e{-}8}\NormalTok{)}

    \CommentTok{\# Expanding stats (from start to t): long{-}memory}
\NormalTok{    out[}\StringTok{"exp\_mean"}\NormalTok{] }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].expanding(min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).mean().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    out[}\StringTok{"exp\_std"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].expanding(min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

    \CommentTok{\# Exponential weighted (decayed memory)}
    \ControlFlowTok{for}\NormalTok{ W }\KeywordTok{in}\NormalTok{ [}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{]:}
\NormalTok{        out[}\SpecialStringTok{f"ewm\_mean\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ s: s.ewm(span}\OperatorTok{=}\NormalTok{W, adjust}\OperatorTok{=}\VariableTok{False}\NormalTok{).mean())}
\NormalTok{        out[}\SpecialStringTok{f"ewm\_std\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ s: s.ewm(span}\OperatorTok{=}\NormalTok{W, adjust}\OperatorTok{=}\VariableTok{False}\NormalTok{).std())}

    \CommentTok{\# Optional RSI(14) using returns sign proxy (toy version)}
    \ControlFlowTok{if}\NormalTok{ add\_rsi:}
        \KeywordTok{def}\NormalTok{ rsi14(s):}
\NormalTok{            delta }\OperatorTok{=}\NormalTok{ s.diff()}
\NormalTok{            up }\OperatorTok{=}\NormalTok{ delta.clip(lower}\OperatorTok{=}\DecValTok{0}\NormalTok{).ewm(alpha}\OperatorTok{=}\DecValTok{1}\OperatorTok{/}\DecValTok{14}\NormalTok{, adjust}\OperatorTok{=}\VariableTok{False}\NormalTok{).mean()}
\NormalTok{            dn }\OperatorTok{=}\NormalTok{ (}\OperatorTok{{-}}\NormalTok{delta.clip(upper}\OperatorTok{=}\DecValTok{0}\NormalTok{)).ewm(alpha}\OperatorTok{=}\DecValTok{1}\OperatorTok{/}\DecValTok{14}\NormalTok{, adjust}\OperatorTok{=}\VariableTok{False}\NormalTok{).mean()}
\NormalTok{            rs }\OperatorTok{=}\NormalTok{ up }\OperatorTok{/}\NormalTok{ (dn }\OperatorTok{+} \FloatTok{1e{-}12}\NormalTok{)}
            \ControlFlowTok{return} \DecValTok{100} \OperatorTok{{-}}\NormalTok{ (}\DecValTok{100} \OperatorTok{/}\NormalTok{ (}\DecValTok{1} \OperatorTok{+}\NormalTok{ rs))}
\NormalTok{        out[}\StringTok{"rsi\_14"}\NormalTok{] }\OperatorTok{=}\NormalTok{ g[}\StringTok{"adj\_close"}\NormalTok{].}\BuiltInTok{apply}\NormalTok{(rsi14) }\ControlFlowTok{if} \StringTok{"adj\_close"} \KeywordTok{in}\NormalTok{ out }\ControlFlowTok{else}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].}\BuiltInTok{apply}\NormalTok{(rsi14)}

    \CommentTok{\# Cast dtypes}
    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ out.columns:}
        \ControlFlowTok{if}\NormalTok{ c }\KeywordTok{not} \KeywordTok{in}\NormalTok{ [}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"weekday"}\NormalTok{,}\StringTok{"month"}\NormalTok{] }\KeywordTok{and}\NormalTok{ pd.api.types.is\_float\_dtype(out[c]):}
\NormalTok{            out[c] }\OperatorTok{=}\NormalTok{ out[c].astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{    out[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ out}

\CommentTok{\# Merge adj\_close and volume into returns (if not already)}
\NormalTok{ret2 }\OperatorTok{=}\NormalTok{ returns.merge(prices[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{]], on}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{], how}\OperatorTok{=}\StringTok{"left"}\NormalTok{)}
\NormalTok{features }\OperatorTok{=}\NormalTok{ build\_features(ret2, windows}\OperatorTok{=}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{20}\NormalTok{), add\_rsi}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{features.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{3) (Optional) Weekly resampling demo (OHLCV +
returns)}\label{optional-weekly-resampling-demo-ohlcv-returns}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Safe weekly resample per ticker, aggregating OHLCV and log returns}
\KeywordTok{def}\NormalTok{ weekly\_ohlcv(df):}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).copy()}
\NormalTok{    df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{])}
\NormalTok{    res}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        wk }\OperatorTok{=}\NormalTok{ (g.resample(}\StringTok{"W{-}FRI"}\NormalTok{, on}\OperatorTok{=}\StringTok{"date"}\NormalTok{)}
\NormalTok{              .agg(\{}\StringTok{"adj\_close"}\NormalTok{:}\StringTok{"last"}\NormalTok{,}\StringTok{"volume"}\NormalTok{:}\StringTok{"sum"}\NormalTok{\}).dropna().reset\_index())}
\NormalTok{        wk[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ tkr}
        \CommentTok{\# Weekly log return = log(adj\_close\_t / adj\_close\_\{t{-}1\})}
\NormalTok{        wk }\OperatorTok{=}\NormalTok{ wk.sort\_values(}\StringTok{"date"}\NormalTok{)}
\NormalTok{        wk[}\StringTok{"wk\_log\_return"}\NormalTok{] }\OperatorTok{=}\NormalTok{ np.log(wk[}\StringTok{"adj\_close"}\NormalTok{]}\OperatorTok{/}\NormalTok{wk[}\StringTok{"adj\_close"}\NormalTok{].shift(}\DecValTok{1}\NormalTok{))}
\NormalTok{        res.append(wk)}
    \ControlFlowTok{return}\NormalTok{ pd.concat(res, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{weekly }\OperatorTok{=}\NormalTok{ weekly\_ohlcv(prices[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{]])}
\NormalTok{weekly.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) Save \texttt{features\_v1.parquet} (+
optional partition by
ticker)}{4) Save features\_v1.parquet (+ optional partition by ticker)}}\label{save-features_v1.parquet-optional-partition-by-ticker}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Select a compact set to start with}
\NormalTok{keep }\OperatorTok{=}\NormalTok{ [}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"weekday"}\NormalTok{,}\StringTok{"month"}\NormalTok{,}
        \StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{,}
        \StringTok{"roll\_mean\_5"}\NormalTok{,}\StringTok{"roll\_std\_5"}\NormalTok{,}\StringTok{"zscore\_5"}\NormalTok{,}
        \StringTok{"roll\_mean\_10"}\NormalTok{,}\StringTok{"roll\_std\_10"}\NormalTok{,}\StringTok{"zscore\_10"}\NormalTok{,}
        \StringTok{"roll\_mean\_20"}\NormalTok{,}\StringTok{"roll\_std\_20"}\NormalTok{,}\StringTok{"zscore\_20"}\NormalTok{,}
        \StringTok{"ewm\_mean\_10"}\NormalTok{,}\StringTok{"ewm\_std\_10"}\NormalTok{,}\StringTok{"ewm\_mean\_20"}\NormalTok{,}\StringTok{"ewm\_std\_20"}\NormalTok{,}
        \StringTok{"exp\_mean"}\NormalTok{,}\StringTok{"exp\_std"}\NormalTok{,}\StringTok{"rsi\_14"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{]}

\NormalTok{keep }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ keep }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ features.columns]}
\NormalTok{fv1 }\OperatorTok{=}\NormalTok{ features.loc[:, keep].dropna().sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{fv1[}\StringTok{"weekday"}\NormalTok{] }\OperatorTok{=}\NormalTok{ fv1[}\StringTok{"weekday"}\NormalTok{].astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{fv1[}\StringTok{"month"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ fv1[}\StringTok{"month"}\NormalTok{].astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{fv1[}\StringTok{"ticker"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ fv1[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}

\NormalTok{fv1\_path }\OperatorTok{=} \StringTok{"data/processed/features\_v1.parquet"}
\NormalTok{fv1.to\_parquet(fv1\_path, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote:"}\NormalTok{, fv1\_path, }\StringTok{"| rows:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(fv1), }\StringTok{"| cols:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(fv1.columns))}

\CommentTok{\# Optional partition}
\NormalTok{part\_dir }\OperatorTok{=} \StringTok{"data/processed/features\_v1\_by\_ticker"}
\ControlFlowTok{try}\NormalTok{:}
\NormalTok{    fv1.to\_parquet(part\_dir, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{, engine}\OperatorTok{=}\StringTok{"pyarrow"}\NormalTok{, partition\_cols}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{])}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote partitioned:"}\NormalTok{, part\_dir)}
\ControlFlowTok{except} \PreprocessorTok{TypeError}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Partition writing skipped (engine missing)."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (what to emphasize)}\label{wrapup-what-to-emphasize}

\begin{itemize}
\tightlist
\item
  For \textbf{next‑day} targets \(r_{t+1}\), rolling stats up to
  \textbf{t} are fine; never use future rows.
\item
  Be explicit about \textbf{\texttt{min\_periods}} to avoid unstable
  early rows.
\item
  Keep features small and typed; document your cookbook in the repo.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
11)}\label{homework-due-before-session-11}

\textbf{Goal:} Add an \textbf{automated leakage check} and re‑run
feature build.

\subsection{\texorpdfstring{A. Script:
\texttt{scripts/build\_features\_v1.py}}{A. Script: scripts/build\_features\_v1.py}}\label{a.-script-scriptsbuild_features_v1.py}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/usr/bin/env python}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd, pathlib}
\KeywordTok{def}\NormalTok{ build():}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ pathlib.Path(}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ p.exists(): }\ControlFlowTok{raise} \PreprocessorTok{SystemExit}\NormalTok{(}\StringTok{"Missing returns.parquet — finish Session 9."}\NormalTok{)}
\NormalTok{    prices }\OperatorTok{=}\NormalTok{ pd.read\_parquet(}\StringTok{"data/processed/prices.parquet"}\NormalTok{)}
\NormalTok{    ret }\OperatorTok{=}\NormalTok{ pd.read\_parquet(p)}
\NormalTok{    ret2 }\OperatorTok{=}\NormalTok{ ret.merge(prices[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{]], on}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{], how}\OperatorTok{=}\StringTok{"left"}\NormalTok{)}
    \CommentTok{\# (Paste the build\_features() from class)}
    \CommentTok{\# ...}
\NormalTok{    fv1 }\OperatorTok{=}\NormalTok{ build\_features(ret2)}
\NormalTok{    keep }\OperatorTok{=}\NormalTok{ [}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"weekday"}\NormalTok{,}\StringTok{"month"}\NormalTok{,}
            \StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{,}\StringTok{"roll\_mean\_20"}\NormalTok{,}\StringTok{"roll\_std\_20"}\NormalTok{,}\StringTok{"zscore\_20"}\NormalTok{,}
            \StringTok{"ewm\_mean\_20"}\NormalTok{,}\StringTok{"ewm\_std\_20"}\NormalTok{,}\StringTok{"exp\_mean"}\NormalTok{,}\StringTok{"exp\_std"}\NormalTok{,}\StringTok{"adj\_close"}\NormalTok{,}\StringTok{"volume"}\NormalTok{]}
\NormalTok{    keep }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ keep }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ fv1.columns]}
\NormalTok{    fv1 }\OperatorTok{=}\NormalTok{ fv1[keep].dropna().sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
\NormalTok{    fv1.to\_parquet(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote data/processed/features\_v1.parquet"}\NormalTok{, fv1.shape)}
\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    build()}
\end{Highlighting}
\end{Shaded}

Make executable:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/build\_features\_v1.py}
\ExtensionTok{python}\NormalTok{ scripts/build\_features\_v1.py}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{B. Test:
\texttt{tests/test\_no\_lookahead.py}}{B. Test: tests/test\_no\_lookahead.py}}\label{b.-test-teststest_no_lookahead.py}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}

\KeywordTok{def}\NormalTok{ test\_features\_no\_lookahead():}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
    \CommentTok{\# For each ticker, recompute roll\_mean\_20 with an independent method and compare}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        s }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{]}
\NormalTok{        rm }\OperatorTok{=}\NormalTok{ s.rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).mean()}
        \CommentTok{\# Our feature should equal this rolling mean (within tol)}
        \ControlFlowTok{if} \StringTok{"roll\_mean\_20"} \KeywordTok{in}\NormalTok{ g:}
            \ControlFlowTok{assert}\NormalTok{ np.allclose(g[}\StringTok{"roll\_mean\_20"}\NormalTok{].values, rm.values, equal\_nan}\OperatorTok{=}\VariableTok{True}\NormalTok{, atol}\OperatorTok{=}\FloatTok{1e{-}7}\NormalTok{)}
        \CommentTok{\# r\_1d must be the **lead** of log\_return}
        \ControlFlowTok{assert}\NormalTok{ g[}\StringTok{"r\_1d"}\NormalTok{].shift(}\DecValTok{1}\NormalTok{).iloc[}\DecValTok{21}\NormalTok{:].equals(g[}\StringTok{"log\_return"}\NormalTok{].iloc[}\DecValTok{21}\NormalTok{:])}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\bookmarksetup{startatroot}

\chapter{\texorpdfstring{Session 11 --- APIs with \texttt{requests}:
Secrets, Retries, and
Caching}{Session 11 --- APIs with requests: Secrets, Retries, and Caching}}\label{session-11-apis-with-requests-secrets-retries-and-caching}

\bookmarksetup{startatroot}

\chapter{\texorpdfstring{\textbf{Session 11 --- APIs with
\texttt{requests}: Secrets, Retries, and Caching (75
min)}}{Session 11 --- APIs with requests: Secrets, Retries, and Caching (75 min)}}\label{session-11-apis-with-requests-secrets-retries-and-caching-75-min}

\subsection{Learning goals}\label{learning-goals-10}

Students will be able to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Call a REST API with \texttt{requests} + robust retry/backoff.
\item
  Manage secrets with \texttt{.env} and \textbf{never} commit keys.
\item
  Cache responses (file or SQLite) and align external series by date.
\item
  Save enriched data to SQLite and Parquet.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-8}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: anatomy of a GET; query params; JSON; status
  codes
\item
  \textbf{(10 min)} Slides: secrets (\texttt{python-dotenv}), file
  layout (\texttt{.env}, \texttt{.env.template}), \texttt{.gitignore}
\item
  \textbf{(10 min)} Slides: retries and caching patterns; idempotent
  design
\item
  \textbf{(35 min)} \textbf{In‑class lab}: fetch \textbf{FRED VIX
  (VIXCLS)} + optional \textbf{FEDFUNDS} → cache → store in SQLite →
  join to daily features
\item
  \textbf{(10 min)} Wrap‑up + homework
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slide talking points}\label{slide-talking-points-1}

\textbf{Requests pattern}

\begin{itemize}
\tightlist
\item
  \texttt{Session} + \texttt{HTTPAdapter} + \texttt{Retry} → robust.
\item
  Validate: status code, content type; guard against partial data.
\end{itemize}

\textbf{Secrets}

\begin{itemize}
\tightlist
\item
  \texttt{.env.template} committed; \texttt{.env} untracked.
\item
  Load with \texttt{dotenv.load\_dotenv()}. Access via
  \texttt{os.getenv("FRED\_API\_KEY")}.
\end{itemize}

\textbf{Caching}

\begin{itemize}
\tightlist
\item
  \textbf{File cache}: key by URL+params hash.
\item
  \textbf{DB cache}:
  \texttt{cache\ (key\ TEXT\ PRIMARY\ KEY,\ value\ BLOB,\ fetched\_at)}.
\end{itemize}

\textbf{Alignment}

\begin{itemize}
\tightlist
\item
  After download, \textbf{normalize to \texttt{date}} and join on date.
\item
  Store to SQLite table with a composite key
  \texttt{(series\_id,\ date)}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab}\label{inclass-lab}

\subsection{0) Setup, folders, and
templates}\label{setup-folders-and-templates}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, json, hashlib, time, sqlite3, pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{".cache/api"}\NormalTok{,}\StringTok{"data"}\NormalTok{,}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"data/raw"}\NormalTok{]:}
\NormalTok{    Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# .env template for secrets}
\NormalTok{Path(}\StringTok{".env.template"}\NormalTok{).write\_text(}\StringTok{"FRED\_API\_KEY=}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\# Ensure .gitignore has secrets \& cache}
\NormalTok{gi }\OperatorTok{=}\NormalTok{ Path(}\StringTok{".gitignore"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ gi.exists():}
\NormalTok{    gi\_txt }\OperatorTok{=}\NormalTok{ gi.read\_text()}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    gi\_txt }\OperatorTok{=} \StringTok{""}
\ControlFlowTok{for}\NormalTok{ line }\KeywordTok{in}\NormalTok{ [}\StringTok{".env"}\NormalTok{, }\StringTok{".cache/"}\NormalTok{, }\StringTok{"\_\_pycache\_\_/"}\NormalTok{]:}
    \ControlFlowTok{if}\NormalTok{ line }\KeywordTok{not} \KeywordTok{in}\NormalTok{ gi\_txt:}
\NormalTok{        gi\_txt }\OperatorTok{+=}\NormalTok{ (}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"} \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ gi\_txt.endswith(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{) }\ControlFlowTok{else} \StringTok{""}\NormalTok{) }\OperatorTok{+}\NormalTok{ line}
\NormalTok{gi.write\_text(gi\_txt)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Ready. Fill your FRED key in a local .env (do not commit)."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{1) Robust GET with retry + file
cache}\label{robust-get-with-retry-file-cache}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ os, requests}
\ImportTok{from}\NormalTok{ urllib3.util.retry }\ImportTok{import}\NormalTok{ Retry}
\ImportTok{from}\NormalTok{ requests.adapters }\ImportTok{import}\NormalTok{ HTTPAdapter}
\ImportTok{from}\NormalTok{ dotenv }\ImportTok{import}\NormalTok{ load\_dotenv}

\NormalTok{load\_dotenv()  }\CommentTok{\# reads .env if present}

\KeywordTok{def}\NormalTok{ session\_with\_retry(total}\OperatorTok{=}\DecValTok{3}\NormalTok{, backoff}\OperatorTok{=}\FloatTok{0.5}\NormalTok{):}
\NormalTok{    s }\OperatorTok{=}\NormalTok{ requests.Session()}
\NormalTok{    retry }\OperatorTok{=}\NormalTok{ Retry(total}\OperatorTok{=}\NormalTok{total, backoff\_factor}\OperatorTok{=}\NormalTok{backoff, status\_forcelist}\OperatorTok{=}\NormalTok{[}\DecValTok{429}\NormalTok{,}\DecValTok{500}\NormalTok{,}\DecValTok{502}\NormalTok{,}\DecValTok{503}\NormalTok{,}\DecValTok{504}\NormalTok{])}
\NormalTok{    s.mount(}\StringTok{"https://"}\NormalTok{, HTTPAdapter(max\_retries}\OperatorTok{=}\NormalTok{retry))}
\NormalTok{    s.headers.update(\{}\StringTok{"User{-}Agent"}\NormalTok{: }\StringTok{"dspt{-}class/1.0 (+edu)"}\NormalTok{\})}
    \ControlFlowTok{return}\NormalTok{ s}

\KeywordTok{def}\NormalTok{ cache\_key(url, params):}
\NormalTok{    raw }\OperatorTok{=}\NormalTok{ url }\OperatorTok{+} \StringTok{"?"} \OperatorTok{+} \StringTok{"\&"}\NormalTok{.join(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{=}\SpecialCharTok{\{}\NormalTok{params[k]}\SpecialCharTok{\}}\SpecialStringTok{"} \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{sorted}\NormalTok{(params))}
    \ControlFlowTok{return}\NormalTok{ hashlib.sha1(raw.encode()).hexdigest()}

\KeywordTok{def}\NormalTok{ cached\_get(url, params, ttl\_hours}\OperatorTok{=}\DecValTok{24}\NormalTok{):}
\NormalTok{    key }\OperatorTok{=}\NormalTok{ cache\_key(url, params)}
\NormalTok{    path }\OperatorTok{=}\NormalTok{ Path(}\SpecialStringTok{f".cache/api/}\SpecialCharTok{\{}\NormalTok{key}\SpecialCharTok{\}}\SpecialStringTok{.json"}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ path.exists() }\KeywordTok{and}\NormalTok{ (time.time() }\OperatorTok{{-}}\NormalTok{ path.stat().st\_mtime }\OperatorTok{\textless{}}\NormalTok{ ttl\_hours}\OperatorTok{*}\DecValTok{3600}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ json.loads(path.read\_text())}
\NormalTok{    s }\OperatorTok{=}\NormalTok{ session\_with\_retry()}
\NormalTok{    r }\OperatorTok{=}\NormalTok{ s.get(url, params}\OperatorTok{=}\NormalTok{params, timeout}\OperatorTok{=}\DecValTok{20}\NormalTok{)}
\NormalTok{    r.raise\_for\_status()}
\NormalTok{    data }\OperatorTok{=}\NormalTok{ r.json()}
\NormalTok{    path.write\_text(json.dumps(data))}
    \ControlFlowTok{return}\NormalTok{ data}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Fetch \textbf{VIX (VIXCLS)} and
\textbf{FEDFUNDS} from FRED; store to
SQLite}{2) Fetch VIX (VIXCLS) and FEDFUNDS from FRED; store to SQLite}}\label{fetch-vix-vixcls-and-fedfunds-from-fred-store-to-sqlite}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{API\_KEY }\OperatorTok{=}\NormalTok{ os.getenv(}\StringTok{"FRED\_API\_KEY"}\NormalTok{, }\StringTok{""}\NormalTok{).strip()}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ API\_KEY:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"WARNING: No FRED\_API\_KEY in .env; continuing with unauthenticated request may fail on FRED. Add your key to use in class."}\NormalTok{)}

\NormalTok{FRED\_SERIES\_URL }\OperatorTok{=} \StringTok{"https://api.stlouisfed.org/fred/series/observations"}

\KeywordTok{def}\NormalTok{ fred\_series(series\_id, start}\OperatorTok{=}\StringTok{"2010{-}01{-}01"}\NormalTok{, end}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ \{}\StringTok{"series\_id"}\NormalTok{:series\_id, }\StringTok{"api\_key"}\NormalTok{:API\_KEY, }\StringTok{"file\_type"}\NormalTok{:}\StringTok{"json"}\NormalTok{,}
         \StringTok{"observation\_start"}\NormalTok{:start\}}
    \ControlFlowTok{if}\NormalTok{ end }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{: p[}\StringTok{"observation\_end"}\NormalTok{]}\OperatorTok{=}\NormalTok{end}
\NormalTok{    data }\OperatorTok{=}\NormalTok{ cached\_get(FRED\_SERIES\_URL, p, ttl\_hours}\OperatorTok{=}\DecValTok{24}\NormalTok{)}
\NormalTok{    obs }\OperatorTok{=}\NormalTok{ data.get(}\StringTok{"observations"}\NormalTok{, [])}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.DataFrame(obs)[[}\StringTok{"date"}\NormalTok{,}\StringTok{"value"}\NormalTok{]]}
\NormalTok{    df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{])}
\NormalTok{    df[}\StringTok{"value"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_numeric(df[}\StringTok{"value"}\NormalTok{], errors}\OperatorTok{=}\StringTok{"coerce"}\NormalTok{)}
\NormalTok{    df[}\StringTok{"series\_id"}\NormalTok{] }\OperatorTok{=}\NormalTok{ series\_id}
    \ControlFlowTok{return}\NormalTok{ df.dropna()}

\NormalTok{vix }\OperatorTok{=}\NormalTok{ fred\_series(}\StringTok{"VIXCLS"}\NormalTok{, start}\OperatorTok{=}\StringTok{"2015{-}01{-}01"}\NormalTok{)       }\CommentTok{\# CBOE VIX}
\NormalTok{fed }\OperatorTok{=}\NormalTok{ fred\_series(}\StringTok{"FEDFUNDS"}\NormalTok{, start}\OperatorTok{=}\StringTok{"2015{-}01{-}01"}\NormalTok{)     }\CommentTok{\# Effective Fed Funds}

\CommentTok{\# Write to SQLite}
\NormalTok{db }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(}\StringTok{"data/prices.db"}\NormalTok{)}
\NormalTok{db.execute(}\StringTok{"""CREATE TABLE IF NOT EXISTS macro\_series(}
\StringTok{    series\_id TEXT NOT NULL, date TEXT NOT NULL, value REAL NOT NULL,}
\StringTok{    PRIMARY KEY(series\_id, date))"""}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ df }\KeywordTok{in}\NormalTok{ [vix, fed]:}
\NormalTok{    df.to\_sql(}\StringTok{"macro\_series"}\NormalTok{, db, if\_exists}\OperatorTok{=}\StringTok{"append"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{db.commit()}\OperatorTok{;}\NormalTok{ db.close()}

\NormalTok{vix.head(), fed.head()}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Join macro series to daily
returns/features by
\texttt{date}}{3) Join macro series to daily returns/features by date}}\label{join-macro-series-to-daily-returnsfeatures-by-date}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Load features (build if missing)}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{fvpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ fvpath.exists():}
    \ControlFlowTok{raise} \PreprocessorTok{SystemExit}\NormalTok{(}\StringTok{"Missing features\_v1.parquet — run Session 10 lab or homework."}\NormalTok{)}

\NormalTok{fv1 }\OperatorTok{=}\NormalTok{ pd.read\_parquet(fvpath).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
\NormalTok{macro }\OperatorTok{=}\NormalTok{ pd.concat([vix.rename(columns}\OperatorTok{=}\NormalTok{\{}\StringTok{"value"}\NormalTok{:}\StringTok{"vix"}\NormalTok{\}).drop(columns}\OperatorTok{=}\StringTok{"series\_id"}\NormalTok{),}
\NormalTok{                   fed.rename(columns}\OperatorTok{=}\NormalTok{\{}\StringTok{"value"}\NormalTok{:}\StringTok{"fedfunds"}\NormalTok{\}).drop(columns}\OperatorTok{=}\StringTok{"series\_id"}\NormalTok{)], axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\CommentTok{\# Pivot macro wide}
\NormalTok{macro\_wide }\OperatorTok{=}\NormalTok{ (pd.concat([}
\NormalTok{    vix.assign(var}\OperatorTok{=}\StringTok{"vix"}\NormalTok{).rename(columns}\OperatorTok{=}\NormalTok{\{}\StringTok{"value"}\NormalTok{:}\StringTok{"val"}\NormalTok{\}),}
\NormalTok{    fed.assign(var}\OperatorTok{=}\StringTok{"fedfunds"}\NormalTok{).rename(columns}\OperatorTok{=}\NormalTok{\{}\StringTok{"value"}\NormalTok{:}\StringTok{"val"}\NormalTok{\})}
\NormalTok{]) .pivot\_table(index}\OperatorTok{=}\StringTok{"date"}\NormalTok{, columns}\OperatorTok{=}\StringTok{"var"}\NormalTok{, values}\OperatorTok{=}\StringTok{"val"}\NormalTok{).reset\_index())}

\NormalTok{enriched }\OperatorTok{=}\NormalTok{ fv1.merge(macro\_wide, on}\OperatorTok{=}\StringTok{"date"}\NormalTok{, how}\OperatorTok{=}\StringTok{"left"}\NormalTok{)}
\NormalTok{enriched[[}\StringTok{"vix"}\NormalTok{,}\StringTok{"fedfunds"}\NormalTok{]] }\OperatorTok{=}\NormalTok{ enriched[[}\StringTok{"vix"}\NormalTok{,}\StringTok{"fedfunds"}\NormalTok{]].astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{enriched.to\_parquet(}\StringTok{"data/processed/features\_v1\_ext.parquet"}\NormalTok{, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote data/processed/features\_v1\_ext.parquet"}\NormalTok{, enriched.shape)}
\NormalTok{enriched.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up}\label{wrapup}

\begin{itemize}
\tightlist
\item
  You built a \textbf{retrying, cached} API client, stored macro data in
  \textbf{SQLite}, and aligned it by date.
\item
  Secrets live in \textbf{\texttt{.env}} (never committed).
\item
  Enriched features are saved for modeling later.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
12)}\label{homework-due-before-session-12}

\textbf{Goal:} Add \textbf{one more external series} (your choice) via
FRED and keep everything cached and reproducible.

\subsection{\texorpdfstring{A. Script:
\texttt{scripts/get\_macro.py}}{A. Script: scripts/get\_macro.py}}\label{a.-script-scriptsget_macro.py}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/usr/bin/env python}
\ImportTok{import}\NormalTok{ os, json, time, hashlib, pandas }\ImportTok{as}\NormalTok{ pd, sqlite3}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ requests}
\ImportTok{from}\NormalTok{ urllib3.util.retry }\ImportTok{import}\NormalTok{ Retry}
\ImportTok{from}\NormalTok{ requests.adapters }\ImportTok{import}\NormalTok{ HTTPAdapter}
\ImportTok{from}\NormalTok{ dotenv }\ImportTok{import}\NormalTok{ load\_dotenv}

\NormalTok{load\_dotenv()}
\NormalTok{API\_KEY }\OperatorTok{=}\NormalTok{ os.getenv(}\StringTok{"FRED\_API\_KEY"}\NormalTok{,}\StringTok{""}\NormalTok{).strip()}
\NormalTok{BASE }\OperatorTok{=} \StringTok{"https://api.stlouisfed.org/fred/series/observations"}

\KeywordTok{def}\NormalTok{ sess():}
\NormalTok{    s }\OperatorTok{=}\NormalTok{ requests.Session()}
\NormalTok{    s.headers.update(\{}\StringTok{"User{-}Agent"}\NormalTok{:}\StringTok{"dspt{-}class/1.0"}\NormalTok{\})}
\NormalTok{    s.mount(}\StringTok{"https://"}\NormalTok{, HTTPAdapter(max\_retries}\OperatorTok{=}\NormalTok{Retry(total}\OperatorTok{=}\DecValTok{3}\NormalTok{, backoff\_factor}\OperatorTok{=}\FloatTok{0.5}\NormalTok{,}
\NormalTok{                                                      status\_forcelist}\OperatorTok{=}\NormalTok{[}\DecValTok{429}\NormalTok{,}\DecValTok{500}\NormalTok{,}\DecValTok{502}\NormalTok{,}\DecValTok{503}\NormalTok{,}\DecValTok{504}\NormalTok{])))}
    \ControlFlowTok{return}\NormalTok{ s}

\KeywordTok{def}\NormalTok{ ckey(url, params):}
\NormalTok{    raw }\OperatorTok{=}\NormalTok{ url }\OperatorTok{+} \StringTok{"?"} \OperatorTok{+} \StringTok{"\&"}\NormalTok{.join(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{=}\SpecialCharTok{\{}\NormalTok{params[k]}\SpecialCharTok{\}}\SpecialStringTok{"} \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{sorted}\NormalTok{(params))}
    \ControlFlowTok{return}\NormalTok{ hashlib.sha1(raw.encode()).hexdigest()}

\KeywordTok{def}\NormalTok{ cached\_get(url, params, ttl}\OperatorTok{=}\DecValTok{86400}\NormalTok{):}
\NormalTok{    key }\OperatorTok{=}\NormalTok{ ckey(url, params)}\OperatorTok{;}\NormalTok{ p }\OperatorTok{=}\NormalTok{ Path(}\SpecialStringTok{f".cache/api/}\SpecialCharTok{\{}\NormalTok{key}\SpecialCharTok{\}}\SpecialStringTok{.json"}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ p.exists() }\KeywordTok{and}\NormalTok{ (time.time() }\OperatorTok{{-}}\NormalTok{ p.stat().st\_mtime }\OperatorTok{\textless{}}\NormalTok{ ttl):}
        \ControlFlowTok{return}\NormalTok{ json.loads(p.read\_text())}
\NormalTok{    r }\OperatorTok{=}\NormalTok{ sess().get(url, params}\OperatorTok{=}\NormalTok{params, timeout}\OperatorTok{=}\DecValTok{20}\NormalTok{)}\OperatorTok{;}\NormalTok{ r.raise\_for\_status()}
\NormalTok{    data }\OperatorTok{=}\NormalTok{ r.json()}\OperatorTok{;}\NormalTok{ p.write\_text(json.dumps(data))}\OperatorTok{;} \ControlFlowTok{return}\NormalTok{ data}

\KeywordTok{def}\NormalTok{ fetch\_series(series\_id, start}\OperatorTok{=}\StringTok{"2015{-}01{-}01"}\NormalTok{):}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ API\_KEY: }\ControlFlowTok{raise} \PreprocessorTok{SystemExit}\NormalTok{(}\StringTok{"Set FRED\_API\_KEY in .env"}\NormalTok{)}
\NormalTok{    params }\OperatorTok{=}\NormalTok{ \{}\StringTok{"series\_id"}\NormalTok{:series\_id, }\StringTok{"api\_key"}\NormalTok{:API\_KEY, }\StringTok{"file\_type"}\NormalTok{:}\StringTok{"json"}\NormalTok{, }\StringTok{"observation\_start"}\NormalTok{:start\}}
\NormalTok{    data }\OperatorTok{=}\NormalTok{ cached\_get(BASE, params)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.DataFrame(data[}\StringTok{"observations"}\NormalTok{])[[}\StringTok{"date"}\NormalTok{,}\StringTok{"value"}\NormalTok{]]}
\NormalTok{    df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{])}
\NormalTok{    df[}\StringTok{"value"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_numeric(df[}\StringTok{"value"}\NormalTok{], errors}\OperatorTok{=}\StringTok{"coerce"}\NormalTok{)}
\NormalTok{    df[}\StringTok{"series\_id"}\NormalTok{] }\OperatorTok{=}\NormalTok{ series\_id}
    \ControlFlowTok{return}\NormalTok{ df.dropna()}

\KeywordTok{def}\NormalTok{ main(series\_id):}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ fetch\_series(series\_id)}
\NormalTok{    con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(}\StringTok{"data/prices.db"}\NormalTok{)}
\NormalTok{    con.execute(}\StringTok{"""CREATE TABLE IF NOT EXISTS macro\_series(}
\StringTok{        series\_id TEXT, date TEXT, value REAL, PRIMARY KEY(series\_id,date))"""}\NormalTok{)}
\NormalTok{    df.to\_sql(}\StringTok{"macro\_series"}\NormalTok{, con, if\_exists}\OperatorTok{=}\StringTok{"append"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{    con.commit()}\OperatorTok{;}\NormalTok{ con.close()}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Stored }\SpecialCharTok{\{}\NormalTok{series\_id}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\BuiltInTok{len}\NormalTok{(df)}\SpecialCharTok{\}}\SpecialStringTok{ rows"}\NormalTok{)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
    \ImportTok{import}\NormalTok{ argparse}
\NormalTok{    ap }\OperatorTok{=}\NormalTok{ argparse.ArgumentParser()}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}series{-}id"}\NormalTok{, required}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}start"}\NormalTok{, default}\OperatorTok{=}\StringTok{"2015{-}01{-}01"}\NormalTok{)}
\NormalTok{    args }\OperatorTok{=}\NormalTok{ ap.parse\_args()}
\NormalTok{    main(args.series\_id)}
\end{Highlighting}
\end{Shaded}

Run example:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/get\_macro.py}
\ExtensionTok{python}\NormalTok{ scripts/get\_macro.py }\AttributeTok{{-}{-}series{-}id}\NormalTok{ DGS10   }\CommentTok{\# 10‑Year Treasury Constant Maturity Rate}
\end{Highlighting}
\end{Shaded}

\subsection{B. Enrich features with your new
series}\label{b.-enrich-features-with-your-new-series}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, sqlite3}
\NormalTok{fv }\OperatorTok{=}\NormalTok{ pd.read\_parquet(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
\NormalTok{con }\OperatorTok{=}\NormalTok{ sqlite3.}\ExtensionTok{connect}\NormalTok{(}\StringTok{"data/prices.db"}\NormalTok{)}
\NormalTok{macro }\OperatorTok{=}\NormalTok{ pd.read\_sql\_query(}\StringTok{"SELECT series\_id, date, value FROM macro\_series"}\NormalTok{, con, parse\_dates}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{])}
\NormalTok{con.close()}
\NormalTok{wide }\OperatorTok{=}\NormalTok{ macro.pivot\_table(index}\OperatorTok{=}\StringTok{"date"}\NormalTok{, columns}\OperatorTok{=}\StringTok{"series\_id"}\NormalTok{, values}\OperatorTok{=}\StringTok{"value"}\NormalTok{).reset\_index()}
\NormalTok{out }\OperatorTok{=}\NormalTok{ fv.merge(wide, on}\OperatorTok{=}\StringTok{"date"}\NormalTok{, how}\OperatorTok{=}\StringTok{"left"}\NormalTok{)}
\NormalTok{out.to\_parquet(}\StringTok{"data/processed/features\_v1\_ext.parquet"}\NormalTok{, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote features\_v1\_ext.parquet with extra series:"}\NormalTok{, out.shape)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{C. Short test:
\texttt{tests/test\_macro\_join.py}}{C. Short test: tests/test\_macro\_join.py}}\label{c.-short-test-teststest_macro_join.py}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\KeywordTok{def}\NormalTok{ test\_enriched\_has\_macro():}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(}\StringTok{"data/processed/features\_v1\_ext.parquet"}\NormalTok{)}
    \ControlFlowTok{assert} \StringTok{"date"} \KeywordTok{in}\NormalTok{ df }\KeywordTok{and} \StringTok{"ticker"} \KeywordTok{in}\NormalTok{ df}
    \ControlFlowTok{assert}\NormalTok{ df.}\BuiltInTok{filter}\NormalTok{(regex}\OperatorTok{=}\StringTok{"\^{}(VIXCLS|DGS10|FEDFUNDS)$"}\NormalTok{).shape[}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}=} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\bookmarksetup{startatroot}

\chapter{Session 12 --- HTML Scraping: Ethics \&
Resilience}\label{session-12-html-scraping-ethics-resilience}

\bookmarksetup{startatroot}

\chapter{\texorpdfstring{\textbf{Session 12 --- HTML Scraping: Ethics \&
Resilience (75
min)}}{Session 12 --- HTML Scraping: Ethics \& Resilience (75 min)}}\label{session-12-html-scraping-ethics-resilience-75-min}

\subsection{Learning goals}\label{learning-goals-11}

Students will be able to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Respect robots.txt and basic site etiquette (throttling, user‑agent,
  caching).
\item
  Extract structured tables with \textbf{BeautifulSoup} and fall back to
  \texttt{pandas.read\_html}.
\item
  Normalize scraped data (clean headers, dtypes, categories).
\item
  Save provenance and update a \textbf{data dictionary} for the repo.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-9}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: ethics, robots, terms; caching, rate limits
\item
  \textbf{(10 min)} Slides: stable selectors (ids, table headers), text
  cleanup, date parsing
\item
  \textbf{(35 min)} \textbf{In‑class lab}: scrape a static sector table
  (Wikipedia S\&P 500 components), map to your tickers, save
  \texttt{data/static/sector\_map.csv}; merge into
  \texttt{prices.parquet} if missing
\item
  \textbf{(10 min)} Wrap‑up + homework brief
\item
  \textbf{(10 min)} Buffer
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slide talking points}\label{slide-talking-points-2}

\textbf{Ethics + resilience}

\begin{itemize}
\tightlist
\item
  \textbf{Check robots.txt}; identify disallow rules.
\item
  Set a clear \textbf{User‑Agent} and \textbf{sleep} between requests.
\item
  Cache HTML locally; \textbf{don't hammer} sites.
\item
  Expect structure to change; write \textbf{defensive} code.
\end{itemize}

\textbf{Parsing patterns}

\begin{itemize}
\tightlist
\item
  Prefer table selectors; use \texttt{read\_html} for well‑formed
  tables.
\item
  Clean headers → snake\_case; drop footnotes; trim whitespace.
\item
  Normalize keys (e.g., ticker symbols: map \texttt{.} ↔ \texttt{-} if
  needed).
\end{itemize}

\textbf{Provenance}

\begin{itemize}
\tightlist
\item
  Save \texttt{source\_url}, \texttt{fetched\_at}, and a checksum
  alongside the CSV.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab}\label{inclass-lab-1}

\begin{quote}
We'll scrape \textbf{Wikipedia: List of S\&P 500 companies} (static
table). If blocked, we fall back to \texttt{pandas.read\_html} or a
small local stub.
\end{quote}

\subsection{0) Setup + robots check + HTML
caching}\label{setup-robots-check-html-caching}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, requests, time, hashlib, pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ bs4 }\ImportTok{import}\NormalTok{ BeautifulSoup}
\ImportTok{from}\NormalTok{ urllib.parse }\ImportTok{import}\NormalTok{ urljoin}
\ImportTok{from}\NormalTok{ datetime }\ImportTok{import}\NormalTok{ datetime}

\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{".cache/html"}\NormalTok{,}\StringTok{"data/static"}\NormalTok{,}\StringTok{"reports"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{UA }\OperatorTok{=}\NormalTok{ \{}\StringTok{"User{-}Agent"}\NormalTok{: }\StringTok{"dspt{-}class/1.0 (+edu)"}\NormalTok{\}}
\NormalTok{WIKI\_URL }\OperatorTok{=} \StringTok{"https://en.wikipedia.org/wiki/List\_of\_S\%26P\_500\_companies"}

\KeywordTok{def}\NormalTok{ allowed\_by\_robots(base, path}\OperatorTok{=}\StringTok{"/wiki/"}\NormalTok{):}
\NormalTok{    r }\OperatorTok{=}\NormalTok{ requests.get(urljoin(base, }\StringTok{"/robots.txt"}\NormalTok{), headers}\OperatorTok{=}\NormalTok{UA, timeout}\OperatorTok{=}\DecValTok{20}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ r.status\_code }\OperatorTok{!=} \DecValTok{200}\NormalTok{: }\ControlFlowTok{return} \VariableTok{True}
\NormalTok{    lines }\OperatorTok{=}\NormalTok{ r.text.splitlines()}
\NormalTok{    disallows }\OperatorTok{=}\NormalTok{ [ln.split(}\StringTok{":"}\NormalTok{)[}\DecValTok{1}\NormalTok{].strip() }\ControlFlowTok{for}\NormalTok{ ln }\KeywordTok{in}\NormalTok{ lines }\ControlFlowTok{if}\NormalTok{ ln.lower().startswith(}\StringTok{"disallow:"}\NormalTok{)]}
    \ControlFlowTok{return} \BuiltInTok{all}\NormalTok{(}\KeywordTok{not}\NormalTok{ path.startswith(d) }\ControlFlowTok{for}\NormalTok{ d }\KeywordTok{in}\NormalTok{ disallows)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Robots allows /wiki/?"}\NormalTok{, allowed\_by\_robots(}\StringTok{"https://en.wikipedia.org"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\subsection{1) Download (with cache) and parse the first big
table}\label{download-with-cache-and-parse-the-first-big-table}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ get\_html\_cached(url, ttl\_hours}\OperatorTok{=}\DecValTok{24}\NormalTok{):}
\NormalTok{    key }\OperatorTok{=}\NormalTok{ hashlib.sha1(url.encode()).hexdigest()}
\NormalTok{    path }\OperatorTok{=}\NormalTok{ pathlib.Path(}\SpecialStringTok{f".cache/html/}\SpecialCharTok{\{}\NormalTok{key}\SpecialCharTok{\}}\SpecialStringTok{.html"}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ path.exists() }\KeywordTok{and}\NormalTok{ (time.time() }\OperatorTok{{-}}\NormalTok{ path.stat().st\_mtime }\OperatorTok{\textless{}}\NormalTok{ ttl\_hours }\OperatorTok{*} \DecValTok{3600}\NormalTok{):}
        \ControlFlowTok{return}\NormalTok{ path.read\_text()}
\NormalTok{    r }\OperatorTok{=}\NormalTok{ requests.get(url, headers}\OperatorTok{=}\NormalTok{UA, timeout}\OperatorTok{=}\DecValTok{30}\NormalTok{)}
\NormalTok{    r.raise\_for\_status()}
\NormalTok{    path.write\_text(r.text)}
\NormalTok{    time.sleep(}\FloatTok{1.0}\NormalTok{)  }\CommentTok{\# be polite}
    \ControlFlowTok{return}\NormalTok{ r.text}

\NormalTok{html }\OperatorTok{=}\NormalTok{ get\_html\_cached(WIKI\_URL)}
\NormalTok{soup }\OperatorTok{=}\NormalTok{ BeautifulSoup(html, }\StringTok{"html.parser"}\NormalTok{)}

\CommentTok{\# Try soup table first; fallback to pandas.read\_html}
\NormalTok{table }\OperatorTok{=}\NormalTok{ soup.find(}\StringTok{"table"}\NormalTok{, \{}\StringTok{"id"}\NormalTok{:}\StringTok{"constituents"}\NormalTok{\}) }\KeywordTok{or}\NormalTok{ soup.find(}\StringTok{"table"}\NormalTok{, \{}\StringTok{"class"}\NormalTok{:}\StringTok{"wikitable"}\NormalTok{\})}
\ControlFlowTok{if}\NormalTok{ table }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{    rows }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    headers }\OperatorTok{=}\NormalTok{ [th.get\_text(strip}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ th }\KeywordTok{in}\NormalTok{ table.find(}\StringTok{"tr"}\NormalTok{).find\_all(}\StringTok{"th"}\NormalTok{)]}
    \ControlFlowTok{for}\NormalTok{ tr }\KeywordTok{in}\NormalTok{ table.find\_all(}\StringTok{"tr"}\NormalTok{)[}\DecValTok{1}\NormalTok{:]:}
\NormalTok{        tds }\OperatorTok{=}\NormalTok{ [td.get\_text(strip}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\ControlFlowTok{for}\NormalTok{ td }\KeywordTok{in}\NormalTok{ tr.find\_all([}\StringTok{"td"}\NormalTok{,}\StringTok{"th"}\NormalTok{])]}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(tds) }\OperatorTok{==} \BuiltInTok{len}\NormalTok{(headers):}
\NormalTok{            rows.append(}\BuiltInTok{dict}\NormalTok{(}\BuiltInTok{zip}\NormalTok{(headers, tds)))}
\NormalTok{    sp }\OperatorTok{=}\NormalTok{ pd.DataFrame(rows)}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    sp }\OperatorTok{=}\NormalTok{ pd.read\_html(html)[}\DecValTok{0}\NormalTok{]}

\NormalTok{sp.head(}\DecValTok{3}\NormalTok{), sp.columns.tolist()}
\end{Highlighting}
\end{Shaded}

\subsection{2) Clean + normalize + keep only ticker ↔
sector}\label{clean-normalize-keep-only-ticker-sector}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ re}
\KeywordTok{def}\NormalTok{ snake(s): }
\NormalTok{    s }\OperatorTok{=}\NormalTok{ re.sub(}\VerbatimStringTok{r"[\^{}\textbackslash{}w\textbackslash{}s]"}\NormalTok{, }\StringTok{"\_"}\NormalTok{, s)}
\NormalTok{    s }\OperatorTok{=}\NormalTok{ re.sub(}\VerbatimStringTok{r"\textbackslash{}s+"}\NormalTok{, }\StringTok{"\_"}\NormalTok{, s.strip().lower())}
    \ControlFlowTok{return}\NormalTok{ re.sub(}\VerbatimStringTok{r"\_+"}\NormalTok{, }\StringTok{"\_"}\NormalTok{, s)}

\NormalTok{sp.columns }\OperatorTok{=}\NormalTok{ [snake(c) }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ sp.columns]}
\NormalTok{cand\_cols }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ sp.columns }\ControlFlowTok{if} \StringTok{"symbol"} \KeywordTok{in}\NormalTok{ c }\KeywordTok{or} \StringTok{"security"} \KeywordTok{in}\NormalTok{ c }\KeywordTok{or} \StringTok{"sector"} \KeywordTok{in}\NormalTok{ c]}
\NormalTok{sp }\OperatorTok{=}\NormalTok{ sp.rename(columns}\OperatorTok{=}\NormalTok{\{c:}\StringTok{"symbol"} \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ sp.columns }\ControlFlowTok{if} \StringTok{"symbol"} \KeywordTok{in}\NormalTok{ c }\KeywordTok{or}\NormalTok{ c}\OperatorTok{==}\StringTok{"ticker"}\NormalTok{\})}
\NormalTok{sp }\OperatorTok{=}\NormalTok{ sp.rename(columns}\OperatorTok{=}\NormalTok{\{c:}\StringTok{"sector"} \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ sp.columns }\ControlFlowTok{if} \StringTok{"sector"} \KeywordTok{in}\NormalTok{ c\})}
\NormalTok{keep }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ [}\StringTok{"symbol"}\NormalTok{,}\StringTok{"sector"}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ sp.columns]}
\NormalTok{sp }\OperatorTok{=}\NormalTok{ sp[keep].dropna().drop\_duplicates()}
\NormalTok{sp }\OperatorTok{=}\NormalTok{ sp.rename(columns}\OperatorTok{=}\NormalTok{\{}\StringTok{"symbol"}\NormalTok{:}\StringTok{"ticker"}\NormalTok{\})}
\NormalTok{sp[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ sp[}\StringTok{"ticker"}\NormalTok{].}\BuiltInTok{str}\NormalTok{.strip()}
\NormalTok{sp[}\StringTok{"sector"}\NormalTok{] }\OperatorTok{=}\NormalTok{ sp[}\StringTok{"sector"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}

\CommentTok{\# Save with provenance}
\NormalTok{src }\OperatorTok{=}\NormalTok{ \{}\StringTok{"source\_url"}\NormalTok{: WIKI\_URL, }\StringTok{"fetched\_at\_utc"}\NormalTok{: datetime.utcnow().isoformat()}\OperatorTok{+}\StringTok{"Z"}\NormalTok{\}}
\NormalTok{sp.to\_csv(}\StringTok{"data/static/sector\_map.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(}\StringTok{"data/static/sector\_map.provenance.json"}\NormalTok{,}\StringTok{"w"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
    \ImportTok{import}\NormalTok{ json}\OperatorTok{;}\NormalTok{ json.dump(src, f, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote data/static/sector\_map.csv"}\NormalTok{, sp.shape)}
\NormalTok{sp.head(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{3) Merge sector mapping into prices if missing
sector}\label{merge-sector-mapping-into-prices-if-missing-sector}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{pp }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/prices.parquet"}\NormalTok{)}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ pp.exists():}
    \ControlFlowTok{raise} \PreprocessorTok{SystemExit}\NormalTok{(}\StringTok{"Need prices.parquet (Session 9)."}\NormalTok{)}

\NormalTok{prices }\OperatorTok{=}\NormalTok{ pd.read\_parquet(pp)}
\ControlFlowTok{if} \StringTok{"sector"} \KeywordTok{not} \KeywordTok{in}\NormalTok{ prices.columns }\KeywordTok{or}\NormalTok{ prices[}\StringTok{"sector"}\NormalTok{].isna().}\BuiltInTok{all}\NormalTok{():}
\NormalTok{    prices2 }\OperatorTok{=}\NormalTok{ prices.merge(sp, on}\OperatorTok{=}\StringTok{"ticker"}\NormalTok{, how}\OperatorTok{=}\StringTok{"left"}\NormalTok{)}
\NormalTok{    prices2[}\StringTok{"sector"}\NormalTok{] }\OperatorTok{=}\NormalTok{ prices2[}\StringTok{"sector"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{    prices2.to\_parquet(}\StringTok{"data/processed/prices.parquet"}\NormalTok{, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Updated prices.parquet with sector column."}\NormalTok{)}
\ControlFlowTok{else}\NormalTok{:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Sector already present; no merge needed."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up}\label{wrapup-1}

\begin{itemize}
\tightlist
\item
  You scraped a static table \textbf{politely} (robots, throttle, cache)
  and extracted a tidy map.
\item
  You persisted \textbf{provenance} and used it to enrich your dataset.
\item
  Keep scrapers \textbf{small, cached, and resilient}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due next week)}\label{homework-due-next-week}

\textbf{Goal:} Document your web data provenance and generate a minimal
\textbf{data dictionary} for the project.

\subsection{A. Provenance section (script that composes a Markdown
file)}\label{a.-provenance-section-script-that-composes-a-markdown-file}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scripts/write\_provenance.py}
\CommentTok{\#!/usr/bin/env python}
\ImportTok{import}\NormalTok{ json, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{provenance }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{if}\NormalTok{ Path(}\StringTok{"data/static/sector\_map.provenance.json"}\NormalTok{).exists():}
\NormalTok{    provenance.append(json.loads(Path(}\StringTok{"data/static/sector\_map.provenance.json"}\NormalTok{).read\_text()))}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    provenance.append(\{}\StringTok{"source\_url"}\NormalTok{:}\StringTok{"(none)"}\NormalTok{,}\StringTok{"fetched\_at\_utc"}\NormalTok{:}\StringTok{"(n/a)"}\NormalTok{\})}

\NormalTok{md }\OperatorTok{=}\NormalTok{ [}\StringTok{"\# Data provenance"}\NormalTok{,}
      \StringTok{""}\NormalTok{,}
      \StringTok{"\#\# Web sources"}\NormalTok{,}
      \StringTok{""}\NormalTok{,}
      \StringTok{"| Source | Fetched at |"}\NormalTok{,}
      \StringTok{"|{-}{-}{-}|{-}{-}{-}|"}\NormalTok{]}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ provenance:}
\NormalTok{    md.append(}\SpecialStringTok{f"| }\SpecialCharTok{\{}\NormalTok{p[}\StringTok{\textquotesingle{}source\_url\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{ | }\SpecialCharTok{\{}\NormalTok{p[}\StringTok{\textquotesingle{}fetched\_at\_utc\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{ |"}\NormalTok{)}

\NormalTok{Path(}\StringTok{"reports/provenance.md"}\NormalTok{).write\_text(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{.join(md))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote reports/provenance.md"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/write\_provenance.py}
\ExtensionTok{python}\NormalTok{ scripts/write\_provenance.py}
\end{Highlighting}
\end{Shaded}

\subsection{B. Data dictionary
generator}\label{b.-data-dictionary-generator}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scripts/data\_dictionary.py}
\CommentTok{\#!/usr/bin/env python}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\KeywordTok{def}\NormalTok{ describe\_parquet(path):}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(path)}
\NormalTok{    dtypes }\OperatorTok{=}\NormalTok{ df.dtypes.astype(}\BuiltInTok{str}\NormalTok{).to\_dict()}
    \ControlFlowTok{return}\NormalTok{ pd.DataFrame(\{}\StringTok{"column"}\NormalTok{: }\BuiltInTok{list}\NormalTok{(dtypes.keys()), }\StringTok{"dtype"}\NormalTok{: }\BuiltInTok{list}\NormalTok{(dtypes.values())\})}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ path }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/processed/prices.parquet"}\NormalTok{,}
                 \StringTok{"data/processed/returns.parquet"}\NormalTok{,}
                 \StringTok{"data/processed/features\_v1.parquet"}\NormalTok{,}
                 \StringTok{"data/processed/features\_v1\_ext.parquet"}\NormalTok{]:}
\NormalTok{        p }\OperatorTok{=}\NormalTok{ Path(path)}
        \ControlFlowTok{if}\NormalTok{ p.exists():}
\NormalTok{            df }\OperatorTok{=}\NormalTok{ describe\_parquet(p)}
\NormalTok{            df.insert(}\DecValTok{0}\NormalTok{, }\StringTok{"dataset"}\NormalTok{, p.name)}
\NormalTok{            rows.append(df)}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ pd.concat(rows, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ rows }\ControlFlowTok{else}\NormalTok{ pd.DataFrame(columns}\OperatorTok{=}\NormalTok{[}\StringTok{"dataset"}\NormalTok{,}\StringTok{"column"}\NormalTok{,}\StringTok{"dtype"}\NormalTok{])}
\NormalTok{    Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    out.to\_csv(}\StringTok{"reports/data\_dictionary.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote reports/data\_dictionary.csv"}\NormalTok{)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/data\_dictionary.py}
\ExtensionTok{python}\NormalTok{ scripts/data\_dictionary.py}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{C. (Optional) Add a short \textbf{Quarto}
page that includes both
files}{C. (Optional) Add a short Quarto page that includes both files}}\label{c.-optional-add-a-short-quarto-page-that-includes-both-files}

Create \texttt{reports/data\_overview.qmd} and render in your next
report.

\subsection{D. Quick tests}\label{d.-quick-tests}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_dictionary\_provenance.py}
\ImportTok{import}\NormalTok{ os, pandas }\ImportTok{as}\NormalTok{ pd}
\KeywordTok{def}\NormalTok{ test\_provenance\_and\_dict():}
    \ControlFlowTok{assert}\NormalTok{ os.path.exists(}\StringTok{"reports/provenance.md"}\NormalTok{)}
    \ControlFlowTok{assert}\NormalTok{ os.path.exists(}\StringTok{"reports/data\_dictionary.csv"}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"reports/data\_dictionary.csv"}\NormalTok{)}
    \ControlFlowTok{assert}\NormalTok{ \{}\StringTok{"dataset"}\NormalTok{,}\StringTok{"column"}\NormalTok{,}\StringTok{"dtype"}\NormalTok{\}.issubset(df.columns)}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor tips (for all three
sessions)}\label{instructor-tips-for-all-three-sessions}

\begin{itemize}
\tightlist
\item
  Keep a one‑page ``\textbf{no leakage}'' checklist handy and point to
  it often.
\item
  For Session 11, have a prepared \texttt{.env} with a working FRED key
  to avoid classroom delays.
\item
  For Session 12, if Wikipedia blocks requests, switch to
  \texttt{pandas.read\_html} (shown) or use a small pre‑saved HTML in
  \texttt{data/static/} to demonstrate parsing.
\end{itemize}

These three sessions carry you from solid \textbf{feature engineering} →
\textbf{external data integration} → \textbf{web scraping with ethics},
setting up a strong foundation for the testing/CI weeks that follow.

\bookmarksetup{startatroot}

\chapter{Session 13}\label{session-13}

Below is a complete lecture package for \textbf{Session 13 --- pytest +
Data Validation} (75 minutes). It includes a timed agenda, slide talking
points, a \textbf{Colab‑friendly in‑class lab with copy‑paste code}, and
\textbf{homework with copy‑paste code}. You'll add \textbf{high‑value
tests} around your features and a \textbf{Pandera} (optional) schema,
practice \textbf{logging}, and wire everything so tests run fast and
deterministically.

\begin{quote}
\textbf{Assumptions:} You completed Session 9--12 and have
\texttt{data/processed/features\_v1.parquet} (or
\texttt{features\_v1\_ext.parquet}). If a file is missing, the lab
provides a small synthetic fallback so tests still run. \textbf{Goal
today:} Make it \textbf{hard to ship bad data} by adding precise, fast
tests.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 13 --- pytest + Data Validation (75
min)}\label{session-13-pytest-data-validation-75-min}

\subsection{Learning goals}\label{learning-goals-12}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Write \textbf{fast, high‑signal tests} for data pipelines (shapes,
  dtypes, nulls, \textbf{no look‑ahead}).
\item
  Validate a DataFrame with \textbf{Pandera} (schema + value checks) or
  \textbf{custom checks} only.
\item
  Use \textbf{logging} effectively and capture logs in tests.
\item
  Run tests in Colab / locally and prepare for CI in Session 14.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-10}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: What to test (and not), ``data tests'' vs
  unit tests, speed budget
\item
  \textbf{(10 min)} Slides: Pandera schemas \& custom checks; tolerance
  and stability
\item
  \textbf{(10 min)} Slides: Logging basics (\texttt{logging}, levels,
  handlers); testing logs with \texttt{caplog}
\item
  \textbf{(35 min)} \textbf{In‑class lab}: add
  \texttt{tests/test\_features.py} (+ optional Pandera test), fixtures,
  config; run \& fix
\item
  \textbf{(10 min)} Wrap‑up + homework briefing
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points (drop into your
deck)}\label{slides-talking-points-drop-into-your-deck}

\subsection{What to test (fast, crisp)}\label{what-to-test-fast-crisp}

\begin{itemize}
\item
  \textbf{Contract tests} for data:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Schema}: required columns exist; dtypes sane
    (\texttt{ticker} categorical, calendar ints).
  \item
    \textbf{Nulls}: no NAs in training‑critical cols.
  \item
    \textbf{Semantics}: \texttt{r\_1d} is \textbf{lead} of
    \texttt{log\_return}; rolling features computed from \textbf{past
    only}.
  \item
    \textbf{Keys}: no duplicate \texttt{(ticker,\ date)}; dates strictly
    increasing within ticker.
  \end{itemize}
\item
  Keep tests \textbf{under \textasciitilde5s total} (CI budget). Avoid
  long recomputations; sample/take head.
\end{itemize}

\subsection{Pandera vs custom checks}\label{pandera-vs-custom-checks}

\begin{itemize}
\tightlist
\item
  \textbf{Pandera}: declarative schema; optional dependency; good for
  \textbf{column existence + ranges}.
\item
  \textbf{Custom}: essential for \textbf{domain logic} (look‑ahead bans,
  exact rolling formulas).
\end{itemize}

\subsection{Logging basics}\label{logging-basics}

\begin{itemize}
\tightlist
\item
  Use \texttt{logging.getLogger(\_\_name\_\_)}; set level via env
  (\texttt{LOGLEVEL=INFO}).
\item
  Log \textbf{counts, ranges, and any data drops} inside build scripts.
\item
  In tests: use \texttt{caplog} to assert a warning is emitted for
  suspicious conditions.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min)}\label{inclass-lab-35-min-7}

\begin{quote}
Run each block as its \textbf{own Colab cell}. Adjust
\texttt{REPO\_NAME} as needed.
\end{quote}

\subsection{0) Setup: mount \& folders}\label{setup-mount-folders}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}  \CommentTok{\# \textless{}{-} change if needed}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"tests"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"reports"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}
\end{Highlighting}
\end{Shaded}

\subsection{1) (Optional) Install test‑time helpers
(Pandera)}\label{optional-install-testtime-helpers-pandera}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{pip }\OperatorTok{{-}}\NormalTok{q install pytest pandera pyarrow}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Put a tiny \textbf{logging helper} in
your repo (used by build scripts \&
tests)}{2) Put a tiny logging helper in your repo (used by build scripts \& tests)}}\label{put-a-tiny-logging-helper-in-your-repo-used-by-build-scripts-tests}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scripts/logsetup.py}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ logging, os}

\KeywordTok{def}\NormalTok{ setup\_logging(name: }\BuiltInTok{str} \OperatorTok{=} \StringTok{"dspt"}\NormalTok{):}
\NormalTok{    level }\OperatorTok{=}\NormalTok{ os.getenv(}\StringTok{"LOGLEVEL"}\NormalTok{, }\StringTok{"INFO"}\NormalTok{).upper()}
\NormalTok{    logger }\OperatorTok{=}\NormalTok{ logging.getLogger(name)}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ logger.handlers:}
\NormalTok{        handler }\OperatorTok{=}\NormalTok{ logging.StreamHandler()}
\NormalTok{        fmt }\OperatorTok{=} \StringTok{"}\SpecialCharTok{\%(asctime)s}\StringTok{ | }\SpecialCharTok{\%(levelname)s}\StringTok{ | }\SpecialCharTok{\%(name)s}\StringTok{ | }\SpecialCharTok{\%(message)s}\StringTok{"}
\NormalTok{        handler.setFormatter(logging.Formatter(fmt))}
\NormalTok{        logger.addHandler(handler)}
\NormalTok{    logger.setLevel(level)}
    \ControlFlowTok{return}\NormalTok{ logger}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Create \textbf{pytest config} and a
fixture (with safe fallback
data)}{3) Create pytest config and a fixture (with safe fallback data)}}\label{create-pytest-config-and-a-fixture-with-safe-fallback-data}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# pytest.ini}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{Path(}\StringTok{"pytest.ini"}\NormalTok{).write\_text(}\StringTok{"""[pytest]}
\StringTok{addopts = {-}q}
\StringTok{testpaths = tests}
\StringTok{filterwarnings =}
\StringTok{    ignore::FutureWarning}
\StringTok{"""}\NormalTok{)}

\CommentTok{\# tests/conftest.py}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np, pytest}

\KeywordTok{def}\NormalTok{ \_synth\_features():}
    \CommentTok{\# minimal synthetic features for 3 tickers, 60 days}
\NormalTok{    rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\NormalTok{    dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2023{-}01{-}02"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{60}\NormalTok{)}
\NormalTok{    frames}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{]:}
\NormalTok{        ret }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.01}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)).astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        adj }\OperatorTok{=} \DecValTok{100} \OperatorTok{*}\NormalTok{ np.exp(np.cumsum(ret))}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
            \StringTok{"date"}\NormalTok{: dates,}
            \StringTok{"ticker"}\NormalTok{: t,}
            \StringTok{"adj\_close"}\NormalTok{: adj.astype(}\StringTok{"float32"}\NormalTok{),}
            \StringTok{"log\_return"}\NormalTok{: np.r\_[np.nan, np.diff(np.log(adj))].astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        \})}
        \CommentTok{\# next{-}day label}
\NormalTok{        df[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"log\_return"}\NormalTok{].shift(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
        \CommentTok{\# rolling}
\NormalTok{        df[}\StringTok{"roll\_mean\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).mean()}
\NormalTok{        df[}\StringTok{"roll\_std\_20"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ df[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std()}
\NormalTok{        df[}\StringTok{"zscore\_20"}\NormalTok{]    }\OperatorTok{=}\NormalTok{ (df[}\StringTok{"log\_return"}\NormalTok{]}\OperatorTok{{-}}\NormalTok{df[}\StringTok{"roll\_mean\_20"}\NormalTok{])}\OperatorTok{/}\NormalTok{(df[}\StringTok{"roll\_std\_20"}\NormalTok{]}\OperatorTok{+}\FloatTok{1e{-}8}\NormalTok{)}
\NormalTok{        df[}\StringTok{"weekday"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.weekday.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{        df[}\StringTok{"month"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.month.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{        frames.append(df)}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ pd.concat(frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    out[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ out}

\AttributeTok{@pytest.fixture}\NormalTok{(scope}\OperatorTok{=}\StringTok{"session"}\NormalTok{)}
\KeywordTok{def}\NormalTok{ features\_df():}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ p.exists():}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(p)}
        \CommentTok{\# Ensure expected minimal cols exist (compute light ones if missing)}
        \ControlFlowTok{if} \StringTok{"weekday"} \KeywordTok{not} \KeywordTok{in}\NormalTok{ df: df[}\StringTok{"weekday"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{]).dt.weekday.astype(}\StringTok{"int8"}\NormalTok{)}
        \ControlFlowTok{if} \StringTok{"month"} \KeywordTok{not} \KeywordTok{in}\NormalTok{ df:   df[}\StringTok{"month"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{]).dt.month.astype(}\StringTok{"int8"}\NormalTok{)}
        \ControlFlowTok{return}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
    \CommentTok{\# fallback}
    \ControlFlowTok{return}\NormalTok{ \_synth\_features().sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) \textbf{High‑value tests}: shapes, nulls,
look‑ahead ban (as
requested)}{4) High‑value tests: shapes, nulls, look‑ahead ban (as requested)}}\label{highvalue-tests-shapes-nulls-lookahead-ban-as-requested}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_features.py}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ pytest}

\NormalTok{REQUIRED\_COLS }\OperatorTok{=}\NormalTok{ [}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"weekday"}\NormalTok{,}\StringTok{"month"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ test\_required\_columns\_present(features\_df):}
\NormalTok{    missing }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ REQUIRED\_COLS }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{not} \KeywordTok{in}\NormalTok{ features\_df.columns]}
    \ControlFlowTok{assert} \KeywordTok{not}\NormalTok{ missing, }\SpecialStringTok{f"Missing required columns: }\SpecialCharTok{\{}\NormalTok{missing}\SpecialCharTok{\}}\SpecialStringTok{"}

\KeywordTok{def}\NormalTok{ test\_key\_no\_duplicates(features\_df):}
\NormalTok{    dup }\OperatorTok{=}\NormalTok{ features\_df[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]].duplicated().}\BuiltInTok{sum}\NormalTok{()}
    \ControlFlowTok{assert}\NormalTok{ dup }\OperatorTok{==} \DecValTok{0}\NormalTok{, }\SpecialStringTok{f"Found }\SpecialCharTok{\{}\NormalTok{dup}\SpecialCharTok{\}}\SpecialStringTok{ duplicate (ticker,date) rows"}

\KeywordTok{def}\NormalTok{ test\_sorted\_within\_ticker(features\_df):}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ features\_df.groupby(}\StringTok{"ticker"}\NormalTok{):}
        \ControlFlowTok{assert}\NormalTok{ g[}\StringTok{"date"}\NormalTok{].is\_monotonic\_increasing, }\SpecialStringTok{f"Dates not sorted for }\SpecialCharTok{\{}\NormalTok{tkr}\SpecialCharTok{\}}\SpecialStringTok{"}

\KeywordTok{def}\NormalTok{ test\_nulls\_in\_critical\_columns(features\_df):}
\NormalTok{    crit }\OperatorTok{=}\NormalTok{ [}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{]}
\NormalTok{    na }\OperatorTok{=}\NormalTok{ features\_df[crit].isna().}\BuiltInTok{sum}\NormalTok{().to\_dict()}
    \ControlFlowTok{assert} \BuiltInTok{all}\NormalTok{(v }\OperatorTok{==} \DecValTok{0} \ControlFlowTok{for}\NormalTok{ v }\KeywordTok{in}\NormalTok{ na.values()), }\SpecialStringTok{f"NAs in critical cols: }\SpecialCharTok{\{}\NormalTok{na}\SpecialCharTok{\}}\SpecialStringTok{"}

\KeywordTok{def}\NormalTok{ test\_calendar\_dtypes(features\_df):}
    \ControlFlowTok{assert} \BuiltInTok{str}\NormalTok{(features\_df[}\StringTok{"weekday"}\NormalTok{].dtype) }\KeywordTok{in}\NormalTok{ (}\StringTok{"int8"}\NormalTok{,}\StringTok{"Int8"}\NormalTok{), }\StringTok{"weekday should be compact int"}
    \ControlFlowTok{assert} \BuiltInTok{str}\NormalTok{(features\_df[}\StringTok{"month"}\NormalTok{].dtype)   }\KeywordTok{in}\NormalTok{ (}\StringTok{"int8"}\NormalTok{,}\StringTok{"Int8"}\NormalTok{), }\StringTok{"month should be compact int"}

\KeywordTok{def}\NormalTok{ test\_ticker\_is\_categorical(features\_df):}
    \CommentTok{\# allow object if reading from some parquet engines, but prefer category}
    \ControlFlowTok{assert}\NormalTok{ features\_df[}\StringTok{"ticker"}\NormalTok{].dtype.name }\KeywordTok{in}\NormalTok{ (}\StringTok{"category"}\NormalTok{,}\StringTok{"CategoricalDtype"}\NormalTok{,}\StringTok{"object"}\NormalTok{)}

\KeywordTok{def}\NormalTok{ test\_r1d\_is\_lead\_of\_log\_return(features\_df):}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ features\_df.groupby(}\StringTok{"ticker"}\NormalTok{):}
        \CommentTok{\# r\_1d at t equals log\_return at t+1}
        \ControlFlowTok{assert}\NormalTok{ g[}\StringTok{"r\_1d"}\NormalTok{].iloc[:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].equals(g[}\StringTok{"log\_return"}\NormalTok{].iloc[}\DecValTok{1}\NormalTok{:]), }\SpecialStringTok{f"Lead/lag mismatch for }\SpecialCharTok{\{}\NormalTok{tkr}\SpecialCharTok{\}}\SpecialStringTok{"}

\AttributeTok{@pytest.mark.parametrize}\NormalTok{(}\StringTok{"W"}\NormalTok{, [}\DecValTok{20}\NormalTok{])}
\KeywordTok{def}\NormalTok{ test\_rolling\_mean\_matches\_definition(features\_df, W):}
    \ControlFlowTok{if} \SpecialStringTok{f"roll\_mean\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{"} \KeywordTok{not} \KeywordTok{in}\NormalTok{ features\_df.columns:}
\NormalTok{        pytest.skip(}\SpecialStringTok{f"roll\_mean\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{ not present"}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ features\_df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        s }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{]}
\NormalTok{        rm }\OperatorTok{=}\NormalTok{ s.rolling(W, min\_periods}\OperatorTok{=}\NormalTok{W).mean()}
        \CommentTok{\# compare only where defined}
\NormalTok{        mask }\OperatorTok{=} \OperatorTok{\textasciitilde{}}\NormalTok{rm.isna()}
\NormalTok{        diff }\OperatorTok{=}\NormalTok{ (g[}\SpecialStringTok{f"roll\_mean\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{][mask] }\OperatorTok{{-}}\NormalTok{ rm[mask]).}\BuiltInTok{abs}\NormalTok{().}\BuiltInTok{max}\NormalTok{()}
        \ControlFlowTok{assert} \BuiltInTok{float}\NormalTok{(diff) }\OperatorTok{\textless{}=} \FloatTok{1e{-}7}\NormalTok{, }\SpecialStringTok{f"roll\_mean\_}\SpecialCharTok{\{}\NormalTok{W}\SpecialCharTok{\}}\SpecialStringTok{ mismatch for }\SpecialCharTok{\{}\NormalTok{tkr}\SpecialCharTok{\}}\SpecialStringTok{ (max diff }\SpecialCharTok{\{}\NormalTok{diff}\SpecialCharTok{\}}\SpecialStringTok{)"}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{5) \textbf{Optional} Pandera schema test
(declarative)}{5) Optional Pandera schema test (declarative)}}\label{optional-pandera-schema-test-declarative}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_schema\_pandera.py}
\ImportTok{import}\NormalTok{ pytest, pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}
\ControlFlowTok{try}\NormalTok{:}
    \ImportTok{import}\NormalTok{ pandera }\ImportTok{as}\NormalTok{ pa}
    \ImportTok{from}\NormalTok{ pandera }\ImportTok{import}\NormalTok{ Column, Check, DataFrameSchema}
\ControlFlowTok{except} \PreprocessorTok{Exception}\NormalTok{:}
\NormalTok{    pytest.skip(}\StringTok{"pandera not installed"}\NormalTok{, allow\_module\_level}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{schema }\OperatorTok{=}\NormalTok{ pa.DataFrameSchema(\{}
    \StringTok{"date"}\NormalTok{:    Column(pa.DateTime, nullable}\OperatorTok{=}\VariableTok{False}\NormalTok{),}
    \StringTok{"ticker"}\NormalTok{:  Column(pa.String, nullable}\OperatorTok{=}\VariableTok{False}\NormalTok{, }\BuiltInTok{coerce}\OperatorTok{=}\VariableTok{True}\NormalTok{, checks}\OperatorTok{=}\NormalTok{Check.str\_length(}\DecValTok{1}\NormalTok{, }\DecValTok{12}\NormalTok{)),}
    \StringTok{"log\_return"}\NormalTok{: Column(pa.Float, nullable}\OperatorTok{=}\VariableTok{False}\NormalTok{, checks}\OperatorTok{=}\NormalTok{Check.is\_finite()),}
    \StringTok{"r\_1d"}\NormalTok{:       Column(pa.Float, nullable}\OperatorTok{=}\VariableTok{False}\NormalTok{, checks}\OperatorTok{=}\NormalTok{Check.is\_finite()),}
    \StringTok{"weekday"}\NormalTok{:    Column(pa.Int8,  checks}\OperatorTok{=}\NormalTok{Check.in\_range(}\DecValTok{0}\NormalTok{, }\DecValTok{6}\NormalTok{)),}
    \StringTok{"month"}\NormalTok{:      Column(pa.Int8,  checks}\OperatorTok{=}\NormalTok{Check.in\_range(}\DecValTok{1}\NormalTok{, }\DecValTok{12}\NormalTok{)),}
\NormalTok{\}, }\BuiltInTok{coerce}\OperatorTok{=}\VariableTok{True}\NormalTok{, strict}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\KeywordTok{def}\NormalTok{ test\_schema\_validate(features\_df):}
    \CommentTok{\# Cast ticker to string for schema validation; categorical is ok → string}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ features\_df.copy()}
\NormalTok{    df[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{)}
\NormalTok{    schema.validate(df[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"weekday"}\NormalTok{,}\StringTok{"month"}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{6) \textbf{Logging} test: assert a warning
is emitted on duplicates (toy
demo)}{6) Logging test: assert a warning is emitted on duplicates (toy demo)}}\label{logging-test-assert-a-warning-is-emitted-on-duplicates-toy-demo}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_logging.py}
\ImportTok{import}\NormalTok{ logging, pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np, pytest}
\ImportTok{from}\NormalTok{ scripts.logsetup }\ImportTok{import}\NormalTok{ setup\_logging}

\KeywordTok{def}\NormalTok{ check\_for\_duplicates(df, logger}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
\NormalTok{    logger }\OperatorTok{=}\NormalTok{ logger }\KeywordTok{or}\NormalTok{ setup\_logging(}\StringTok{"dspt"}\NormalTok{)}
\NormalTok{    dups }\OperatorTok{=}\NormalTok{ df[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]].duplicated().}\BuiltInTok{sum}\NormalTok{()}
    \ControlFlowTok{if}\NormalTok{ dups }\OperatorTok{\textgreater{}} \DecValTok{0}\NormalTok{:}
\NormalTok{        logger.warning(}\StringTok{"Found }\SpecialCharTok{\%d}\StringTok{ duplicate (ticker,date) rows"}\NormalTok{, dups)}
    \ControlFlowTok{return}\NormalTok{ dups}

\KeywordTok{def}\NormalTok{ test\_duplicate\_warning(caplog):}
\NormalTok{    caplog.set\_level(logging.WARNING)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{"ticker"}\NormalTok{:[}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"AAPL"}\NormalTok{], }\StringTok{"date"}\NormalTok{:pd.to\_datetime([}\StringTok{"2024{-}01{-}02"}\NormalTok{,}\StringTok{"2024{-}01{-}02"}\NormalTok{])\})}
\NormalTok{    dups }\OperatorTok{=}\NormalTok{ check\_for\_duplicates(df)}
    \ControlFlowTok{assert}\NormalTok{ dups }\OperatorTok{==} \DecValTok{1}
    \ControlFlowTok{assert} \BuiltInTok{any}\NormalTok{(}\StringTok{"duplicate"} \KeywordTok{in}\NormalTok{ rec.message }\ControlFlowTok{for}\NormalTok{ rec }\KeywordTok{in}\NormalTok{ caplog.records)}
\end{Highlighting}
\end{Shaded}

\subsection{7) Run tests now}\label{run-tests-now}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{pytest }\OperatorTok{{-}}\NormalTok{q}
\end{Highlighting}
\end{Shaded}

\begin{quote}
If a test fails on your real data, fix your pipeline (e.g., regenerate
\texttt{features\_v1.parquet}) and re‑run. \textbf{Do not} relax the
test without understanding the failure.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-6}

\begin{itemize}
\tightlist
\item
  You now have \textbf{tests that fail loudly} if labels leak, required
  columns/keys break, or schemas drift.
\item
  Pandera provides a declarative baseline; custom tests encode your
  \textbf{domain logic}.
\item
  Logging helps you \textbf{debug data issues}; you can assert on log
  messages in tests.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
14)}\label{homework-due-before-session-14}

\textbf{Goal:} Create a \textbf{Health Check} notebook that prints key
diagnostics and is easy to include in your Quarto report.

\subsection{\texorpdfstring{Part A --- Build a reusable \textbf{health}
module}{Part A --- Build a reusable health module}}\label{part-a-build-a-reusable-health-module}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scripts/health.py}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np, json}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\KeywordTok{def}\NormalTok{ df\_health(df: pd.DataFrame) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{dict}\NormalTok{:}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ \{\}}
\NormalTok{    out[}\StringTok{"rows"}\NormalTok{] }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(}\BuiltInTok{len}\NormalTok{(df))}
\NormalTok{    out[}\StringTok{"cols"}\NormalTok{] }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(df.shape[}\DecValTok{1}\NormalTok{])}
\NormalTok{    out[}\StringTok{"date\_min"}\NormalTok{] }\OperatorTok{=} \BuiltInTok{str}\NormalTok{(pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{]).}\BuiltInTok{min}\NormalTok{().date())}
\NormalTok{    out[}\StringTok{"date\_max"}\NormalTok{] }\OperatorTok{=} \BuiltInTok{str}\NormalTok{(pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{]).}\BuiltInTok{max}\NormalTok{().date())}
\NormalTok{    out[}\StringTok{"tickers"}\NormalTok{]  }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(df[}\StringTok{"ticker"}\NormalTok{].nunique())}
    \CommentTok{\# Null counts (top 10)}
\NormalTok{    na }\OperatorTok{=}\NormalTok{ df.isna().}\BuiltInTok{sum}\NormalTok{().sort\_values(ascending}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{    out[}\StringTok{"nulls"}\NormalTok{] }\OperatorTok{=}\NormalTok{ na[na}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{].head(}\DecValTok{10}\NormalTok{).to\_dict()}
    \CommentTok{\# Duplicates}
\NormalTok{    out[}\StringTok{"dup\_key\_rows"}\NormalTok{] }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(df[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]].duplicated().}\BuiltInTok{sum}\NormalTok{())}
    \CommentTok{\# Example numeric ranges for core cols}
    \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ [x }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ [}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"roll\_std\_20"}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ x }\KeywordTok{in}\NormalTok{ df.columns]:}
\NormalTok{        s }\OperatorTok{=}\NormalTok{ pd.to\_numeric(df[c], errors}\OperatorTok{=}\StringTok{"coerce"}\NormalTok{)}
\NormalTok{        out[}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{c}\SpecialCharTok{\}}\SpecialStringTok{\_min"}\NormalTok{] }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(np.nanmin(s))}
\NormalTok{        out[}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{c}\SpecialCharTok{\}}\SpecialStringTok{\_max"}\NormalTok{] }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(np.nanmax(s))}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ write\_health\_report(in\_parquet}\OperatorTok{=}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{,}
\NormalTok{                        out\_json}\OperatorTok{=}\StringTok{"reports/health.json"}\NormalTok{, out\_md}\OperatorTok{=}\StringTok{"reports/health.md"}\NormalTok{):}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ Path(in\_parquet)}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ p.exists():}
        \ControlFlowTok{raise} \PreprocessorTok{SystemExit}\NormalTok{(}\SpecialStringTok{f"Missing }\SpecialCharTok{\{}\NormalTok{in\_parquet}\SpecialCharTok{\}}\SpecialStringTok{."}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(p)}
\NormalTok{    h }\OperatorTok{=}\NormalTok{ df\_health(df)}
\NormalTok{    Path(out\_json).write\_text(json.dumps(h, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{))}
    \CommentTok{\# Render a small Markdown summary}
\NormalTok{    lines }\OperatorTok{=}\NormalTok{ [}
        \StringTok{"\# Data Health Summary"}\NormalTok{,}
        \StringTok{""}\NormalTok{,}
        \SpecialStringTok{f"{-} Rows: **}\SpecialCharTok{\{}\NormalTok{h[}\StringTok{\textquotesingle{}rows\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{**; Cols: **}\SpecialCharTok{\{}\NormalTok{h[}\StringTok{\textquotesingle{}cols\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{**; Tickers: **}\SpecialCharTok{\{}\NormalTok{h[}\StringTok{\textquotesingle{}tickers\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{**"}\NormalTok{,}
        \SpecialStringTok{f"{-} Date range: **}\SpecialCharTok{\{}\NormalTok{h[}\StringTok{\textquotesingle{}date\_min\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{ → }\SpecialCharTok{\{}\NormalTok{h[}\StringTok{\textquotesingle{}date\_max\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{**"}\NormalTok{,}
        \SpecialStringTok{f"{-} Duplicate (ticker,date) rows: **}\SpecialCharTok{\{}\NormalTok{h[}\StringTok{\textquotesingle{}dup\_key\_rows\textquotesingle{}}\NormalTok{]}\SpecialCharTok{\}}\SpecialStringTok{**"}\NormalTok{,}
\NormalTok{    ]}
    \ControlFlowTok{if}\NormalTok{ h.get(}\StringTok{"nulls"}\NormalTok{):}
\NormalTok{        lines }\OperatorTok{+=}\NormalTok{ [}\StringTok{""}\NormalTok{, }\StringTok{"\#\# Top Null Counts"}\NormalTok{, }\StringTok{""}\NormalTok{]}
\NormalTok{        lines }\OperatorTok{+=}\NormalTok{ [}\SpecialStringTok{f"{-} **}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{**: }\SpecialCharTok{\{}\NormalTok{v}\SpecialCharTok{\}}\SpecialStringTok{"} \ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ h[}\StringTok{"nulls"}\NormalTok{].items()]}
\NormalTok{    Path(out\_md).write\_text(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{.join(lines))}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, out\_json, }\StringTok{"and"}\NormalTok{, out\_md)}
\end{Highlighting}
\end{Shaded}

Run once to generate the files:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{python scripts}\OperatorTok{/}\NormalTok{health.py}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Part B --- \textbf{Health Check notebook}
(\texttt{reports/health.ipynb})}{Part B --- Health Check notebook (reports/health.ipynb)}}\label{part-b-health-check-notebook-reportshealth.ipynb}

Create a new notebook \texttt{reports/health.ipynb} with \textbf{two
cells}:

\textbf{Cell 1 (setup):}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\%}\NormalTok{load\_ext autoreload}
\OperatorTok{\%}\NormalTok{autoreload }\DecValTok{2}
\ImportTok{from}\NormalTok{ scripts.health }\ImportTok{import}\NormalTok{ write\_health\_report}
\NormalTok{write\_health\_report()  }\CommentTok{\# writes reports/health.json and reports/health.md}
\end{Highlighting}
\end{Shaded}

\textbf{Cell 2 (display in notebook):}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\BuiltInTok{print}\NormalTok{(Path(}\StringTok{"reports/health.md"}\NormalTok{).read\_text())}
\end{Highlighting}
\end{Shaded}

\begin{quote}
Commit the notebook. It will be light and re‑usable. You'll include its
output in Quarto below.
\end{quote}

\subsection{\texorpdfstring{Part C --- Include health output in your
\textbf{Quarto
report}}{Part C --- Include health output in your Quarto report}}\label{part-c-include-health-output-in-your-quarto-report}

In \texttt{reports/eda.qmd}, add a section:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# Data Health (auto{-}generated)}

\NormalTok{::: \{.cell execution\_count=1\}}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{} \{.python .cell{-}code\}}
\InformationTok{from pathlib import Path}
\InformationTok{print(Path("reports/health.md").read\_text())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Render EDA:
```bash
quarto render reports/eda.qmd
\end{verbatim}

\subsection{\texorpdfstring{Part D --- Add a \textbf{Makefile} target
and a quick
test}{Part D --- Add a Makefile target and a quick test}}\label{part-d-add-a-makefile-target-and-a-quick-test}

\textbf{Makefile append:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.PHONY: health test}
\NormalTok{health: \#\# Generate health.json and health.md from the current features parquet}
\NormalTok{\textbackslash{}tpython scripts/health.py}

\NormalTok{test: \#\# Run fast tests}
\NormalTok{\textbackslash{}tpytest {-}q}
\end{Highlighting}
\end{Shaded}

:::

\textbf{Test that health files exist:}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_health\_outputs.py}
\ImportTok{import}\NormalTok{ os, json}

\KeywordTok{def}\NormalTok{ test\_health\_files\_exist():}
    \ControlFlowTok{assert}\NormalTok{ os.path.exists(}\StringTok{"reports/health.json"}\NormalTok{)}
    \ControlFlowTok{assert}\NormalTok{ os.path.exists(}\StringTok{"reports/health.md"}\NormalTok{)}
    \CommentTok{\# json is valid}
    \ImportTok{import}\NormalTok{ json}
\NormalTok{    json.load(}\BuiltInTok{open}\NormalTok{(}\StringTok{"reports/health.json"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{make}\NormalTok{ health}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}k}\NormalTok{ health}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-6}

\begin{itemize}
\tightlist
\item
  Ensure \texttt{features\_v1.parquet} exists or the fixture's synthetic
  fallback works.
\item
  Dry‑run \texttt{pytest\ -q} in a fresh runtime; keep total time
  \textless{} 5s.
\item
  Prepare 2--3 ``expected failures'' you can toggle (e.g., edit one
  feature column to NaN) to show tests catching bugs.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-6}

\begin{itemize}
\tightlist
\item
  \textbf{Fast tests only} for CI; keep heavy, long recomputations out.
\item
  \textbf{No look‑ahead} and \textbf{unique (ticker,date)} are
  non‑negotiable contracts.
\item
  Logging is a first‑class tool---tests can assert on \textbf{warnings}
  you emit.
\end{itemize}

\section{Grading (pass/revise)}\label{grading-passrevise-5}

\begin{itemize}
\tightlist
\item
  \texttt{tests/test\_features.py} present with \textbf{shapes, nulls,
  look‑ahead ban} (and rolling check).
\item
  Tests pass locally (\texttt{pytest\ -q}).
\item
  \texttt{reports/health.ipynb} and \texttt{reports/health.md/.json}
  exist and integrate into \texttt{eda.qmd}.
\item
  Makefile \texttt{health} and \texttt{test} targets work.
\end{itemize}

You now have a \textbf{safety net} around your data. In \textbf{Session
14}, we'll enforce style with \textbf{pre‑commit} and bring your tests
to \textbf{GitHub Actions CI}.

\bookmarksetup{startatroot}

\chapter{pre‑commit \& GitHub Actions
CI}\label{precommit-github-actions-ci}

Below is a complete lecture package for \textbf{Session 14 ---
pre‑commit \& GitHub Actions CI} (75 minutes). It includes a timed
agenda, slide talking points, a \textbf{Colab‑friendly in‑class lab with
copy‑paste code}, and \textbf{homework with copy‑paste code}. By the
end, your repo will (1) enforce \textbf{style and lint} automatically
with \textbf{pre‑commit} (Black, Ruff, nbstripout), and (2) run
\textbf{CI} on every PR with a fast GitHub Actions workflow that lints
and runs tests in under \textasciitilde3--4 minutes.

\begin{quote}
\textbf{Assumptions:} You completed Session 13 and have a repo in Drive
(e.g., \texttt{unified-stocks-teamX}) with a small test suite
(\texttt{pytest}) and Parquet data present locally. Colab + Drive
workflow assumed. \textbf{Goals today:} Make code quality and basic data
tests automatic and repeatable in CI.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 14 --- pre‑commit \& GitHub Actions CI (75
min)}\label{session-14-precommit-github-actions-ci-75-min}

\subsection{Learning goals}\label{learning-goals-13}

Students will be able to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Configure \textbf{pre‑commit} to run \textbf{Black}, \textbf{Ruff}
  (lint + import sort), and \textbf{nbstripout} on every commit.
\item
  Keep commits clean and \textbf{notebook outputs stripped}.
\item
  Add a fast \textbf{GitHub Actions} CI workflow that runs pre‑commit
  hooks and \textbf{pytest} on each PR.
\item
  Keep CI runtime \textbf{under \textasciitilde3--4 minutes} with
  caching and a lean dependency set.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-11}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: why pre‑commit; the ``quality gate'';
  anatomy of a fast CI
\item
  \textbf{(10 min)} Slides: Black vs Ruff; when nbstripout matters; what
  belongs in CI
\item
  \textbf{(35 min)} \textbf{In‑class lab}: configure pre‑commit (Black,
  Ruff, nbstripout) → run locally → add CI workflow → local dry‑run
\item
  \textbf{(10 min)} Wrap‑up + homework briefing
\item
  \textbf{(10 min)} Buffer
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Main points}\label{main-points-2}

\textbf{Why pre‑commit?}

\begin{itemize}
\tightlist
\item
  Prevent ``drive‑by'' problems before they enter history: unformatted
  code, stray notebook outputs, trailing whitespace.
\item
  Hooks run \textbf{locally on commit}, then again in \textbf{CI} for
  defense‑in‑depth.
\end{itemize}

\textbf{Black \& Ruff}

\begin{itemize}
\tightlist
\item
  \textbf{Black}: opinionated formatter → consistent diffs; no
  bikeshedding.
\item
  \textbf{Ruff}: very fast linter (flake8 family), plus \textbf{import
  sorting}; can also fix many issues (\texttt{-\/-fix}).
\item
  You can use \textbf{both} (common) or let Ruff handle formatting too;
  we'll use both for clarity.
\end{itemize}

\textbf{nbstripout}

\begin{itemize}
\tightlist
\item
  Remove cell outputs from notebooks to keep diffs small, avoid binary
  bloat, and reduce CI time.
\item
  Two patterns: \textbf{pre‑commit hook} (recommended) and/or
  \textbf{git filter} (\texttt{nbstripout\ -\/-install}).
\end{itemize}

\textbf{CI scope (fast!)}

\begin{itemize}
\tightlist
\item
  Lint + tests only; \textbf{no heavy training} in CI.
\item
  Cache dependencies; pin Python (3.11+).
\item
  Keep tests deterministic and \textbf{\textless{} \textasciitilde5s}
  (already done in Session 13).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min,
Colab‑friendly)}\label{inclass-lab-35-min-colabfriendly}

\begin{quote}
Run each block as its \textbf{own Colab cell}. Update
\texttt{REPO\_NAME} to your repo. The cells create and modify files
inside your repo.
\end{quote}

\subsection{0) Mount Drive \& go to repo}\label{mount-drive-go-to-repo}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}  \CommentTok{\# \textless{}{-} change if needed}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{".github/workflows"}\NormalTok{,}\StringTok{"tests"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"reports"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}
\end{Highlighting}
\end{Shaded}

\subsection{1) Install tools locally (for this Colab
runtime)}\label{install-tools-locally-for-this-colab-runtime}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{pip }\OperatorTok{{-}}\NormalTok{q install pre}\OperatorTok{{-}}\NormalTok{commit black ruff nbstripout pytest}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Add \textbf{tool config} to
\texttt{pyproject.toml} (Black +
Ruff)}{2) Add tool config to pyproject.toml (Black + Ruff)}}\label{add-tool-config-to-pyproject.toml-black-ruff}

\begin{quote}
If you don't have a \texttt{pyproject.toml}, this cell will create a
minimal one; otherwise it appends/updates sections.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ textwrap, re}

\NormalTok{pyproj }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"pyproject.toml"}\NormalTok{)}
\NormalTok{existing }\OperatorTok{=}\NormalTok{ pyproj.read\_text() }\ControlFlowTok{if}\NormalTok{ pyproj.exists() }\ControlFlowTok{else} \StringTok{""}

\KeywordTok{def}\NormalTok{ upsert(section\_header, body):}
    \KeywordTok{global}\NormalTok{ existing}
\NormalTok{    pattern }\OperatorTok{=} \VerbatimStringTok{rf"(?ms)\^{}\textbackslash{}[}\SpecialCharTok{\{}\NormalTok{re}\SpecialCharTok{.}\NormalTok{escape(section\_header)}\SpecialCharTok{\}}\VerbatimStringTok{\textbackslash{}]\textbackslash{}s*.*?(?=\^{}\textbackslash{}[|\textbackslash{}Z)"}
    \ControlFlowTok{if}\NormalTok{ re.search(pattern, existing):}
\NormalTok{        existing }\OperatorTok{=}\NormalTok{ re.sub(pattern, }\SpecialStringTok{f"[}\SpecialCharTok{\{}\NormalTok{section\_header}\SpecialCharTok{\}}\SpecialStringTok{]}\CharTok{\textbackslash{}n}\SpecialCharTok{\{}\NormalTok{body}\SpecialCharTok{\}}\CharTok{\textbackslash{}n}\SpecialStringTok{"}\NormalTok{, existing)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        existing }\OperatorTok{+=} \SpecialStringTok{f"}\CharTok{\textbackslash{}n}\SpecialStringTok{[}\SpecialCharTok{\{}\NormalTok{section\_header}\SpecialCharTok{\}}\SpecialStringTok{]}\CharTok{\textbackslash{}n}\SpecialCharTok{\{}\NormalTok{body}\SpecialCharTok{\}}\CharTok{\textbackslash{}n}\SpecialStringTok{"}

\CommentTok{\# Black}
\NormalTok{upsert(}\StringTok{"tool.black"}\NormalTok{, textwrap.dedent(}\StringTok{"""}
\StringTok{line{-}length = 88}
\StringTok{target{-}version = ["py311"]}
\StringTok{"""}\NormalTok{).strip())}

\CommentTok{\# Ruff (modern layout)}
\NormalTok{upsert(}\StringTok{"tool.ruff"}\NormalTok{, textwrap.dedent(}\StringTok{"""}
\StringTok{line{-}length = 88}
\StringTok{target{-}version = "py311"}
\StringTok{"""}\NormalTok{).strip())}

\NormalTok{upsert(}\StringTok{"tool.ruff.lint"}\NormalTok{, textwrap.dedent(}\StringTok{"""}
\StringTok{select = ["E","F","I"]  \# flake8 errors, pyflakes, import sort}
\StringTok{ignore = ["E501"]       \# let Black handle line length}
\StringTok{"""}\NormalTok{).strip())}

\NormalTok{upsert(}\StringTok{"tool.ruff.lint.isort"}\NormalTok{, textwrap.dedent(}\StringTok{"""}
\StringTok{known{-}first{-}party = ["projectname"]}
\StringTok{"""}\NormalTok{).strip())}

\NormalTok{pyproj.write\_text(existing.strip()}\OperatorTok{+}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(pyproj.read\_text())}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Create \texttt{.pre-commit-config.yaml}
with hooks (Black, Ruff,
nbstripout)}{3) Create .pre-commit-config.yaml with hooks (Black, Ruff, nbstripout)}}\label{create-.pre-commit-config.yaml-with-hooks-black-ruff-nbstripout}

\begin{quote}
Versions below are stable at time of writing---feel free to bump later.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{cfg }\OperatorTok{=}\NormalTok{ Path(}\StringTok{".pre{-}commit{-}config.yaml"}\NormalTok{)}
\NormalTok{cfg.write\_text(}\StringTok{"""repos:}
\StringTok{  {-} repo: https://github.com/psf/black}
\StringTok{    rev: 24.4.2}
\StringTok{    hooks:}
\StringTok{      {-} id: black}
\StringTok{        language\_version: python3.11}

\StringTok{  {-} repo: https://github.com/astral{-}sh/ruff{-}pre{-}commit}
\StringTok{    rev: v0.5.0}
\StringTok{    hooks:}
\StringTok{      {-} id: ruff}
\StringTok{        args: [{-}{-}fix, {-}{-}exit{-}non{-}zero{-}on{-}fix]}
\StringTok{      {-} id: ruff{-}format}

\StringTok{  {-} repo: https://github.com/kynan/nbstripout}
\StringTok{    rev: 0.7.1}
\StringTok{    hooks:}
\StringTok{      {-} id: nbstripout}
\StringTok{        files: }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{.ipynb$}

\StringTok{  {-} repo: https://github.com/pre{-}commit/pre{-}commit{-}hooks}
\StringTok{    rev: v4.6.0}
\StringTok{    hooks:}
\StringTok{      {-} id: end{-}of{-}file{-}fixer}
\StringTok{      {-} id: trailing{-}whitespace}
\StringTok{      {-} id: check{-}yaml}
\StringTok{      {-} id: check{-}added{-}large{-}files}
\StringTok{"""}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(cfg.read\_text())}
\end{Highlighting}
\end{Shaded}

\subsection{4) Install the local git hook \& run on all
files}\label{install-the-local-git-hook-run-on-all-files}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{pre}\OperatorTok{{-}}\NormalTok{commit install}
\OperatorTok{!}\NormalTok{pre}\OperatorTok{{-}}\NormalTok{commit run }\OperatorTok{{-}{-}}\BuiltInTok{all}\OperatorTok{{-}}\NormalTok{files}
\end{Highlighting}
\end{Shaded}

\begin{quote}
The first run will \textbf{download} hook toolchains (Black, Ruff,
etc.), format files, and strip notebook outputs. Commit changes after
verifying.
\end{quote}

\subsection{\texorpdfstring{5) (Optional) Also install \textbf{git
filter} for
nbstripout}{5) (Optional) Also install git filter for nbstripout}}\label{optional-also-install-git-filter-for-nbstripout}

\begin{quote}
This is an extra layer; pre‑commit hook above already strips outputs.
Use this to guarantee outputs are removed even when bypassing
pre‑commit.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{nbstripout }\OperatorTok{{-}{-}}\NormalTok{install }\OperatorTok{{-}{-}}\NormalTok{attributes .gitattributes}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{".gitattributes"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

\subsection{6) Add a tiny ``bad style'' file to see hooks in
action}\label{add-a-tiny-bad-style-file-to-see-hooks-in-action}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{p }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"scripts/bad\_style.py"}\NormalTok{)}
\NormalTok{p.write\_text(}\StringTok{"import os,sys}\CharTok{\textbackslash{}n\textbackslash{}n\textbackslash{}n}\StringTok{def add(a,b):}\CharTok{\textbackslash{}n}\StringTok{  return(a +  b)}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote:"}\NormalTok{, p)}

\CommentTok{\# Run hooks just on this file}
\OperatorTok{!}\NormalTok{pre}\OperatorTok{{-}}\NormalTok{commit run }\OperatorTok{{-}{-}}\NormalTok{files scripts}\OperatorTok{/}\NormalTok{bad\_style.py}
\BuiltInTok{print}\NormalTok{(}\BuiltInTok{open}\NormalTok{(}\StringTok{"scripts/bad\_style.py"}\NormalTok{).read())}
\end{Highlighting}
\end{Shaded}

\begin{quote}
You should see Black and Ruff fix spacing/imports; trailing whitespace
hooks may also fire.
\end{quote}

\subsection{\texorpdfstring{7) Add a fast \textbf{GitHub Actions CI}
workflow
(\texttt{.github/workflows/ci.yml})}{7) Add a fast GitHub Actions CI workflow (.github/workflows/ci.yml)}}\label{add-a-fast-github-actions-ci-workflow-.githubworkflowsci.yml}

\begin{quote}
This runs pre‑commit and your tests on Ubuntu with Python 3.11, with pip
caching.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{wf }\OperatorTok{=}\NormalTok{ Path(}\StringTok{".github/workflows/ci.yml"}\NormalTok{)}
\NormalTok{wf.write\_text(}\StringTok{"""name: CI}
\StringTok{on:}
\StringTok{  push:}
\StringTok{    branches: [ main, master, develop ]}
\StringTok{  pull\_request:}
\StringTok{    branches: [ main, master, develop ]}
\StringTok{concurrency:}
\StringTok{  group: $}\SpecialCharTok{\{\{}\StringTok{ github.workflow }\SpecialCharTok{\}\}}\StringTok{{-}$}\SpecialCharTok{\{\{}\StringTok{ github.ref }\SpecialCharTok{\}\}}
\StringTok{  cancel{-}in{-}progress: true}
\StringTok{jobs:}
\StringTok{  build:}
\StringTok{    runs{-}on: ubuntu{-}latest}
\StringTok{    timeout{-}minutes: 10}
\StringTok{    steps:}
\StringTok{      {-} uses: actions/checkout@v4}

\StringTok{      {-} uses: actions/setup{-}python@v5}
\StringTok{        with:}
\StringTok{          python{-}version: \textquotesingle{}3.11\textquotesingle{}}
\StringTok{          cache: \textquotesingle{}pip\textquotesingle{}}
\StringTok{          cache{-}dependency{-}path: |}
\StringTok{            requirements.txt}
\StringTok{            pyproject.toml}

\StringTok{      {-} name: Install dependencies}
\StringTok{        run: |}
\StringTok{          python {-}m pip install {-}{-}upgrade pip}
\StringTok{          if [ {-}f requirements.txt ]; then pip install {-}r requirements.txt; fi}
\StringTok{          pip install pre{-}commit pytest}

\StringTok{      \# Run pre{-}commit (Black, Ruff, nbstripout, etc.)}
\StringTok{      {-} name: pre{-}commit}
\StringTok{        uses: pre{-}commit/action@v3.0.1}

\StringTok{      \# Run tests (fast only)}
\StringTok{      {-} name: pytest}
\StringTok{        run: pytest {-}q {-}{-}maxfail=1}
\StringTok{"""}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(wf.read\_text())}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{8) Add a \texttt{Makefile} convenience
(optional but
nice)}{8) Add a Makefile convenience (optional but nice)}}\label{add-a-makefile-convenience-optional-but-nice}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{mk }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"Makefile"}\NormalTok{)}
\NormalTok{text }\OperatorTok{=}\NormalTok{ mk.read\_text() }\ControlFlowTok{if}\NormalTok{ mk.exists() }\ControlFlowTok{else} \StringTok{""}
\ControlFlowTok{if} \StringTok{"lint"} \KeywordTok{not} \KeywordTok{in}\NormalTok{ text:}
\NormalTok{    text }\OperatorTok{+=} \StringTok{"""}

\StringTok{.PHONY: lint test ci{-}local}
\StringTok{lint: \#\# Run pre{-}commit hooks on all files}
\CharTok{\textbackslash{}t}\StringTok{pre{-}commit run {-}{-}all{-}files}

\StringTok{test: \#\# Run fast tests}
\CharTok{\textbackslash{}t}\StringTok{pytest {-}q {-}{-}maxfail=1}

\StringTok{ci{-}local: lint test \#\# Simulate CI locally}
\StringTok{"""}
\NormalTok{    mk.write\_text(text)}
\BuiltInTok{print}\NormalTok{(mk.read\_text())}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-7}

\begin{itemize}
\tightlist
\item
  You configured \textbf{pre‑commit} with \textbf{Black}, \textbf{Ruff}
  (lint + import sort), and \textbf{nbstripout} to keep the repo clean.
\item
  You added a fast \textbf{CI} that runs the same hooks plus
  \textbf{pytest} on every PR.
\item
  CI time stays small due to \textbf{caching} and a \textbf{lean
  dependency set}; tests are fast by design (Session 13).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before next
session)}\label{homework-due-before-next-session}

\textbf{Goal:} Prove the workflow works end‑to‑end with a green PR from
a \textbf{fresh clone}.

\subsection{Part A --- Fresh‑clone smoke test
(local)}\label{part-a-freshclone-smoke-test-local}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# On your laptop or a new Colab session:}
\FunctionTok{git}\NormalTok{ clone https://github.com/YOUR\_USER/unified{-}stocks{-}teamX.git}
\BuiltInTok{cd}\NormalTok{ unified{-}stocks{-}teamX}
\ExtensionTok{python} \AttributeTok{{-}m}\NormalTok{ pip install }\AttributeTok{{-}U}\NormalTok{ pip}
\ExtensionTok{pip}\NormalTok{ install pre{-}commit pytest}
\ExtensionTok{pre{-}commit}\NormalTok{ install}
\ExtensionTok{pre{-}commit}\NormalTok{ run }\AttributeTok{{-}{-}all{-}files}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}{-}maxfail}\OperatorTok{=}\NormalTok{1}
\end{Highlighting}
\end{Shaded}

\subsection{Part B --- Open a PR that turns CI
green}\label{part-b-open-a-pr-that-turns-ci-green}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Create a branch} and make a tiny, style‑breaking change, then
  commit and let pre‑commit fix it automatically.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{git}\NormalTok{ checkout }\AttributeTok{{-}b}\NormalTok{ chore/ci{-}badge{-}and{-}hooks}
\BuiltInTok{echo} \StringTok{"\# Tiny edit  "} \OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ README.md   }\CommentTok{\# trailing spaces (will be fixed)}
\FunctionTok{git}\NormalTok{ add }\AttributeTok{{-}A}
\FunctionTok{git}\NormalTok{ commit }\AttributeTok{{-}m} \StringTok{"chore: add CI badge + enable pre{-}commit hooks"}
\FunctionTok{git}\NormalTok{ push }\AttributeTok{{-}u}\NormalTok{ origin chore/ci{-}badge{-}and{-}hooks}
\end{Highlighting}
\end{Shaded}
\item
  \textbf{Add a CI badge} to \texttt{README.md}:

\begin{Shaded}
\begin{Highlighting}[]
\AlertTok{![CI](https://github.com/YOUR\_USER/unified{-}stocks{-}teamX/actions/workflows/ci.yml/badge.svg)}
\end{Highlighting}
\end{Shaded}
\item
  Open a \textbf{Pull Request} on GitHub. Verify that:

  \begin{itemize}
  \tightlist
  \item
    The \textbf{pre‑commit} step passes.
  \item
    \textbf{pytest} passes.
  \item
    Total runtime is \textbf{\textless{} \textasciitilde3--4 minutes}.
  \end{itemize}
\item
  Merge once green. (If red, fix locally; do \emph{not} disable hooks.)
\end{enumerate}

\subsection{Part C --- (Optional) Tune Ruff + Black to your
taste}\label{part-c-optional-tune-ruff-black-to-your-taste}

\begin{itemize}
\item
  In \texttt{pyproject.toml}, try:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{[tool.black]}
\DataTypeTok{line{-}length} \OperatorTok{=} \DecValTok{100}

\KeywordTok{[tool.ruff]}
\DataTypeTok{line{-}length} \OperatorTok{=} \DecValTok{100}

\KeywordTok{[tool.ruff.lint]}
\DataTypeTok{select} \OperatorTok{=} \OperatorTok{[}\StringTok{"E"}\OperatorTok{,}\StringTok{"F"}\OperatorTok{,}\StringTok{"I"}\OperatorTok{,}\StringTok{"B"}\OperatorTok{]}  \CommentTok{\# enable flake8{-}bugbear}
\DataTypeTok{ignore} \OperatorTok{=} \OperatorTok{[}\StringTok{"E501"}\OperatorTok{]}
\end{Highlighting}
\end{Shaded}
\item
  Run \texttt{pre-commit\ run\ -\/-all-files} and ensure CI remains
  green.
\end{itemize}

\subsection{Part D --- (Optional) Add notebook QA without executing
them}\label{part-d-optional-add-notebook-qa-without-executing-them}

\begin{itemize}
\item
  Add \textbf{nbqa} to run Ruff on notebooks (markdown \& code cells):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# append to .pre{-}commit{-}config.yaml}
\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{repo}\KeywordTok{:}\AttributeTok{ https://github.com/nbQA{-}dev/nbQA}
\AttributeTok{  }\FunctionTok{rev}\KeywordTok{:}\AttributeTok{ }\FloatTok{1.8.5}
\AttributeTok{  }\FunctionTok{hooks}\KeywordTok{:}
\AttributeTok{    }\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{id}\KeywordTok{:}\AttributeTok{ nbqa{-}ruff}
\AttributeTok{      }\FunctionTok{args}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{{-}{-}fix}\KeywordTok{]}
\AttributeTok{      }\FunctionTok{additional\_dependencies}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\AttributeTok{ruff==}\FloatTok{0.5.0}\KeywordTok{]}
\end{Highlighting}
\end{Shaded}
\item
  Re‑install hooks and run \texttt{pre-commit\ run\ -\/-all-files}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Reference checklist (for
grading)}\label{reference-checklist-for-grading}

\begin{itemize}
\tightlist
\item
  \texttt{.pre-commit-config.yaml} present with \textbf{Black, Ruff,
  nbstripout}.
\item
  \texttt{pyproject.toml} includes \textbf{{[}tool.black{]}} and
  \textbf{{[}tool.ruff{]}} sections.
\item
  \texttt{.github/workflows/ci.yml} runs \textbf{pre‑commit} and
  \textbf{pytest} with \textbf{Python 3.11} and pip caching.
\item
  \texttt{make\ lint}, \texttt{make\ test}, \texttt{make\ ci-local} work
  (if you added them).
\item
  A PR was opened and CI is \textbf{green}; README has the \textbf{CI
  badge}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor tips / gotchas}\label{instructor-tips-gotchas}

\begin{itemize}
\tightlist
\item
  If pre‑commit says ``no files to check'' for nbstripout, ensure your
  \textbf{file matcher} \texttt{files:\ \textbackslash{}.ipynb\$} is
  correct and that notebooks are tracked.
\item
  If Ruff conflicts with Black on formatting: keep \textbf{Black} as the
  authority, disable \texttt{E501} in Ruff, and let Ruff handle
  \textbf{imports} (\texttt{I}) and errors (\texttt{E}, \texttt{F}).
\item
  CI failures from missing deps: ensure your \texttt{requirements.txt}
  (or \texttt{pyproject.toml} with \texttt{{[}project.dependencies{]}})
  includes \textbf{pandas}, \textbf{pyarrow}, and \textbf{pytest} if
  your tests read Parquet.
\item
  Keep CI lean: no data downloads or training; use \textbf{fixtures} and
  tiny synthetic datasets (Session 13 pattern).
\end{itemize}

You now have an automated quality gate---\textbf{style, lint, and tests
run locally and in CI}---so your future PRs start green and stay green.

\bookmarksetup{startatroot}

\chapter{Session 15 --- Framing \& Metrics (Rolling‑Origin
Evaluation)}\label{session-15-framing-metrics-rollingorigin-evaluation}

Below is a complete lecture package for \textbf{Session 15 --- Framing
\& Metrics (Rolling‑Origin Evaluation)} (75 minutes). It includes a
timed agenda, slide talking points, a \textbf{Colab‑friendly in‑class
lab with copy‑paste code}, and \textbf{homework with copy‑paste code}.
You'll formalize the forecasting problem (horizon/step), implement a
\textbf{rolling‑origin splitter} (a.k.a. walk‑forward), and evaluate
\textbf{naive} and \textbf{seasonal‑naive} baselines with \textbf{MAE,
sMAPE, MASE}, aggregated \textbf{across tickers} (macro vs
micro/weighted).

\begin{quote}
\textbf{Educational use only --- not trading advice.} Assumes your repo
in Drive (e.g., \texttt{unified-stocks-teamX}) and
\texttt{data/processed/returns.parquet} from Session 9. If missing, the
lab creates a small fallback.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 15 --- Framing \& Metrics (75
min)}\label{session-15-framing-metrics-75-min}

\subsection{Learning goals}\label{learning-goals-14}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Specify \textbf{forecast horizon} \(H\), \textbf{step} (stride), and
  choose between \textbf{expanding} vs \textbf{sliding} rolling‑origin
  evaluation with an \textbf{embargo} gap.
\item
  Implement a \textbf{date‑based splitter} that yields
  \texttt{(train\_idx,\ val\_idx)} for all tickers at once.
\item
  Compute \textbf{MAE}, \textbf{sMAPE}, \textbf{MASE} (with a proper
  \textbf{training‑window scale}), and aggregate \textbf{per‑ticker} and
  \textbf{across tickers} (macro vs micro/weighted).
\item
  Produce a tidy CSV of baseline results to serve as your course's
  ground truth.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-12}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: forecasting setup --- horizon \(H\), step,
  rolling‑origin (expanding vs sliding), embargo
\item
  \textbf{(10 min)} Slides: metrics --- MAE, sMAPE, MASE; aggregation
  across tickers (macro vs micro/weighted)
\item
  \textbf{(35 min)} \textbf{In‑class lab}: implement a date‑based
  splitter → compute naive \& seasonal‑naive baselines → MAE/sMAPE/MASE
  per split/ticker → save reports
\item
  \textbf{(10 min)} Wrap‑up \& homework brief
\item
  \textbf{(10 min)} Buffer
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points (add these bullets to your
deck)}\label{slides-talking-points-add-these-bullets-to-your-deck}

\subsection{Framing the forecast}\label{framing-the-forecast}

\begin{itemize}
\item
  \textbf{Target:} next‑day log return \(r_{t+1}\) (you built this as
  \texttt{r\_1d}).
\item
  \textbf{Horizon \(H\):} 1 business day.
\item
  \textbf{Step (stride):} how far the \textbf{origin} moves forward each
  split (e.g., 63 trading days ≈ a quarter).
\item
  \textbf{Rolling‑origin schemes}

  \begin{itemize}
  \tightlist
  \item
    \textbf{Expanding:} train start fixed; \textbf{train grows} over
    time.
  \item
    \textbf{Sliding (rolling):} fixed‑length train window
    \textbf{slides} forward.
  \end{itemize}
\item
  \textbf{Embargo:} small \textbf{gap} (e.g., 5 days) between train end
  and validation start to avoid adjacency leakage.
\end{itemize}

\subsection{Metrics (scalar, easy to
compare)}\label{metrics-scalar-easy-to-compare}

\begin{itemize}
\item
  \textbf{MAE:} \(\frac{1}{n}\sum |y - \hat{y}|\) --- robust \&
  interpretable.
\item
  \textbf{sMAPE:}
  \(\frac{2}{n}\sum \frac{|y - \hat{y}|}{(|y| + |\hat{y}| + \epsilon)}\)
  --- scale‑free, safe for near‑zero returns with \(\epsilon\).
\item
  \textbf{MASE:}
  \(\text{MASE}=\frac{\text{MAE}_\text{model}}{\text{MAE}_\text{naive (train)}}\)
  --- \textless1 means better than naive.

  \begin{itemize}
  \tightlist
  \item
    For seasonality \(s\), the \textbf{naive comparator} predicts
    \(y_{t+1} \approx y_{t+1-s}\) (we'll use \(s=5\) for day‑of‑week
    seasonality on business days).
  \item
    \textbf{Scale} is computed on the \textbf{training window only}, per
    ticker.
  \end{itemize}
\end{itemize}

\subsection{Aggregation across
tickers}\label{aggregation-across-tickers}

\begin{itemize}
\tightlist
\item
  \textbf{Per‑ticker metrics} first → then aggregate.
\item
  \textbf{Macro average:} mean of per‑ticker metrics (each ticker equal
  weight).
\item
  \textbf{Micro/weighted:} pool all rows (or weight tickers by sample
  count); for MAE, pooled MAE equals sample‑count weighted average of
  per‑ticker MAEs.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min,
Colab‑friendly)}\label{inclass-lab-35-min-colabfriendly-1}

\begin{quote}
Run each block as its own cell. Adjust \texttt{REPO\_NAME} if needed.
\end{quote}

\subsection{0) Setup \& fallback data}\label{setup-fallback-data}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}  \CommentTok{\# \textless{}{-} change to your repo name}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/raw"}\NormalTok{,}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"reports"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{]:}
\NormalTok{    Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}

\CommentTok{\# Load returns or create a tiny fallback}
\NormalTok{rpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ rpath.exists():}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ pd.read\_parquet(rpath)}
\ControlFlowTok{else}\NormalTok{:}
    \CommentTok{\# Fallback synthetic returns for 5 tickers, 320 business days}
\NormalTok{    rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\NormalTok{    dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{320}\NormalTok{)}
\NormalTok{    frames}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ tkr }\KeywordTok{in}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{]:}
\NormalTok{        eps }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.012}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)).astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        adj }\OperatorTok{=} \DecValTok{100}\OperatorTok{*}\NormalTok{np.exp(np.cumsum(eps))}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
            \StringTok{"date"}\NormalTok{: dates,}
            \StringTok{"ticker"}\NormalTok{: tkr,}
            \StringTok{"adj\_close"}\NormalTok{: adj.astype(}\StringTok{"float32"}\NormalTok{),}
            \StringTok{"log\_return"}\NormalTok{: np.r\_[np.nan, np.diff(np.log(adj))].astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        \})}
\NormalTok{        df[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"log\_return"}\NormalTok{].shift(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{        df[}\StringTok{"weekday"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.weekday.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{        df[}\StringTok{"month"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.month.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{        frames.append(df)}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ pd.concat(frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    returns[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ returns[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{    returns.to\_parquet(rpath, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\CommentTok{\# Standardize}
\NormalTok{returns[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(returns[}\StringTok{"date"}\NormalTok{])}
\NormalTok{returns }\OperatorTok{=}\NormalTok{ returns.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{returns[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ returns[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{returns.head()}
\end{Highlighting}
\end{Shaded}

\subsection{1) Rolling‑origin date splitter (expanding windows +
embargo)}\label{rollingorigin-date-splitter-expanding-windows-embargo}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}

\KeywordTok{def}\NormalTok{ make\_rolling\_origin\_splits(dates: pd.Series,}
\NormalTok{                               train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{,   }\CommentTok{\# \textasciitilde{}1y of trading days}
\NormalTok{                               val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{,     }\CommentTok{\# \textasciitilde{}1 quarter}
\NormalTok{                               step}\OperatorTok{=}\DecValTok{63}\NormalTok{,}
\NormalTok{                               embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
    \CommentTok{"""Return a list of (train\_start, train\_end, val\_start, val\_end) date tuples."""}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(dates.unique())))}
\NormalTok{    n }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(u)}
\NormalTok{    splits}\OperatorTok{=}\NormalTok{[]}
\NormalTok{    i }\OperatorTok{=}\NormalTok{ train\_min }\OperatorTok{{-}} \DecValTok{1}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{\textgreater{}=}\NormalTok{ n: }\ControlFlowTok{break}
\NormalTok{        tr\_start, tr\_end }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}
\NormalTok{        vs\_idx }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ embargo }\OperatorTok{+} \DecValTok{1}
\NormalTok{        ve\_idx }\OperatorTok{=}\NormalTok{ vs\_idx }\OperatorTok{+}\NormalTok{ val\_size }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve\_idx }\OperatorTok{\textgreater{}=}\NormalTok{ n: }\ControlFlowTok{break}
\NormalTok{        splits.append((tr\_start, tr\_end, u[vs\_idx], u[ve\_idx]))}
\NormalTok{        i }\OperatorTok{+=}\NormalTok{ step}
    \ControlFlowTok{return}\NormalTok{ splits}

\KeywordTok{def}\NormalTok{ splits\_to\_indices(df, split):}
    \CommentTok{"""Map a date split to index arrays for the full multi{-}ticker frame."""}
\NormalTok{    a,b,c,d }\OperatorTok{=}\NormalTok{ split}
\NormalTok{    tr\_idx }\OperatorTok{=}\NormalTok{ df.index[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a) }\OperatorTok{\&}\NormalTok{ (df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)].to\_numpy()}
\NormalTok{    va\_idx }\OperatorTok{=}\NormalTok{ df.index[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c) }\OperatorTok{\&}\NormalTok{ (df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)].to\_numpy()}
    \CommentTok{\# sanity: embargo =\textgreater{} last train date \textless{} first val date}
    \ControlFlowTok{assert}\NormalTok{ b }\OperatorTok{\textless{}}\NormalTok{ c}
    \ControlFlowTok{return}\NormalTok{ tr\_idx, va\_idx}

\NormalTok{splits }\OperatorTok{=}\NormalTok{ make\_rolling\_origin\_splits(returns[}\StringTok{"date"}\NormalTok{], train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\BuiltInTok{len}\NormalTok{(splits), splits[:}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\subsection{2) Metrics \& baseline predictors (naive and
seasonal‑naive)}\label{metrics-baseline-predictors-naive-and-seasonalnaive}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ typing }\ImportTok{import}\NormalTok{ Dict, Tuple}

\KeywordTok{def}\NormalTok{ mae(y, yhat): }
\NormalTok{    y }\OperatorTok{=}\NormalTok{ np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.asarray(yhat)}\OperatorTok{;} 
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat)))}

\KeywordTok{def}\NormalTok{ smape(y, yhat, eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{):}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.asarray(yhat)}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(}\FloatTok{2.0}\OperatorTok{*}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat)}\OperatorTok{/}\NormalTok{(np.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps)))}

\KeywordTok{def}\NormalTok{ mase(y\_true, y\_pred, y\_train\_true, y\_train\_naive):}
    \CommentTok{\# Scale = MAE of comparator (naive) on TRAIN only; add tiny epsilon}
\NormalTok{    scale }\OperatorTok{=}\NormalTok{ mae(y\_train\_true, y\_train\_naive) }\OperatorTok{+} \FloatTok{1e{-}12}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(mae(y\_true, y\_pred) }\OperatorTok{/}\NormalTok{ scale)}

\KeywordTok{def}\NormalTok{ add\_baseline\_preds(df: pd.DataFrame, seasonality:}\BuiltInTok{int}\OperatorTok{=}\DecValTok{5}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame:}
    \CommentTok{"""}
\CommentTok{    For each ticker:}
\CommentTok{      {-} naive predicts r\_\{t+1\} ≈ log\_return\_t (s=1)}
\CommentTok{      {-} seasonal naive (s) predicts r\_\{t+1\} ≈ log\_return\_\{t+1{-}s\}  =\textgreater{} shift(s{-}1)}
\CommentTok{    Adds columns: yhat\_naive, yhat\_s\{s\}}
\CommentTok{    """}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    out[}\StringTok{"yhat\_naive"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].transform(}\KeywordTok{lambda}\NormalTok{ s: s)  }\CommentTok{\# s=1}
    \ControlFlowTok{if}\NormalTok{ seasonality }\OperatorTok{\textless{}=} \DecValTok{1}\NormalTok{:}
\NormalTok{        out[}\StringTok{"yhat\_s"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out[}\StringTok{"yhat\_naive"}\NormalTok{]}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        out[}\StringTok{"yhat\_s"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].transform(}\KeywordTok{lambda}\NormalTok{ s: s.shift(seasonality}\OperatorTok{{-}}\DecValTok{1}\NormalTok{))}
    \ControlFlowTok{return}\NormalTok{ out}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Evaluate baselines across \textbf{first 2
splits} (fast in
class)}{3) Evaluate baselines across first 2 splits (fast in class)}}\label{evaluate-baselines-across-first-2-splits-fast-in-class}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Precompute predictions over the entire frame once (safe: uses only past values via shift)}
\NormalTok{seasonality }\OperatorTok{=} \DecValTok{5}  \CommentTok{\# business{-}day weekly}
\NormalTok{preds\_all }\OperatorTok{=}\NormalTok{ add\_baseline\_preds(returns, seasonality}\OperatorTok{=}\NormalTok{seasonality)}

\KeywordTok{def}\NormalTok{ per\_ticker\_metrics(df\_val, df\_train, method}\OperatorTok{=}\StringTok{"naive"}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame:}
    \CommentTok{"""}
\CommentTok{    Compute per{-}ticker MAE, sMAPE, MASE for the chosen method (\textquotesingle{}naive\textquotesingle{} or \textquotesingle{}s\textquotesingle{}).}
\CommentTok{    MASE scale uses TRAIN window and the same comparator as method.}
\CommentTok{    """}
\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
\NormalTok{    col }\OperatorTok{=} \StringTok{"yhat\_naive"} \ControlFlowTok{if}\NormalTok{ method}\OperatorTok{==}\StringTok{"naive"} \ControlFlowTok{else} \StringTok{"yhat\_s"}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ df\_val.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        gv }\OperatorTok{=}\NormalTok{ g.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{, col])}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(gv)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }
            \ControlFlowTok{continue}
        \CommentTok{\# TRAIN scale (per ticker)}
\NormalTok{        gt }\OperatorTok{=}\NormalTok{ df\_train[df\_train[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr].dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{])}
        \ControlFlowTok{if}\NormalTok{ method}\OperatorTok{==}\StringTok{"naive"}\NormalTok{:}
\NormalTok{            gt\_pred }\OperatorTok{=}\NormalTok{ gt[}\StringTok{"log\_return"}\NormalTok{]  }\CommentTok{\# s=1}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            gt\_pred }\OperatorTok{=}\NormalTok{ gt[}\StringTok{"log\_return"}\NormalTok{].shift(seasonality}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{        gt\_clean }\OperatorTok{=}\NormalTok{ gt.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{]).copy()}
\NormalTok{        gt\_pred }\OperatorTok{=}\NormalTok{ gt\_pred.loc[gt\_clean.index]}
\NormalTok{        gt\_clean }\OperatorTok{=}\NormalTok{ gt\_clean.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{])}
        \CommentTok{\# Align indices}
\NormalTok{        y\_tr }\OperatorTok{=}\NormalTok{ gt\_clean[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy()}
\NormalTok{        yhat\_tr\_naive }\OperatorTok{=}\NormalTok{ gt\_pred.to\_numpy()}
        \CommentTok{\# VAL metrics}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ gv[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy()}
\NormalTok{        yhat }\OperatorTok{=}\NormalTok{ gv[col].to\_numpy()}
\NormalTok{        rows.append(\{}
            \StringTok{"ticker"}\NormalTok{: tkr,}
            \StringTok{"n"}\NormalTok{: }\BuiltInTok{int}\NormalTok{(}\BuiltInTok{len}\NormalTok{(y)),}
            \StringTok{"mae"}\NormalTok{: mae(y,yhat),}
            \StringTok{"smape"}\NormalTok{: smape(y,yhat),}
            \StringTok{"mase"}\NormalTok{: mase(y, yhat, y\_tr, yhat\_tr\_naive),}
\NormalTok{        \})}
    \ControlFlowTok{return}\NormalTok{ pd.DataFrame(rows)}

\KeywordTok{def}\NormalTok{ aggregate\_across\_tickers(per\_ticker\_df: pd.DataFrame) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Dict[}\BuiltInTok{str}\NormalTok{,}\BuiltInTok{float}\NormalTok{]:}
    \ControlFlowTok{if}\NormalTok{ per\_ticker\_df.empty:}
        \ControlFlowTok{return}\NormalTok{ \{}\StringTok{"macro\_mae"}\NormalTok{:np.nan,}\StringTok{"macro\_smape"}\NormalTok{:np.nan,}\StringTok{"macro\_mase"}\NormalTok{:np.nan,}
                \StringTok{"micro\_mae"}\NormalTok{:np.nan,}\StringTok{"micro\_smape"}\NormalTok{:np.nan,}\StringTok{"micro\_mase"}\NormalTok{:np.nan\}}
    \CommentTok{\# Macro = unweighted mean across tickers}
\NormalTok{    macro }\OperatorTok{=}\NormalTok{ per\_ticker\_df[[}\StringTok{"mae"}\NormalTok{,}\StringTok{"smape"}\NormalTok{,}\StringTok{"mase"}\NormalTok{]].mean().to\_dict()}
    \CommentTok{\# Micro/weighted by n (pooled)}
\NormalTok{    w }\OperatorTok{=}\NormalTok{ per\_ticker\_df[}\StringTok{"n"}\NormalTok{].to\_numpy()}
\NormalTok{    micro }\OperatorTok{=}\NormalTok{ \{}
        \StringTok{"micro\_mae"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(per\_ticker\_df[}\StringTok{"mae"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
        \StringTok{"micro\_smape"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(per\_ticker\_df[}\StringTok{"smape"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
        \StringTok{"micro\_mase"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(per\_ticker\_df[}\StringTok{"mase"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
\NormalTok{    \}}
    \ControlFlowTok{return}\NormalTok{ \{}\SpecialStringTok{f"macro\_}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(v) }\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ macro.items()\} }\OperatorTok{|}\NormalTok{ micro}

\CommentTok{\# Run on 2 splits in class; you can expand later}
\ImportTok{import}\NormalTok{ pathlib, json}
\NormalTok{pathlib.Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{rows}\OperatorTok{=}\NormalTok{[]}
\ControlFlowTok{for}\NormalTok{ sid, split }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(splits[:}\DecValTok{2}\NormalTok{], start}\OperatorTok{=}\DecValTok{1}\NormalTok{):}
\NormalTok{    a,b,c,d }\OperatorTok{=}\NormalTok{ split}
\NormalTok{    tr\_idx, va\_idx }\OperatorTok{=}\NormalTok{ splits\_to\_indices(returns, split)}
\NormalTok{    tr }\OperatorTok{=}\NormalTok{ preds\_all.loc[tr\_idx].copy()}
\NormalTok{    va }\OperatorTok{=}\NormalTok{ preds\_all.loc[va\_idx].copy()}
    \CommentTok{\# Per{-}ticker metrics for two baselines}
\NormalTok{    pt\_naive }\OperatorTok{=}\NormalTok{ per\_ticker\_metrics(va, tr, method}\OperatorTok{=}\StringTok{"naive"}\NormalTok{)}
\NormalTok{    pt\_s     }\OperatorTok{=}\NormalTok{ per\_ticker\_metrics(va, tr, method}\OperatorTok{=}\StringTok{"s"}\NormalTok{)}
\NormalTok{    agg\_naive }\OperatorTok{=}\NormalTok{ aggregate\_across\_tickers(pt\_naive)}
\NormalTok{    agg\_s     }\OperatorTok{=}\NormalTok{ aggregate\_across\_tickers(pt\_s)}
    \CommentTok{\# Save per{-}split, per{-}ticker}
\NormalTok{    pt\_naive.to\_csv(}\SpecialStringTok{f"reports/baseline\_naive\_split}\SpecialCharTok{\{}\NormalTok{sid}\SpecialCharTok{\}}\SpecialStringTok{.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{    pt\_s.to\_csv(}\SpecialStringTok{f"reports/baseline\_s}\SpecialCharTok{\{}\NormalTok{seasonality}\SpecialCharTok{\}}\SpecialStringTok{\_split}\SpecialCharTok{\{}\NormalTok{sid}\SpecialCharTok{\}}\SpecialStringTok{.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{    rows.append(\{}
        \StringTok{"split"}\NormalTok{: sid,}
        \StringTok{"train\_range"}\NormalTok{: }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{b}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}
        \StringTok{"val\_range"}\NormalTok{: }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{c}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{d}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}
        \StringTok{"method"}\NormalTok{: }\StringTok{"naive"}\NormalTok{, }\OperatorTok{**}\NormalTok{agg\_naive}
\NormalTok{    \})}
\NormalTok{    rows.append(\{}
        \StringTok{"split"}\NormalTok{: sid,}
        \StringTok{"train\_range"}\NormalTok{: }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{b}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}
        \StringTok{"val\_range"}\NormalTok{: }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{c}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{d}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}
        \StringTok{"method"}\NormalTok{: }\SpecialStringTok{f"s}\SpecialCharTok{\{}\NormalTok{seasonality}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{, }\OperatorTok{**}\NormalTok{agg\_s}
\NormalTok{    \})}

\NormalTok{summary }\OperatorTok{=}\NormalTok{ pd.DataFrame(rows)}
\NormalTok{summary.to\_csv(}\StringTok{"reports/baselines\_rollingorigin\_summary.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\subsection{4) Quick sanity assertions (no overlap; embargo
honored)}\label{quick-sanity-assertions-no-overlap-embargo-honored}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ check\_no\_overlap(df, split):}
\NormalTok{    a,b,c,d }\OperatorTok{=}\NormalTok{ split}
    \ControlFlowTok{assert}\NormalTok{ b }\OperatorTok{\textless{}}\NormalTok{ c, }\SpecialStringTok{f"Embargo violation: train\_end }\SpecialCharTok{\{}\NormalTok{b}\SpecialCharTok{\}}\SpecialStringTok{ \textgreater{}= val\_start }\SpecialCharTok{\{}\NormalTok{c}\SpecialCharTok{\}}\SpecialStringTok{"}
\NormalTok{    tr\_idx, va\_idx }\OperatorTok{=}\NormalTok{ splits\_to\_indices(df, split)}
    \ControlFlowTok{assert} \BuiltInTok{set}\NormalTok{(tr\_idx).isdisjoint(}\BuiltInTok{set}\NormalTok{(va\_idx))}
    \ControlFlowTok{return} \VariableTok{True}

\BuiltInTok{all}\NormalTok{(check\_no\_overlap(returns, s) }\ControlFlowTok{for}\NormalTok{ s }\KeywordTok{in}\NormalTok{ splits[:}\DecValTok{2}\NormalTok{]), }\BuiltInTok{len}\NormalTok{(summary)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-8}

\begin{itemize}
\tightlist
\item
  You now have a \textbf{date‑based rolling‑origin splitter} with an
  \textbf{embargo}, and \textbf{baseline metrics} that set a credible
  reference.
\item
  \textbf{MASE} uses a \textbf{training‑window naive} as scale (per
  ticker), so you can read ``\textless1 is better than naive'' at a
  glance.
\item
  Aggregation: report both \textbf{macro} (per‑ticker average) and
  \textbf{micro/weighted} (pooled).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
16)}\label{homework-due-before-session-16}

\textbf{Goal:} Build a small CLI to reproduce these baselines over
\textbf{all splits}, then generate per‑ticker \& aggregated tables.

\subsection{\texorpdfstring{Part A --- Script:
\texttt{scripts/baselines\_eval.py}}{Part A --- Script: scripts/baselines\_eval.py}}\label{part-a-script-scriptsbaselines_eval.py}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/usr/bin/env python}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ argparse, numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\KeywordTok{def}\NormalTok{ mae(y,yhat): }\ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(np.asarray(y)}\OperatorTok{{-}}\NormalTok{np.asarray(yhat))))}
\KeywordTok{def}\NormalTok{ smape(y,yhat,eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{):}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.asarray(yhat)}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(}\DecValTok{2}\OperatorTok{*}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(y}\OperatorTok{{-}}\NormalTok{yhat)}\OperatorTok{/}\NormalTok{(np.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps)))}
\KeywordTok{def}\NormalTok{ mase(y\_true, y\_pred, y\_train\_true, y\_train\_naive):}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(mae(y\_true, y\_pred) }\OperatorTok{/}\NormalTok{ (mae(y\_train\_true, y\_train\_naive)}\OperatorTok{+}\FloatTok{1e{-}12}\NormalTok{))}

\KeywordTok{def}\NormalTok{ make\_splits(dates, train\_min, val\_size, step, embargo):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(dates.unique())))}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(u)}\OperatorTok{;}\NormalTok{ out}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{ i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        a,b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}\OperatorTok{;}\NormalTok{ vs }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ embargo }\OperatorTok{+} \DecValTok{1}\OperatorTok{;}\NormalTok{ ve }\OperatorTok{=}\NormalTok{ vs }\OperatorTok{+}\NormalTok{ val\_size }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        out.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=}\NormalTok{ step}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ add\_preds(df, s):}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    out[}\StringTok{"yhat\_naive"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].transform(}\KeywordTok{lambda}\NormalTok{ x: x)}
\NormalTok{    out[}\StringTok{"yhat\_s"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].transform(}\KeywordTok{lambda}\NormalTok{ x: x.shift(s}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)) }\ControlFlowTok{if}\NormalTok{ s}\OperatorTok{\textgreater{}}\DecValTok{1} \ControlFlowTok{else}\NormalTok{ out[}\StringTok{"yhat\_naive"}\NormalTok{]}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ per\_ticker(df\_val, df\_train, method, s):}
\NormalTok{    col }\OperatorTok{=} \StringTok{"yhat\_naive"} \ControlFlowTok{if}\NormalTok{ method}\OperatorTok{==}\StringTok{"naive"} \ControlFlowTok{else} \StringTok{"yhat\_s"}
\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ df\_val.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        gv }\OperatorTok{=}\NormalTok{ g.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{, col])}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(gv)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{        gt }\OperatorTok{=}\NormalTok{ df\_train[df\_train[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr].dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{])}
\NormalTok{        gt\_pred }\OperatorTok{=}\NormalTok{ gt[}\StringTok{"log\_return"}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ method}\OperatorTok{==}\StringTok{"naive"} \ControlFlowTok{else}\NormalTok{ gt[}\StringTok{"log\_return"}\NormalTok{].shift(s}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{        gt\_pred }\OperatorTok{=}\NormalTok{ gt\_pred.loc[gt.index]}
\NormalTok{        y\_tr }\OperatorTok{=}\NormalTok{ gt[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy()}\OperatorTok{;}\NormalTok{ yhat\_tr }\OperatorTok{=}\NormalTok{ gt\_pred.to\_numpy()}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ gv[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy()}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ gv[col].to\_numpy()}
\NormalTok{        rows.append(\{}\StringTok{"ticker"}\NormalTok{:tkr,}\StringTok{"n"}\NormalTok{:}\BuiltInTok{int}\NormalTok{(}\BuiltInTok{len}\NormalTok{(y)),}
                     \StringTok{"mae"}\NormalTok{: mae(y,yhat),}
                     \StringTok{"smape"}\NormalTok{: smape(y,yhat),}
                     \StringTok{"mase"}\NormalTok{: mase(y,yhat,y\_tr,yhat\_tr)\})}
    \ControlFlowTok{return}\NormalTok{ pd.DataFrame(rows)}

\KeywordTok{def}\NormalTok{ agg(pt):}
    \ControlFlowTok{if}\NormalTok{ pt.empty: }\ControlFlowTok{return}\NormalTok{ \{}\StringTok{"macro\_mae"}\NormalTok{:np.nan,}\StringTok{"macro\_smape"}\NormalTok{:np.nan,}\StringTok{"macro\_mase"}\NormalTok{:np.nan,}
                         \StringTok{"micro\_mae"}\NormalTok{:np.nan,}\StringTok{"micro\_smape"}\NormalTok{:np.nan,}\StringTok{"micro\_mase"}\NormalTok{:np.nan\}}
\NormalTok{    macro }\OperatorTok{=}\NormalTok{ pt[[}\StringTok{"mae"}\NormalTok{,}\StringTok{"smape"}\NormalTok{,}\StringTok{"mase"}\NormalTok{]].mean().to\_dict()}
\NormalTok{    w }\OperatorTok{=}\NormalTok{ pt[}\StringTok{"n"}\NormalTok{].to\_numpy()}
\NormalTok{    micro }\OperatorTok{=}\NormalTok{ \{}
        \StringTok{"micro\_mae"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(pt[}\StringTok{"mae"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
        \StringTok{"micro\_smape"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(pt[}\StringTok{"smape"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
        \StringTok{"micro\_mase"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(pt[}\StringTok{"mase"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
\NormalTok{    \}}
    \ControlFlowTok{return}\NormalTok{ \{}\SpecialStringTok{f"macro\_}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(v) }\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ macro.items()\} }\OperatorTok{|}\NormalTok{ micro}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    ap }\OperatorTok{=}\NormalTok{ argparse.ArgumentParser()}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}returns"}\NormalTok{, default}\OperatorTok{=}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}seasonality"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}train{-}min"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{252}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}val{-}size"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{63}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}step"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{63}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}embargo"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}out{-}summary"}\NormalTok{, default}\OperatorTok{=}\StringTok{"reports/baselines\_rollingorigin\_summary.csv"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}out{-}per{-}ticker"}\NormalTok{, default}\OperatorTok{=}\StringTok{"reports/baselines\_per\_ticker\_split}\SpecialCharTok{\{sid\}}\StringTok{\_}\SpecialCharTok{\{method\}}\StringTok{.csv"}\NormalTok{)}
\NormalTok{    args }\OperatorTok{=}\NormalTok{ ap.parse\_args()}

\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(args.returns).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    splits }\OperatorTok{=}\NormalTok{ make\_splits(df[}\StringTok{"date"}\NormalTok{], args.train\_min, args.val\_size, args.step, args.embargo)}
\NormalTok{    pred }\OperatorTok{=}\NormalTok{ add\_preds(df, args.seasonality)}

\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ sid, (a,b,c,d) }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(splits, start}\OperatorTok{=}\DecValTok{1}\NormalTok{):}
\NormalTok{        tr }\OperatorTok{=}\NormalTok{ pred[(pred[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(pred[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)]}
\NormalTok{        va }\OperatorTok{=}\NormalTok{ pred[(pred[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c)}\OperatorTok{\&}\NormalTok{(pred[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)]}
        \ControlFlowTok{for}\NormalTok{ method }\KeywordTok{in}\NormalTok{ [}\StringTok{"naive"}\NormalTok{,}\StringTok{"s"}\NormalTok{]:}
\NormalTok{            pt }\OperatorTok{=}\NormalTok{ per\_ticker(va, tr, method, args.seasonality)}
\NormalTok{            Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{            pt.to\_csv(args.out\_per\_ticker.}\BuiltInTok{format}\NormalTok{(sid}\OperatorTok{=}\NormalTok{sid, method}\OperatorTok{=}\NormalTok{method), index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{            rows.append(\{}\StringTok{"split"}\NormalTok{:sid,}\StringTok{"train\_range"}\NormalTok{:}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{b}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}\StringTok{"val\_range"}\NormalTok{:}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{c}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{d}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}
                         \StringTok{"method"}\NormalTok{:}\StringTok{"naive"} \ControlFlowTok{if}\NormalTok{ method}\OperatorTok{==}\StringTok{"naive"} \ControlFlowTok{else} \SpecialStringTok{f"s}\SpecialCharTok{\{}\NormalTok{args}\SpecialCharTok{.}\NormalTok{seasonality}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{, }\OperatorTok{**}\NormalTok{agg(pt)\})}
\NormalTok{    pd.DataFrame(rows).to\_csv(args.out\_summary, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, args.out\_summary, }\StringTok{"and per{-}ticker CSVs."}\NormalTok{)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Make executable \& run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/baselines\_eval.py}
\ExtensionTok{python}\NormalTok{ scripts/baselines\_eval.py }\AttributeTok{{-}{-}seasonality}\NormalTok{ 5}
\end{Highlighting}
\end{Shaded}

\subsection{Part B --- Plot a tiny, informative results
figure}\label{part-b-plot-a-tiny-informative-results-figure}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt, pathlib}
\NormalTok{pathlib.Path(}\StringTok{"docs/figs"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{summary }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"reports/baselines\_rollingorigin\_summary.csv"}\NormalTok{)}
\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{6}\NormalTok{,}\FloatTok{3.5}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{ method, g }\KeywordTok{in}\NormalTok{ summary.groupby(}\StringTok{"method"}\NormalTok{):}
\NormalTok{    plt.plot(g[}\StringTok{"split"}\NormalTok{], g[}\StringTok{"micro\_mae"}\NormalTok{], marker}\OperatorTok{=}\StringTok{"o"}\NormalTok{, label}\OperatorTok{=}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{method}\SpecialCharTok{\}}\SpecialStringTok{ micro MAE"}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{"Split"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.ylabel(}\StringTok{"MAE"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.title(}\StringTok{"Baseline MAE across splits"}\NormalTok{)}
\NormalTok{plt.legend()}\OperatorTok{;}\NormalTok{ plt.tight\_layout()}
\NormalTok{plt.savefig(}\StringTok{"docs/figs/baselines\_mae\_splits.png"}\NormalTok{, dpi}\OperatorTok{=}\DecValTok{200}\NormalTok{)}
\CommentTok{"Saved docs/figs/baselines\_mae\_splits.png"}
\end{Highlighting}
\end{Shaded}

\subsection{Part C --- Add a quick test to protect the
splitter}\label{part-c-add-a-quick-test-to-protect-the-splitter}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_rolling\_splitter.py}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ datetime }\ImportTok{import}\NormalTok{ timedelta}

\KeywordTok{def}\NormalTok{ make\_splits(dates, train\_min, val\_size, step, embargo):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(dates.unique())))}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(u)}\OperatorTok{;}\NormalTok{ out}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{ i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        a,b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val\_size}\OperatorTok{{-}}\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        out.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+=}\NormalTok{step}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ test\_embargo\_and\_order():}
\NormalTok{    dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2024{-}01{-}01"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{400}\NormalTok{)}
\NormalTok{    s }\OperatorTok{=}\NormalTok{ make\_splits(pd.Series(dates), }\DecValTok{252}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{5}\NormalTok{)}
    \ControlFlowTok{assert} \BuiltInTok{all}\NormalTok{(b }\OperatorTok{\textless{}}\NormalTok{ c }\ControlFlowTok{for}\NormalTok{ (a,b,c,d) }\KeywordTok{in}\NormalTok{ s), }\StringTok{"Embargo/order violated"}
    \CommentTok{\# Splits should move forward}
    \ControlFlowTok{assert} \BuiltInTok{len}\NormalTok{(s) }\OperatorTok{\textgreater{}=} \DecValTok{2} \KeywordTok{and}\NormalTok{ s[}\DecValTok{1}\NormalTok{][}\DecValTok{1}\NormalTok{] }\OperatorTok{\textgreater{}}\NormalTok{ s[}\DecValTok{0}\NormalTok{][}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}k}\NormalTok{ rolling\_splitter}
\end{Highlighting}
\end{Shaded}

\subsection{Part D --- (Optional) Makefile
targets}\label{part-d-optional-makefile-targets}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.PHONY: baselines}
\NormalTok{baselines: \#\# Evaluate naive \& seasonal{-}naive baselines across all splits}
\NormalTok{\textbackslash{}tpython scripts/baselines\_eval.py {-}{-}seasonality 5}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-7}

\begin{itemize}
\tightlist
\item
  Ensure \texttt{returns.parquet} exists or fallback works.
\item
  Be ready to whiteboard \textbf{why} the seasonal naïve for daily data
  uses \texttt{s=5}.
\item
  Emphasize \textbf{MASE scale from TRAIN} and \textbf{macro vs micro}
  aggregation.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-7}

\begin{itemize}
\tightlist
\item
  \textbf{Define the problem first} (H, step, splits); metrics only make
  sense after framing.
\item
  \textbf{MASE \textless{} 1} ⇒ better than naïve; report both macro \&
  micro.
\item
  \textbf{Embargo} helps mitigate adjacency leakage; keep it small but
  nonzero.
\end{itemize}

\section{Grading (pass/revise)}\label{grading-passrevise-6}

\begin{itemize}
\tightlist
\item
  Rolling‑origin splitter implemented and used (train/val ranges
  printed).
\item
  Reports written: \texttt{baselines\_rollingorigin\_summary.csv} and
  per‑ticker CSVs per split \& method.
\item
  Metrics include \textbf{MAE}, \textbf{sMAPE}, \textbf{MASE};
  aggregation includes \textbf{macro} and \textbf{micro}.
\item
  A test asserts basic splitter properties (no overlap; forward
  progress).
\end{itemize}

You now have clear \textbf{framing and metrics} for your project. In
Session 16, you'll fit \textbf{classical baselines} (e.g., lags‑only
linear, ARIMA/ETS quick sketches) and log them in the same results table
schema.

\bookmarksetup{startatroot}

\chapter{Session 16}\label{session-16}

Below is a complete lecture package for \textbf{Session 16 --- Classical
Baselines} (75 minutes). It includes a timed agenda, slide talking
points, a \textbf{Colab‑friendly in‑class lab with copy‑paste code}, and
\textbf{homework with copy‑paste code}. In class you'll train a
\textbf{lags‑only linear regressor per ticker} and compare it to the
\textbf{naive} and \textbf{seasonal‑naive} baselines from Session 15.
You'll also see a short, optional \textbf{ARIMA} demo and log results in
a consistent schema for future comparison.

\begin{quote}
\textbf{Educational use only --- not trading advice.} Assumes your repo
(e.g., \texttt{unified-stocks-teamX}) with
\texttt{data/processed/returns.parquet} and
\texttt{data/processed/features\_v1.parquet} from Sessions 9--10. Cells
include safe fallbacks if some files are missing.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 16 --- Classical baselines (75
min)}\label{session-16-classical-baselines-75-min}

\subsection{Learning goals}\label{learning-goals-15}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Fit a \textbf{per‑ticker} lags‑only linear regressor to predict
  \textbf{next‑day log return} \(r_{t+1}\).
\item
  Evaluate models with \textbf{MAE, sMAPE, MASE} using the
  \textbf{rolling‑origin splits} (with embargo) from Session 15.
\item
  Log results in a \textbf{consistent table schema} for per‑ticker and
  split‑level summaries.
\item
  Understand \textbf{ARIMA} at a glance and its common pitfalls
  (optional demo).
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-13}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: where classical models fit; pitfalls with
  ARIMA; cross‑sectional regressors
\item
  \textbf{(10 min)} Slides: results table schema \& comparison to
  baselines
\item
  \textbf{(35 min)} \textbf{In‑class lab}: train per‑ticker
  \textbf{Linear (lags‑only)} → evaluate across 2 splits → compare to
  naive/seasonal‑naive → log CSVs
\item
  \textbf{(10 min)} Wrap‑up + homework brief
\item
  \textbf{(10 min)} Buffer
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points}\label{slides-talking-points-2}

\subsection{Why ``classical'' now?}\label{why-classical-now}

\begin{itemize}
\tightlist
\item
  Creates a \textbf{credible, strong baseline} against naive that's
  still transparent.
\item
  Supports \textbf{fast iteration} and helps you debug feature
  definitions before deep models.
\end{itemize}

\subsection{Lags‑only linear regressor}\label{lagsonly-linear-regressor}

\begin{itemize}
\tightlist
\item
  \textbf{Features} at time \(t\): \texttt{lag1}, \texttt{lag2},
  \texttt{lag3} (i.e., past returns), optionally a few stable stats
  (\texttt{roll\_std\_20}, \texttt{zscore\_20}).
\item
  \textbf{Target}: \texttt{r\_1d} (next‑day log return).
\item
  Fit \textbf{per ticker} to avoid cross‑sectional leakage for now.
\end{itemize}

\subsection{ARIMA 60‑second pitfall
tour}\label{arima-60second-pitfall-tour}

\begin{itemize}
\tightlist
\item
  Stationarity: \textbf{fit on returns}, not prices (unless
  differencing).
\item
  Evaluation: \textbf{re‑fit only on train}; generate
  \textbf{one‑step‑ahead} forecasts on val, updating state
  \textbf{without peeking}.
\item
  Over‑differencing \& mis‑specified seasonal terms → bad bias.
\item
  Computational cost grows with grid search; keep demo tiny.
\end{itemize}

\subsection{Results table schema (consistent across
sessions)}\label{results-table-schema-consistent-across-sessions}

\begin{itemize}
\tightlist
\item
  \textbf{Per‑split summary}:
  \texttt{split,\ train\_range,\ val\_range,\ model,\ macro\_mae,\ macro\_smape,\ macro\_mase,\ micro\_mae,\ micro\_smape,\ micro\_mase}
\item
  \textbf{Per‑ticker metrics}:
  \texttt{split,\ ticker,\ n,\ model,\ mae,\ smape,\ mase}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min,
Colab‑friendly)}\label{inclass-lab-35-min-colabfriendly-2}

\begin{quote}
Run each block as its \textbf{own cell}. Update \texttt{REPO\_NAME} if
needed.
\end{quote}

\subsection{0) Setup \& data (with
fallbacks)}\label{setup-data-with-fallbacks}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}  \CommentTok{\# \textless{}{-} change if needed}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/raw"}\NormalTok{,}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"reports"}\NormalTok{,}\StringTok{"models"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{]:}
\NormalTok{    Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}

\CommentTok{\# Load returns; if missing, synthesize}
\NormalTok{rpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ rpath.exists():}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ pd.read\_parquet(rpath)}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\NormalTok{    dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{360}\NormalTok{)}
\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{]:}
\NormalTok{        eps }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.012}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)).astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        adj }\OperatorTok{=} \DecValTok{100}\OperatorTok{*}\NormalTok{np.exp(np.cumsum(eps))}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
            \StringTok{"date"}\NormalTok{: dates, }\StringTok{"ticker"}\NormalTok{: t,}
            \StringTok{"adj\_close"}\NormalTok{: adj.astype(}\StringTok{"float32"}\NormalTok{),}
            \StringTok{"log\_return"}\NormalTok{: np.r\_[np.nan, np.diff(np.log(adj))].astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        \})}
\NormalTok{        df[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"log\_return"}\NormalTok{].shift(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{        df[}\StringTok{"weekday"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.weekday.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{        df[}\StringTok{"month"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.month.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{        rows.append(df)}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ pd.concat(rows, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    returns[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ returns[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{    returns.to\_parquet(rpath, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\CommentTok{\# Load features\_v1 or derive minimal lags from returns if missing}
\NormalTok{fpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ fpath.exists():}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ pd.read\_parquet(fpath)}
\ControlFlowTok{else}\NormalTok{:}
    \CommentTok{\# Minimal lags derived just from returns}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ returns.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).copy()}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]:}
\NormalTok{        feats[}\SpecialStringTok{f"lag}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{=}\NormalTok{ feats.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].shift(k)}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ feats.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Harmonize}
\NormalTok{feats[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(feats[}\StringTok{"date"}\NormalTok{])}
\NormalTok{feats[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ feats[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{feats }\OperatorTok{=}\NormalTok{ feats.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{feats.head()}
\end{Highlighting}
\end{Shaded}

\subsection{1) Rolling‑origin date splits (reuse Session 15
logic)}\label{rollingorigin-date-splits-reuse-session-15-logic}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ make\_rolling\_origin\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    splits}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{ i }\OperatorTok{=}\NormalTok{ train\_min}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(u)}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        a,b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val\_size}\OperatorTok{{-}}\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        splits.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+=}\NormalTok{step}
    \ControlFlowTok{return}\NormalTok{ splits}

\NormalTok{splits }\OperatorTok{=}\NormalTok{ make\_rolling\_origin\_splits(feats[}\StringTok{"date"}\NormalTok{], }\DecValTok{252}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\BuiltInTok{len}\NormalTok{(splits), splits[:}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\subsection{2) Metrics \& baselines (from Session
15)}\label{metrics-baselines-from-session-15}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ mae(y, yhat): }
\NormalTok{    y }\OperatorTok{=}\NormalTok{ np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.asarray(yhat)}\OperatorTok{;} 
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat)))}

\KeywordTok{def}\NormalTok{ smape(y, yhat, eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{):}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.asarray(yhat)}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(}\FloatTok{2.0}\OperatorTok{*}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat)}\OperatorTok{/}\NormalTok{(np.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps)))}

\KeywordTok{def}\NormalTok{ mase(y\_true, y\_pred, y\_train\_true, y\_train\_naive):}
\NormalTok{    scale }\OperatorTok{=}\NormalTok{ mae(y\_train\_true, y\_train\_naive) }\OperatorTok{+} \FloatTok{1e{-}12}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(mae(y\_true, y\_pred)}\OperatorTok{/}\NormalTok{scale)}

\KeywordTok{def}\NormalTok{ add\_baseline\_preds(df: pd.DataFrame, seasonality:}\BuiltInTok{int}\OperatorTok{=}\DecValTok{5}\NormalTok{) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame:}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    out[}\StringTok{"yhat\_naive"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].transform(}\KeywordTok{lambda}\NormalTok{ s: s)}
\NormalTok{    out[}\StringTok{"yhat\_s"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].transform(}\KeywordTok{lambda}\NormalTok{ s: s.shift(seasonality}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)) }\ControlFlowTok{if}\NormalTok{ seasonality}\OperatorTok{\textgreater{}}\DecValTok{1} \ControlFlowTok{else}\NormalTok{ out[}\StringTok{"yhat\_naive"}\NormalTok{]}
    \ControlFlowTok{return}\NormalTok{ out}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) \textbf{Per‑ticker lags‑only
LinearRegression} (fit only on each split's
TRAIN)}{3) Per‑ticker lags‑only LinearRegression (fit only on each split's TRAIN)}}\label{perticker-lagsonly-linearregression-fit-only-on-each-splits-train}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\ImportTok{from}\NormalTok{ sklearn.pipeline }\ImportTok{import}\NormalTok{ Pipeline}

\CommentTok{\# Choose features (lags only for in{-}class lab)}
\NormalTok{XCOLS }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ [}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ feats.columns]}
\ControlFlowTok{assert}\NormalTok{ XCOLS, }\StringTok{"No lag features found. Ensure features\_v1 or fallback creation ran."}

\KeywordTok{def}\NormalTok{ fit\_predict\_lin\_lags(train\_df, val\_df):}
    \CommentTok{"""Fit per{-}ticker pipeline(StandardScaler, LinearRegression) on TRAIN; predict on VAL."""}
\NormalTok{    preds}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ tkr, tr }\KeywordTok{in}\NormalTok{ train\_df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        va }\OperatorTok{=}\NormalTok{ val\_df[val\_df[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr]}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(tr)}\OperatorTok{==}\DecValTok{0} \KeywordTok{or} \BuiltInTok{len}\NormalTok{(va)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }
            \ControlFlowTok{continue}
\NormalTok{        pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{"scaler"}\NormalTok{, StandardScaler(with\_mean}\OperatorTok{=}\VariableTok{True}\NormalTok{, with\_std}\OperatorTok{=}\VariableTok{True}\NormalTok{)),}
\NormalTok{                         (}\StringTok{"lr"}\NormalTok{, LinearRegression())])}
\NormalTok{        pipe.fit(tr[XCOLS].values, tr[}\StringTok{"r\_1d"}\NormalTok{].values)}
\NormalTok{        yhat }\OperatorTok{=}\NormalTok{ pipe.predict(va[XCOLS].values)}
\NormalTok{        out }\OperatorTok{=}\NormalTok{ va[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{]].copy()}
\NormalTok{        out[}\StringTok{"yhat\_linlags"}\NormalTok{] }\OperatorTok{=}\NormalTok{ yhat.astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        preds.append(out)}
    \ControlFlowTok{return}\NormalTok{ pd.concat(preds, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ preds }\ControlFlowTok{else}\NormalTok{ pd.DataFrame(columns}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"yhat\_linlags"}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) Evaluate \textbf{across the first 2
splits}; compare to
naive/seasonal‑naive}{4) Evaluate across the first 2 splits; compare to naive/seasonal‑naive}}\label{evaluate-across-the-first-2-splits-compare-to-naiveseasonalnaive}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{seasonality }\OperatorTok{=} \DecValTok{5}
\NormalTok{feats\_baseline }\OperatorTok{=}\NormalTok{ add\_baseline\_preds(feats, seasonality}\OperatorTok{=}\NormalTok{seasonality)}

\KeywordTok{def}\NormalTok{ per\_ticker\_metrics(df\_val\_pred, df\_train, method\_col):}
\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ tkr, gv }\KeywordTok{in}\NormalTok{ df\_val\_pred.groupby(}\StringTok{"ticker"}\NormalTok{):}
        \ControlFlowTok{if}\NormalTok{ method\_col }\KeywordTok{not} \KeywordTok{in}\NormalTok{ gv: }
            \ControlFlowTok{continue}
\NormalTok{        gv }\OperatorTok{=}\NormalTok{ gv.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{, method\_col])}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(gv)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }
            \ControlFlowTok{continue}
        \CommentTok{\# TRAIN scale for MASE}
\NormalTok{        gt }\OperatorTok{=}\NormalTok{ df\_train[df\_train[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr].dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{])}
\NormalTok{        gt\_naive }\OperatorTok{=}\NormalTok{ gt[}\StringTok{"log\_return"}\NormalTok{] }\ControlFlowTok{if} \StringTok{"yhat\_s"} \KeywordTok{not} \KeywordTok{in}\NormalTok{ method\_col }\ControlFlowTok{else}\NormalTok{ gt[}\StringTok{"log\_return"}\NormalTok{].shift(seasonality}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{        gt\_naive }\OperatorTok{=}\NormalTok{ gt\_naive.loc[gt.index]}
\NormalTok{        rows.append(\{}
            \StringTok{"ticker"}\NormalTok{: tkr,}
            \StringTok{"n"}\NormalTok{: }\BuiltInTok{int}\NormalTok{(}\BuiltInTok{len}\NormalTok{(gv)),}
            \StringTok{"mae"}\NormalTok{: mae(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[method\_col]),}
            \StringTok{"smape"}\NormalTok{: smape(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[method\_col]),}
            \StringTok{"mase"}\NormalTok{: mase(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[method\_col], gt[}\StringTok{"r\_1d"}\NormalTok{], gt\_naive),}
\NormalTok{        \})}
    \ControlFlowTok{return}\NormalTok{ pd.DataFrame(rows)}

\KeywordTok{def}\NormalTok{ summarize\_split(feats\_frame, sid, split, save\_prefix}\OperatorTok{=}\StringTok{"linlags"}\NormalTok{):}
\NormalTok{    a,b,c,d }\OperatorTok{=}\NormalTok{ split}
\NormalTok{    tr }\OperatorTok{=}\NormalTok{ feats\_frame[(feats\_frame[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(feats\_frame[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)].copy()}
\NormalTok{    va }\OperatorTok{=}\NormalTok{ feats\_frame[(feats\_frame[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c)}\OperatorTok{\&}\NormalTok{(feats\_frame[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)].copy()}
    \CommentTok{\# Predictions}
\NormalTok{    val\_pred }\OperatorTok{=}\NormalTok{ fit\_predict\_lin\_lags(tr, va)}
    \CommentTok{\# Attach baseline preds on val slice}
\NormalTok{    va\_base }\OperatorTok{=}\NormalTok{ add\_baseline\_preds(va, seasonality}\OperatorTok{=}\NormalTok{seasonality)}
\NormalTok{    val\_pred }\OperatorTok{=}\NormalTok{ val\_pred.merge(va\_base[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"yhat\_naive"}\NormalTok{,}\StringTok{"yhat\_s"}\NormalTok{]], on}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{], how}\OperatorTok{=}\StringTok{"left"}\NormalTok{)}

    \CommentTok{\# Per{-}ticker metrics}
\NormalTok{    pt\_lin }\OperatorTok{=}\NormalTok{ per\_ticker\_metrics(val\_pred, tr, }\StringTok{"yhat\_linlags"}\NormalTok{)}\OperatorTok{;}\NormalTok{ pt\_lin[}\StringTok{"model"}\NormalTok{] }\OperatorTok{=} \StringTok{"lin\_lags"}
\NormalTok{    pt\_nav }\OperatorTok{=}\NormalTok{ per\_ticker\_metrics(val\_pred.rename(columns}\OperatorTok{=}\NormalTok{\{}\StringTok{"yhat\_naive"}\NormalTok{:}\StringTok{"yhat\_linlags"}\NormalTok{\}), tr, }\StringTok{"yhat\_linlags"}\NormalTok{)}\OperatorTok{;}\NormalTok{ pt\_nav[}\StringTok{"model"}\NormalTok{]}\OperatorTok{=}\StringTok{"naive"}
\NormalTok{    pt\_sea }\OperatorTok{=}\NormalTok{ per\_ticker\_metrics(val\_pred.rename(columns}\OperatorTok{=}\NormalTok{\{}\StringTok{"yhat\_s"}\NormalTok{:}\StringTok{"yhat\_linlags"}\NormalTok{\}), tr, }\StringTok{"yhat\_linlags"}\NormalTok{)}\OperatorTok{;}\NormalTok{ pt\_sea[}\StringTok{"model"}\NormalTok{]}\OperatorTok{=}\SpecialStringTok{f"s}\SpecialCharTok{\{}\NormalTok{seasonality}\SpecialCharTok{\}}\SpecialStringTok{"}

    \CommentTok{\# Save per{-}ticker}
\NormalTok{    out\_pt }\OperatorTok{=}\NormalTok{ pd.concat([pt\_lin.assign(split}\OperatorTok{=}\NormalTok{sid), pt\_nav.assign(split}\OperatorTok{=}\NormalTok{sid), pt\_sea.assign(split}\OperatorTok{=}\NormalTok{sid)], ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    out\_pt.to\_csv(}\SpecialStringTok{f"reports/}\SpecialCharTok{\{}\NormalTok{save\_prefix}\SpecialCharTok{\}}\SpecialStringTok{\_per\_ticker\_split}\SpecialCharTok{\{}\NormalTok{sid}\SpecialCharTok{\}}\SpecialStringTok{.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

    \CommentTok{\# Aggregate}
    \KeywordTok{def}\NormalTok{ agg(df):}
        \ControlFlowTok{if}\NormalTok{ df.empty: }
            \ControlFlowTok{return}\NormalTok{ \{}\StringTok{"macro\_mae"}\NormalTok{:np.nan,}\StringTok{"macro\_smape"}\NormalTok{:np.nan,}\StringTok{"macro\_mase"}\NormalTok{:np.nan,}\StringTok{"micro\_mae"}\NormalTok{:np.nan,}\StringTok{"micro\_smape"}\NormalTok{:np.nan,}\StringTok{"micro\_mase"}\NormalTok{:np.nan\}}
\NormalTok{        macro }\OperatorTok{=}\NormalTok{ df[[}\StringTok{"mae"}\NormalTok{,}\StringTok{"smape"}\NormalTok{,}\StringTok{"mase"}\NormalTok{]].mean().to\_dict()}
\NormalTok{        w }\OperatorTok{=}\NormalTok{ df[}\StringTok{"n"}\NormalTok{].to\_numpy()}
\NormalTok{        micro }\OperatorTok{=}\NormalTok{ \{}\StringTok{"micro\_mae"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(df[}\StringTok{"mae"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
                 \StringTok{"micro\_smape"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(df[}\StringTok{"smape"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
                 \StringTok{"micro\_mase"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(df[}\StringTok{"mase"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w))\}}
        \ControlFlowTok{return}\NormalTok{ \{}\SpecialStringTok{f"macro\_}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{:}\BuiltInTok{float}\NormalTok{(v) }\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ macro.items()\} }\OperatorTok{|}\NormalTok{ micro}

\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ name, pt }\KeywordTok{in}\NormalTok{ [(}\StringTok{"lin\_lags"}\NormalTok{, pt\_lin), (}\StringTok{"naive"}\NormalTok{, pt\_nav), (}\SpecialStringTok{f"s}\SpecialCharTok{\{}\NormalTok{seasonality}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{, pt\_sea)]:}
\NormalTok{        rows.append(\{}\StringTok{"split"}\NormalTok{:sid, }\StringTok{"train\_range"}\NormalTok{: }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{b}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}
                     \StringTok{"val\_range"}\NormalTok{: }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{c}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{d}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}
                     \StringTok{"model"}\NormalTok{:name, }\OperatorTok{**}\NormalTok{agg(pt)\})}
    \ControlFlowTok{return}\NormalTok{ pd.DataFrame(rows)}

\CommentTok{\# Run on first 2 splits in class}
\NormalTok{summary\_frames}\OperatorTok{=}\NormalTok{[]}
\ControlFlowTok{for}\NormalTok{ sid, split }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(splits[:}\DecValTok{2}\NormalTok{], start}\OperatorTok{=}\DecValTok{1}\NormalTok{):}
\NormalTok{    sf }\OperatorTok{=}\NormalTok{ summarize\_split(feats\_baseline, sid, split, save\_prefix}\OperatorTok{=}\StringTok{"linlags"}\NormalTok{)}
\NormalTok{    summary\_frames.append(sf)}

\NormalTok{summary }\OperatorTok{=}\NormalTok{ pd.concat(summary\_frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{summary.to\_csv(}\StringTok{"reports/linlags\_summary\_splits12.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{5) (Optional) Tiny ARIMA demo on \textbf{one
ticker} for the first
split}{5) (Optional) Tiny ARIMA demo on one ticker for the first split}}\label{optional-tiny-arima-demo-on-one-ticker-for-the-first-split}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Optional: quick ARIMA(1,0,0) demo predicting r\_\{t+1\} on val for a single ticker}
\ControlFlowTok{try}\NormalTok{:}
    \ImportTok{from}\NormalTok{ statsmodels.tsa.arima.model }\ImportTok{import}\NormalTok{ ARIMA}
    \ImportTok{import}\NormalTok{ warnings}\OperatorTok{;}\NormalTok{ warnings.filterwarnings(}\StringTok{"ignore"}\NormalTok{)}
\NormalTok{    a,b,c,d }\OperatorTok{=}\NormalTok{ splits[}\DecValTok{0}\NormalTok{]}
\NormalTok{    tkr }\OperatorTok{=}\NormalTok{ feats[}\StringTok{"ticker"}\NormalTok{].cat.categories[}\DecValTok{0}\NormalTok{]}
\NormalTok{    tr }\OperatorTok{=}\NormalTok{ feats[(feats[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr) }\OperatorTok{\&}\NormalTok{ (feats[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a) }\OperatorTok{\&}\NormalTok{ (feats[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)]}
\NormalTok{    va }\OperatorTok{=}\NormalTok{ feats[(feats[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr) }\OperatorTok{\&}\NormalTok{ (feats[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c) }\OperatorTok{\&}\NormalTok{ (feats[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)]}
    \CommentTok{\# Fit on TRAIN returns only (endog = log\_return). Predict one{-}step ahead for VAL dates.}
\NormalTok{    model }\OperatorTok{=}\NormalTok{ ARIMA(tr[}\StringTok{"log\_return"}\NormalTok{].to\_numpy(), order}\OperatorTok{=}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{))}
\NormalTok{    res }\OperatorTok{=}\NormalTok{ model.fit()}
    \CommentTok{\# Forecast length = len(va), one{-}step{-}ahead with dynamic=False updates internally}
    \CommentTok{\# (For strict no{-}peek rolling one{-}step, loop and append val true values; here we keep demo simple.)}
\NormalTok{    fc }\OperatorTok{=}\NormalTok{ res.forecast(steps}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(va))}
\NormalTok{    arima\_mae }\OperatorTok{=}\NormalTok{ mae(va[}\StringTok{"r\_1d"}\NormalTok{], fc)  }\CommentTok{\# compare against next{-}day return}
    \BuiltInTok{float}\NormalTok{(arima\_mae)}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"ARIMA demo skipped:"}\NormalTok{, e)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
⚠️ ARIMA is \textbf{optional} and \textbf{slow} on large loops. If you
try it per ticker/per split, keep the dataset tiny.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-9}

\begin{itemize}
\tightlist
\item
  You trained a \textbf{per‑ticker lags‑only linear} model and compared
  it fairly to \textbf{naive} and \textbf{seasonal‑naive} using the
  \textbf{same splits} and \textbf{MASE scale} (from the train window).
\item
  You logged results in a \textbf{stable schema} that you'll reuse for
  future models (LSTM / Transformer).
\item
  ARIMA can be illustrative but is often \textbf{fragile + slower};
  treat it as optional for your project scale.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before next
session)}\label{homework-due-before-next-session-1}

\textbf{Goal:} 1) Run the linear lags baseline across \textbf{all
splits}; 2) Write your \textbf{first model card} (Quarto) for the
classical baseline.

\subsection{\texorpdfstring{Part A --- CLI script to evaluate
Linear‑Lags across \emph{all}
splits}{Part A --- CLI script to evaluate Linear‑Lags across all splits}}\label{part-a-cli-script-to-evaluate-linearlags-across-all-splits}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scripts/eval\_linlags.py}
\CommentTok{\#!/usr/bin/env python}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ argparse, numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ sklearn.pipeline }\ImportTok{import}\NormalTok{ Pipeline}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\KeywordTok{def}\NormalTok{ mae(y,yhat): }\ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(np.asarray(y)}\OperatorTok{{-}}\NormalTok{np.asarray(yhat))))}
\KeywordTok{def}\NormalTok{ smape(y,yhat,eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{):}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.asarray(yhat)}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(}\DecValTok{2}\OperatorTok{*}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(y}\OperatorTok{{-}}\NormalTok{yhat)}\OperatorTok{/}\NormalTok{(np.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps)))}
\KeywordTok{def}\NormalTok{ mase(y\_true, y\_pred, y\_train\_true, y\_train\_naive):}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(mae(y\_true, y\_pred) }\OperatorTok{/}\NormalTok{ (mae(y\_train\_true, y\_train\_naive)}\OperatorTok{+}\FloatTok{1e{-}12}\NormalTok{))}

\KeywordTok{def}\NormalTok{ make\_splits(dates, train\_min, val\_size, step, embargo):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    splits}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{ i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(u)}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        a,b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val\_size}\OperatorTok{{-}}\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        splits.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+=}\NormalTok{step}
    \ControlFlowTok{return}\NormalTok{ splits}

\KeywordTok{def}\NormalTok{ add\_baselines(df, seasonality):}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    out[}\StringTok{"yhat\_naive"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].transform(}\KeywordTok{lambda}\NormalTok{ s: s)}
\NormalTok{    out[}\StringTok{"yhat\_s"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].transform(}\KeywordTok{lambda}\NormalTok{ s: s.shift(seasonality}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)) }\ControlFlowTok{if}\NormalTok{ seasonality}\OperatorTok{\textgreater{}}\DecValTok{1} \ControlFlowTok{else}\NormalTok{ out[}\StringTok{"yhat\_naive"}\NormalTok{]}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ fit\_predict\_lin(train\_df, val\_df, xcols):}
    \ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
    \ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
    \ImportTok{from}\NormalTok{ sklearn.pipeline }\ImportTok{import}\NormalTok{ Pipeline}
\NormalTok{    preds}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ tkr, tr }\KeywordTok{in}\NormalTok{ train\_df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        va }\OperatorTok{=}\NormalTok{ val\_df[val\_df[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr]}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(tr)}\OperatorTok{==}\DecValTok{0} \KeywordTok{or} \BuiltInTok{len}\NormalTok{(va)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{        pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{"scaler"}\NormalTok{, StandardScaler()), (}\StringTok{"lr"}\NormalTok{, LinearRegression())])}
\NormalTok{        pipe.fit(tr[xcols].values, tr[}\StringTok{"r\_1d"}\NormalTok{].values)}
\NormalTok{        yhat }\OperatorTok{=}\NormalTok{ pipe.predict(va[xcols].values)}
\NormalTok{        out }\OperatorTok{=}\NormalTok{ va[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{]].copy()}
\NormalTok{        out[}\StringTok{"yhat\_linlags"}\NormalTok{] }\OperatorTok{=}\NormalTok{ yhat}
\NormalTok{        preds.append(out)}
    \ControlFlowTok{return}\NormalTok{ pd.concat(preds, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ preds }\ControlFlowTok{else}\NormalTok{ pd.DataFrame()}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    ap }\OperatorTok{=}\NormalTok{ argparse.ArgumentParser()}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}features"}\NormalTok{, default}\OperatorTok{=}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}seasonality"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}train{-}min"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{252}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}val{-}size"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{63}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}step"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{63}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}embargo"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}xcols"}\NormalTok{, nargs}\OperatorTok{=}\StringTok{"+"}\NormalTok{, default}\OperatorTok{=}\NormalTok{[}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{])}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}out{-}summary"}\NormalTok{, default}\OperatorTok{=}\StringTok{"reports/linlags\_summary.csv"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}out{-}per{-}ticker"}\NormalTok{, default}\OperatorTok{=}\StringTok{"reports/linlags\_per\_ticker\_split}\SpecialCharTok{\{sid\}}\StringTok{.csv"}\NormalTok{)}
\NormalTok{    args }\OperatorTok{=}\NormalTok{ ap.parse\_args()}

\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(args.features).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    df[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{    splits }\OperatorTok{=}\NormalTok{ make\_splits(df[}\StringTok{"date"}\NormalTok{], args.train\_min, args.val\_size, args.step, args.embargo)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ add\_baselines(df, args.seasonality)}

\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ sid, (a,b,c,d) }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(splits, start}\OperatorTok{=}\DecValTok{1}\NormalTok{):}
\NormalTok{        tr }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)]}
\NormalTok{        va }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)]}
\NormalTok{        val\_pred }\OperatorTok{=}\NormalTok{ fit\_predict\_lin(tr, va, args.xcols)}
\NormalTok{        va }\OperatorTok{=}\NormalTok{ va.merge(val\_pred[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"yhat\_linlags"}\NormalTok{]], on}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{], how}\OperatorTok{=}\StringTok{"left"}\NormalTok{)}
        \CommentTok{\# per{-}ticker}
\NormalTok{        pts}\OperatorTok{=}\NormalTok{[]}
        \ControlFlowTok{for}\NormalTok{ tkr, gv }\KeywordTok{in}\NormalTok{ va.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{            gv }\OperatorTok{=}\NormalTok{ gv.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"yhat\_linlags"}\NormalTok{])}
            \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(gv)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{            gt }\OperatorTok{=}\NormalTok{ tr[tr[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr].dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{])}
\NormalTok{            gt\_naive }\OperatorTok{=}\NormalTok{ gt[}\StringTok{"log\_return"}\NormalTok{]  }\CommentTok{\# scale comparator for MASE}
\NormalTok{            pts.append(\{}\StringTok{"ticker"}\NormalTok{:tkr,}\StringTok{"n"}\NormalTok{:}\BuiltInTok{int}\NormalTok{(}\BuiltInTok{len}\NormalTok{(gv)),}
                        \StringTok{"mae"}\NormalTok{: mae(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[}\StringTok{"yhat\_linlags"}\NormalTok{]),}
                        \StringTok{"smape"}\NormalTok{: smape(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[}\StringTok{"yhat\_linlags"}\NormalTok{]),}
                        \StringTok{"mase"}\NormalTok{: mase(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[}\StringTok{"yhat\_linlags"}\NormalTok{], gt[}\StringTok{"r\_1d"}\NormalTok{], gt\_naive)\})}
\NormalTok{        pt }\OperatorTok{=}\NormalTok{ pd.DataFrame(pts)}
\NormalTok{        Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        pt.assign(split}\OperatorTok{=}\NormalTok{sid, model}\OperatorTok{=}\StringTok{"lin\_lags"}\NormalTok{).to\_csv(args.out\_per\_ticker.}\BuiltInTok{format}\NormalTok{(sid}\OperatorTok{=}\NormalTok{sid), index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

        \CommentTok{\# aggregate}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ pt.empty:}
\NormalTok{            macro }\OperatorTok{=}\NormalTok{ pt[[}\StringTok{"mae"}\NormalTok{,}\StringTok{"smape"}\NormalTok{,}\StringTok{"mase"}\NormalTok{]].mean().to\_dict()}
\NormalTok{            w }\OperatorTok{=}\NormalTok{ pt[}\StringTok{"n"}\NormalTok{].to\_numpy()}
\NormalTok{            micro }\OperatorTok{=}\NormalTok{ \{}\StringTok{"micro\_mae"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(pt[}\StringTok{"mae"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
                     \StringTok{"micro\_smape"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(pt[}\StringTok{"smape"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
                     \StringTok{"micro\_mase"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(pt[}\StringTok{"mase"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w))\}}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            macro }\OperatorTok{=}\NormalTok{ \{}\StringTok{"mae"}\NormalTok{:np.nan,}\StringTok{"smape"}\NormalTok{:np.nan,}\StringTok{"mase"}\NormalTok{:np.nan\}}
\NormalTok{            micro }\OperatorTok{=}\NormalTok{ \{}\StringTok{"micro\_mae"}\NormalTok{:np.nan,}\StringTok{"micro\_smape"}\NormalTok{:np.nan,}\StringTok{"micro\_mase"}\NormalTok{:np.nan\}}
\NormalTok{        rows.append(\{}\StringTok{"split"}\NormalTok{:sid,}\StringTok{"train\_range"}\NormalTok{:}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{b}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}\StringTok{"val\_range"}\NormalTok{:}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{c}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{d}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{,}
                     \StringTok{"model"}\NormalTok{:}\StringTok{"lin\_lags"}\NormalTok{, }\StringTok{"macro\_mae"}\NormalTok{:}\BuiltInTok{float}\NormalTok{(macro[}\StringTok{"mae"}\NormalTok{]), }\StringTok{"macro\_smape"}\NormalTok{:}\BuiltInTok{float}\NormalTok{(macro[}\StringTok{"smape"}\NormalTok{]), }\StringTok{"macro\_mase"}\NormalTok{:}\BuiltInTok{float}\NormalTok{(macro[}\StringTok{"mase"}\NormalTok{]),}
                     \OperatorTok{**}\NormalTok{micro\})}

\NormalTok{    pd.DataFrame(rows).to\_csv(args.out\_summary, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, args.out\_summary)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Make executable \& run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/eval\_linlags.py}
\ExtensionTok{python}\NormalTok{ scripts/eval\_linlags.py }\AttributeTok{{-}{-}xcols}\NormalTok{ lag1 lag2 lag3}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Part B --- Quarto \textbf{Model Card} for
the Linear‑Lags
baseline}{Part B --- Quarto Model Card for the Linear‑Lags baseline}}\label{part-b-quarto-model-card-for-the-linearlags-baseline}

Create \texttt{docs/model\_card\_linear.qmd}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{{-}{-}{-}}
\AnnotationTok{title:}\CommentTok{ "Model Card — Linear Lags (Per‑Ticker)"}
\AnnotationTok{format:}
\CommentTok{  html:}
\CommentTok{    theme: cosmo}
\CommentTok{    toc: true}
\AnnotationTok{params:}
\CommentTok{  model\_name: "Linear Lags (per‑ticker)"}
\CommentTok{  data: "features\_v1.parquet"}
\CommentTok{{-}{-}{-}}

\AttributeTok{\textgreater{} **Educational use only — not trading advice.** Predicts next‑day log return }\SpecialCharTok{\textbackslash{}(}\AttributeTok{r\_\{t+1\}}\SpecialCharTok{\textbackslash{})}\AttributeTok{ using past lags.}

\FunctionTok{\#\# Overview}

\SpecialStringTok{{-} }\NormalTok{**Model:** Per‑ticker linear regression with features: }\InformationTok{\textasciigrave{}lag1\textasciigrave{}}\NormalTok{, }\InformationTok{\textasciigrave{}lag2\textasciigrave{}}\NormalTok{, }\InformationTok{\textasciigrave{}lag3\textasciigrave{}}\NormalTok{.}
\SpecialStringTok{{-} }\NormalTok{**Data:** }\InformationTok{\textasciigrave{}features\_v1.parquet\textasciigrave{}}\NormalTok{ (Session 10).  }
\SpecialStringTok{{-} }\NormalTok{**Splits:** Expanding, quarterly val, 5‑day embargo (Session 15).  }
\SpecialStringTok{{-} }\NormalTok{**Baselines:** Naive and seasonal‑naive }\SpecialCharTok{\textbackslash{}(}\NormalTok{s=5}\SpecialCharTok{\textbackslash{})}\NormalTok{.}

\FunctionTok{\#\# Metrics (across splits)}

\NormalTok{::: \{.cell execution\_count=1\}}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{} \{.python .cell{-}code\}}
\InformationTok{import pandas as pd}
\InformationTok{df = pd.read\_csv("reports/linlags\_summary.csv")}
\InformationTok{df}
\end{Highlighting}
\end{Shaded}

\section{Discussion}\label{discussion}

\begin{itemize}
\tightlist
\item
  \textbf{Assumptions:} Linear relation to recent returns; stationarity
  at return level.
\item
  \textbf{Strengths:} Fast, interpretable, leakage‑resistant with proper
  splits.
\item
  \textbf{Failure modes:} Regime shifts; volatility spikes;
  nonlinearity.
\item
  \textbf{Ethics:} Educational; not suitable for trading.
\end{itemize}

\begin{verbatim}

Render (if Quarto is available):
```bash
quarto render docs/model_card_linear.qmd
\end{verbatim}

\subsection{Part C --- Quick test to safeguard results
shape}\label{part-c-quick-test-to-safeguard-results-shape}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_linlags\_results.py}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, os}

\KeywordTok{def}\NormalTok{ test\_linlags\_summary\_exists\_and\_columns():}
    \ControlFlowTok{assert}\NormalTok{ os.path.exists(}\StringTok{"reports/linlags\_summary.csv"}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"reports/linlags\_summary.csv"}\NormalTok{)}
\NormalTok{    need }\OperatorTok{=}\NormalTok{ \{}\StringTok{"split"}\NormalTok{,}\StringTok{"model"}\NormalTok{,}\StringTok{"macro\_mae"}\NormalTok{,}\StringTok{"micro\_mae"}\NormalTok{\}}
    \ControlFlowTok{assert}\NormalTok{ need.issubset(df.columns)}
\end{Highlighting}
\end{Shaded}

:::

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}k}\NormalTok{ linlags\_results}
\end{Highlighting}
\end{Shaded}

\subsection{Part D --- (Optional) Extend features or add
Ridge}\label{part-d-optional-extend-features-or-add-ridge}

\begin{itemize}
\tightlist
\item
  Try \texttt{-\/-xcols\ lag1\ lag2\ lag3\ roll\_std\_20\ zscore\_20}
  (if present in \texttt{features\_v1}).
\item
  Swap \texttt{LinearRegression} for \texttt{Ridge(alpha=1.0)}; log and
  compare.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-8}

\begin{itemize}
\tightlist
\item
  Verify \texttt{features\_v1.parquet} has \texttt{lag1..lag3} or the
  fallback cell creates them.
\item
  Dry‑run the 2‑split demo; ensure total runtime \textless{} 5--6
  minutes.
\item
  Optionally prepare an ARIMA demo on \textbf{one} ticker to illustrate
  pitfalls.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-8}

\begin{itemize}
\tightlist
\item
  Keep \textbf{splits identical} across models for fair comparison.
\item
  \textbf{MASE \textless{} 1} ⇒ your model beats naive on train‑scale;
  report macro \& micro.
\item
  Linear lags are a \textbf{transparent baseline}---use them to validate
  your entire pipeline.
\end{itemize}

\section{Grading (pass/revise)}\label{grading-passrevise-7}

\begin{itemize}
\tightlist
\item
  \texttt{scripts/eval\_linlags.py} runs and writes
  \texttt{reports/linlags\_summary.csv} + per‑ticker CSVs.
\item
  Model card exists and renders (locally or in CI artifact).
\item
  Tests for results table shape pass.
\item
  Results show a reasonable comparison against naive/seasonal‑naive.
\end{itemize}

You now have a \textbf{solid classical baseline} with a reproducible
evaluation and reporting workflow---perfect for benchmarking upcoming
neural models.

\bookmarksetup{startatroot}

\chapter{Session 17 --- Feature Timing, Biases \&
Leakage}\label{session-17-feature-timing-biases-leakage}

Below is a complete lecture package for \textbf{Session 17 --- Feature
Timing, Biases \& Leakage} (75 minutes). It includes a timed agenda,
slide talking points, a \textbf{Colab‑friendly in‑class lab with
copy‑paste code}, and \textbf{homework with copy‑paste code}. In class
you'll \textbf{freeze a static ticker universe} (avoid survivorship
bias), \textbf{formalize label definitions} (t+1 and multi‑step), and
add a \textbf{leakage test suite} that fails if any feature at time
\emph{t} uses information from \emph{t+1} or later.

\begin{quote}
\textbf{Educational use only --- not trading advice.} Assumes your
Drive‑mounted repo (e.g., \texttt{unified-stocks-teamX}) with
\texttt{data/processed/returns.parquet} and
\texttt{data/processed/features\_v1.parquet} from Sessions 9--10. Cells
include safe fallbacks when files are missing.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 17 --- Feature Timing, Biases \& Leakage (75
min)}\label{session-17-feature-timing-biases-leakage-75-min}

\subsection{Learning goals}\label{learning-goals-16}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain and \textbf{avoid look‑ahead} and \textbf{survivorship}
  biases.
\item
  Freeze and use a \textbf{static ticker universe} chosen from the
  \textbf{train window} (not the whole history).
\item
  Define labels correctly (e.g., \textbf{t+1} and \textbf{t+5}) and
  verify them with tests.
\item
  Add \textbf{leakage tests} that recompute trusted features and fail on
  any future‑peek.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-14}

\begin{itemize}
\item
  \textbf{(10 min)} Slides: what leakage looks like; examples; how it
  sneaks in
\item
  \textbf{(10 min)} Slides: survivorship bias (today's constituents ≠
  past reality); freezing a universe
\item
  \textbf{(10 min)} Slides: label definitions (t+1, multi‑step) and
  alignment rules
\item
  \textbf{(35 min)} \textbf{In‑class lab}:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Freeze a static universe from the first split's train window
  \item
    Add leakage tests that recompute known‑good features
  \item
    Add multi‑step labels (e.g., t+5) with tests
  \end{enumerate}
\item
  \textbf{(10 min)} Wrap‑up \& homework brief
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points (drop into your
deck)}\label{slides-talking-points-drop-into-your-deck-1}

\subsection{What is data leakage?}\label{what-is-data-leakage}

\begin{itemize}
\tightlist
\item
  \textbf{Look‑ahead leakage:} using any info from \emph{t+1} or later
  to compute features at \emph{t} or to scale/normalize train and
  validation together.
\item
  \textbf{Common culprits:} \texttt{shift(-1)} in features, global
  scaling fit on full data, forward‑fill across split boundaries, using
  today's close to predict today's close.
\end{itemize}

\subsection{Survivorship bias}\label{survivorship-bias}

\begin{itemize}
\tightlist
\item
  Using \textbf{today's index membership} to pick tickers for the past ⇒
  drops delisted/removed names ⇒ \textbf{optimistically biased} results.
\item
  \textbf{Cure:} freeze a \textbf{static universe} from the
  \textbf{training window} (e.g., all tickers with ≥ 252 observations by
  the end of the first train window). Save it and \textbf{filter by it}
  for all future experiments.
\end{itemize}

\subsection{Label definitions (be
explicit)}\label{label-definitions-be-explicit}

\begin{itemize}
\tightlist
\item
  \textbf{t+1 log return}: \texttt{r\_1d\ =\ log\_return.shift(-1)} per
  ticker (your Session‑9 label).
\item
  \textbf{t+5 log return} (multi‑step):
  \texttt{r\_5d\ =\ log\_return.shift(-1)\ +\ …\ +\ log\_return.shift(-5)}
  per ticker.
\item
  Rules: labels come from \textbf{future}; features come from \textbf{≤
  t}. Splits with \textbf{embargo} reduce adjacency leakage.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min,
Colab‑friendly)}\label{inclass-lab-35-min-colabfriendly-3}

\begin{quote}
Run each block as its own cell. Update \texttt{REPO\_NAME} as needed.
\end{quote}

\subsection{0) Setup \& load data (with
fallbacks)}\label{setup-load-data-with-fallbacks}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}   \CommentTok{\# \textless{}{-} change if needed}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/raw"}\NormalTok{,}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"data/static"}\NormalTok{,}\StringTok{"reports"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{]:}
\NormalTok{    Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}

\CommentTok{\# Load returns or synthesize a small fallback}
\NormalTok{rpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ rpath.exists():}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ pd.read\_parquet(rpath)}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\NormalTok{    dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{360}\NormalTok{)}
\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{,}\StringTok{"TSLA"}\NormalTok{,}\StringTok{"META"}\NormalTok{,}\StringTok{"NFLX"}\NormalTok{]:}
\NormalTok{        eps }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.012}\NormalTok{,size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)).astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        adj }\OperatorTok{=} \DecValTok{100}\OperatorTok{*}\NormalTok{np.exp(np.cumsum(eps))}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
            \StringTok{"date"}\NormalTok{: dates, }\StringTok{"ticker"}\NormalTok{: t,}
            \StringTok{"adj\_close"}\NormalTok{: adj.astype(}\StringTok{"float32"}\NormalTok{),}
            \StringTok{"log\_return"}\NormalTok{: np.r\_[np.nan, np.diff(np.log(adj))].astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        \})}
\NormalTok{        df[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"log\_return"}\NormalTok{].shift(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{        df[}\StringTok{"weekday"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.weekday.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{        df[}\StringTok{"month"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.month.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{        rows.append(df)}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ pd.concat(rows, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    returns[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ returns[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{    returns.to\_parquet(rpath, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\CommentTok{\# Load features\_v1 or construct minimal lags for tests}
\NormalTok{fpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ fpath.exists():}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ pd.read\_parquet(fpath).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ returns.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).copy()}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]:}
\NormalTok{        feats[}\SpecialStringTok{f"lag}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{=}\NormalTok{ feats.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].shift(k)}
\NormalTok{    feats[}\StringTok{"roll\_mean\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ feats.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).mean().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    feats[}\StringTok{"roll\_std\_20"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ feats.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    feats[}\StringTok{"zscore\_20"}\NormalTok{]    }\OperatorTok{=}\NormalTok{ (feats[}\StringTok{"log\_return"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ feats[}\StringTok{"roll\_mean\_20"}\NormalTok{]) }\OperatorTok{/}\NormalTok{ (feats[}\StringTok{"roll\_std\_20"}\NormalTok{] }\OperatorTok{+} \FloatTok{1e{-}8}\NormalTok{)}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ feats.dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Harmonize types}
\NormalTok{returns[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(returns[}\StringTok{"date"}\NormalTok{])}
\NormalTok{feats[}\StringTok{"date"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ pd.to\_datetime(feats[}\StringTok{"date"}\NormalTok{])}
\NormalTok{returns[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ returns[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{feats[}\StringTok{"ticker"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ feats[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{returns }\OperatorTok{=}\NormalTok{ returns.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{feats   }\OperatorTok{=}\NormalTok{ feats.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{returns.head(}\DecValTok{3}\NormalTok{), feats.head(}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{1) Freeze a \textbf{static universe} from
the \textbf{first split's train
window}}{1) Freeze a static universe from the first split's train window}}\label{freeze-a-static-universe-from-the-first-splits-train-window}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}

\KeywordTok{def}\NormalTok{ make\_rolling\_origin\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    i }\OperatorTok{=}\NormalTok{ train\_min }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ splits}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{\textgreater{}=} \BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        a,b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}
\NormalTok{        vs }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ embargo }\OperatorTok{+} \DecValTok{1}
\NormalTok{        ve }\OperatorTok{=}\NormalTok{ vs }\OperatorTok{+}\NormalTok{ val\_size }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve }\OperatorTok{\textgreater{}=} \BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        splits.append((a,b,u[vs],u[ve]))}
\NormalTok{        i }\OperatorTok{+=}\NormalTok{ step}
    \ControlFlowTok{return}\NormalTok{ splits}

\NormalTok{splits }\OperatorTok{=}\NormalTok{ make\_rolling\_origin\_splits(returns[}\StringTok{"date"}\NormalTok{], train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\ControlFlowTok{assert} \BuiltInTok{len}\NormalTok{(splits) }\OperatorTok{\textgreater{}=} \DecValTok{1}\NormalTok{, }\StringTok{"Not enough history for a first split."}
\NormalTok{a,b,c,d }\OperatorTok{=}\NormalTok{ splits[}\DecValTok{0}\NormalTok{]}
\BuiltInTok{print}\NormalTok{(}\StringTok{"First train window:"}\NormalTok{, a.date(), }\StringTok{"→"}\NormalTok{, b.date())}

\CommentTok{\# Eligible = tickers with at least train\_min rows by train\_end (b)}
\NormalTok{train\_slice }\OperatorTok{=}\NormalTok{ returns[(returns[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a) }\OperatorTok{\&}\NormalTok{ (returns[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)]}
\NormalTok{counts }\OperatorTok{=}\NormalTok{ train\_slice.groupby(}\StringTok{"ticker"}\NormalTok{).size()}
\NormalTok{eligible }\OperatorTok{=}\NormalTok{ counts[counts }\OperatorTok{\textgreater{}=} \DecValTok{252}\NormalTok{].index.sort\_values()}
\NormalTok{universe }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{"ticker"}\NormalTok{: eligible\})}
\NormalTok{univ\_name }\OperatorTok{=} \SpecialStringTok{f"data/static/universe\_}\SpecialCharTok{\{}\NormalTok{b}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{.csv"}
\NormalTok{universe.to\_csv(univ\_name, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Saved static universe:"}\NormalTok{, univ\_name, }\StringTok{"| tickers:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(universe))}
\NormalTok{universe.head()}
\end{Highlighting}
\end{Shaded}

\begin{quote}
From now on, \textbf{filter} your data to \texttt{universe} before
modeling/evaluation.
\end{quote}

\subsection{2) Apply the static universe to your
features}\label{apply-the-static-universe-to-your-features}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{feats\_static }\OperatorTok{=}\NormalTok{ feats[feats[}\StringTok{"ticker"}\NormalTok{].isin(}\BuiltInTok{set}\NormalTok{(universe[}\StringTok{"ticker"}\NormalTok{]))].copy()}
\NormalTok{feats\_static.to\_parquet(}\StringTok{"data/processed/features\_v1\_static.parquet"}\NormalTok{, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote data/processed/features\_v1\_static.parquet"}\NormalTok{, feats\_static.shape)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Add \textbf{leakage tests} that recompute
trusted features \&
compare}{3) Add leakage tests that recompute trusted features \& compare}}\label{add-leakage-tests-that-recompute-trusted-features-compare}

Create a high‑value test file that \textbf{fails} if any feature depends
on future rows.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_leakage\_features.py}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ pytest}

\NormalTok{SAFE\_ROLL }\OperatorTok{=} \DecValTok{20}

\AttributeTok{@pytest.fixture}\NormalTok{(scope}\OperatorTok{=}\StringTok{"session"}\NormalTok{)}
\KeywordTok{def}\NormalTok{ df():}
    \ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
    \ImportTok{import}\NormalTok{ pathlib}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ pathlib.Path(}\StringTok{"data/processed/features\_v1\_static.parquet"}\NormalTok{)}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ p.exists():}
\NormalTok{        p }\OperatorTok{=}\NormalTok{ pathlib.Path(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(p).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{])}
    \ControlFlowTok{return}\NormalTok{ df}

\KeywordTok{def}\NormalTok{ test\_label\_definition\_r1d(df):}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{):}
        \ControlFlowTok{assert}\NormalTok{ g[}\StringTok{"r\_1d"}\NormalTok{].iloc[:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].equals(g[}\StringTok{"log\_return"}\NormalTok{].iloc[}\DecValTok{1}\NormalTok{:]), }\SpecialStringTok{f"r\_1d mismatch for }\SpecialCharTok{\{}\NormalTok{tkr}\SpecialCharTok{\}}\SpecialStringTok{"}

\KeywordTok{def}\NormalTok{ \_recompute\_safe(g: pd.DataFrame) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame:}
    \CommentTok{\# Recompute causal features using only \textless{}= t information}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ pd.DataFrame(index}\OperatorTok{=}\NormalTok{g.index)}
\NormalTok{    s }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{]}
\NormalTok{    out[}\StringTok{"lag1"}\NormalTok{] }\OperatorTok{=}\NormalTok{ s.shift(}\DecValTok{1}\NormalTok{)}
\NormalTok{    out[}\StringTok{"lag2"}\NormalTok{] }\OperatorTok{=}\NormalTok{ s.shift(}\DecValTok{2}\NormalTok{)}
\NormalTok{    out[}\StringTok{"lag3"}\NormalTok{] }\OperatorTok{=}\NormalTok{ s.shift(}\DecValTok{3}\NormalTok{)}
\NormalTok{    rm }\OperatorTok{=}\NormalTok{ s.rolling(SAFE\_ROLL, min\_periods}\OperatorTok{=}\NormalTok{SAFE\_ROLL).mean()}
\NormalTok{    rs }\OperatorTok{=}\NormalTok{ s.rolling(SAFE\_ROLL, min\_periods}\OperatorTok{=}\NormalTok{SAFE\_ROLL).std()}
\NormalTok{    out[}\StringTok{"roll\_mean\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ rm}
\NormalTok{    out[}\StringTok{"roll\_std\_20"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ rs}
\NormalTok{    out[}\StringTok{"zscore\_20"}\NormalTok{]    }\OperatorTok{=}\NormalTok{ (s }\OperatorTok{{-}}\NormalTok{ rm) }\OperatorTok{/}\NormalTok{ (rs }\OperatorTok{+} \FloatTok{1e{-}8}\NormalTok{)}
    \CommentTok{\# EWM \& expanding if present}
\NormalTok{    out[}\StringTok{"exp\_mean"}\NormalTok{] }\OperatorTok{=}\NormalTok{ s.expanding(min\_periods}\OperatorTok{=}\NormalTok{SAFE\_ROLL).mean()}
\NormalTok{    out[}\StringTok{"exp\_std"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ s.expanding(min\_periods}\OperatorTok{=}\NormalTok{SAFE\_ROLL).std()}
\NormalTok{    out[}\StringTok{"ewm\_mean\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ s.ewm(span}\OperatorTok{=}\DecValTok{20}\NormalTok{, adjust}\OperatorTok{=}\VariableTok{False}\NormalTok{).mean()}
\NormalTok{    out[}\StringTok{"ewm\_std\_20"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ s.ewm(span}\OperatorTok{=}\DecValTok{20}\NormalTok{, adjust}\OperatorTok{=}\VariableTok{False}\NormalTok{).std()}
    \CommentTok{\# RSI(14) if adj\_close present}
    \ControlFlowTok{if} \StringTok{"adj\_close"} \KeywordTok{in}\NormalTok{ g:}
\NormalTok{        delta }\OperatorTok{=}\NormalTok{ g[}\StringTok{"adj\_close"}\NormalTok{].diff()}
\NormalTok{        up }\OperatorTok{=}\NormalTok{ delta.clip(lower}\OperatorTok{=}\DecValTok{0}\NormalTok{).ewm(alpha}\OperatorTok{=}\DecValTok{1}\OperatorTok{/}\DecValTok{14}\NormalTok{, adjust}\OperatorTok{=}\VariableTok{False}\NormalTok{).mean()}
\NormalTok{        dn }\OperatorTok{=}\NormalTok{ (}\OperatorTok{{-}}\NormalTok{delta.clip(upper}\OperatorTok{=}\DecValTok{0}\NormalTok{)).ewm(alpha}\OperatorTok{=}\DecValTok{1}\OperatorTok{/}\DecValTok{14}\NormalTok{, adjust}\OperatorTok{=}\VariableTok{False}\NormalTok{).mean()}
\NormalTok{        rs }\OperatorTok{=}\NormalTok{ up }\OperatorTok{/}\NormalTok{ (dn }\OperatorTok{+} \FloatTok{1e{-}12}\NormalTok{)}
\NormalTok{        out[}\StringTok{"rsi\_14"}\NormalTok{] }\OperatorTok{=} \DecValTok{100} \OperatorTok{{-}}\NormalTok{ (}\DecValTok{100}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\NormalTok{rs))}
    \ControlFlowTok{return}\NormalTok{ out}

\AttributeTok{@pytest.mark.parametrize}\NormalTok{(}\StringTok{"col"}\NormalTok{, [}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{,}\StringTok{"roll\_mean\_20"}\NormalTok{,}\StringTok{"roll\_std\_20"}\NormalTok{,}\StringTok{"zscore\_20"}\NormalTok{,}\StringTok{"exp\_mean"}\NormalTok{,}\StringTok{"exp\_std"}\NormalTok{,}\StringTok{"ewm\_mean\_20"}\NormalTok{,}\StringTok{"ewm\_std\_20"}\NormalTok{,}\StringTok{"rsi\_14"}\NormalTok{])}
\KeywordTok{def}\NormalTok{ test\_features\_match\_causal\_recompute(df, col):}
    \ControlFlowTok{if}\NormalTok{ col }\KeywordTok{not} \KeywordTok{in}\NormalTok{ df.columns:}
\NormalTok{        pytest.skip(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{col}\SpecialCharTok{\}}\SpecialStringTok{ not present"}\NormalTok{)}
    \CommentTok{\# Compare per ticker to avoid cross{-}group alignment issues}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{, sort}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
\NormalTok{        ref }\OperatorTok{=}\NormalTok{ \_recompute\_safe(g)}
        \ControlFlowTok{if}\NormalTok{ col }\KeywordTok{not} \KeywordTok{in}\NormalTok{ ref.columns: }
            \ControlFlowTok{continue}
\NormalTok{        a }\OperatorTok{=}\NormalTok{ g[col].to\_numpy()}
\NormalTok{        b }\OperatorTok{=}\NormalTok{ ref[col].to\_numpy()}
        \CommentTok{\# Allow NaNs at the start; compare where both finite}
\NormalTok{        mask }\OperatorTok{=}\NormalTok{ np.isfinite(a) }\OperatorTok{\&}\NormalTok{ np.isfinite(b)}
        \ControlFlowTok{if}\NormalTok{ mask.}\BuiltInTok{sum}\NormalTok{() }\OperatorTok{==} \DecValTok{0}\NormalTok{: }
            \ControlFlowTok{continue}
\NormalTok{        diff }\OperatorTok{=}\NormalTok{ np.nanmax(np.}\BuiltInTok{abs}\NormalTok{(a[mask] }\OperatorTok{{-}}\NormalTok{ b[mask]))}
        \ControlFlowTok{assert} \BuiltInTok{float}\NormalTok{(diff) }\OperatorTok{\textless{}=} \FloatTok{1e{-}6}\NormalTok{, }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{col}\SpecialCharTok{\}}\SpecialStringTok{ deviates from causal recompute for }\SpecialCharTok{\{}\NormalTok{tkr}\SpecialCharTok{\}}\SpecialStringTok{: max |Δ|=}\SpecialCharTok{\{}\NormalTok{diff}\SpecialCharTok{\}}\SpecialStringTok{"}

\KeywordTok{def}\NormalTok{ test\_no\_feature\_equals\_target(df):}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ df[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy()}
    \ControlFlowTok{for}\NormalTok{ col }\KeywordTok{in}\NormalTok{ df.select\_dtypes(include}\OperatorTok{=}\NormalTok{[}\StringTok{"float32"}\NormalTok{,}\StringTok{"float64"}\NormalTok{]).columns:}
        \ControlFlowTok{if}\NormalTok{ col }\KeywordTok{in}\NormalTok{ \{}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{\}: }
            \ControlFlowTok{continue}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ df[col].to\_numpy()}
        \CommentTok{\# Proportion of exact equality (within tiny tol) should not be high}
\NormalTok{        eq }\OperatorTok{=}\NormalTok{ np.isfinite(x) }\OperatorTok{\&}\NormalTok{ np.isfinite(y) }\OperatorTok{\&}\NormalTok{ (np.}\BuiltInTok{abs}\NormalTok{(x }\OperatorTok{{-}}\NormalTok{ y) }\OperatorTok{\textless{}} \FloatTok{1e{-}12}\NormalTok{)}
        \ControlFlowTok{assert}\NormalTok{ eq.mean() }\OperatorTok{\textless{}} \FloatTok{0.8}\NormalTok{, }\SpecialStringTok{f"Suspicious: feature }\SpecialCharTok{\{}\NormalTok{col}\SpecialCharTok{\}}\SpecialStringTok{ equals target too often"}
\end{Highlighting}
\end{Shaded}

Run tests now:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{pytest }\OperatorTok{{-}}\NormalTok{q tests}\OperatorTok{/}\NormalTok{test\_leakage\_features.py}
\end{Highlighting}
\end{Shaded}

\begin{quote}
If a test fails, \textbf{fix the pipeline}, don't weaken the test.
\end{quote}

\subsection{\texorpdfstring{4) Add \textbf{multi‑step labels} (e.g.,
t+5) and
tests}{4) Add multi‑step labels (e.g., t+5) and tests}}\label{add-multistep-labels-e.g.-t5-and-tests}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scripts/make\_multistep\_labels.py}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\KeywordTok{def}\NormalTok{ make\_multistep(in\_parquet}\OperatorTok{=}\StringTok{"data/processed/returns.parquet"}\NormalTok{, horizons}\OperatorTok{=}\NormalTok{(}\DecValTok{5}\NormalTok{,)):}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(in\_parquet).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ H }\KeywordTok{in}\NormalTok{ horizons:}
        \CommentTok{\# r\_Hd = sum of next H log returns: shift({-}1) ... shift({-}H)}
\NormalTok{        s }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{]}
\NormalTok{        acc }\OperatorTok{=} \VariableTok{None}
        \ControlFlowTok{for}\NormalTok{ h }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, H}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{            sh }\OperatorTok{=}\NormalTok{ s.shift(}\OperatorTok{{-}}\NormalTok{h)}
\NormalTok{            acc }\OperatorTok{=}\NormalTok{ sh }\ControlFlowTok{if}\NormalTok{ acc }\KeywordTok{is} \VariableTok{None} \ControlFlowTok{else}\NormalTok{ (acc }\OperatorTok{+}\NormalTok{ sh)}
\NormalTok{        df[}\SpecialStringTok{f"r\_}\SpecialCharTok{\{}\NormalTok{H}\SpecialCharTok{\}}\SpecialStringTok{d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ acc}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df}
\NormalTok{    Path(}\StringTok{"data/processed"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    out.to\_parquet(}\StringTok{"data/processed/returns\_multistep.parquet"}\NormalTok{, compression}\OperatorTok{=}\StringTok{"zstd"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote data/processed/returns\_multistep.parquet"}\NormalTok{, out.shape)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    make\_multistep()}
\end{Highlighting}
\end{Shaded}

Run it:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{python scripts}\OperatorTok{/}\NormalTok{make\_multistep\_labels.py}
\end{Highlighting}
\end{Shaded}

Add a test for label correctness:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_labels\_multistep.py}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}

\KeywordTok{def}\NormalTok{ test\_r5d\_definition():}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(}\StringTok{"data/processed/returns\_multistep.parquet"}\NormalTok{).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
    \ControlFlowTok{if} \StringTok{"r\_5d"} \KeywordTok{not} \KeywordTok{in}\NormalTok{ df.columns:}
        \ControlFlowTok{return}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        lr }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{]}
\NormalTok{        r5 }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(lr.shift(}\OperatorTok{{-}}\NormalTok{h) }\ControlFlowTok{for}\NormalTok{ h }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{6}\NormalTok{))}
\NormalTok{        diff }\OperatorTok{=}\NormalTok{ (g[}\StringTok{"r\_5d"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ r5).}\BuiltInTok{abs}\NormalTok{().}\BuiltInTok{max}\NormalTok{()}
        \ControlFlowTok{assert} \BuiltInTok{float}\NormalTok{(diff) }\OperatorTok{\textless{}} \FloatTok{1e{-}10}\NormalTok{, }\SpecialStringTok{f"r\_5d misdefined for }\SpecialCharTok{\{}\NormalTok{tkr}\SpecialCharTok{\}}\SpecialStringTok{ (max |Δ|=}\SpecialCharTok{\{}\NormalTok{diff}\SpecialCharTok{\}}\SpecialStringTok{)"}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{pytest }\OperatorTok{{-}}\NormalTok{q tests}\OperatorTok{/}\NormalTok{test\_labels\_multistep.py}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-10}

\begin{itemize}
\tightlist
\item
  \textbf{Static universe} removes \textbf{survivorship bias}: pick
  tickers with adequate history \textbf{by train end} and \textbf{stick
  to them}.
\item
  Label definitions must be \textbf{explicit and tested} (t+1, t+5).
\item
  Leakage tests \textbf{recompute causal features} and compare---if you
  accidentally used \texttt{shift(-1)} or cross‑split fills, tests fail.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
18)}\label{homework-due-before-session-18}

\textbf{Goal:} Document your evaluation protocol and ship a concise
``leakage \& bias'' memo, plus a one‑command audit.

\subsection{\texorpdfstring{Part A --- Generate a \textbf{protocol memo}
(\texttt{reports/eval\_protocol.md})}{Part A --- Generate a protocol memo (reports/eval\_protocol.md)}}\label{part-a-generate-a-protocol-memo-reportseval_protocol.md}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# scripts/write\_eval\_protocol.py}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{from}\NormalTok{ datetime }\ImportTok{import}\NormalTok{ date}

\KeywordTok{def}\NormalTok{ make\_rolling\_origin\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    i }\OperatorTok{=}\NormalTok{ train\_min }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ out}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{\textgreater{}=} \BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        a,b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val\_size}\OperatorTok{{-}}\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve }\OperatorTok{\textgreater{}=} \BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        out.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i }\OperatorTok{+=}\NormalTok{ step}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    ret }\OperatorTok{=}\NormalTok{ pd.read\_parquet(}\StringTok{"data/processed/returns.parquet"}\NormalTok{).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
\NormalTok{    splits }\OperatorTok{=}\NormalTok{ make\_rolling\_origin\_splits(ret[}\StringTok{"date"}\NormalTok{])}
\NormalTok{    a,b,c,d }\OperatorTok{=}\NormalTok{ splits[}\DecValTok{0}\NormalTok{]}
    \CommentTok{\# Universe info}
\NormalTok{    univ\_files }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(Path(}\StringTok{"data/static"}\NormalTok{).glob(}\StringTok{"universe\_*.csv"}\NormalTok{))}
\NormalTok{    univ }\OperatorTok{=}\NormalTok{ univ\_files[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ univ\_files }\ControlFlowTok{else} \VariableTok{None}
\NormalTok{    univ\_count }\OperatorTok{=}\NormalTok{ pd.read\_csv(univ).shape[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ univ }\ControlFlowTok{else}\NormalTok{ ret[}\StringTok{"ticker"}\NormalTok{].nunique()}
\NormalTok{    md }\OperatorTok{=}\NormalTok{ []}
\NormalTok{    md }\OperatorTok{+=}\NormalTok{ [}\StringTok{"\# Evaluation Protocol (Leakage‑Aware)"}\NormalTok{, }\StringTok{""}\NormalTok{]}
\NormalTok{    md }\OperatorTok{+=}\NormalTok{ [}\StringTok{"**Date:** "} \OperatorTok{+}\NormalTok{ date.today().isoformat(), }\StringTok{""}\NormalTok{]}
\NormalTok{    md }\OperatorTok{+=}\NormalTok{ [}\StringTok{"\#\# Splits"}\NormalTok{, }\SpecialStringTok{f"{-} Train window (split 1): **}\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{ → }\SpecialCharTok{\{}\NormalTok{b}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{**"}\NormalTok{,}
           \SpecialStringTok{f"{-} Embargo: **5** business days"}\NormalTok{, }\SpecialStringTok{f"{-} Validation window: **}\SpecialCharTok{\{}\NormalTok{c}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{ → }\SpecialCharTok{\{}\NormalTok{d}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{**"}\NormalTok{,}
           \SpecialStringTok{f"{-} Step between origins: **63** business days"}\NormalTok{, }\StringTok{""}\NormalTok{]}
\NormalTok{    md }\OperatorTok{+=}\NormalTok{ [}\StringTok{"\#\# Static Universe"}\NormalTok{, }\SpecialStringTok{f"{-} Universe file: **}\SpecialCharTok{\{}\NormalTok{univ}\SpecialCharTok{.}\NormalTok{name }\ControlFlowTok{if}\NormalTok{ univ }\ControlFlowTok{else} \StringTok{\textquotesingle{}(none)\textquotesingle{}}\SpecialCharTok{\}}\SpecialStringTok{**"}\NormalTok{,}
           \SpecialStringTok{f"{-} Count: **}\SpecialCharTok{\{}\NormalTok{univ\_count}\SpecialCharTok{\}}\SpecialStringTok{** tickers"}\NormalTok{, }
           \StringTok{"{-} Selection rule: tickers with ≥252 obs by first train end; fixed for all splits."}\NormalTok{, }\StringTok{""}\NormalTok{]}
\NormalTok{    md }\OperatorTok{+=}\NormalTok{ [}\StringTok{"\#\# Labels"}\NormalTok{, }\StringTok{"{-} \textasciigrave{}r\_1d\textasciigrave{} = next‑day log return \textasciigrave{}log\_return.shift({-}1)\textasciigrave{} per ticker."}\NormalTok{,}
           \StringTok{"{-} \textasciigrave{}r\_5d\textasciigrave{} (if used) = sum of \textasciigrave{}log\_return.shift({-}1..{-}5)\textasciigrave{}."}\NormalTok{, }\StringTok{""}\NormalTok{]}
\NormalTok{    md }\OperatorTok{+=}\NormalTok{ [}\StringTok{"\#\# Leakage Controls"}\NormalTok{,}
           \StringTok{"{-} Features computed from ≤ t only (rolling/ewm/expanding without negative shifts)."}\NormalTok{,}
           \StringTok{"{-} No forward‑fill across split boundaries; embargo = 5 days."}\NormalTok{,}
           \StringTok{"{-} Scalers/normalizers fit on TRAIN only."}\NormalTok{,}
           \StringTok{"{-} Tests: \textasciigrave{}tests/test\_leakage\_features.py\textasciigrave{}, \textasciigrave{}tests/test\_labels\_multistep.py\textasciigrave{}."}\NormalTok{, }\StringTok{""}\NormalTok{]}
\NormalTok{    md }\OperatorTok{+=}\NormalTok{ [}\StringTok{"\#\# Caveats"}\NormalTok{,}
           \StringTok{"{-} Educational dataset; not investment advice."}\NormalTok{,}
           \StringTok{"{-} Survivorship minimized via static universe; still subject to data vendor quirks."}\NormalTok{, }\StringTok{""}\NormalTok{]}
\NormalTok{    Path(}\StringTok{"reports"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    Path(}\StringTok{"reports/eval\_protocol.md"}\NormalTok{).write\_text(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{.join(md))}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote reports/eval\_protocol.md"}\NormalTok{)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{!}\NormalTok{python scripts}\OperatorTok{/}\NormalTok{write\_eval\_protocol.py}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Part B --- One‑command \textbf{leakage
audit}
target}{Part B --- One‑command leakage audit target}}\label{part-b-onecommand-leakage-audit-target}

Append to your \texttt{Makefile}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.PHONY: leakage{-}audit}
\NormalTok{leakage{-}audit: \#\# Run leakage \& label tests; write eval protocol}
\NormalTok{\textbackslash{}tpytest {-}q tests/test\_leakage\_features.py tests/test\_labels\_multistep.py}
\NormalTok{\textbackslash{}tpython scripts/write\_eval\_protocol.py}
\end{Highlighting}
\end{Shaded}

Then run:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{make}\NormalTok{ leakage{-}audit}
\end{Highlighting}
\end{Shaded}

\subsection{Part C --- Short memo (1--2 pages
max)}\label{part-c-short-memo-12-pages-max}

\begin{itemize}
\item
  Open \texttt{reports/eval\_protocol.md} and add \textbf{two
  paragraphs} in your own words:

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \tightlist
  \item
    Why these splits and embargo are credible for your task.
  \item
    Where leakage could still hide (e.g., future macro revisions,
    implicit target leakage), and how you'd detect it.
  \end{enumerate}
\end{itemize}

\begin{quote}
Submit the updated \texttt{reports/eval\_protocol.md} and a screenshot
of \texttt{make\ leakage-audit} passing.
\end{quote}

\subsection{Part D --- (Optional) Quarto
inclusion}\label{part-d-optional-quarto-inclusion}

Add this to your Quarto report:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# Evaluation Protocol (Leakage‑Aware)}

\NormalTok{::: \{.cell execution\_count=1\}}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{} \{.python .cell{-}code\}}
\InformationTok{from pathlib import Path}
\InformationTok{print(Path("reports/eval\_protocol.md").read\_text())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
:::


---

## Instructor checklist (before class)
- Ensure `returns.parquet` and `features_v1.parquet` exist or fallback works.  
- Intentionally create a leaked feature (e.g., `lag1 = log_return.shift(-1)`) on your copy to show tests **failing**, then fix.  
- Decide an anchor date policy for universe freeze; today’s lab uses **first split’s train end**.

## Emphasize while teaching
- **Define labels first**, then prove features are **causal (≤ t)**.  
- Freezing the **universe** is small effort with big impact on credibility.  
- Tests are your **guardrails**—if they go red, **don’t** relax them; fix the pipeline.

## Grading (pass/revise)
- `data/static/universe_YYYY-MM-DD.csv` created; `features_v1_static.parquet` filtered by it.  
- Leakage tests present and **green** on the clean pipeline; **red** if you inject a future‑peek.  
- `reports/eval_protocol.md` exists and includes student commentary.  
- `make leakage-audit` runs without errors.

You now have a **credibility layer** on top of your data pipeline—ready to analyze regimes and calibration next (Session 18).
```



`<!-- quarto-file-metadata: eyJyZXNvdXJjZURpciI6Ii4ifQ== -->`{=html}

```{=html}
<!-- quarto-file-metadata: eyJyZXNvdXJjZURpciI6Ii4iLCJib29rSXRlbVR5cGUiOiJjaGFwdGVyIiwiYm9va0l0ZW1OdW1iZXIiOjE4LCJib29rSXRlbUZpbGUiOiJsZWMxOC5xbWQiLCJib29rSXRlbURlcHRoIjowfQ== -->
```

# Session 18 — Walk‑forward + Regime Analysi 

```````{.quarto-title-block template='/Users/yiwang/Applications/quarto/share/projects/book/pandoc/title-block.md'}
---
title: Session 18 — Walk‑forward + Regime Analysi

---
\end{verbatim}

Below is a complete lecture package for \textbf{Session 18 ---
Walk‑forward + Regime Analysis} (75 minutes). It includes a timed
agenda, slide talking points, a \textbf{Colab‑friendly in‑class lab with
copy‑paste code}, and \textbf{homework with copy‑paste code}. You'll add
\textbf{volatility regimes} to your rolling‑origin evaluation (with
embargo), compute \textbf{metrics by regime}, and produce
\textbf{calibration plots} that reveal where baselines
over/under‑predict.

\begin{quote}
\textbf{Educational use only --- not trading advice.} Assumes your repo
in Drive (e.g., \texttt{unified-stocks-teamX}) with
\texttt{data/processed/returns.parquet} and
\texttt{data/processed/features\_v1.parquet}. If missing, the lab will
synthesize a small fallback so you can run end‑to‑end.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 18 --- Walk‑forward + Regime Analysis (75
min)}\label{session-18-walkforward-regime-analysis-75-min}

\subsection{Learning goals}\label{learning-goals-17}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use \textbf{embargoed} rolling‑origin splits (Session 15) and apply a
  \textbf{static universe} (Session 17) consistently.
\item
  Construct \textbf{volatility regimes} (low/med/high) from
  \textbf{rolling volatility} computed \textbf{causally} (≤ t), and set
  regime thresholds \textbf{using training‑only} data per split.
\item
  Evaluate \textbf{MAE, sMAPE, MASE} \textbf{by regime}, with macro and
  micro aggregation.
\item
  Make \textbf{calibration plots} (binned predicted vs.~realized
  returns) \textbf{by regime} and interpret them.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-15}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: walk‑forward recap (expanding vs sliding),
  embargo; regime intuition
\item
  \textbf{(10 min)} Slides: defining regimes (rolling std),
  training‑only thresholds, leakage pitfalls
\item
  \textbf{(35 min)} \textbf{In‑class lab}: add regime labels (train‑only
  quantiles) → evaluate naive \& linear‑lags \textbf{by regime} →
  calibration plots
\item
  \textbf{(10 min)} Wrap‑up + homework brief
\item
  \textbf{(10 min)} Buffer / Q\&A
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slide talking points (paste into your
deck)}\label{slide-talking-points-paste-into-your-deck}

\subsection{Why regime analysis?}\label{why-regime-analysis}

\begin{itemize}
\tightlist
\item
  Model error is \textbf{not uniform}. Many models fail during
  \textbf{high‑volatility} periods.
\item
  Reporting \textbf{one global metric} hides when/where models break.
\item
  Regime‑aware metrics guide \textbf{feature/model design} and
  \textbf{risk controls}.
\end{itemize}

\subsection{Splits \& embargo refresher}\label{splits-embargo-refresher}

\begin{itemize}
\tightlist
\item
  \textbf{Rolling‑origin, expanding}: train grows, validation moves
  forward.
\item
  \textbf{Embargo}: gap (e.g., 5 business days) between train end and
  val start to reduce adjacency leakage.
\end{itemize}

\subsection{Defining volatility regimes (avoid
leakage)}\label{defining-volatility-regimes-avoid-leakage}

\begin{itemize}
\tightlist
\item
  Use \textbf{rolling standard deviation} of returns (e.g.,
  \texttt{roll\_std\_20}) computed \textbf{up to and including t}.
\item
  \textbf{Thresholds}: choose quantiles (e.g., 33\% and 66\%) \textbf{on
  TRAIN ONLY} for each split; label both train \& val using those fixed
  thresholds.
\item
  \textbf{Categories}: \texttt{low}, \texttt{med}, \texttt{high}. Treat
  labels as \textbf{categorical dtypes}.
\end{itemize}

\subsection{Metrics \& calibration by
regime}\label{metrics-calibration-by-regime}

\begin{itemize}
\item
  Compute \textbf{MAE, sMAPE, MASE} \textbf{within each regime}.
  Aggregate macro/micro.
\item
  \textbf{Calibration (point forecasts)}: bin predictions into deciles;
  plot \textbf{mean predicted vs.~mean realized} per bin.

  \begin{itemize}
  \tightlist
  \item
    Perfect calibration ⇒ points on the 45° line.
  \item
    Plot one figure \textbf{overall} and one \textbf{per regime}.
  \end{itemize}
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min,
Colab‑friendly)}\label{inclass-lab-35-min-colabfriendly-4}

\begin{quote}
Run each block as its \textbf{own cell}. Adjust \texttt{REPO\_NAME} to
your repo name.
\end{quote}

\subsection{0) Setup \& load (with safe
fallbacks)}\label{setup-load-with-safe-fallbacks}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}   \CommentTok{\# \textless{}{-} change if needed}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd, json}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/raw"}\NormalTok{,}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"data/static"}\NormalTok{,}\StringTok{"reports"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{,}\StringTok{"docs/figs"}\NormalTok{]:}
\NormalTok{    Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}

\CommentTok{\# Load returns; synthesize if missing}
\NormalTok{rpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ rpath.exists():}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ pd.read\_parquet(rpath)}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\NormalTok{    dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{360}\NormalTok{)}
\NormalTok{    frames}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{]:}
\NormalTok{        eps }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.012}\NormalTok{,size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)).astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        adj }\OperatorTok{=} \DecValTok{100}\OperatorTok{*}\NormalTok{np.exp(np.cumsum(eps))}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
            \StringTok{"date"}\NormalTok{: dates, }\StringTok{"ticker"}\NormalTok{: t,}
            \StringTok{"adj\_close"}\NormalTok{: adj.astype(}\StringTok{"float32"}\NormalTok{),}
            \StringTok{"log\_return"}\NormalTok{: np.r\_[np.nan, np.diff(np.log(adj))].astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        \})}
\NormalTok{        df[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"log\_return"}\NormalTok{].shift(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{        df[}\StringTok{"weekday"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.weekday.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{        df[}\StringTok{"month"}\NormalTok{]   }\OperatorTok{=}\NormalTok{ df[}\StringTok{"date"}\NormalTok{].dt.month.astype(}\StringTok{"int8"}\NormalTok{)}
\NormalTok{        frames.append(df)}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ pd.concat(frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    returns[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ returns[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{    returns.to\_parquet(rpath, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\CommentTok{\# Load features or generate minimal set with rolling std (causal)}
\NormalTok{fpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ fpath.exists():}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ pd.read\_parquet(fpath)}
    \ControlFlowTok{if} \StringTok{"roll\_std\_20"} \KeywordTok{not} \KeywordTok{in}\NormalTok{ feats.columns:}
        \CommentTok{\# ensure we have rolling volatility}
\NormalTok{        feats }\OperatorTok{=}\NormalTok{ feats.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
\NormalTok{        feats[}\StringTok{"roll\_std\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ feats.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ returns.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).copy()}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]:}
\NormalTok{        feats[}\SpecialStringTok{f"lag}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{=}\NormalTok{ feats.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].shift(k)}
\NormalTok{    feats[}\StringTok{"roll\_std\_20"}\NormalTok{] }\OperatorTok{=}\NormalTok{ feats.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# If static universe exists from Session 17, apply it}
\NormalTok{univ\_files }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(Path(}\StringTok{"data/static"}\NormalTok{).glob(}\StringTok{"universe\_*.csv"}\NormalTok{))}
\ControlFlowTok{if}\NormalTok{ univ\_files:}
\NormalTok{    univ }\OperatorTok{=}\NormalTok{ pd.read\_csv(univ\_files[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{])[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{)}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ feats[feats[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{).isin(}\BuiltInTok{set}\NormalTok{(univ))]}
\NormalTok{    returns }\OperatorTok{=}\NormalTok{ returns[returns[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{).isin(}\BuiltInTok{set}\NormalTok{(univ))]}

\CommentTok{\# Harmonize types \& sort}
\ControlFlowTok{for}\NormalTok{ df }\KeywordTok{in}\NormalTok{ (returns, feats):}
\NormalTok{    df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{])}
\NormalTok{    df[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{feats }\OperatorTok{=}\NormalTok{ feats.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"log\_return"}\NormalTok{]).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{returns }\OperatorTok{=}\NormalTok{ returns.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{feats.head(}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{1) Rolling‑origin splits (expanding) with
embargo}\label{rollingorigin-splits-expanding-with-embargo}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}

\KeywordTok{def}\NormalTok{ make\_rolling\_origin\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    splits}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{ i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(u)}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        a,b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}
\NormalTok{        vs }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ embargo }\OperatorTok{+} \DecValTok{1}
\NormalTok{        ve }\OperatorTok{=}\NormalTok{ vs }\OperatorTok{+}\NormalTok{ val\_size }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        splits.append((a,b,u[vs],u[ve]))}
\NormalTok{        i }\OperatorTok{+=}\NormalTok{ step}
    \ControlFlowTok{return}\NormalTok{ splits}

\NormalTok{splits }\OperatorTok{=}\NormalTok{ make\_rolling\_origin\_splits(feats[}\StringTok{"date"}\NormalTok{], train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Num splits:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(splits))}
\NormalTok{splits[:}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Regime thresholds from
\textbf{training‑only} (quantiles of rolling
vol)}{2) Regime thresholds from training‑only (quantiles of rolling vol)}}\label{regime-thresholds-from-trainingonly-quantiles-of-rolling-vol}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ regime\_thresholds(train\_df, vol\_col}\OperatorTok{=}\StringTok{"roll\_std\_20"}\NormalTok{, q\_low}\OperatorTok{=}\FloatTok{0.33}\NormalTok{, q\_high}\OperatorTok{=}\FloatTok{0.66}\NormalTok{):}
\NormalTok{    v }\OperatorTok{=}\NormalTok{ train\_df[vol\_col].dropna().to\_numpy()}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(v) }\OperatorTok{\textless{}} \DecValTok{100}\NormalTok{:  }\CommentTok{\# defensive: small train}
\NormalTok{        q\_low, q\_high }\OperatorTok{=} \FloatTok{0.4}\NormalTok{, }\FloatTok{0.8}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.quantile(v, q\_low)), }\BuiltInTok{float}\NormalTok{(np.quantile(v, q\_high))}

\KeywordTok{def}\NormalTok{ label\_regime(df, vol\_col, lo, hi):}
    \CommentTok{\# low: \textless{}= lo, high: \textgreater{}= hi, else med; NaNs {-}\textgreater{} \textquotesingle{}unknown\textquotesingle{}}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    vc }\OperatorTok{=}\NormalTok{ out[vol\_col]}
\NormalTok{    regime }\OperatorTok{=}\NormalTok{ pd.Series(pd.Categorical([}\StringTok{"unknown"}\NormalTok{]}\OperatorTok{*}\BuiltInTok{len}\NormalTok{(out), categories}\OperatorTok{=}\NormalTok{[}\StringTok{"low"}\NormalTok{,}\StringTok{"med"}\NormalTok{,}\StringTok{"high"}\NormalTok{,}\StringTok{"unknown"}\NormalTok{]), index}\OperatorTok{=}\NormalTok{out.index)}
\NormalTok{    regime[(vc.notna()) }\OperatorTok{\&}\NormalTok{ (vc }\OperatorTok{\textless{}=}\NormalTok{ lo)] }\OperatorTok{=} \StringTok{"low"}
\NormalTok{    regime[(vc.notna()) }\OperatorTok{\&}\NormalTok{ (vc }\OperatorTok{\textgreater{}}\NormalTok{ lo) }\OperatorTok{\&}\NormalTok{ (vc }\OperatorTok{\textless{}}\NormalTok{ hi)] }\OperatorTok{=} \StringTok{"med"}
\NormalTok{    regime[(vc.notna()) }\OperatorTok{\&}\NormalTok{ (vc }\OperatorTok{\textgreater{}=}\NormalTok{ hi)] }\OperatorTok{=} \StringTok{"high"}
\NormalTok{    out[}\StringTok{"regime"}\NormalTok{] }\OperatorTok{=}\NormalTok{ regime.astype(}\StringTok{"category"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ out}

\CommentTok{\# Demonstrate on first split in class}
\NormalTok{a,b,c,d }\OperatorTok{=}\NormalTok{ splits[}\DecValTok{0}\NormalTok{]}
\NormalTok{tr }\OperatorTok{=}\NormalTok{ feats[(feats[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a) }\OperatorTok{\&}\NormalTok{ (feats[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)]}
\NormalTok{va }\OperatorTok{=}\NormalTok{ feats[(feats[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c) }\OperatorTok{\&}\NormalTok{ (feats[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)]}
\NormalTok{lo, hi }\OperatorTok{=}\NormalTok{ regime\_thresholds(tr, }\StringTok{"roll\_std\_20"}\NormalTok{, }\FloatTok{0.33}\NormalTok{, }\FloatTok{0.66}\NormalTok{)}
\NormalTok{tr\_lab }\OperatorTok{=}\NormalTok{ label\_regime(tr, }\StringTok{"roll\_std\_20"}\NormalTok{, lo, hi)}
\NormalTok{va\_lab }\OperatorTok{=}\NormalTok{ label\_regime(va, }\StringTok{"roll\_std\_20"}\NormalTok{, lo, hi)}
\BuiltInTok{print}\NormalTok{(\{}\StringTok{"lo"}\NormalTok{: lo, }\StringTok{"hi"}\NormalTok{: hi\}, tr\_lab[}\StringTok{"regime"}\NormalTok{].value\_counts().to\_dict(), va\_lab[}\StringTok{"regime"}\NormalTok{].value\_counts().to\_dict())}
\end{Highlighting}
\end{Shaded}

\subsection{3) Baseline predictions (naive \& linear‑lags per ticker,
fit on TRAIN
only)}\label{baseline-predictions-naive-linearlags-per-ticker-fit-on-train-only}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.pipeline }\ImportTok{import}\NormalTok{ Pipeline}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}

\CommentTok{\# features we will use for linear baseline}
\NormalTok{XCOLS }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ [}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ feats.columns]}
\ControlFlowTok{if} \KeywordTok{not}\NormalTok{ XCOLS:}
    \CommentTok{\# create lags on the fly (causal)}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ feats.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).copy()}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]:}
\NormalTok{        feats[}\SpecialStringTok{f"lag}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{=}\NormalTok{ feats.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].shift(k)}
\NormalTok{    XCOLS }\OperatorTok{=}\NormalTok{ [}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{]}

\KeywordTok{def}\NormalTok{ fit\_predict\_lin\_per\_ticker(train\_df, val\_df):}
\NormalTok{    preds}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ tkr, trk }\KeywordTok{in}\NormalTok{ train\_df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        vak }\OperatorTok{=}\NormalTok{ val\_df[val\_df[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr]}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(trk)}\OperatorTok{==}\DecValTok{0} \KeywordTok{or} \BuiltInTok{len}\NormalTok{(vak)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{        pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{"scaler"}\NormalTok{, StandardScaler()), (}\StringTok{"lr"}\NormalTok{, LinearRegression())])}
\NormalTok{        pipe.fit(trk[XCOLS].dropna().values, trk.dropna(subset}\OperatorTok{=}\NormalTok{XCOLS)[}\StringTok{"r\_1d"}\NormalTok{].values)}
\NormalTok{        yhat }\OperatorTok{=}\NormalTok{ pipe.predict(vak[XCOLS].fillna(}\DecValTok{0}\NormalTok{).values)}
\NormalTok{        out }\OperatorTok{=}\NormalTok{ vak[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"regime"}\NormalTok{]].copy()}
\NormalTok{        out[}\StringTok{"yhat\_lin"}\NormalTok{] }\OperatorTok{=}\NormalTok{ yhat.astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        preds.append(out)}
    \ControlFlowTok{return}\NormalTok{ pd.concat(preds, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ preds }\ControlFlowTok{else}\NormalTok{ pd.DataFrame()}

\KeywordTok{def}\NormalTok{ add\_naive\_preds(df):}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    out[}\StringTok{"yhat\_naive"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out[}\StringTok{"log\_return"}\NormalTok{]  }\CommentTok{\# r\_\{t+1\} \textasciitilde{} log\_return\_t}
    \ControlFlowTok{return}\NormalTok{ out}

\NormalTok{tr\_lab2 }\OperatorTok{=}\NormalTok{ add\_naive\_preds(tr\_lab)}
\NormalTok{va\_lab2 }\OperatorTok{=}\NormalTok{ add\_naive\_preds(va\_lab)}
\NormalTok{val\_lin }\OperatorTok{=}\NormalTok{ fit\_predict\_lin\_per\_ticker(tr\_lab2, va\_lab2)}
\NormalTok{val }\OperatorTok{=}\NormalTok{ va\_lab2.merge(val\_lin[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"yhat\_lin"}\NormalTok{]], on}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{], how}\OperatorTok{=}\StringTok{"left"}\NormalTok{)}
\NormalTok{val.head(}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) Metrics \textbf{by regime} (MAE, sMAPE,
MASE; macro \&
micro)}{4) Metrics by regime (MAE, sMAPE, MASE; macro \& micro)}}\label{metrics-by-regime-mae-smape-mase-macro-micro}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ mae(y, yhat): }
\NormalTok{    y }\OperatorTok{=}\NormalTok{ np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.asarray(yhat)}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat)))}

\KeywordTok{def}\NormalTok{ smape(y,yhat,eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{):}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.asarray(yhat)}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(}\FloatTok{2.0}\OperatorTok{*}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(y}\OperatorTok{{-}}\NormalTok{yhat)}\OperatorTok{/}\NormalTok{(np.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps)))}

\KeywordTok{def}\NormalTok{ mase(y\_true, y\_pred, y\_train\_true, y\_train\_naive):}
\NormalTok{    scale }\OperatorTok{=}\NormalTok{ mae(y\_train\_true, y\_train\_naive) }\OperatorTok{+} \FloatTok{1e{-}12}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(mae(y\_true,y\_pred)}\OperatorTok{/}\NormalTok{scale)}

\KeywordTok{def}\NormalTok{ per\_regime\_metrics(val\_df, train\_df, pred\_col):}
\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ reg, g }\KeywordTok{in}\NormalTok{ val\_df.groupby(}\StringTok{"regime"}\NormalTok{):}
        \ControlFlowTok{if}\NormalTok{ reg }\OperatorTok{==} \StringTok{"unknown"} \KeywordTok{or} \BuiltInTok{len}\NormalTok{(g)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }
            \ControlFlowTok{continue}
        \CommentTok{\# build per{-}ticker MASE scales from TRAIN}
\NormalTok{        per\_t }\OperatorTok{=}\NormalTok{ []}
        \ControlFlowTok{for}\NormalTok{ tkr, gv }\KeywordTok{in}\NormalTok{ g.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{            gt }\OperatorTok{=}\NormalTok{ train\_df[train\_df[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr].dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{])}
            \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(gt)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{            m }\OperatorTok{=}\NormalTok{ \{}
                \StringTok{"ticker"}\NormalTok{: tkr,}
                \StringTok{"n"}\NormalTok{: }\BuiltInTok{int}\NormalTok{(gv[}\StringTok{"r\_1d"}\NormalTok{].notna().}\BuiltInTok{sum}\NormalTok{()),}
                \StringTok{"mae"}\NormalTok{: mae(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[pred\_col]),}
                \StringTok{"smape"}\NormalTok{: smape(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[pred\_col]),}
                \StringTok{"mase"}\NormalTok{: mase(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[pred\_col], gt[}\StringTok{"r\_1d"}\NormalTok{], gt[}\StringTok{"log\_return"}\NormalTok{]),}
                \StringTok{"regime"}\NormalTok{: reg}
\NormalTok{            \}}
\NormalTok{            per\_t.append(m)}
\NormalTok{        per\_t }\OperatorTok{=}\NormalTok{ pd.DataFrame(per\_t)}
        \ControlFlowTok{if}\NormalTok{ per\_t.empty: }
            \ControlFlowTok{continue}
        \CommentTok{\# macro (mean of per{-}ticker)}
\NormalTok{        macro }\OperatorTok{=}\NormalTok{ per\_t[[}\StringTok{"mae"}\NormalTok{,}\StringTok{"smape"}\NormalTok{,}\StringTok{"mase"}\NormalTok{]].mean().to\_dict()}
        \CommentTok{\# micro (weighted by n)}
\NormalTok{        w }\OperatorTok{=}\NormalTok{ per\_t[}\StringTok{"n"}\NormalTok{].to\_numpy()}
\NormalTok{        micro }\OperatorTok{=}\NormalTok{ \{}
            \StringTok{"micro\_mae"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(per\_t[}\StringTok{"mae"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
            \StringTok{"micro\_smape"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(per\_t[}\StringTok{"smape"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
            \StringTok{"micro\_mase"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(per\_t[}\StringTok{"mase"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
\NormalTok{        \}}
\NormalTok{        rows.append(\{}\StringTok{"regime"}\NormalTok{:reg, }\OperatorTok{**}\NormalTok{\{}\SpecialStringTok{f"macro\_}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{:}\BuiltInTok{float}\NormalTok{(v) }\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ macro.items()\}, }\OperatorTok{**}\NormalTok{micro\})}
    \ControlFlowTok{return}\NormalTok{ pd.DataFrame(rows)}

\NormalTok{met\_naive }\OperatorTok{=}\NormalTok{ per\_regime\_metrics(val, tr\_lab2, }\StringTok{"yhat\_naive"}\NormalTok{)}
\NormalTok{met\_lin   }\OperatorTok{=}\NormalTok{ per\_regime\_metrics(val.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"yhat\_lin"}\NormalTok{]), tr\_lab2, }\StringTok{"yhat\_lin"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"NAIVE by regime:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, met\_naive)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{LIN{-}LAGS by regime:}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, met\_lin)}
\CommentTok{\# Save}
\NormalTok{pd.concat([}
\NormalTok{    met\_naive.assign(model}\OperatorTok{=}\StringTok{"naive"}\NormalTok{),}
\NormalTok{    met\_lin.assign(model}\OperatorTok{=}\StringTok{"lin\_lags"}\NormalTok{)}
\NormalTok{], ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).to\_csv(}\StringTok{"reports/regime\_metrics\_split1.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{5) \textbf{Calibration plots} overall and by
regime
(binned)}{5) Calibration plots overall and by regime (binned)}}\label{calibration-plots-overall-and-by-regime-binned}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd, pathlib}

\KeywordTok{def}\NormalTok{ calibration\_by\_bins(df, pred\_col, y\_col}\OperatorTok{=}\StringTok{"r\_1d"}\NormalTok{, n\_bins}\OperatorTok{=}\DecValTok{10}\NormalTok{):}
\NormalTok{    d }\OperatorTok{=}\NormalTok{ df.dropna(subset}\OperatorTok{=}\NormalTok{[pred\_col, y\_col]).copy()}
\NormalTok{    d[}\StringTok{"bin"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.qcut(d[pred\_col], q}\OperatorTok{=}\NormalTok{n\_bins, duplicates}\OperatorTok{=}\StringTok{"drop"}\NormalTok{)}
\NormalTok{    grp }\OperatorTok{=}\NormalTok{ d.groupby(}\StringTok{"bin"}\NormalTok{).agg(}
\NormalTok{        mean\_pred}\OperatorTok{=}\NormalTok{(pred\_col, }\StringTok{"mean"}\NormalTok{),}
\NormalTok{        mean\_true}\OperatorTok{=}\NormalTok{(y\_col, }\StringTok{"mean"}\NormalTok{),}
\NormalTok{        count}\OperatorTok{=}\NormalTok{(y\_col, }\StringTok{"size"}\NormalTok{)}
\NormalTok{    ).reset\_index()}
    \ControlFlowTok{return}\NormalTok{ grp}

\CommentTok{\# Overall calibration (lin\_lags) on validation slice}
\NormalTok{cal\_overall }\OperatorTok{=}\NormalTok{ calibration\_by\_bins(val.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"yhat\_lin"}\NormalTok{]), }\StringTok{"yhat\_lin"}\NormalTok{, }\StringTok{"r\_1d"}\NormalTok{, n\_bins}\OperatorTok{=}\DecValTok{10}\NormalTok{)}

\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\NormalTok{plt.plot(cal\_overall[}\StringTok{"mean\_pred"}\NormalTok{], cal\_overall[}\StringTok{"mean\_true"}\NormalTok{], marker}\OperatorTok{=}\StringTok{"o"}\NormalTok{)}
\NormalTok{lim }\OperatorTok{=} \BuiltInTok{max}\NormalTok{(}\BuiltInTok{abs}\NormalTok{(cal\_overall[}\StringTok{"mean\_pred"}\NormalTok{]).}\BuiltInTok{max}\NormalTok{(), }\BuiltInTok{abs}\NormalTok{(cal\_overall[}\StringTok{"mean\_true"}\NormalTok{]).}\BuiltInTok{max}\NormalTok{())}
\NormalTok{plt.plot([}\OperatorTok{{-}}\NormalTok{lim, lim], [}\OperatorTok{{-}}\NormalTok{lim, lim], linestyle}\OperatorTok{=}\StringTok{"{-}{-}"}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{"Mean predicted (bin)"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.ylabel(}\StringTok{"Mean realized (bin)"}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"Calibration (overall) — lin\_lags"}\NormalTok{)}
\NormalTok{plt.tight\_layout()}
\NormalTok{plt.savefig(}\StringTok{"docs/figs/calibration\_overall\_lin.png"}\NormalTok{, dpi}\OperatorTok{=}\DecValTok{160}\NormalTok{)}
\CommentTok{"Saved docs/figs/calibration\_overall\_lin.png"}

\CommentTok{\# By regime}
\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\FloatTok{6.5}\NormalTok{,}\FloatTok{4.5}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{ i, reg }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{([}\StringTok{"low"}\NormalTok{,}\StringTok{"med"}\NormalTok{,}\StringTok{"high"}\NormalTok{], start}\OperatorTok{=}\DecValTok{1}\NormalTok{):}
\NormalTok{    g }\OperatorTok{=}\NormalTok{ val[(val[}\StringTok{"regime"}\NormalTok{]}\OperatorTok{==}\NormalTok{reg) }\OperatorTok{\&}\NormalTok{ (val[}\StringTok{"yhat\_lin"}\NormalTok{].notna())]}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(g) }\OperatorTok{\textless{}} \DecValTok{50}\NormalTok{: }
        \ControlFlowTok{continue}
\NormalTok{    cal }\OperatorTok{=}\NormalTok{ calibration\_by\_bins(g, }\StringTok{"yhat\_lin"}\NormalTok{, }\StringTok{"r\_1d"}\NormalTok{, n\_bins}\OperatorTok{=}\DecValTok{6}\NormalTok{)}
\NormalTok{    plt.plot(cal[}\StringTok{"mean\_pred"}\NormalTok{], cal[}\StringTok{"mean\_true"}\NormalTok{], marker}\OperatorTok{=}\StringTok{"o"}\NormalTok{, label}\OperatorTok{=}\NormalTok{reg)}
\NormalTok{lim }\OperatorTok{=} \FloatTok{0.02}  \CommentTok{\# small returns}
\NormalTok{plt.plot([}\OperatorTok{{-}}\NormalTok{lim, lim], [}\OperatorTok{{-}}\NormalTok{lim, lim], linestyle}\OperatorTok{=}\StringTok{"{-}{-}"}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{"Mean predicted (bin)"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.ylabel(}\StringTok{"Mean realized (bin)"}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"Calibration by regime — lin\_lags"}\NormalTok{)}
\NormalTok{plt.legend()}
\NormalTok{plt.tight\_layout()}
\NormalTok{plt.savefig(}\StringTok{"docs/figs/calibration\_by\_regime\_lin.png"}\NormalTok{, dpi}\OperatorTok{=}\DecValTok{160}\NormalTok{)}
\CommentTok{"Saved docs/figs/calibration\_by\_regime\_lin.png"}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min) --- key points to
emphasize}\label{wrapup-10-min-key-points-to-emphasize}

\begin{itemize}
\tightlist
\item
  \textbf{Regime thresholds must be set on TRAIN ONLY} each split to
  avoid leakage.
\item
  Report \textbf{by‑regime} metrics alongside overall metrics; show
  \textbf{macro} \& \textbf{micro}.
\item
  Calibration plots (binned predicted vs.~realized) quickly show
  \textbf{systematic bias}; compare regimes.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
19)}\label{homework-due-before-session-19}

\textbf{Goal:} Produce a \textbf{full regime‑aware evaluation} across
\textbf{all splits} for \textbf{naive} and \textbf{linear‑lags} models
and include the figures in your Quarto report.

\subsection{\texorpdfstring{A. Script: \texttt{scripts/regime\_eval.py}
--- run across all
splits}{A. Script: scripts/regime\_eval.py --- run across all splits}}\label{a.-script-scriptsregime_eval.py-run-across-all-splits}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/usr/bin/env python}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ argparse, json, numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{from}\NormalTok{ sklearn.pipeline }\ImportTok{import}\NormalTok{ Pipeline}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}

\KeywordTok{def}\NormalTok{ make\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    splits}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{ i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(u)}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        a,b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val\_size}\OperatorTok{{-}}\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\NormalTok{n: }\ControlFlowTok{break}
\NormalTok{        splits.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+=}\NormalTok{step}
    \ControlFlowTok{return}\NormalTok{ splits}

\KeywordTok{def}\NormalTok{ regime\_thresholds(train\_df, vol\_col}\OperatorTok{=}\StringTok{"roll\_std\_20"}\NormalTok{, q\_low}\OperatorTok{=}\FloatTok{0.33}\NormalTok{, q\_high}\OperatorTok{=}\FloatTok{0.66}\NormalTok{):}
\NormalTok{    v }\OperatorTok{=}\NormalTok{ train\_df[vol\_col].dropna().to\_numpy()}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(v) }\OperatorTok{\textless{}} \DecValTok{100}\NormalTok{:}
\NormalTok{        q\_low, q\_high }\OperatorTok{=} \FloatTok{0.4}\NormalTok{, }\FloatTok{0.8}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.quantile(v, q\_low)), }\BuiltInTok{float}\NormalTok{(np.quantile(v, q\_high))}

\KeywordTok{def}\NormalTok{ label\_regime(df, vol\_col, lo, hi):}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    vc }\OperatorTok{=}\NormalTok{ out[vol\_col]}
\NormalTok{    reg }\OperatorTok{=}\NormalTok{ pd.Series(pd.Categorical([}\StringTok{"unknown"}\NormalTok{]}\OperatorTok{*}\BuiltInTok{len}\NormalTok{(out), categories}\OperatorTok{=}\NormalTok{[}\StringTok{"low"}\NormalTok{,}\StringTok{"med"}\NormalTok{,}\StringTok{"high"}\NormalTok{,}\StringTok{"unknown"}\NormalTok{]), index}\OperatorTok{=}\NormalTok{out.index)}
\NormalTok{    reg[(vc.notna()) }\OperatorTok{\&}\NormalTok{ (vc }\OperatorTok{\textless{}=}\NormalTok{ lo)] }\OperatorTok{=} \StringTok{"low"}
\NormalTok{    reg[(vc.notna()) }\OperatorTok{\&}\NormalTok{ (vc }\OperatorTok{\textgreater{}}\NormalTok{ lo) }\OperatorTok{\&}\NormalTok{ (vc }\OperatorTok{\textless{}}\NormalTok{ hi)] }\OperatorTok{=} \StringTok{"med"}
\NormalTok{    reg[(vc.notna()) }\OperatorTok{\&}\NormalTok{ (vc }\OperatorTok{\textgreater{}=}\NormalTok{ hi)] }\OperatorTok{=} \StringTok{"high"}
\NormalTok{    out[}\StringTok{"regime"}\NormalTok{] }\OperatorTok{=}\NormalTok{ reg.astype(}\StringTok{"category"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ add\_naive(df):}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ df.copy()}
\NormalTok{    out[}\StringTok{"yhat\_naive"}\NormalTok{] }\OperatorTok{=}\NormalTok{ out[}\StringTok{"log\_return"}\NormalTok{]}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ fit\_lin(tr, va, xcols):}
    \ImportTok{from}\NormalTok{ sklearn.pipeline }\ImportTok{import}\NormalTok{ Pipeline}
    \ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
    \ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\NormalTok{    preds}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ tkr, trk }\KeywordTok{in}\NormalTok{ tr.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        vak }\OperatorTok{=}\NormalTok{ va[va[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr]}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(trk)}\OperatorTok{==}\DecValTok{0} \KeywordTok{or} \BuiltInTok{len}\NormalTok{(vak)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{        Xtr }\OperatorTok{=}\NormalTok{ trk.dropna(subset}\OperatorTok{=}\NormalTok{xcols)}\OperatorTok{;} 
\NormalTok{        pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{"scaler"}\NormalTok{, StandardScaler()), (}\StringTok{"lr"}\NormalTok{, LinearRegression())])}
\NormalTok{        pipe.fit(Xtr[xcols].values, Xtr[}\StringTok{"r\_1d"}\NormalTok{].values)}
\NormalTok{        yhat }\OperatorTok{=}\NormalTok{ pipe.predict(vak[xcols].fillna(}\DecValTok{0}\NormalTok{).values)}
\NormalTok{        out }\OperatorTok{=}\NormalTok{ vak[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"regime"}\NormalTok{]].copy()}
\NormalTok{        out[}\StringTok{"yhat\_lin"}\NormalTok{] }\OperatorTok{=}\NormalTok{ yhat}
\NormalTok{        preds.append(out)}
    \ControlFlowTok{return}\NormalTok{ pd.concat(preds, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ preds }\ControlFlowTok{else}\NormalTok{ pd.DataFrame()}

\KeywordTok{def}\NormalTok{ mae(y, yhat): y}\OperatorTok{=}\NormalTok{np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat}\OperatorTok{=}\NormalTok{np.asarray(yhat)}\OperatorTok{;} \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(y}\OperatorTok{{-}}\NormalTok{yhat)))}
\KeywordTok{def}\NormalTok{ smape(y,yhat,eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{):}
\NormalTok{    y}\OperatorTok{=}\NormalTok{np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat}\OperatorTok{=}\NormalTok{np.asarray(yhat)}\OperatorTok{;} \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(}\DecValTok{2}\OperatorTok{*}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(y}\OperatorTok{{-}}\NormalTok{yhat)}\OperatorTok{/}\NormalTok{(np.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps)))}
\KeywordTok{def}\NormalTok{ mase(y\_true, y\_pred, y\_train\_true, y\_train\_naive):}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(mae(y\_true, y\_pred)}\OperatorTok{/}\NormalTok{(mae(y\_train\_true, y\_train\_naive)}\OperatorTok{+}\FloatTok{1e{-}12}\NormalTok{))}

\KeywordTok{def}\NormalTok{ per\_regime\_metrics(val\_df, train\_df, pred\_col):}
\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ reg, g }\KeywordTok{in}\NormalTok{ val\_df.groupby(}\StringTok{"regime"}\NormalTok{):}
        \ControlFlowTok{if}\NormalTok{ reg}\OperatorTok{==}\StringTok{"unknown"} \KeywordTok{or} \BuiltInTok{len}\NormalTok{(g)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{        per}\OperatorTok{=}\NormalTok{[]}
        \ControlFlowTok{for}\NormalTok{ tkr, gv }\KeywordTok{in}\NormalTok{ g.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{            gt }\OperatorTok{=}\NormalTok{ train\_df[train\_df[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr].dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{])}
            \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(gt)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{            per.append(\{}\StringTok{"ticker"}\NormalTok{:tkr,}\StringTok{"n"}\NormalTok{:}\BuiltInTok{int}\NormalTok{(gv[}\StringTok{"r\_1d"}\NormalTok{].notna().}\BuiltInTok{sum}\NormalTok{()),}
                        \StringTok{"mae"}\NormalTok{: mae(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[pred\_col]),}
                        \StringTok{"smape"}\NormalTok{: smape(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[pred\_col]),}
                        \StringTok{"mase"}\NormalTok{: mase(gv[}\StringTok{"r\_1d"}\NormalTok{], gv[pred\_col], gt[}\StringTok{"r\_1d"}\NormalTok{], gt[}\StringTok{"log\_return"}\NormalTok{]),}
                        \StringTok{"regime"}\NormalTok{: reg\})}
\NormalTok{        pt }\OperatorTok{=}\NormalTok{ pd.DataFrame(per)}
        \ControlFlowTok{if}\NormalTok{ pt.empty: }\ControlFlowTok{continue}
\NormalTok{        macro }\OperatorTok{=}\NormalTok{ pt[[}\StringTok{"mae"}\NormalTok{,}\StringTok{"smape"}\NormalTok{,}\StringTok{"mase"}\NormalTok{]].mean().to\_dict()}
\NormalTok{        w }\OperatorTok{=}\NormalTok{ pt[}\StringTok{"n"}\NormalTok{].to\_numpy()}
\NormalTok{        micro }\OperatorTok{=}\NormalTok{ \{}\StringTok{"micro\_mae"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(pt[}\StringTok{"mae"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
                 \StringTok{"micro\_smape"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(pt[}\StringTok{"smape"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w)),}
                 \StringTok{"micro\_mase"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.average(pt[}\StringTok{"mase"}\NormalTok{], weights}\OperatorTok{=}\NormalTok{w))\}}
\NormalTok{        rows.append(\{}\StringTok{"regime"}\NormalTok{:reg, }\OperatorTok{**}\NormalTok{\{}\SpecialStringTok{f"macro\_}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{:}\BuiltInTok{float}\NormalTok{(v) }\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ macro.items()\}, }\OperatorTok{**}\NormalTok{micro\})}
    \ControlFlowTok{return}\NormalTok{ pd.DataFrame(rows)}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    ap }\OperatorTok{=}\NormalTok{ argparse.ArgumentParser()}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}features"}\NormalTok{, default}\OperatorTok{=}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}train{-}min"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{252}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}val{-}size"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{63}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}step"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{63}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}embargo"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{5}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}vol{-}col"}\NormalTok{, default}\OperatorTok{=}\StringTok{"roll\_std\_20"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}xcols"}\NormalTok{, nargs}\OperatorTok{=}\StringTok{"+"}\NormalTok{, default}\OperatorTok{=}\NormalTok{[}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{])}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}out{-}summary"}\NormalTok{, default}\OperatorTok{=}\StringTok{"reports/regime\_summary.csv"}\NormalTok{)}
\NormalTok{    args }\OperatorTok{=}\NormalTok{ ap.parse\_args()}

\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(args.features).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
    \CommentTok{\# Ensure vol col exists}
    \ControlFlowTok{if}\NormalTok{ args.vol\_col }\KeywordTok{not} \KeywordTok{in}\NormalTok{ df.columns:}
\NormalTok{        df[args.vol\_col] }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

    \CommentTok{\# Build lags if missing}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]:}
\NormalTok{        col }\OperatorTok{=} \SpecialStringTok{f"lag}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}
        \ControlFlowTok{if}\NormalTok{ col }\KeywordTok{not} \KeywordTok{in}\NormalTok{ df.columns:}
\NormalTok{            df[col] }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].shift(k)}

\NormalTok{    splits }\OperatorTok{=}\NormalTok{ make\_splits(df[}\StringTok{"date"}\NormalTok{], args.train\_min, args.val\_size, args.step, args.embargo)}
\NormalTok{    Path(}\StringTok{"reports"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    thresh\_rec }\OperatorTok{=}\NormalTok{ \{\}}

\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ sid,(a,b,c,d) }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(splits, start}\OperatorTok{=}\DecValTok{1}\NormalTok{):}
\NormalTok{        tr }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)]}
\NormalTok{        va }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)]}
\NormalTok{        lo, hi }\OperatorTok{=}\NormalTok{ regime\_thresholds(tr, args.vol\_col)}
\NormalTok{        thresh\_rec[sid] }\OperatorTok{=}\NormalTok{ \{}\StringTok{"lo"}\NormalTok{:lo, }\StringTok{"hi"}\NormalTok{:hi, }\StringTok{"train\_range"}\NormalTok{:}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{a}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{→}\SpecialCharTok{\{}\NormalTok{b}\SpecialCharTok{.}\NormalTok{date()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{\}}
\NormalTok{        trL }\OperatorTok{=}\NormalTok{ label\_regime(tr, args.vol\_col, lo, hi)}
\NormalTok{        vaL }\OperatorTok{=}\NormalTok{ label\_regime(va, args.vol\_col, lo, hi)}

        \CommentTok{\# predictions}
\NormalTok{        trN, vaN }\OperatorTok{=}\NormalTok{ add\_naive(trL), add\_naive(vaL)}
\NormalTok{        val\_lin }\OperatorTok{=}\NormalTok{ fit\_lin(trN, vaN, args.xcols)}
\NormalTok{        vaN }\OperatorTok{=}\NormalTok{ vaN.merge(val\_lin[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"yhat\_lin"}\NormalTok{]], on}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{], how}\OperatorTok{=}\StringTok{"left"}\NormalTok{)}

        \CommentTok{\# metrics}
\NormalTok{        m\_naive }\OperatorTok{=}\NormalTok{ per\_regime\_metrics(vaN, trN, }\StringTok{"yhat\_naive"}\NormalTok{).assign(split}\OperatorTok{=}\NormalTok{sid, model}\OperatorTok{=}\StringTok{"naive"}\NormalTok{)}
\NormalTok{        m\_lin   }\OperatorTok{=}\NormalTok{ per\_regime\_metrics(vaN.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"yhat\_lin"}\NormalTok{]), trN, }\StringTok{"yhat\_lin"}\NormalTok{).assign(split}\OperatorTok{=}\NormalTok{sid, model}\OperatorTok{=}\StringTok{"lin\_lags"}\NormalTok{)}

\NormalTok{        out }\OperatorTok{=}\NormalTok{ pd.concat([m\_naive, m\_lin], ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        out.to\_csv(}\SpecialStringTok{f"reports/regime\_metrics\_split}\SpecialCharTok{\{}\NormalTok{sid}\SpecialCharTok{\}}\SpecialStringTok{.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{        rows.append(out)}

\NormalTok{    pd.concat(rows, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).to\_csv(args.out\_summary, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{    Path(}\StringTok{"reports/regime\_thresholds.json"}\NormalTok{).write\_text(json.dumps(thresh\_rec, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{))}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, args.out\_summary, }\StringTok{"and per{-}split CSVs; thresholds saved to reports/regime\_thresholds.json"}\NormalTok{)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/regime\_eval.py}
\ExtensionTok{python}\NormalTok{ scripts/regime\_eval.py}
\end{Highlighting}
\end{Shaded}

\subsection{B. Plot summary figures for your
report}\label{b.-plot-summary-figures-for-your-report}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt, pathlib}
\NormalTok{pathlib.Path(}\StringTok{"docs/figs"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"reports/regime\_summary.csv"}\NormalTok{)}
\CommentTok{\# Micro MAE by regime per model}
\NormalTok{pivot }\OperatorTok{=}\NormalTok{ df.pivot\_table(index}\OperatorTok{=}\NormalTok{[}\StringTok{"split"}\NormalTok{,}\StringTok{"regime"}\NormalTok{], columns}\OperatorTok{=}\StringTok{"model"}\NormalTok{, values}\OperatorTok{=}\StringTok{"micro\_mae"}\NormalTok{)}
\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{ model }\KeywordTok{in}\NormalTok{ pivot.columns:}
\NormalTok{    plt.plot(pivot.xs(}\StringTok{"low"}\NormalTok{, level}\OperatorTok{=}\StringTok{"regime"}\NormalTok{).index, pivot.xs(}\StringTok{"low"}\NormalTok{, level}\OperatorTok{=}\StringTok{"regime"}\NormalTok{)[model], marker}\OperatorTok{=}\StringTok{"o"}\NormalTok{, label}\OperatorTok{=}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{model}\SpecialCharTok{\}}\SpecialStringTok{ — low"}\NormalTok{)}
\NormalTok{    plt.plot(pivot.xs(}\StringTok{"high"}\NormalTok{, level}\OperatorTok{=}\StringTok{"regime"}\NormalTok{).index, pivot.xs(}\StringTok{"high"}\NormalTok{, level}\OperatorTok{=}\StringTok{"regime"}\NormalTok{)[model], marker}\OperatorTok{=}\StringTok{"s"}\NormalTok{, label}\OperatorTok{=}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{model}\SpecialCharTok{\}}\SpecialStringTok{ — high"}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{"Split"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.ylabel(}\StringTok{"Micro MAE"}\NormalTok{)}
\NormalTok{plt.title(}\StringTok{"Micro MAE by regime (low vs high)"}\NormalTok{)}
\NormalTok{plt.legend()}\OperatorTok{;}\NormalTok{ plt.tight\_layout()}
\NormalTok{plt.savefig(}\StringTok{"docs/figs/regime\_micro\_mae.png"}\NormalTok{, dpi}\OperatorTok{=}\DecValTok{160}\NormalTok{)}
\CommentTok{"Saved docs/figs/regime\_micro\_mae.png"}
\end{Highlighting}
\end{Shaded}

\subsection{C. Add to Quarto report}\label{c.-add-to-quarto-report}

In \texttt{reports/eda.qmd} (or a new \texttt{reports/regime.qmd}),
include:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# Regime‑aware Results}

\NormalTok{::: \{.cell execution\_count=1\}}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{} \{.python .cell{-}code\}}
\InformationTok{import pandas as pd}
\InformationTok{df = pd.read\_csv("reports/regime\_summary.csv")}
\InformationTok{df.sort\_values(["split","model","regime"]).head(12)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{../docs/figs/regime_micro_mae.png}}

\pandocbounded{\includegraphics[keepaspectratio]{../docs/figs/calibration_overall_lin.png}}

\pandocbounded{\includegraphics[keepaspectratio]{../docs/figs/calibration_by_regime_lin.png}}

\begin{verbatim}

Render:
```bash
quarto render reports/eda.qmd
\end{verbatim}

\subsection{\texorpdfstring{D. Quick test to protect \textbf{train‑only}
thresholds}{D. Quick test to protect train‑only thresholds}}\label{d.-quick-test-to-protect-trainonly-thresholds}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_regime\_thresholds.py}
\ImportTok{import}\NormalTok{ json, pandas }\ImportTok{as}\NormalTok{ pd}

\KeywordTok{def}\NormalTok{ test\_thresholds\_exist\_and\_train\_range():}
\NormalTok{    data }\OperatorTok{=}\NormalTok{ json.load(}\BuiltInTok{open}\NormalTok{(}\StringTok{"reports/regime\_thresholds.json"}\NormalTok{))}
    \ControlFlowTok{assert} \BuiltInTok{len}\NormalTok{(data) }\OperatorTok{\textgreater{}=} \DecValTok{1}
    \CommentTok{\# basic sanity: low \textless{} high}
    \ControlFlowTok{for}\NormalTok{ sid, rec }\KeywordTok{in}\NormalTok{ data.items():}
        \ControlFlowTok{assert} \BuiltInTok{float}\NormalTok{(rec[}\StringTok{"lo"}\NormalTok{]) }\OperatorTok{\textless{}} \BuiltInTok{float}\NormalTok{(rec[}\StringTok{"hi"}\NormalTok{])}
        \ControlFlowTok{assert} \StringTok{"→"} \KeywordTok{in}\NormalTok{ rec[}\StringTok{"train\_range"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

:::

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}k}\NormalTok{ regime\_thresholds}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-9}

\begin{itemize}
\tightlist
\item
  Ensure \texttt{features\_v1.parquet} contains \texttt{roll\_std\_20}
  (or let lab compute it).
\item
  Keep the in‑class run to the \textbf{first split} to finish inside the
  time box; homework runs all splits.
\item
  Have a slide explaining \textbf{why thresholds must not be learned on
  validation/test}.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-9}

\begin{itemize}
\tightlist
\item
  Regime thresholds are \textbf{part of your training‑time
  state}---store them (JSON) and \textbf{do not recompute from
  validation/test}.
\item
  Report both \textbf{macro} and \textbf{micro} metrics \textbf{by
  regime} so small/large tickers don't dominate silently.
\item
  Use calibration plots to diagnose \textbf{systematic bias}; e.g.,
  under‑prediction in \textbf{high vol}.
\end{itemize}

\section{Grading (pass/revise)}\label{grading-passrevise-8}

\begin{itemize}
\tightlist
\item
  \texttt{scripts/regime\_eval.py} runs and writes
  \texttt{reports/regime\_summary.csv} + per‑split CSVs.
\item
  Thresholds saved to \texttt{reports/regime\_thresholds.json}.
\item
  Figures exist under \texttt{docs/figs/} and are embedded in the
  report.
\item
  Short tests pass; report includes a paragraph discussing results by
  regime.
\end{itemize}

You now have a \textbf{regime‑aware evaluation} layered on your
rolling‑origin pipeline---perfect preparation for Session 19, where
you'll implement PyTorch datasets and a minimal training loop.

\bookmarksetup{startatroot}

\chapter{Session 19 --- Tensors, Datasets, Training
Loop}\label{session-19-tensors-datasets-training-loop}

Below is a complete lecture package for \textbf{Session 19 --- Tensors,
Datasets, Training Loop} (75 minutes). It includes a timed agenda, slide
talking points, a \textbf{Colab‑friendly in‑class lab with copy‑paste
code}, and \textbf{homework with copy‑paste code}. You will build a
\textbf{windowed multi‑ticker dataset} for next‑day return prediction,
write a \textbf{minimal PyTorch training loop} with \textbf{early
stopping}, and \textbf{save/load checkpoints}. We'll keep it
CPU‑friendly and optionally accelerate with GPU/Mixed Precision on
Colab.

\begin{quote}
\textbf{Educational use only --- not trading advice.} Assumes your
Drive‑mounted repo (e.g., \texttt{unified-stocks-teamX}) and
\texttt{data/processed/features\_v1.parquet} (or
\texttt{features\_v1\_static.parquet}) with columns like:
\texttt{ticker}, \texttt{date}, \texttt{log\_return}, \texttt{r\_1d}
(label), and some features (\texttt{lag1..lag3}, \texttt{roll\_std\_20},
\texttt{zscore\_20}, \ldots). Cells include \textbf{safe fallbacks} if
files are missing.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 19 --- Tensors, Datasets, Training Loop (75
min)}\label{session-19-tensors-datasets-training-loop-75-min}

\subsection{Learning goals}\label{learning-goals-18}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a \textbf{windowed sequence dataset} across \textbf{multiple
  tickers} with shape \texttt{(B,\ T,\ F)} → predict \texttt{r\_1d} at
  time \texttt{t+1}.
\item
  Use \texttt{Dataset}/\texttt{DataLoader} correctly: \textbf{pin
  memory}, worker seeding, and efficient slicing.
\item
  Write a \textbf{minimal training loop} with \textbf{early stopping},
  \textbf{AMP} (mixed precision on GPU), and \textbf{checkpoint
  save/load}.
\item
  Produce a tidy \textbf{validation metrics CSV} to compare later
  models.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-16}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: tensors \& batching;
  \texttt{Dataset}/\texttt{DataLoader}; pinning memory; reproducibility
  with seeds
\item
  \textbf{(10 min)} Slides: training loop anatomy; early stopping; AMP;
  checkpoints
\item
  \textbf{(35 min)} \textbf{In‑class lab}: build
  \texttt{WindowedDataset} → DataLoaders → tiny GRU regressor → train w/
  early stopping → save best checkpoint; evaluate
\item
  \textbf{(10 min)} Wrap‑up + homework brief
\item
  \textbf{(10 min)} Buffer
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points (drop into your
deck)}\label{slides-talking-points-drop-into-your-deck-2}

\subsection{Tensors \& batching}\label{tensors-batching}

\begin{itemize}
\tightlist
\item
  Tensors are N‑D arrays on \textbf{CPU} or \textbf{GPU}
  (\texttt{.to(device)}); keep everything \texttt{float32} unless using
  AMP.
\item
  For sequences: \textbf{batch} × \textbf{time} × \textbf{features} ⇒
  \texttt{(B,\ T,\ F)}. Predict a scalar per sequence end
  (\texttt{r\_1d} at time \texttt{t+1}).
\end{itemize}

\subsection{\texorpdfstring{\texttt{Dataset}/\texttt{DataLoader}
patterns}{Dataset/DataLoader patterns}}\label{datasetdataloader-patterns}

\begin{itemize}
\item
  \textbf{Precompute an index} of windows: for each ticker, sliding
  windows end at \texttt{i} with context \texttt{T}; target is
  \texttt{r\_1d{[}i{]}}.
\item
  \texttt{DataLoader} tips:

  \begin{itemize}
  \tightlist
  \item
    \texttt{pin\_memory=True} and \texttt{non\_blocking=True} on
    \texttt{.to(device)} speed H2D copies (when using GPU).
  \item
    Seed workers for reproducibility; keep \texttt{num\_workers=2}
    (Colab stable).
  \end{itemize}
\end{itemize}

\subsection{Seeds \& determinism}\label{seeds-determinism}

\begin{itemize}
\tightlist
\item
  Set \texttt{python}, \texttt{numpy}, \texttt{torch} seeds; disable
  CuDNN benchmarking for reproducibility; prefer small batch sizes that
  fit CPU/GPU.
\end{itemize}

\subsection{Training loop w/ early
stopping}\label{training-loop-w-early-stopping}

\begin{itemize}
\tightlist
\item
  Loop: \texttt{train\_step} (model in \texttt{train()}),
  \texttt{val\_step} (model in \texttt{eval()} + \texttt{no\_grad()}).
\item
  Track \textbf{best val loss}; stop after \texttt{patience} epochs
  without improvement.
\item
  Save \textbf{checkpoint}: \texttt{state\_dict}, optimizer state,
  epoch, metrics. Load with \texttt{load\_state\_dict}.
\end{itemize}

\subsection{AMP \& checkpoints}\label{amp-checkpoints}

\begin{itemize}
\tightlist
\item
  On CUDA, wrap forward in \texttt{torch.cuda.amp.autocast()} and use
  \texttt{GradScaler} to scale loss.
\item
  Save the best checkpoint to \texttt{models/…pt}; log a CSV under
  \texttt{reports/}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min,
Colab‑friendly)}\label{inclass-lab-35-min-colabfriendly-5}

\begin{quote}
Run each block as its own \textbf{separate cell} in Colab. Replace
\texttt{REPO\_NAME} as needed.
\end{quote}

\subsection{0) Setup, mount, and check
device}\label{setup-mount-and-check-device}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}   \CommentTok{\# \textless{}{-}{-} change to your repo}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, sys}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"models"}\NormalTok{,}\StringTok{"reports"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}

\ImportTok{import}\NormalTok{ torch, platform}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Torch:"}\NormalTok{, torch.\_\_version\_\_, }\StringTok{"| CUDA available:"}\NormalTok{, torch.cuda.is\_available(), }\StringTok{"| Python:"}\NormalTok{, sys.version.split()[}\DecValTok{0}\NormalTok{], }\StringTok{"| OS:"}\NormalTok{, platform.system())}
\end{Highlighting}
\end{Shaded}

\subsection{1) Load features and pick columns (with
fallbacks)}\label{load-features-and-pick-columns-with-fallbacks}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\CommentTok{\# Prefer static universe file if present (from Session 17)}
\NormalTok{f\_static }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1\_static.parquet"}\NormalTok{)}
\NormalTok{f\_base   }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}

\ControlFlowTok{if}\NormalTok{ f\_static.exists():}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(f\_static)}
\ControlFlowTok{elif}\NormalTok{ f\_base.exists():}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(f\_base)}
\ControlFlowTok{else}\NormalTok{:}
    \CommentTok{\# Minimal fallback from returns}
\NormalTok{    rpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ rpath.exists():}
        \CommentTok{\# synthesize small dataset}
\NormalTok{        rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\NormalTok{        dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{320}\NormalTok{)}
\NormalTok{        frames}\OperatorTok{=}\NormalTok{[]}
        \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{]:}
\NormalTok{            eps }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.012}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)).astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{            adj }\OperatorTok{=} \DecValTok{100}\OperatorTok{*}\NormalTok{np.exp(np.cumsum(eps))}
\NormalTok{            g }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
                \StringTok{"date"}\NormalTok{: dates, }\StringTok{"ticker"}\NormalTok{: t,}
                \StringTok{"adj\_close"}\NormalTok{: adj.astype(}\StringTok{"float32"}\NormalTok{),}
                \StringTok{"log\_return"}\NormalTok{: np.r\_[np.nan, np.diff(np.log(adj))].astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{            \})}
\NormalTok{            g[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].shift(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{            frames.append(g)}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.concat(frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        df[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(rpath)}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
        \CommentTok{\# add minimal lags}
        \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]:}
\NormalTok{            df[}\SpecialStringTok{f"lag}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].shift(k)}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ df.dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Ensure minimal features exist}
\NormalTok{cand\_feats }\OperatorTok{=}\NormalTok{ [}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{,}\StringTok{"zscore\_20"}\NormalTok{,}\StringTok{"roll\_std\_20"}\NormalTok{]}
\NormalTok{FEATS }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ cand\_feats }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ df.columns]}
\ControlFlowTok{assert} \StringTok{"r\_1d"} \KeywordTok{in}\NormalTok{ df.columns, }\StringTok{"Label r\_1d missing; rebuild returns/features pipeline."}
\ControlFlowTok{assert} \StringTok{"log\_return"} \KeywordTok{in}\NormalTok{ df.columns, }\StringTok{"log\_return missing."}

\CommentTok{\# Keep a small subset of tickers for speed (5–10 tickers)}
\NormalTok{subset }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{).unique().tolist()[:}\DecValTok{8}\NormalTok{]}
\NormalTok{df }\OperatorTok{=}\NormalTok{ df[df[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{).isin(subset)].copy()}

\CommentTok{\# Harmonize types \& sort}
\NormalTok{df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{])}
\NormalTok{df[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{df }\OperatorTok{=}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\StringTok{"Using features:"}\NormalTok{, FEATS, }\StringTok{"| tickers:"}\NormalTok{, df[}\StringTok{"ticker"}\NormalTok{].nunique(), }\StringTok{"| rows:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(df))}
\NormalTok{df.head()}
\end{Highlighting}
\end{Shaded}

\subsection{2) Time‑based split (first rolling‑origin split with
embargo)}\label{timebased-split-first-rollingorigin-split-with-embargo}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ make\_rolling\_origin\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    i }\OperatorTok{=}\NormalTok{ train\_min }\OperatorTok{{-}} \DecValTok{1}\OperatorTok{;}\NormalTok{ out}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{\textgreater{}=} \BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        a,b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}
\NormalTok{        vs }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ embargo }\OperatorTok{+} \DecValTok{1}
\NormalTok{        ve }\OperatorTok{=}\NormalTok{ vs }\OperatorTok{+}\NormalTok{ val\_size }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve }\OperatorTok{\textgreater{}=} \BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        out.append((a,b,u[vs],u[ve]))}
\NormalTok{        i }\OperatorTok{+=}\NormalTok{ step}
    \ControlFlowTok{return}\NormalTok{ out}

\NormalTok{splits }\OperatorTok{=}\NormalTok{ make\_rolling\_origin\_splits(df[}\StringTok{"date"}\NormalTok{], }\DecValTok{252}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\ControlFlowTok{assert}\NormalTok{ splits, }\StringTok{"Not enough history for a first split."}
\NormalTok{a,b,c,d }\OperatorTok{=}\NormalTok{ splits[}\DecValTok{0}\NormalTok{]}
\NormalTok{train\_df }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)].copy()}
\NormalTok{val\_df   }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)].copy()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Split 1 {-} Train:"}\NormalTok{, a.date(), }\StringTok{"→"}\NormalTok{, b.date(), }\StringTok{"| Val:"}\NormalTok{, c.date(), }\StringTok{"→"}\NormalTok{, d.date(), }
      \StringTok{"| train rows:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(train\_df), }\StringTok{"| val rows:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(val\_df))}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Reproducibility helpers,
\texttt{FeatureScaler}, and
\texttt{WindowedDataset}}{3) Reproducibility helpers, FeatureScaler, and WindowedDataset}}\label{reproducibility-helpers-featurescaler-and-windoweddataset}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ random, math, json}

\KeywordTok{def}\NormalTok{ seed\_everything(seed}\OperatorTok{=}\DecValTok{1337}\NormalTok{):}
\NormalTok{    random.seed(seed)}\OperatorTok{;}\NormalTok{ np.random.seed(seed)}\OperatorTok{;}\NormalTok{ torch.manual\_seed(seed)}
    \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available():}
\NormalTok{        torch.cuda.manual\_seed\_all(seed)}
\NormalTok{        torch.backends.cudnn.benchmark }\OperatorTok{=} \VariableTok{False}
\NormalTok{        torch.backends.cudnn.deterministic }\OperatorTok{=} \VariableTok{True}
\NormalTok{seed\_everything(}\DecValTok{1337}\NormalTok{)}

\KeywordTok{class}\NormalTok{ FeatureScaler:}
    \CommentTok{"""Train{-}only mean/std scaler for numpy arrays."""}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\VariableTok{None}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\VariableTok{None}
    \KeywordTok{def}\NormalTok{ fit(}\VariableTok{self}\NormalTok{, X: np.ndarray):}
        \VariableTok{self}\NormalTok{.mean\_ }\OperatorTok{=}\NormalTok{ X.mean(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}
        \VariableTok{self}\NormalTok{.std\_  }\OperatorTok{=}\NormalTok{ X.std(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64) }\OperatorTok{+} \FloatTok{1e{-}8}
        \ControlFlowTok{return} \VariableTok{self}
    \KeywordTok{def}\NormalTok{ transform(}\VariableTok{self}\NormalTok{, X: np.ndarray) }\OperatorTok{{-}\textgreater{}}\NormalTok{ np.ndarray:}
        \ControlFlowTok{return}\NormalTok{ (X }\OperatorTok{{-}} \VariableTok{self}\NormalTok{.mean\_) }\OperatorTok{/} \VariableTok{self}\NormalTok{.std\_}
    \KeywordTok{def}\NormalTok{ state\_dict(}\VariableTok{self}\NormalTok{): }
        \ControlFlowTok{return}\NormalTok{ \{}\StringTok{"mean"}\NormalTok{: }\VariableTok{self}\NormalTok{.mean\_.tolist(), }\StringTok{"std"}\NormalTok{: }\VariableTok{self}\NormalTok{.std\_.tolist()\}}
    \KeywordTok{def}\NormalTok{ load\_state\_dict(}\VariableTok{self}\NormalTok{, d): }
        \VariableTok{self}\NormalTok{.mean\_ }\OperatorTok{=}\NormalTok{ np.array(d[}\StringTok{"mean"}\NormalTok{], dtype}\OperatorTok{=}\NormalTok{np.float64)}
        \VariableTok{self}\NormalTok{.std\_  }\OperatorTok{=}\NormalTok{ np.array(d[}\StringTok{"std"}\NormalTok{],  dtype}\OperatorTok{=}\NormalTok{np.float64)}

\ImportTok{from}\NormalTok{ torch.utils.data }\ImportTok{import}\NormalTok{ Dataset, DataLoader}

\KeywordTok{class}\NormalTok{ WindowedDataset(Dataset):}
    \CommentTok{"""}
\CommentTok{    Sliding windows over time per ticker (multi{-}ticker, fixed context\_len).}
\CommentTok{    Each item: X in shape (T, F), y scalar: r\_1d at window end.}
\CommentTok{    """}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, frame: pd.DataFrame, feature\_cols, context\_len}\OperatorTok{=}\DecValTok{64}\NormalTok{, scaler: FeatureScaler}\OperatorTok{|}\VariableTok{None}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
        \ControlFlowTok{assert} \StringTok{"ticker"} \KeywordTok{in}\NormalTok{ frame }\KeywordTok{and} \StringTok{"date"} \KeywordTok{in}\NormalTok{ frame }\KeywordTok{and} \StringTok{"r\_1d"} \KeywordTok{in}\NormalTok{ frame}
        \VariableTok{self}\NormalTok{.feature\_cols }\OperatorTok{=}\NormalTok{ feature\_cols}
        \VariableTok{self}\NormalTok{.T }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(context\_len)}
        \VariableTok{self}\NormalTok{.groups }\OperatorTok{=}\NormalTok{ \{\}   }\CommentTok{\# ticker {-}\textgreater{} dict(\textquotesingle{}X\textquotesingle{}: np.ndarray [N,F], \textquotesingle{}y\textquotesingle{}: np.ndarray [N])}
        \VariableTok{self}\NormalTok{.index  }\OperatorTok{=}\NormalTok{ []   }\CommentTok{\# list of (ticker, end\_idx)}
        \CommentTok{\# Build groups (per ticker)}
        \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ frame.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{            g }\OperatorTok{=}\NormalTok{ g.sort\_values(}\StringTok{"date"}\NormalTok{).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{            X }\OperatorTok{=}\NormalTok{ g[feature\_cols].to\_numpy(dtype}\OperatorTok{=}\NormalTok{np.float32)}
\NormalTok{            y }\OperatorTok{=}\NormalTok{ g[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy(dtype}\OperatorTok{=}\NormalTok{np.float32)}
            \CommentTok{\# valid windows end where we have T steps and y is finite}
            \ControlFlowTok{for}\NormalTok{ end }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\VariableTok{self}\NormalTok{.T}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(g)):}
                \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ np.isfinite(y[end]): }
                    \ControlFlowTok{continue}
                \VariableTok{self}\NormalTok{.index.append((tkr, end))}
            \VariableTok{self}\NormalTok{.groups[tkr] }\OperatorTok{=}\NormalTok{ \{}\StringTok{"X"}\NormalTok{: X, }\StringTok{"y"}\NormalTok{: y\}}
        \CommentTok{\# Fit scaler on all TRAIN rows (only when building train dataset)}
        \VariableTok{self}\NormalTok{.scaler }\OperatorTok{=}\NormalTok{ scaler }\KeywordTok{or}\NormalTok{ FeatureScaler().fit(}
\NormalTok{            np.concatenate([}\VariableTok{self}\NormalTok{.groups[t][}\StringTok{"X"}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in} \VariableTok{self}\NormalTok{.groups], axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\NormalTok{        )}
    \KeywordTok{def} \FunctionTok{\_\_len\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(}\VariableTok{self}\NormalTok{.index)}
    \KeywordTok{def} \FunctionTok{\_\_getitem\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, i):}
\NormalTok{        tkr, end }\OperatorTok{=} \VariableTok{self}\NormalTok{.index[i]}
\NormalTok{        g }\OperatorTok{=} \VariableTok{self}\NormalTok{.groups[tkr]}
\NormalTok{        xs }\OperatorTok{=}\NormalTok{ g[}\StringTok{"X"}\NormalTok{][end}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.T}\OperatorTok{+}\DecValTok{1}\NormalTok{:end}\OperatorTok{+}\DecValTok{1}\NormalTok{]        }\CommentTok{\# (T, F) context}
\NormalTok{        xs }\OperatorTok{=} \VariableTok{self}\NormalTok{.scaler.transform(xs)         }\CommentTok{\# scale using train stats}
\NormalTok{        y  }\OperatorTok{=}\NormalTok{ g[}\StringTok{"y"}\NormalTok{][end]                       }\CommentTok{\# scalar target}
        \ControlFlowTok{return}\NormalTok{ torch.from\_numpy(xs), torch.tensor(y), }\BuiltInTok{str}\NormalTok{(tkr)}

\KeywordTok{def}\NormalTok{ make\_loaders(train\_df, val\_df, feature\_cols, context\_len}\OperatorTok{=}\DecValTok{64}\NormalTok{, batch\_size}\OperatorTok{=}\DecValTok{256}\NormalTok{, num\_workers}\OperatorTok{=}\DecValTok{2}\NormalTok{):}
    \CommentTok{\# Train dataset fits scaler; Val shares it}
\NormalTok{    train\_ds }\OperatorTok{=}\NormalTok{ WindowedDataset(train\_df, feature\_cols, context\_len}\OperatorTok{=}\NormalTok{context\_len, scaler}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\NormalTok{    val\_ds   }\OperatorTok{=}\NormalTok{ WindowedDataset(val\_df,   feature\_cols, context\_len}\OperatorTok{=}\NormalTok{context\_len, scaler}\OperatorTok{=}\NormalTok{train\_ds.scaler)}
    \CommentTok{\# Persist scaler for reuse}
\NormalTok{    Path(}\StringTok{"models"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    Path(}\StringTok{"models/scaler\_split1.json"}\NormalTok{).write\_text(json.dumps(train\_ds.scaler.state\_dict()))}
\NormalTok{    pin }\OperatorTok{=}\NormalTok{ torch.cuda.is\_available()}
\NormalTok{    g }\OperatorTok{=}\NormalTok{ torch.Generator()}
\NormalTok{    g.manual\_seed(}\DecValTok{42}\NormalTok{)}
    \KeywordTok{def}\NormalTok{ \_seed\_worker(\_):}
\NormalTok{        worker\_seed }\OperatorTok{=}\NormalTok{ torch.initial\_seed() }\OperatorTok{\%}\NormalTok{ (}\DecValTok{2}\OperatorTok{**}\DecValTok{32}\NormalTok{)}
\NormalTok{        np.random.seed(worker\_seed)}\OperatorTok{;}\NormalTok{ random.seed(worker\_seed)}
\NormalTok{    train\_loader }\OperatorTok{=}\NormalTok{ DataLoader(train\_ds, batch\_size}\OperatorTok{=}\NormalTok{batch\_size, shuffle}\OperatorTok{=}\VariableTok{True}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{True}\NormalTok{,}
\NormalTok{                              num\_workers}\OperatorTok{=}\NormalTok{num\_workers, pin\_memory}\OperatorTok{=}\NormalTok{pin, persistent\_workers}\OperatorTok{=}\NormalTok{(num\_workers}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{),}
\NormalTok{                              worker\_init\_fn}\OperatorTok{=}\NormalTok{\_seed\_worker, generator}\OperatorTok{=}\NormalTok{g)}
\NormalTok{    val\_loader   }\OperatorTok{=}\NormalTok{ DataLoader(val\_ds, batch\_size}\OperatorTok{=}\NormalTok{batch\_size, shuffle}\OperatorTok{=}\VariableTok{False}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{False}\NormalTok{,}
\NormalTok{                              num\_workers}\OperatorTok{=}\NormalTok{num\_workers, pin\_memory}\OperatorTok{=}\NormalTok{pin, persistent\_workers}\OperatorTok{=}\NormalTok{(num\_workers}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{),}
\NormalTok{                              worker\_init\_fn}\OperatorTok{=}\NormalTok{\_seed\_worker)}
    \ControlFlowTok{return}\NormalTok{ train\_ds, val\_ds, train\_loader, val\_loader}

\NormalTok{train\_ds, val\_ds, train\_loader, val\_loader }\OperatorTok{=}\NormalTok{ make\_loaders(train\_df, val\_df, FEATS, context\_len}\OperatorTok{=}\DecValTok{64}\NormalTok{, batch\_size}\OperatorTok{=}\DecValTok{256}\NormalTok{)}
\BuiltInTok{len}\NormalTok{(train\_ds), }\BuiltInTok{len}\NormalTok{(val\_ds), }\BuiltInTok{next}\NormalTok{(}\BuiltInTok{iter}\NormalTok{(train\_loader))[}\DecValTok{0}\NormalTok{].shape}
\end{Highlighting}
\end{Shaded}

\subsection{4) Define a tiny GRU
regressor}\label{define-a-tiny-gru-regressor}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ torch.nn }\ImportTok{as}\NormalTok{ nn, torch}

\KeywordTok{class}\NormalTok{ GRURegressor(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_features: }\BuiltInTok{int}\NormalTok{, hidden: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{64}\NormalTok{, num\_layers: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{2}\NormalTok{, dropout: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.1}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.gru }\OperatorTok{=}\NormalTok{ nn.GRU(input\_size}\OperatorTok{=}\NormalTok{in\_features, hidden\_size}\OperatorTok{=}\NormalTok{hidden, num\_layers}\OperatorTok{=}\NormalTok{num\_layers,}
\NormalTok{                          batch\_first}\OperatorTok{=}\VariableTok{True}\NormalTok{, dropout}\OperatorTok{=}\NormalTok{dropout }\ControlFlowTok{if}\NormalTok{ num\_layers}\OperatorTok{\textgreater{}}\DecValTok{1} \ControlFlowTok{else} \FloatTok{0.0}\NormalTok{)}
        \VariableTok{self}\NormalTok{.head }\OperatorTok{=}\NormalTok{ nn.Sequential(}
\NormalTok{            nn.Linear(hidden, hidden),}
\NormalTok{            nn.ReLU(),}
\NormalTok{            nn.Dropout(dropout),}
\NormalTok{            nn.Linear(hidden, }\DecValTok{1}\NormalTok{)}
\NormalTok{        )}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):        }\CommentTok{\# x: (B, T, F)}
\NormalTok{        \_, hN }\OperatorTok{=} \VariableTok{self}\NormalTok{.gru(x)      }\CommentTok{\# hN: (num\_layers, B, H); take last layer}
\NormalTok{        h }\OperatorTok{=}\NormalTok{ hN[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]               }\CommentTok{\# (B, H)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.head(h).squeeze(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)  }\CommentTok{\# (B,)}

\KeywordTok{def}\NormalTok{ make\_model():}
    \ControlFlowTok{return}\NormalTok{ GRURegressor(in\_features}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(FEATS), hidden}\OperatorTok{=}\DecValTok{64}\NormalTok{, num\_layers}\OperatorTok{=}\DecValTok{2}\NormalTok{, dropout}\OperatorTok{=}\FloatTok{0.1}\NormalTok{)}

\NormalTok{device }\OperatorTok{=}\NormalTok{ torch.device(}\StringTok{"cuda"} \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"cpu"}\NormalTok{)}
\NormalTok{model }\OperatorTok{=}\NormalTok{ make\_model().to(device)}
\BuiltInTok{sum}\NormalTok{(p.numel() }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ model.parameters())}\OperatorTok{/}\FloatTok{1e6}\NormalTok{, device}
\end{Highlighting}
\end{Shaded}

\subsection{5) Training loop with AMP, early stopping,
checkpointing}\label{training-loop-with-amp-early-stopping-checkpointing}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ torch.optim }\ImportTok{import}\NormalTok{ AdamW}
\ImportTok{from}\NormalTok{ torch.cuda.amp }\ImportTok{import}\NormalTok{ autocast, GradScaler}
\ImportTok{import}\NormalTok{ math, time}

\KeywordTok{def}\NormalTok{ mae\_t(y\_true, y\_pred): }\ControlFlowTok{return}\NormalTok{ torch.mean(torch.}\BuiltInTok{abs}\NormalTok{(y\_true }\OperatorTok{{-}}\NormalTok{ y\_pred))}
\KeywordTok{def}\NormalTok{ smape\_t(y\_true, y\_pred, eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{):}
    \ControlFlowTok{return}\NormalTok{ torch.mean(}\FloatTok{2.0}\OperatorTok{*}\NormalTok{torch.}\BuiltInTok{abs}\NormalTok{(y\_true }\OperatorTok{{-}}\NormalTok{ y\_pred)}\OperatorTok{/}\NormalTok{(torch.}\BuiltInTok{abs}\NormalTok{(y\_true)}\OperatorTok{+}\NormalTok{torch.}\BuiltInTok{abs}\NormalTok{(y\_pred)}\OperatorTok{+}\NormalTok{eps))}

\KeywordTok{def}\NormalTok{ train\_one\_epoch(model, loader, optimizer, scaler, device, use\_amp}\OperatorTok{=}\VariableTok{True}\NormalTok{):}
\NormalTok{    model.train()}\OperatorTok{;}\NormalTok{ total}\OperatorTok{=}\FloatTok{0.0}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ xb, yb, \_ }\KeywordTok{in}\NormalTok{ loader:}
\NormalTok{        xb }\OperatorTok{=}\NormalTok{ xb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        yb }\OperatorTok{=}\NormalTok{ yb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        optimizer.zero\_grad(set\_to\_none}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ use\_amp }\KeywordTok{and}\NormalTok{ device.}\BuiltInTok{type}\OperatorTok{==}\StringTok{"cuda"}\NormalTok{:}
            \ControlFlowTok{with}\NormalTok{ autocast(dtype}\OperatorTok{=}\NormalTok{torch.float16):}
\NormalTok{                pred }\OperatorTok{=}\NormalTok{ model(xb)}
\NormalTok{                loss }\OperatorTok{=}\NormalTok{ mae\_t(yb, pred)  }\CommentTok{\# train with MAE (robust)}
\NormalTok{            scaler.scale(loss).backward()}
\NormalTok{            scaler.step(optimizer)}\OperatorTok{;}\NormalTok{ scaler.update()}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            pred }\OperatorTok{=}\NormalTok{ model(xb)}\OperatorTok{;}\NormalTok{ loss }\OperatorTok{=}\NormalTok{ mae\_t(yb, pred)}
\NormalTok{            loss.backward()}\OperatorTok{;}\NormalTok{ optimizer.step()}
\NormalTok{        bs }\OperatorTok{=}\NormalTok{ xb.size(}\DecValTok{0}\NormalTok{)}\OperatorTok{;}\NormalTok{ total }\OperatorTok{+=}\NormalTok{ loss.item()}\OperatorTok{*}\NormalTok{bs}\OperatorTok{;}\NormalTok{ n }\OperatorTok{+=}\NormalTok{ bs}
    \ControlFlowTok{return}\NormalTok{ total}\OperatorTok{/}\BuiltInTok{max}\NormalTok{(n,}\DecValTok{1}\NormalTok{)}

\AttributeTok{@torch.no\_grad}\NormalTok{()}
\KeywordTok{def}\NormalTok{ evaluate(model, loader, device):}
\NormalTok{    model.}\BuiltInTok{eval}\NormalTok{()}\OperatorTok{;}\NormalTok{ tot\_mae}\OperatorTok{=}\NormalTok{tot\_smape}\OperatorTok{=}\FloatTok{0.0}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ xb, yb, \_ }\KeywordTok{in}\NormalTok{ loader:}
\NormalTok{        xb }\OperatorTok{=}\NormalTok{ xb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        yb }\OperatorTok{=}\NormalTok{ yb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        pred }\OperatorTok{=}\NormalTok{ model(xb)}
\NormalTok{        bs }\OperatorTok{=}\NormalTok{ xb.size(}\DecValTok{0}\NormalTok{)}
\NormalTok{        tot\_mae   }\OperatorTok{+=}\NormalTok{ mae\_t(yb, pred).item()}\OperatorTok{*}\NormalTok{bs}
\NormalTok{        tot\_smape }\OperatorTok{+=}\NormalTok{ smape\_t(yb, pred).item()}\OperatorTok{*}\NormalTok{bs}
\NormalTok{        n }\OperatorTok{+=}\NormalTok{ bs}
    \ControlFlowTok{return}\NormalTok{ \{}\StringTok{"mae"}\NormalTok{: tot\_mae}\OperatorTok{/}\BuiltInTok{max}\NormalTok{(n,}\DecValTok{1}\NormalTok{), }\StringTok{"smape"}\NormalTok{: tot\_smape}\OperatorTok{/}\BuiltInTok{max}\NormalTok{(n,}\DecValTok{1}\NormalTok{)\}}

\KeywordTok{def}\NormalTok{ fit(model, train\_loader, val\_loader, epochs}\OperatorTok{=}\DecValTok{12}\NormalTok{, lr}\OperatorTok{=}\FloatTok{1e{-}3}\NormalTok{, wd}\OperatorTok{=}\FloatTok{1e{-}5}\NormalTok{, patience}\OperatorTok{=}\DecValTok{3}\NormalTok{, use\_amp}\OperatorTok{=}\VariableTok{True}\NormalTok{):}
\NormalTok{    opt }\OperatorTok{=}\NormalTok{ AdamW(model.parameters(), lr}\OperatorTok{=}\NormalTok{lr, weight\_decay}\OperatorTok{=}\NormalTok{wd)}
\NormalTok{    scaler }\OperatorTok{=}\NormalTok{ GradScaler(enabled}\OperatorTok{=}\NormalTok{use\_amp }\KeywordTok{and}\NormalTok{ (device.}\BuiltInTok{type}\OperatorTok{==}\StringTok{"cuda"}\NormalTok{))}
\NormalTok{    best }\OperatorTok{=}\NormalTok{ math.inf}\OperatorTok{;}\NormalTok{ best\_metrics}\OperatorTok{=}\VariableTok{None}\OperatorTok{;}\NormalTok{ best\_epoch}\OperatorTok{={-}}\DecValTok{1}
\NormalTok{    ckpt\_path }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"models/gru\_split1.pt"}\NormalTok{)}
\NormalTok{    history}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ epoch }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, epochs}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{        t0}\OperatorTok{=}\NormalTok{time.time()}
\NormalTok{        tr\_loss }\OperatorTok{=}\NormalTok{ train\_one\_epoch(model, train\_loader, opt, scaler, device, use\_amp)}
\NormalTok{        val }\OperatorTok{=}\NormalTok{ evaluate(model, val\_loader, device)}
\NormalTok{        dt}\OperatorTok{=}\NormalTok{time.time()}\OperatorTok{{-}}\NormalTok{t0}
\NormalTok{        history.append(\{}\StringTok{"epoch"}\NormalTok{:epoch,}\StringTok{"train\_mae"}\NormalTok{:tr\_loss,}\StringTok{"val\_mae"}\NormalTok{:val[}\StringTok{"mae"}\NormalTok{],}\StringTok{"val\_smape"}\NormalTok{:val[}\StringTok{"smape"}\NormalTok{],}\StringTok{"seconds"}\NormalTok{:dt\})}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Epoch }\SpecialCharTok{\{}\NormalTok{epoch}\SpecialCharTok{:02d\}}\SpecialStringTok{  train\_mae=}\SpecialCharTok{\{}\NormalTok{tr\_loss}\SpecialCharTok{:.5f\}}\SpecialStringTok{  val\_mae=}\SpecialCharTok{\{}\NormalTok{val[}\StringTok{\textquotesingle{}mae\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.5f\}}\SpecialStringTok{  val\_sMAPE=}\SpecialCharTok{\{}\NormalTok{val[}\StringTok{\textquotesingle{}smape\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.5f\}}\SpecialStringTok{  (}\SpecialCharTok{\{}\NormalTok{dt}\SpecialCharTok{:.1f\}}\SpecialStringTok{s)"}\NormalTok{)}
        \CommentTok{\# early stopping on val mae}
        \ControlFlowTok{if}\NormalTok{ val[}\StringTok{"mae"}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ best }\OperatorTok{{-}} \FloatTok{1e{-}6}\NormalTok{:}
\NormalTok{            best }\OperatorTok{=}\NormalTok{ val[}\StringTok{"mae"}\NormalTok{]}\OperatorTok{;}\NormalTok{ best\_metrics}\OperatorTok{=}\NormalTok{val}\OperatorTok{;}\NormalTok{ best\_epoch}\OperatorTok{=}\NormalTok{epoch}
\NormalTok{            torch.save(\{}
                \StringTok{"model\_state"}\NormalTok{: model.state\_dict(),}
                \StringTok{"optimizer\_state"}\NormalTok{: opt.state\_dict(),}
                \StringTok{"epoch"}\NormalTok{: epoch,}
                \StringTok{"val"}\NormalTok{: val,}
                \StringTok{"config"}\NormalTok{: \{}\StringTok{"lr"}\NormalTok{:lr,}\StringTok{"wd"}\NormalTok{:wd,}\StringTok{"epochs"}\NormalTok{:epochs,}\StringTok{"context\_len"}\NormalTok{:train\_loader.dataset.T,}\StringTok{"feats"}\NormalTok{:FEATS\}}
\NormalTok{            \}, ckpt\_path)}
        \ControlFlowTok{elif}\NormalTok{ epoch }\OperatorTok{{-}}\NormalTok{ best\_epoch }\OperatorTok{\textgreater{}=}\NormalTok{ patience:}
            \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Early stopping at epoch }\SpecialCharTok{\{}\NormalTok{epoch}\SpecialCharTok{\}}\SpecialStringTok{ (best }\SpecialCharTok{\{}\NormalTok{best}\SpecialCharTok{:.5f\}}\SpecialStringTok{ @ }\SpecialCharTok{\{}\NormalTok{best\_epoch}\SpecialCharTok{\}}\SpecialStringTok{)"}\NormalTok{)}
            \ControlFlowTok{break}
    \ControlFlowTok{return}\NormalTok{ history, best, best\_epoch, ckpt\_path}

\NormalTok{history, best, best\_epoch, ckpt\_path }\OperatorTok{=}\NormalTok{ fit(model, train\_loader, val\_loader,}
\NormalTok{                                           epochs}\OperatorTok{=}\DecValTok{10}\NormalTok{, lr}\OperatorTok{=}\FloatTok{1e{-}3}\NormalTok{, wd}\OperatorTok{=}\FloatTok{1e{-}5}\NormalTok{, patience}\OperatorTok{=}\DecValTok{3}\NormalTok{, use\_amp}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Best val\_mae:"}\NormalTok{, best, }\StringTok{"at epoch"}\NormalTok{, best\_epoch, }\StringTok{"| saved:"}\NormalTok{, ckpt\_path.exists())}
\end{Highlighting}
\end{Shaded}

\subsection{6) Evaluate best checkpoint \& write a small
report}\label{evaluate-best-checkpoint-write-a-small-report}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reload best checkpoint and compute final validation metrics + save CSV}
\NormalTok{ckpt }\OperatorTok{=}\NormalTok{ torch.load(}\StringTok{"models/gru\_split1.pt"}\NormalTok{, map\_location}\OperatorTok{=}\StringTok{"cpu"}\NormalTok{)}
\NormalTok{model.load\_state\_dict(ckpt[}\StringTok{"model\_state"}\NormalTok{])}
\NormalTok{model.to(device)}
\NormalTok{final }\OperatorTok{=}\NormalTok{ evaluate(model, val\_loader, device)}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{rep }\OperatorTok{=}\NormalTok{ pd.DataFrame([\{}
    \StringTok{"split"}\NormalTok{: }\DecValTok{1}\NormalTok{,}
    \StringTok{"context\_len"}\NormalTok{: train\_loader.dataset.T,}
    \StringTok{"feats"}\NormalTok{: }\StringTok{","}\NormalTok{.join(FEATS),}
    \StringTok{"val\_mae"}\NormalTok{: final[}\StringTok{"mae"}\NormalTok{],}
    \StringTok{"val\_smape"}\NormalTok{: final[}\StringTok{"smape"}\NormalTok{],}
    \StringTok{"best\_epoch"}\NormalTok{: ckpt.get(}\StringTok{"epoch"}\NormalTok{, }\VariableTok{None}\NormalTok{),}
    \StringTok{"params\_M"}\NormalTok{: }\BuiltInTok{round}\NormalTok{(}\BuiltInTok{sum}\NormalTok{(p.numel() }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ model.parameters())}\OperatorTok{/}\FloatTok{1e6}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{\}])}
\NormalTok{rep.to\_csv(}\StringTok{"reports/gru\_split1\_metrics.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{rep}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Time check:} With \textasciitilde5--8 tickers, \texttt{T=64},
and 10 epochs, this should finish in a couple of minutes on Colab CPU;
faster on GPU.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min) --- emphasize these
points}\label{wrapup-10-min-emphasize-these-points}

\begin{itemize}
\tightlist
\item
  \textbf{WindowedDataset} emits causal windows \texttt{(≤\ t)} and
  targets \texttt{r\_1d{[}t{]}} (i.e., \texttt{t+1} return).
\item
  Use \textbf{train‑fit scaler} and \textbf{reuse it} on validation to
  avoid leakage.
\item
  Keep the training loop \textbf{simple}: MAE training objective, AMP on
  CUDA, \textbf{early stopping} on validation MAE, and save a
  \textbf{checkpoint}.
\item
  Produce a \textbf{CSV} with validation metrics to track progress and
  compare future models.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
20)}\label{homework-due-before-session-20}

\textbf{Goal:} Train a stronger \textbf{sequence baseline} (choose
\textbf{LSTM} or \textbf{TCN}) on a subset (5--10 tickers). Log metrics
and push your checkpoint + report.

\subsection{\texorpdfstring{Part A --- Script
\texttt{scripts/train\_seq.py} (LSTM or
TCN)}{Part A --- Script scripts/train\_seq.py (LSTM or TCN)}}\label{part-a-script-scriptstrain_seq.py-lstm-or-tcn}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/usr/bin/env python}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ argparse, json, math}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd, torch, torch.nn }\ImportTok{as}\NormalTok{ nn}
\ImportTok{from}\NormalTok{ torch.utils.data }\ImportTok{import}\NormalTok{ DataLoader, Dataset}
\ImportTok{from}\NormalTok{ torch.cuda.amp }\ImportTok{import}\NormalTok{ autocast, GradScaler}

\CommentTok{\# {-}{-}{-} (reuse minimal dataset/scaler from class; compact copy here) {-}{-}{-}}
\KeywordTok{class}\NormalTok{ FeatureScaler:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\VariableTok{None}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\VariableTok{None}
    \KeywordTok{def}\NormalTok{ fit(}\VariableTok{self}\NormalTok{, X): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\NormalTok{X.mean(}\DecValTok{0}\NormalTok{)}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\NormalTok{X.std(}\DecValTok{0}\NormalTok{)}\OperatorTok{+}\FloatTok{1e{-}8}\OperatorTok{;} \ControlFlowTok{return} \VariableTok{self}
    \KeywordTok{def}\NormalTok{ transform(}\VariableTok{self}\NormalTok{, X): }\ControlFlowTok{return}\NormalTok{ (X}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.mean\_)}\OperatorTok{/}\VariableTok{self}\NormalTok{.std\_}
    \KeywordTok{def}\NormalTok{ state\_dict(}\VariableTok{self}\NormalTok{): }\ControlFlowTok{return}\NormalTok{ \{}\StringTok{"mean"}\NormalTok{: }\VariableTok{self}\NormalTok{.mean\_.tolist(), }\StringTok{"std"}\NormalTok{: }\VariableTok{self}\NormalTok{.std\_.tolist()\}}
    \KeywordTok{def}\NormalTok{ load\_state\_dict(}\VariableTok{self}\NormalTok{, d): }\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}\OperatorTok{;} \VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\NormalTok{np.array(d[}\StringTok{"mean"}\NormalTok{])}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\NormalTok{np.array(d[}\StringTok{"std"}\NormalTok{])}
\KeywordTok{class}\NormalTok{ WindowedDataset(Dataset):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, df, feats, T}\OperatorTok{=}\DecValTok{64}\NormalTok{, scaler}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
        \VariableTok{self}\NormalTok{.feats}\OperatorTok{=}\NormalTok{feats}\OperatorTok{;} \VariableTok{self}\NormalTok{.T}\OperatorTok{=}\NormalTok{T}\OperatorTok{;} \VariableTok{self}\NormalTok{.idx}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;} \VariableTok{self}\NormalTok{.g}\OperatorTok{=}\NormalTok{\{\}}
        \ControlFlowTok{for}\NormalTok{ tkr,g }\KeywordTok{in}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{            g}\OperatorTok{=}\NormalTok{g.sort\_values(}\StringTok{"date"}\NormalTok{).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{            X}\OperatorTok{=}\NormalTok{g[feats].to\_numpy(}\StringTok{"float32"}\NormalTok{)}\OperatorTok{;}\NormalTok{ y}\OperatorTok{=}\NormalTok{g[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy(}\StringTok{"float32"}\NormalTok{)}
            \ControlFlowTok{for}\NormalTok{ end }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(T}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,}\BuiltInTok{len}\NormalTok{(g)):}
                \ControlFlowTok{if}\NormalTok{ np.isfinite(y[end]): }\VariableTok{self}\NormalTok{.idx.append((tkr,end))}
            \VariableTok{self}\NormalTok{.g[tkr]}\OperatorTok{=}\NormalTok{\{}\StringTok{"X"}\NormalTok{:X,}\StringTok{"y"}\NormalTok{:y\}}
        \VariableTok{self}\NormalTok{.scaler }\OperatorTok{=}\NormalTok{ scaler }\KeywordTok{or}\NormalTok{ FeatureScaler().fit(np.concatenate([}\VariableTok{self}\NormalTok{.g[t][}\StringTok{"X"}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in} \VariableTok{self}\NormalTok{.g],}\DecValTok{0}\NormalTok{))}
    \KeywordTok{def} \FunctionTok{\_\_len\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(}\VariableTok{self}\NormalTok{.idx)}
    \KeywordTok{def} \FunctionTok{\_\_getitem\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{,i):}
\NormalTok{        tkr,end}\OperatorTok{=}\VariableTok{self}\NormalTok{.idx[i]}\OperatorTok{;}\NormalTok{ g}\OperatorTok{=}\VariableTok{self}\NormalTok{.g[tkr]}
\NormalTok{        X}\OperatorTok{=}\NormalTok{g[}\StringTok{"X"}\NormalTok{][end}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.T}\OperatorTok{+}\DecValTok{1}\NormalTok{:end}\OperatorTok{+}\DecValTok{1}\NormalTok{]}\OperatorTok{;}\NormalTok{ X}\OperatorTok{=}\VariableTok{self}\NormalTok{.scaler.transform(X)}
\NormalTok{        y}\OperatorTok{=}\NormalTok{g[}\StringTok{"y"}\NormalTok{][end]}
        \ControlFlowTok{return}\NormalTok{ torch.from\_numpy(X), torch.tensor(y)}

\KeywordTok{def}\NormalTok{ make\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u}\OperatorTok{=}\NormalTok{np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ out}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        a,b}\OperatorTok{=}\NormalTok{u[}\DecValTok{0}\NormalTok{],u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val\_size}\OperatorTok{{-}}\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        out.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+=}\NormalTok{step}
    \ControlFlowTok{return}\NormalTok{ out}

\CommentTok{\# {-}{-}{-} Models {-}{-}{-}}
\KeywordTok{class}\NormalTok{ LSTMReg(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_f, hidden}\OperatorTok{=}\DecValTok{64}\NormalTok{, layers}\OperatorTok{=}\DecValTok{2}\NormalTok{, dropout}\OperatorTok{=}\FloatTok{0.1}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.lstm }\OperatorTok{=}\NormalTok{ nn.LSTM(in\_f, hidden, num\_layers}\OperatorTok{=}\NormalTok{layers, batch\_first}\OperatorTok{=}\VariableTok{True}\NormalTok{, dropout}\OperatorTok{=}\NormalTok{dropout }\ControlFlowTok{if}\NormalTok{ layers}\OperatorTok{\textgreater{}}\DecValTok{1} \ControlFlowTok{else} \FloatTok{0.}\NormalTok{)}
        \VariableTok{self}\NormalTok{.head }\OperatorTok{=}\NormalTok{ nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Dropout(dropout), nn.Linear(hidden,}\DecValTok{1}\NormalTok{))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):}
\NormalTok{        out,\_ }\OperatorTok{=} \VariableTok{self}\NormalTok{.lstm(x)}
\NormalTok{        h }\OperatorTok{=}\NormalTok{ out[:,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,:]}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.head(h).squeeze(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}

\KeywordTok{class}\NormalTok{ TCNBlock(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_c, out\_c, k}\OperatorTok{=}\DecValTok{3}\NormalTok{, d}\OperatorTok{=}\DecValTok{1}\NormalTok{, dropout}\OperatorTok{=}\FloatTok{0.1}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
\NormalTok{        pad }\OperatorTok{=}\NormalTok{ (k}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{d}
        \VariableTok{self}\NormalTok{.net }\OperatorTok{=}\NormalTok{ nn.Sequential(}
\NormalTok{            nn.Conv1d(in\_c, out\_c, k, padding}\OperatorTok{=}\NormalTok{pad, dilation}\OperatorTok{=}\NormalTok{d),}
\NormalTok{            nn.ReLU(),}
\NormalTok{            nn.Dropout(dropout),}
\NormalTok{            nn.Conv1d(out\_c, out\_c, k, padding}\OperatorTok{=}\NormalTok{pad, dilation}\OperatorTok{=}\NormalTok{d),}
\NormalTok{            nn.ReLU(),}
\NormalTok{            nn.Dropout(dropout),}
\NormalTok{        )}
        \VariableTok{self}\NormalTok{.down }\OperatorTok{=}\NormalTok{ nn.Conv1d(in\_c, out\_c, }\DecValTok{1}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ in\_c}\OperatorTok{!=}\NormalTok{out\_c }\ControlFlowTok{else}\NormalTok{ nn.Identity()}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):        }\CommentTok{\# x: (B, F, T)}
\NormalTok{        y }\OperatorTok{=} \VariableTok{self}\NormalTok{.net(x)}
        \CommentTok{\# Causal crop to ensure output aligns with last time step}
\NormalTok{        crop }\OperatorTok{=}\NormalTok{ y.shape[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}\OperatorTok{{-}}\NormalTok{x.shape[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{if}\NormalTok{ crop}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{: y }\OperatorTok{=}\NormalTok{ y[..., :}\OperatorTok{{-}}\NormalTok{crop]}
        \ControlFlowTok{return}\NormalTok{ y }\OperatorTok{+} \VariableTok{self}\NormalTok{.down(x)}

\KeywordTok{class}\NormalTok{ TCNReg(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_f, ch}\OperatorTok{=}\DecValTok{64}\NormalTok{, blocks}\OperatorTok{=}\DecValTok{3}\NormalTok{, k}\OperatorTok{=}\DecValTok{3}\NormalTok{, dropout}\OperatorTok{=}\FloatTok{0.1}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
\NormalTok{        layers}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{ c}\OperatorTok{=}\NormalTok{in\_f}
        \ControlFlowTok{for}\NormalTok{ b }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(blocks):}
\NormalTok{            layers.append(TCNBlock(c, ch, k}\OperatorTok{=}\NormalTok{k, d}\OperatorTok{=}\DecValTok{2}\OperatorTok{**}\NormalTok{b, dropout}\OperatorTok{=}\NormalTok{dropout))}\OperatorTok{;}\NormalTok{ c}\OperatorTok{=}\NormalTok{ch}
        \VariableTok{self}\NormalTok{.tcn }\OperatorTok{=}\NormalTok{ nn.Sequential(}\OperatorTok{*}\NormalTok{layers)}
        \VariableTok{self}\NormalTok{.head }\OperatorTok{=}\NormalTok{ nn.Sequential(nn.AdaptiveAvgPool1d(}\DecValTok{1}\NormalTok{), nn.Flatten(), nn.Linear(ch,}\DecValTok{1}\NormalTok{))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):}
        \CommentTok{\# x: (B,T,F) {-}\textgreater{} (B,F,T) for Conv1d}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ x.transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{        y }\OperatorTok{=} \VariableTok{self}\NormalTok{.tcn(x)              }\CommentTok{\# (B, C, T)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.head(y).squeeze(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}

\KeywordTok{def}\NormalTok{ mae\_t(y,yhat): }\ControlFlowTok{return}\NormalTok{ torch.mean(torch.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat))}
\KeywordTok{def}\NormalTok{ smape\_t(y,yhat,eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{): }\ControlFlowTok{return}\NormalTok{ torch.mean(}\DecValTok{2}\OperatorTok{*}\NormalTok{torch.}\BuiltInTok{abs}\NormalTok{(y}\OperatorTok{{-}}\NormalTok{yhat)}\OperatorTok{/}\NormalTok{(torch.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{torch.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps))}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    ap}\OperatorTok{=}\NormalTok{argparse.ArgumentParser()}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}features"}\NormalTok{, default}\OperatorTok{=}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}context"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{64}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}model"}\NormalTok{, choices}\OperatorTok{=}\NormalTok{[}\StringTok{"lstm"}\NormalTok{,}\StringTok{"tcn"}\NormalTok{], default}\OperatorTok{=}\StringTok{"lstm"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}epochs"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{12}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}batch"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{256}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}lr"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{float}\NormalTok{, default}\OperatorTok{=}\FloatTok{1e{-}3}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}patience"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}tickers"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{8}\NormalTok{)}
\NormalTok{    args}\OperatorTok{=}\NormalTok{ap.parse\_args()}

\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(}\StringTok{"data/processed/features\_v1\_static.parquet"}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1\_static.parquet"}\NormalTok{).exists() }\ControlFlowTok{else}\NormalTok{ pd.read\_parquet(args.features)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    cand }\OperatorTok{=}\NormalTok{ [}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{,}\StringTok{"zscore\_20"}\NormalTok{,}\StringTok{"roll\_std\_20"}\NormalTok{]}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ cand }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ df.columns]}
    \ControlFlowTok{assert} \StringTok{"r\_1d"} \KeywordTok{in}\NormalTok{ df.columns}
    \CommentTok{\# subset tickers}
\NormalTok{    keep }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{).unique().tolist()[:args.tickers]}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ df[df[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{).isin(keep)].copy()}

\NormalTok{    splits }\OperatorTok{=}\NormalTok{ make\_splits(df[}\StringTok{"date"}\NormalTok{])}
\NormalTok{    a,b,c,d }\OperatorTok{=}\NormalTok{ splits[}\DecValTok{0}\NormalTok{]}
\NormalTok{    tr }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)]}
\NormalTok{    va }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)]}

\NormalTok{    train\_ds }\OperatorTok{=}\NormalTok{ WindowedDataset(tr, feats, T}\OperatorTok{=}\NormalTok{args.context, scaler}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\NormalTok{    val\_ds   }\OperatorTok{=}\NormalTok{ WindowedDataset(va, feats, T}\OperatorTok{=}\NormalTok{args.context, scaler}\OperatorTok{=}\NormalTok{train\_ds.scaler)}

\NormalTok{    pin }\OperatorTok{=}\NormalTok{ torch.cuda.is\_available()}
\NormalTok{    g }\OperatorTok{=}\NormalTok{ torch.Generator()}\OperatorTok{;}\NormalTok{ g.manual\_seed(}\DecValTok{42}\NormalTok{)}
    \KeywordTok{def}\NormalTok{ \_seed\_worker(\_): }\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, random, torch}\OperatorTok{;}\NormalTok{ ws}\OperatorTok{=}\NormalTok{torch.initial\_seed()}\OperatorTok{\%}\DecValTok{2}\OperatorTok{**}\DecValTok{32}\OperatorTok{;}\NormalTok{ np.random.seed(ws)}\OperatorTok{;}\NormalTok{ random.seed(ws)}
\NormalTok{    train\_ld }\OperatorTok{=}\NormalTok{ DataLoader(train\_ds, batch\_size}\OperatorTok{=}\NormalTok{args.batch, shuffle}\OperatorTok{=}\VariableTok{True}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{True}\NormalTok{,}
\NormalTok{                          num\_workers}\OperatorTok{=}\DecValTok{2}\NormalTok{, pin\_memory}\OperatorTok{=}\NormalTok{pin, worker\_init\_fn}\OperatorTok{=}\NormalTok{\_seed\_worker, generator}\OperatorTok{=}\NormalTok{g)}
\NormalTok{    val\_ld   }\OperatorTok{=}\NormalTok{ DataLoader(val\_ds, batch\_size}\OperatorTok{=}\NormalTok{args.batch, shuffle}\OperatorTok{=}\VariableTok{False}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{False}\NormalTok{,}
\NormalTok{                          num\_workers}\OperatorTok{=}\DecValTok{2}\NormalTok{, pin\_memory}\OperatorTok{=}\NormalTok{pin, worker\_init\_fn}\OperatorTok{=}\NormalTok{\_seed\_worker)}

\NormalTok{    device }\OperatorTok{=}\NormalTok{ torch.device(}\StringTok{"cuda"} \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"cpu"}\NormalTok{)}
\NormalTok{    net }\OperatorTok{=}\NormalTok{ (LSTMReg(}\BuiltInTok{len}\NormalTok{(feats)) }\ControlFlowTok{if}\NormalTok{ args.model}\OperatorTok{==}\StringTok{"lstm"} \ControlFlowTok{else}\NormalTok{ TCNReg(}\BuiltInTok{len}\NormalTok{(feats))).to(device)}
\NormalTok{    opt }\OperatorTok{=}\NormalTok{ torch.optim.AdamW(net.parameters(), lr}\OperatorTok{=}\NormalTok{args.lr, weight\_decay}\OperatorTok{=}\FloatTok{1e{-}5}\NormalTok{)}
\NormalTok{    scaler }\OperatorTok{=}\NormalTok{ GradScaler(enabled}\OperatorTok{=}\NormalTok{(device.}\BuiltInTok{type}\OperatorTok{==}\StringTok{"cuda"}\NormalTok{))}
\NormalTok{    best }\OperatorTok{=} \FloatTok{1e9}\OperatorTok{;}\NormalTok{ best\_epoch}\OperatorTok{=}\DecValTok{0}
\NormalTok{    ckpt }\OperatorTok{=}\NormalTok{ Path(}\SpecialStringTok{f"models/}\SpecialCharTok{\{}\NormalTok{args}\SpecialCharTok{.}\NormalTok{model}\SpecialCharTok{\}}\SpecialStringTok{\_split1.pt"}\NormalTok{)}

    \ControlFlowTok{for}\NormalTok{ epoch }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, args.epochs}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{        net.train()}\OperatorTok{;}\NormalTok{ tmae}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\DecValTok{0}
        \ControlFlowTok{for}\NormalTok{ xb,yb }\KeywordTok{in}\NormalTok{ train\_ld:}
\NormalTok{            xb}\OperatorTok{=}\NormalTok{xb.to(device).}\BuiltInTok{float}\NormalTok{()}\OperatorTok{;}\NormalTok{ yb}\OperatorTok{=}\NormalTok{yb.to(device).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{            opt.zero\_grad(set\_to\_none}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
            \ControlFlowTok{with}\NormalTok{ autocast(enabled}\OperatorTok{=}\NormalTok{(device.}\BuiltInTok{type}\OperatorTok{==}\StringTok{"cuda"}\NormalTok{), dtype}\OperatorTok{=}\NormalTok{torch.float16):}
\NormalTok{                yhat }\OperatorTok{=}\NormalTok{ net(xb)}
\NormalTok{                loss }\OperatorTok{=}\NormalTok{ mae\_t(yb, yhat)}
\NormalTok{            scaler.scale(loss).backward()}\OperatorTok{;}\NormalTok{ scaler.step(opt)}\OperatorTok{;}\NormalTok{ scaler.update()}
\NormalTok{            bs}\OperatorTok{=}\NormalTok{xb.size(}\DecValTok{0}\NormalTok{)}\OperatorTok{;}\NormalTok{ tmae }\OperatorTok{+=}\NormalTok{ loss.item()}\OperatorTok{*}\NormalTok{bs}\OperatorTok{;}\NormalTok{ n}\OperatorTok{+=}\NormalTok{bs}
\NormalTok{        tr\_mae}\OperatorTok{=}\NormalTok{tmae}\OperatorTok{/}\NormalTok{n}
        \CommentTok{\# val}
\NormalTok{        net.}\BuiltInTok{eval}\NormalTok{()}\OperatorTok{;}\NormalTok{ vmae}\OperatorTok{=}\NormalTok{vsm}\OperatorTok{=}\DecValTok{0}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\DecValTok{0}
        \ControlFlowTok{with}\NormalTok{ torch.no\_grad():}
            \ControlFlowTok{for}\NormalTok{ xb,yb }\KeywordTok{in}\NormalTok{ val\_ld:}
\NormalTok{                xb}\OperatorTok{=}\NormalTok{xb.to(device).}\BuiltInTok{float}\NormalTok{()}\OperatorTok{;}\NormalTok{ yb}\OperatorTok{=}\NormalTok{yb.to(device).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{                yhat }\OperatorTok{=}\NormalTok{ net(xb)}
\NormalTok{                bs}\OperatorTok{=}\NormalTok{xb.size(}\DecValTok{0}\NormalTok{)}\OperatorTok{;}\NormalTok{ vmae }\OperatorTok{+=}\NormalTok{ mae\_t(yb,yhat).item()}\OperatorTok{*}\NormalTok{bs}\OperatorTok{;}\NormalTok{ vsm }\OperatorTok{+=}\NormalTok{ smape\_t(yb,yhat).item()}\OperatorTok{*}\NormalTok{bs}\OperatorTok{;}\NormalTok{ n}\OperatorTok{+=}\NormalTok{bs}
\NormalTok{        vmae}\OperatorTok{/=}\NormalTok{n}\OperatorTok{;}\NormalTok{ vsm}\OperatorTok{/=}\NormalTok{n}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Epoch }\SpecialCharTok{\{}\NormalTok{epoch}\SpecialCharTok{:02d\}}\SpecialStringTok{  tr\_mae=}\SpecialCharTok{\{}\NormalTok{tr\_mae}\SpecialCharTok{:.5f\}}\SpecialStringTok{  val\_mae=}\SpecialCharTok{\{}\NormalTok{vmae}\SpecialCharTok{:.5f\}}\SpecialStringTok{  val\_sMAPE=}\SpecialCharTok{\{}\NormalTok{vsm}\SpecialCharTok{:.5f\}}\SpecialStringTok{"}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ vmae }\OperatorTok{\textless{}}\NormalTok{ best}\OperatorTok{{-}}\FloatTok{1e{-}6}\NormalTok{:}
\NormalTok{            best}\OperatorTok{=}\NormalTok{vmae}\OperatorTok{;}\NormalTok{ best\_epoch}\OperatorTok{=}\NormalTok{epoch}
\NormalTok{            torch.save(\{}\StringTok{"model"}\NormalTok{: net.state\_dict(), }\StringTok{"epoch"}\NormalTok{: epoch, }\StringTok{"feats"}\NormalTok{: feats, }\StringTok{"context"}\NormalTok{: args.context\}, ckpt)}
        \ControlFlowTok{elif}\NormalTok{ epoch }\OperatorTok{{-}}\NormalTok{ best\_epoch }\OperatorTok{\textgreater{}=}\NormalTok{ args.patience:}
            \BuiltInTok{print}\NormalTok{(}\StringTok{"Early stopping."}\NormalTok{)}
            \ControlFlowTok{break}

\NormalTok{    Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    pd.DataFrame([\{}\StringTok{"model"}\NormalTok{:args.model,}\StringTok{"context"}\NormalTok{:args.context,}\StringTok{"val\_mae"}\NormalTok{:best,}\StringTok{"best\_epoch"}\NormalTok{:best\_epoch,}\StringTok{"feats"}\NormalTok{:}\StringTok{","}\NormalTok{.join(feats)\}]).to\_csv(}
        \SpecialStringTok{f"reports/}\SpecialCharTok{\{}\NormalTok{args}\SpecialCharTok{.}\NormalTok{model}\SpecialCharTok{\}}\SpecialStringTok{\_split1\_metrics.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Run (from repo root):

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/train\_seq.py}
\ExtensionTok{python}\NormalTok{ scripts/train\_seq.py }\AttributeTok{{-}{-}model}\NormalTok{ lstm }\AttributeTok{{-}{-}context}\NormalTok{ 64 }\AttributeTok{{-}{-}tickers}\NormalTok{ 8 }\AttributeTok{{-}{-}epochs}\NormalTok{ 12}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{Part B --- Add a quick \textbf{Makefile}
target and a tiny
test}{Part B --- Add a quick Makefile target and a tiny test}}\label{part-b-add-a-quick-makefile-target-and-a-tiny-test}

\textbf{Append to \texttt{Makefile}:}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.PHONY: train{-}lstm}
\NormalTok{train{-}lstm: \#\# Train LSTM baseline on split 1 (subset of tickers)}
\NormalTok{\textbackslash{}tpython scripts/train\_seq.py {-}{-}model lstm {-}{-}context 64 {-}{-}tickers 8 {-}{-}epochs 12}
\end{Highlighting}
\end{Shaded}

\textbf{Basic shape test for dataset windows:}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_windowed\_dataset.py}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np, os}
\KeywordTok{def}\NormalTok{ test\_window\_shapes():}
    \ImportTok{import}\NormalTok{ scripts.train\_seq }\ImportTok{as}\NormalTok{ T}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ [}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ df.columns]}
\NormalTok{    splits }\OperatorTok{=}\NormalTok{ T.make\_splits(df[}\StringTok{"date"}\NormalTok{])}
\NormalTok{    a,b,c,d }\OperatorTok{=}\NormalTok{ splits[}\DecValTok{0}\NormalTok{]}
\NormalTok{    ds }\OperatorTok{=}\NormalTok{ T.WindowedDataset(df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)], feats, T}\OperatorTok{=}\DecValTok{32}\NormalTok{, scaler}\OperatorTok{=}\VariableTok{None}\NormalTok{)}
\NormalTok{    X,y }\OperatorTok{=}\NormalTok{ ds[}\DecValTok{0}\NormalTok{]}
    \ControlFlowTok{assert}\NormalTok{ X.shape }\OperatorTok{==}\NormalTok{ (}\DecValTok{32}\NormalTok{, }\BuiltInTok{len}\NormalTok{(feats))}
    \ControlFlowTok{assert}\NormalTok{ np.isfinite(y.item())}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}k}\NormalTok{ windowed\_dataset}
\end{Highlighting}
\end{Shaded}

\subsection{Part C --- Report}\label{part-c-report}

Add to your Quarto report (e.g., \texttt{reports/eda.qmd}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# PyTorch Baselines}

\NormalTok{::: \{.cell execution\_count=1\}}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{} \{.python .cell{-}code\}}
\InformationTok{import pandas as pd}
\InformationTok{print(pd.read\_csv("reports/gru\_split1\_metrics.csv"))}
\InformationTok{try:}
\InformationTok{    print(pd.read\_csv("reports/lstm\_split1\_metrics.csv"))}
\InformationTok{except Exception as e:}
\InformationTok{    print("lstm metrics not found yet")}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
:::


---

## Instructor checklist (before class)
- Confirm `features_v1.parquet` exists with `r_1d`. If not, ensure the fallback creates minimal lags and `r_1d`.  
- Dry‑run the GRU training in a fresh Colab (~2–5 min).  
- Prepare a slide on **why** we use **MAE** for training (robust to outliers) and **sMAPE** for reporting.

## Emphasize while teaching
- **Causality:** windows contain only information up to time `t`; the label is `t+1`.  
- **No leakage:** scaler fit on **train only**; reuse for val/test.  
- **Reproducibility:** seeds, deterministic flags, and saving checkpoints.  
- **Efficiency:** pin memory, small batch size, AMP on CUDA.

## Grading (pass/revise)
- `WindowedDataset` works and yields `(B, T, F)` batches.  
- Training loop runs with **early stopping** and writes `models/gru_split1.pt`.  
- `reports/gru_split1_metrics.csv` exists with `val_mae` and `val_smape`.  
- Homework script `scripts/train_seq.py` runs and writes its metrics CSV; optional test passes.

You now have a **clean PyTorch scaffold**: deterministic dataset windows, a minimal training loop with early stopping, and saved checkpoints—ready for **Session 20**, where you’ll build a **unified multi‑asset model** (ticker embeddings, mixed batches) on the same pipeline.
```



`<!-- quarto-file-metadata: eyJyZXNvdXJjZURpciI6Ii4ifQ== -->`{=html}

```{=html}
<!-- quarto-file-metadata: eyJyZXNvdXJjZURpciI6Ii4iLCJib29rSXRlbVR5cGUiOiJjaGFwdGVyIiwiYm9va0l0ZW1OdW1iZXIiOjIwLCJib29rSXRlbUZpbGUiOiJsZWMyMC5xbWQiLCJib29rSXRlbURlcHRoIjowfQ== -->
```

# Session 20 — Multi‑asset training (unified model 

```````{.quarto-title-block template='/Users/yiwang/Applications/quarto/share/projects/book/pandoc/title-block.md'}
---
title: Session 20 — Multi‑asset training (unified model

---
\end{verbatim}

Below is a complete lecture package for \textbf{Session 20 ---
Multi‑asset training (unified model)} (75 minutes). It includes a timed
agenda, slide talking points, a \textbf{Colab‑friendly in‑class lab with
copy‑paste code}, and \textbf{homework with copy‑paste code}. In class
you'll add a \textbf{\texttt{ticker\_id} embedding} (and optional
\textbf{sector} embedding) to a sequence model so \textbf{one model}
learns across \textbf{all tickers}.

\begin{quote}
\textbf{Educational use only --- not trading advice.} Assumes your
Drive‑mounted repo (e.g., \texttt{unified-stocks-teamX}) and
availability of \texttt{data/processed/features\_v1.parquet} (or
\texttt{features\_v1\_static.parquet} from Session 17) with columns like
\texttt{ticker}, \texttt{date}, \texttt{log\_return}, \texttt{r\_1d},
and some features (\texttt{lag1..lag3}, \texttt{roll\_std\_20},
\texttt{zscore\_20}, \ldots). Cells include \textbf{safe fallbacks} so
you can run end‑to‑end.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 20 --- Multi‑asset training (unified model) (75
min)}\label{session-20-multiasset-training-unified-model-75-min}

\subsection{Learning goals}\label{learning-goals-19}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Train \textbf{one unified model} across \textbf{many tickers} instead
  of one model per ticker.
\item
  Add a \textbf{\texttt{ticker\_id} embedding} (and optional
  \textbf{sector} embedding) and concatenate it to sequence inputs.
\item
  Batch \textbf{mixed tickers} safely (respecting the same time‑based
  splits and embargo from Session 15).
\item
  Log overall \textbf{validation metrics} and \textbf{per‑ticker}
  metrics for fair comparison later.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-17}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: unified vs per‑asset models; why embeddings;
  pitfalls
\item
  \textbf{(10 min)} Slides: batching mixed tickers; leakage guardrails;
  embedding size heuristics
\item
  \textbf{(35 min)} \textbf{In‑class lab}: dataset that returns
  \texttt{ticker\_id} → GRU with \texttt{nn.Embedding} → train/evaluate
  → write per‑ticker metrics
\item
  \textbf{(10 min)} Wrap‑up + homework brief
\item
  \textbf{(10 min)} Buffer / Q\&A
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slide talking points (add to your
deck)}\label{slide-talking-points-add-to-your-deck}

\subsection{Why unified?}\label{why-unified}

\begin{itemize}
\tightlist
\item
  \textbf{Data efficiency:} share statistical strength across assets.
\item
  \textbf{Personalization:} learn \textbf{asset‑specific biases} via
  \textbf{ID embeddings} (and optional sector embeddings).
\item
  \textbf{Simplicity:} one checkpoint, easier hyperparam search.
\item
  \textbf{Trade‑off:} can \textbf{overfit} to IDs if embedding too
  large; must compare to \textbf{per‑ticker} baselines.
\end{itemize}

\subsection{Embeddings in a regression
model}\label{embeddings-in-a-regression-model}

\begin{itemize}
\tightlist
\item
  Treat categorical IDs (ticker, sector) as learnable vectors.
\item
  Concatenate the embedding to \textbf{every time step} features:
  \(x'_t = [x_t \;\|\; e_{\text{ticker}} \;\|\; e_{\text{sector}}]\).
\item
  Heuristic sizes: \(d_\text{ticker} \in [8, 16]\);
  \(d_\text{sector} \in [4, 8]\). Start small.
\end{itemize}

\subsection{Batching mixed tickers without
leakage}\label{batching-mixed-tickers-without-leakage}

\begin{itemize}
\tightlist
\item
  \textbf{Splits} are \textbf{by date} (same as Session 15); \textbf{do
  not} fit scalers or thresholds on validation.
\item
  The ID mapping is just \textbf{indices}; it's \textbf{not} a data
  leak.
\item
  Keep \textbf{train‑fit scaler}, reuse on val/test.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min,
Colab‑friendly)}\label{inclass-lab-35-min-colabfriendly-6}

\begin{quote}
Run each block as its \textbf{own cell} in Colab. Replace
\texttt{REPO\_NAME} if needed.
\end{quote}

\subsection{0) Setup \& device}\label{setup-device}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME  }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}   \CommentTok{\# \textless{}{-} change to your repo name}
\NormalTok{BASE\_DIR   }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR   }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, sys, platform, random}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"models"}\NormalTok{,}\StringTok{"reports"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd())}

\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd, torch}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Torch:"}\NormalTok{, torch.\_\_version\_\_, }\StringTok{"| CUDA:"}\NormalTok{, torch.cuda.is\_available(), }\StringTok{"| Python:"}\NormalTok{, sys.version.split()[}\DecValTok{0}\NormalTok{], }\StringTok{"| OS:"}\NormalTok{, platform.system())}

\KeywordTok{def}\NormalTok{ seed\_everything(seed}\OperatorTok{=}\DecValTok{2025}\NormalTok{):}
\NormalTok{    random.seed(seed)}\OperatorTok{;}\NormalTok{ np.random.seed(seed)}\OperatorTok{;}\NormalTok{ torch.manual\_seed(seed)}
    \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available():}
\NormalTok{        torch.cuda.manual\_seed\_all(seed)}
\NormalTok{        torch.backends.cudnn.benchmark }\OperatorTok{=} \VariableTok{False}
\NormalTok{        torch.backends.cudnn.deterministic }\OperatorTok{=} \VariableTok{True}
\NormalTok{seed\_everything(}\DecValTok{2025}\NormalTok{)}
\NormalTok{device }\OperatorTok{=}\NormalTok{ torch.device(}\StringTok{"cuda"} \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"cpu"}\NormalTok{)}
\NormalTok{device}
\end{Highlighting}
\end{Shaded}

\subsection{1) Load features (with safe fallback) and define a
split}\label{load-features-with-safe-fallback-and-define-a-split}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\NormalTok{f\_static }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1\_static.parquet"}\NormalTok{)}
\NormalTok{f\_base   }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}

\ControlFlowTok{if}\NormalTok{ f\_static.exists():}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(f\_static)}
\ControlFlowTok{elif}\NormalTok{ f\_base.exists():}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(f\_base)}
\ControlFlowTok{else}\NormalTok{:}
    \CommentTok{\# Fallback from returns}
\NormalTok{    rpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ rpath.exists():}
        \CommentTok{\# synthesize a tiny dataset to keep class flowing}
\NormalTok{        rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\NormalTok{        dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{340}\NormalTok{)}
\NormalTok{        frames}\OperatorTok{=}\NormalTok{[]}
        \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{,}\StringTok{"META"}\NormalTok{]:}
\NormalTok{            eps }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.012}\NormalTok{,size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)).astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{            adj }\OperatorTok{=} \DecValTok{100}\OperatorTok{*}\NormalTok{np.exp(np.cumsum(eps))}
\NormalTok{            g }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
                \StringTok{"date"}\NormalTok{: dates, }\StringTok{"ticker"}\NormalTok{: t,}
                \StringTok{"adj\_close"}\NormalTok{: adj.astype(}\StringTok{"float32"}\NormalTok{),}
                \StringTok{"log\_return"}\NormalTok{: np.r\_[np.nan, np.diff(np.log(adj))].astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{            \})}
\NormalTok{            g[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].shift(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{            frames.append(g)}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.concat(frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        df[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{        df.to\_parquet(}\StringTok{"data/processed/returns.parquet"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(rpath)}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
    \CommentTok{\# ensure minimal features}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]:}
\NormalTok{        df[}\SpecialStringTok{f"lag}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].shift(k)}
\NormalTok{    df[}\StringTok{"roll\_std\_20"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    df[}\StringTok{"zscore\_20"}\NormalTok{]    }\OperatorTok{=}\NormalTok{ (df[}\StringTok{"log\_return"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).mean().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)) }\OperatorTok{/}\NormalTok{ (df[}\StringTok{"roll\_std\_20"}\NormalTok{] }\OperatorTok{+} \FloatTok{1e{-}8}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ df.dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Harmonize and subset for speed}
\NormalTok{df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{])}
\NormalTok{df[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{df }\OperatorTok{=}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{keep }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].cat.categories.tolist()[:}\DecValTok{10}\NormalTok{]  }\CommentTok{\# up to 10 tickers for class}
\NormalTok{df }\OperatorTok{=}\NormalTok{ df[df[}\StringTok{"ticker"}\NormalTok{].isin(keep)].copy()}

\CommentTok{\# Choose features}
\NormalTok{CAND }\OperatorTok{=}\NormalTok{ [}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{,}\StringTok{"zscore\_20"}\NormalTok{,}\StringTok{"roll\_std\_20"}\NormalTok{]}
\NormalTok{FEATS }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ CAND }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ df.columns]}
\ControlFlowTok{assert} \StringTok{"r\_1d"} \KeywordTok{in}\NormalTok{ df.columns }\KeywordTok{and}\NormalTok{ FEATS, }\StringTok{"Missing required columns."}

\KeywordTok{def}\NormalTok{ make\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ out}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        a,b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val\_size}\OperatorTok{{-}}\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        out.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+=}\NormalTok{step}
    \ControlFlowTok{return}\NormalTok{ out}

\NormalTok{splits }\OperatorTok{=}\NormalTok{ make\_splits(df[}\StringTok{"date"}\NormalTok{], }\DecValTok{252}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\ControlFlowTok{assert}\NormalTok{ splits, }\StringTok{"Not enough history for split 1."}
\NormalTok{a,b,c,d }\OperatorTok{=}\NormalTok{ splits[}\DecValTok{0}\NormalTok{]}
\NormalTok{train\_df }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)].copy()}
\NormalTok{val\_df   }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)].copy()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Split1 Train:"}\NormalTok{, a.date(), }\StringTok{"→"}\NormalTok{, b.date(), }\StringTok{"| Val:"}\NormalTok{, c.date(), }\StringTok{"→"}\NormalTok{, d.date(),}
      \StringTok{"| tickers train:"}\NormalTok{, train\_df[}\StringTok{"ticker"}\NormalTok{].nunique(), }\StringTok{"val:"}\NormalTok{, val\_df[}\StringTok{"ticker"}\NormalTok{].nunique())}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Dataset with \textbf{ticker IDs} (+
optional
sector)}{2) Dataset with ticker IDs (+ optional sector)}}\label{dataset-with-ticker-ids-optional-sector}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ json}
\ImportTok{from}\NormalTok{ torch.utils.data }\ImportTok{import}\NormalTok{ Dataset, DataLoader}

\KeywordTok{class}\NormalTok{ FeatureScaler:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\VariableTok{None}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\VariableTok{None}
    \KeywordTok{def}\NormalTok{ fit(}\VariableTok{self}\NormalTok{, X): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\NormalTok{X.mean(}\DecValTok{0}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\NormalTok{X.std(}\DecValTok{0}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}\OperatorTok{+}\FloatTok{1e{-}8}\OperatorTok{;} \ControlFlowTok{return} \VariableTok{self}
    \KeywordTok{def}\NormalTok{ transform(}\VariableTok{self}\NormalTok{, X): }\ControlFlowTok{return}\NormalTok{ (X }\OperatorTok{{-}} \VariableTok{self}\NormalTok{.mean\_) }\OperatorTok{/} \VariableTok{self}\NormalTok{.std\_}
    \KeywordTok{def}\NormalTok{ state\_dict(}\VariableTok{self}\NormalTok{): }\ControlFlowTok{return}\NormalTok{ \{}\StringTok{"mean"}\NormalTok{: }\VariableTok{self}\NormalTok{.mean\_.tolist(), }\StringTok{"std"}\NormalTok{: }\VariableTok{self}\NormalTok{.std\_.tolist()\}}
    \KeywordTok{def}\NormalTok{ load\_state\_dict(}\VariableTok{self}\NormalTok{, d): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\NormalTok{np.array(d[}\StringTok{"mean"}\NormalTok{])}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\NormalTok{np.array(d[}\StringTok{"std"}\NormalTok{])}

\KeywordTok{def}\NormalTok{ build\_sector\_map(frame: pd.DataFrame):}
    \CommentTok{\# Optional: if a \textquotesingle{}sector\textquotesingle{} column exists (from Session 12 scrape), use it; else all \textquotesingle{}UNKNOWN\textquotesingle{}.}
    \ControlFlowTok{if} \StringTok{"sector"} \KeywordTok{in}\NormalTok{ frame.columns:}
\NormalTok{        sec }\OperatorTok{=}\NormalTok{ frame[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"sector"}\NormalTok{]].drop\_duplicates().copy()}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        sec }\OperatorTok{=}\NormalTok{ frame[[}\StringTok{"ticker"}\NormalTok{]].drop\_duplicates().copy()}
\NormalTok{        sec[}\StringTok{"sector"}\NormalTok{] }\OperatorTok{=} \StringTok{"UNKNOWN"}
\NormalTok{    sec[}\StringTok{"sector"}\NormalTok{] }\OperatorTok{=}\NormalTok{ sec[}\StringTok{"sector"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
    \ControlFlowTok{return} \BuiltInTok{dict}\NormalTok{(}\BuiltInTok{zip}\NormalTok{(sec[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{), sec[}\StringTok{"sector"}\NormalTok{].cat.codes.astype(}\BuiltInTok{int}\NormalTok{))), }\BuiltInTok{len}\NormalTok{(sec[}\StringTok{"sector"}\NormalTok{].cat.categories)}

\KeywordTok{class}\NormalTok{ WindowedDatasetXID(Dataset):}
    \CommentTok{"""}
\CommentTok{    Sliding windows per ticker with ID features.}
\CommentTok{    Returns: X\_scaled (T,F), y (scalar), ticker\_id (long), sector\_id (long)}
\CommentTok{    """}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, frame: pd.DataFrame, feature\_cols, context\_len}\OperatorTok{=}\DecValTok{64}\NormalTok{,}
\NormalTok{                 scaler: FeatureScaler}\OperatorTok{|}\VariableTok{None}\OperatorTok{=}\VariableTok{None}\NormalTok{,}
\NormalTok{                 ticker2id: }\BuiltInTok{dict}\OperatorTok{|}\VariableTok{None}\OperatorTok{=}\VariableTok{None}\NormalTok{, sector2id: }\BuiltInTok{dict}\OperatorTok{|}\VariableTok{None}\OperatorTok{=}\VariableTok{None}\NormalTok{, n\_sectors: }\BuiltInTok{int}\OperatorTok{|}\VariableTok{None}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
        \ControlFlowTok{assert}\NormalTok{ \{}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{\}.issubset(frame.columns)}
        \VariableTok{self}\NormalTok{.feature\_cols }\OperatorTok{=} \BuiltInTok{list}\NormalTok{(feature\_cols)}\OperatorTok{;} \VariableTok{self}\NormalTok{.T }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(context\_len)}
        \VariableTok{self}\NormalTok{.groups, }\VariableTok{self}\NormalTok{.index }\OperatorTok{=}\NormalTok{ \{\}, []}

        \CommentTok{\# Build mappings on TRAIN; reuse on VAL}
        \ControlFlowTok{if}\NormalTok{ ticker2id }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{            cats }\OperatorTok{=}\NormalTok{ frame[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{).cat.categories.tolist()}
            \VariableTok{self}\NormalTok{.ticker2id }\OperatorTok{=}\NormalTok{ \{t:i }\ControlFlowTok{for}\NormalTok{ i,t }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(cats)\}}
        \ControlFlowTok{else}\NormalTok{:}
            \VariableTok{self}\NormalTok{.ticker2id }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(ticker2id)}
\NormalTok{        sec\_map, nsec }\OperatorTok{=}\NormalTok{ build\_sector\_map(frame)}
        \ControlFlowTok{if}\NormalTok{ sector2id }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
            \CommentTok{\# Freeze sector ids according to sec\_map order}
\NormalTok{            uniq\_secs }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(}\BuiltInTok{set}\NormalTok{(sec\_map.values()))}
            \VariableTok{self}\NormalTok{.sector2id }\OperatorTok{=}\NormalTok{ \{s:i }\ControlFlowTok{for}\NormalTok{ i,s }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(uniq\_secs)\}}
            \VariableTok{self}\NormalTok{.n\_sectors }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(}\VariableTok{self}\NormalTok{.sector2id)}
        \ControlFlowTok{else}\NormalTok{:}
            \VariableTok{self}\NormalTok{.sector2id }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(sector2id)}
            \VariableTok{self}\NormalTok{.n\_sectors }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(n\_sectors)}

        \CommentTok{\# Build per{-}ticker arrays and global window index}
        \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ frame.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{            g }\OperatorTok{=}\NormalTok{ g.sort\_values(}\StringTok{"date"}\NormalTok{).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{            X }\OperatorTok{=}\NormalTok{ g[}\VariableTok{self}\NormalTok{.feature\_cols].to\_numpy(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{            y }\OperatorTok{=}\NormalTok{ g[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{            t\_id }\OperatorTok{=} \VariableTok{self}\NormalTok{.ticker2id[}\BuiltInTok{str}\NormalTok{(tkr)]}
\NormalTok{            s\_id }\OperatorTok{=} \VariableTok{self}\NormalTok{.sector2id.get(build\_sector\_map(g)[}\DecValTok{0}\NormalTok{][}\BuiltInTok{str}\NormalTok{(tkr)], }\DecValTok{0}\NormalTok{) }\ControlFlowTok{if} \StringTok{"sector"} \KeywordTok{in}\NormalTok{ g }\ControlFlowTok{else} \DecValTok{0}
            \CommentTok{\# Valid windows}
            \ControlFlowTok{for}\NormalTok{ end }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\VariableTok{self}\NormalTok{.T}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(g)):}
                \ControlFlowTok{if}\NormalTok{ np.isfinite(y[end]):}
                    \VariableTok{self}\NormalTok{.index.append((}\BuiltInTok{str}\NormalTok{(tkr), end, t\_id, s\_id))}
            \VariableTok{self}\NormalTok{.groups[}\BuiltInTok{str}\NormalTok{(tkr)] }\OperatorTok{=}\NormalTok{ \{}\StringTok{"X"}\NormalTok{: X, }\StringTok{"y"}\NormalTok{: y\}}

        \CommentTok{\# Fit or reuse scaler}
        \VariableTok{self}\NormalTok{.scaler }\OperatorTok{=}\NormalTok{ scaler }\KeywordTok{or}\NormalTok{ FeatureScaler().fit(}
\NormalTok{            np.concatenate([}\VariableTok{self}\NormalTok{.groups[t][}\StringTok{"X"}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in} \VariableTok{self}\NormalTok{.groups], axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\NormalTok{        )}

    \KeywordTok{def} \FunctionTok{\_\_len\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(}\VariableTok{self}\NormalTok{.index)}

    \KeywordTok{def} \FunctionTok{\_\_getitem\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, i):}
\NormalTok{        tkr, end, t\_id, s\_id }\OperatorTok{=} \VariableTok{self}\NormalTok{.index[i]}
\NormalTok{        g }\OperatorTok{=} \VariableTok{self}\NormalTok{.groups[tkr]}
\NormalTok{        xs }\OperatorTok{=}\NormalTok{ g[}\StringTok{"X"}\NormalTok{][end}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.T}\OperatorTok{+}\DecValTok{1}\NormalTok{:end}\OperatorTok{+}\DecValTok{1}\NormalTok{]}
\NormalTok{        xs }\OperatorTok{=} \VariableTok{self}\NormalTok{.scaler.transform(xs)}
\NormalTok{        y  }\OperatorTok{=}\NormalTok{ g[}\StringTok{"y"}\NormalTok{][end]}
        \ControlFlowTok{return}\NormalTok{ (torch.from\_numpy(xs), torch.tensor(y, dtype}\OperatorTok{=}\NormalTok{torch.float32),}
\NormalTok{                torch.tensor(t\_id, dtype}\OperatorTok{=}\NormalTok{torch.}\BuiltInTok{long}\NormalTok{), torch.tensor(s\_id, dtype}\OperatorTok{=}\NormalTok{torch.}\BuiltInTok{long}\NormalTok{))}

\CommentTok{\# Build TRAIN/VAL datasets \& loaders (reusing train{-}fitted scaler and ID maps)}
\NormalTok{T }\OperatorTok{=} \DecValTok{64}\OperatorTok{;}\NormalTok{ BATCH}\OperatorTok{=}\DecValTok{256}\OperatorTok{;}\NormalTok{ WORKERS}\OperatorTok{=}\DecValTok{2}\OperatorTok{;}\NormalTok{ PIN}\OperatorTok{=}\NormalTok{torch.cuda.is\_available()}

\NormalTok{train\_ds }\OperatorTok{=}\NormalTok{ WindowedDatasetXID(train\_df, FEATS, context\_len}\OperatorTok{=}\NormalTok{T)}
\NormalTok{val\_ds   }\OperatorTok{=}\NormalTok{ WindowedDatasetXID(val\_df,   FEATS, context\_len}\OperatorTok{=}\NormalTok{T,}
\NormalTok{                              scaler}\OperatorTok{=}\NormalTok{train\_ds.scaler,}
\NormalTok{                              ticker2id}\OperatorTok{=}\NormalTok{train\_ds.ticker2id,}
\NormalTok{                              sector2id}\OperatorTok{=}\NormalTok{train\_ds.sector2id,}
\NormalTok{                              n\_sectors}\OperatorTok{=}\NormalTok{train\_ds.n\_sectors)}

\ImportTok{from}\NormalTok{ torch.utils.data }\ImportTok{import}\NormalTok{ DataLoader}
\KeywordTok{def}\NormalTok{ \_seed\_worker(\_):}
\NormalTok{    ws }\OperatorTok{=}\NormalTok{ torch.initial\_seed() }\OperatorTok{\%}\NormalTok{ (}\DecValTok{2}\OperatorTok{**}\DecValTok{32}\NormalTok{)}
\NormalTok{    np.random.seed(ws)}\OperatorTok{;}\NormalTok{ random.seed(ws)}

\NormalTok{g }\OperatorTok{=}\NormalTok{ torch.Generator()}\OperatorTok{;}\NormalTok{ g.manual\_seed(}\DecValTok{42}\NormalTok{)}
\NormalTok{train\_loader }\OperatorTok{=}\NormalTok{ DataLoader(train\_ds, batch\_size}\OperatorTok{=}\NormalTok{BATCH, shuffle}\OperatorTok{=}\VariableTok{True}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{True}\NormalTok{,}
\NormalTok{                          num\_workers}\OperatorTok{=}\NormalTok{WORKERS, pin\_memory}\OperatorTok{=}\NormalTok{PIN, persistent\_workers}\OperatorTok{=}\NormalTok{(WORKERS}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{),}
\NormalTok{                          worker\_init\_fn}\OperatorTok{=}\NormalTok{\_seed\_worker, generator}\OperatorTok{=}\NormalTok{g)}
\NormalTok{val\_loader   }\OperatorTok{=}\NormalTok{ DataLoader(val\_ds, batch\_size}\OperatorTok{=}\NormalTok{BATCH, shuffle}\OperatorTok{=}\VariableTok{False}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{False}\NormalTok{,}
\NormalTok{                          num\_workers}\OperatorTok{=}\NormalTok{WORKERS, pin\_memory}\OperatorTok{=}\NormalTok{PIN, persistent\_workers}\OperatorTok{=}\NormalTok{(WORKERS}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{),}
\NormalTok{                          worker\_init\_fn}\OperatorTok{=}\NormalTok{\_seed\_worker)}

\BuiltInTok{len}\NormalTok{(train\_ds), }\BuiltInTok{len}\NormalTok{(val\_ds), }\BuiltInTok{next}\NormalTok{(}\BuiltInTok{iter}\NormalTok{(train\_loader))[}\DecValTok{0}\NormalTok{].shape, }\BuiltInTok{len}\NormalTok{(train\_ds.ticker2id)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) \textbf{Unified GRU} with
\texttt{ticker\_id} embedding (optional
sector)}{3) Unified GRU with ticker\_id embedding (optional sector)}}\label{unified-gru-with-ticker_id-embedding-optional-sector}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ torch.nn }\ImportTok{as}\NormalTok{ nn, torch}
\ImportTok{from}\NormalTok{ torch.cuda.amp }\ImportTok{import}\NormalTok{ autocast, GradScaler}

\KeywordTok{class}\NormalTok{ UnifiedGRUWithID(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_features: }\BuiltInTok{int}\NormalTok{, n\_tickers: }\BuiltInTok{int}\NormalTok{, d\_ticker: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{12}\NormalTok{,}
\NormalTok{                 n\_sectors: }\BuiltInTok{int} \OperatorTok{|} \VariableTok{None} \OperatorTok{=} \VariableTok{None}\NormalTok{, d\_sector: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{0}\NormalTok{,}
\NormalTok{                 hidden: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{64}\NormalTok{, num\_layers: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{2}\NormalTok{, dropout: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.1}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.tok }\OperatorTok{=}\NormalTok{ nn.Embedding(n\_tickers, d\_ticker)}
        \VariableTok{self}\NormalTok{.sec }\OperatorTok{=}\NormalTok{ nn.Embedding(n\_sectors, d\_sector) }\ControlFlowTok{if}\NormalTok{ (n\_sectors }\KeywordTok{and}\NormalTok{ d\_sector}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{) }\ControlFlowTok{else} \VariableTok{None}
\NormalTok{        augmented\_in }\OperatorTok{=}\NormalTok{ in\_features }\OperatorTok{+}\NormalTok{ d\_ticker }\OperatorTok{+}\NormalTok{ (d\_sector }\ControlFlowTok{if} \VariableTok{self}\NormalTok{.sec }\ControlFlowTok{else} \DecValTok{0}\NormalTok{)}
        \VariableTok{self}\NormalTok{.gru }\OperatorTok{=}\NormalTok{ nn.GRU(input\_size}\OperatorTok{=}\NormalTok{augmented\_in, hidden\_size}\OperatorTok{=}\NormalTok{hidden, num\_layers}\OperatorTok{=}\NormalTok{num\_layers,}
\NormalTok{                          batch\_first}\OperatorTok{=}\VariableTok{True}\NormalTok{, dropout}\OperatorTok{=}\NormalTok{dropout }\ControlFlowTok{if}\NormalTok{ num\_layers}\OperatorTok{\textgreater{}}\DecValTok{1} \ControlFlowTok{else} \FloatTok{0.0}\NormalTok{)}
        \VariableTok{self}\NormalTok{.head }\OperatorTok{=}\NormalTok{ nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Dropout(dropout), nn.Linear(hidden, }\DecValTok{1}\NormalTok{))}

    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x, ticker\_ids, sector\_ids}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
        \CommentTok{\# x: (B,T,F)}
\NormalTok{        e }\OperatorTok{=} \VariableTok{self}\NormalTok{.tok(ticker\_ids)                          }\CommentTok{\# (B, d\_ticker)}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.sec }\KeywordTok{is} \KeywordTok{not} \VariableTok{None} \KeywordTok{and}\NormalTok{ sector\_ids }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{            e }\OperatorTok{=}\NormalTok{ torch.cat([e, }\VariableTok{self}\NormalTok{.sec(sector\_ids)], dim}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)  }\CommentTok{\# (B, d\_ticker+d\_sector)}
\NormalTok{        e }\OperatorTok{=}\NormalTok{ e.unsqueeze(}\DecValTok{1}\NormalTok{).expand(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, x.size(}\DecValTok{1}\NormalTok{), }\OperatorTok{{-}}\DecValTok{1}\NormalTok{)      }\CommentTok{\# repeat across time}
\NormalTok{        x\_aug }\OperatorTok{=}\NormalTok{ torch.cat([x, e], dim}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)                 }\CommentTok{\# (B,T,F+E)}
\NormalTok{        \_, hN }\OperatorTok{=} \VariableTok{self}\NormalTok{.gru(x\_aug)}
\NormalTok{        h }\OperatorTok{=}\NormalTok{ hN[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]                                        }\CommentTok{\# (B, H)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.head(h).squeeze(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}

\KeywordTok{def}\NormalTok{ make\_model():}
    \ControlFlowTok{return}\NormalTok{ UnifiedGRUWithID(in\_features}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(FEATS),}
\NormalTok{                            n\_tickers}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(train\_ds.ticker2id),}
\NormalTok{                            d\_ticker}\OperatorTok{=}\DecValTok{12}\NormalTok{,}
\NormalTok{                            n\_sectors}\OperatorTok{=}\NormalTok{val\_ds.n\_sectors, d\_sector}\OperatorTok{=}\DecValTok{0}\NormalTok{,  }\CommentTok{\# set \textgreater{}0 if you have sector}
\NormalTok{                            hidden}\OperatorTok{=}\DecValTok{64}\NormalTok{, num\_layers}\OperatorTok{=}\DecValTok{2}\NormalTok{, dropout}\OperatorTok{=}\FloatTok{0.1}\NormalTok{)}

\NormalTok{model }\OperatorTok{=}\NormalTok{ make\_model().to(device)}
\BuiltInTok{sum}\NormalTok{(p.numel() }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ model.parameters())}\OperatorTok{/}\FloatTok{1e6}\NormalTok{, device}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) Training loop (AMP + early stopping) and
evaluation (\textbf{per‑ticker}
metrics)}{4) Training loop (AMP + early stopping) and evaluation (per‑ticker metrics)}}\label{training-loop-amp-early-stopping-and-evaluation-perticker-metrics}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ torch.optim }\ImportTok{import}\NormalTok{ AdamW}
\ImportTok{import}\NormalTok{ time, math}

\KeywordTok{def}\NormalTok{ mae\_t(y, yhat): }\ControlFlowTok{return}\NormalTok{ torch.mean(torch.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat))}
\KeywordTok{def}\NormalTok{ smape\_t(y, yhat, eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{): }\ControlFlowTok{return}\NormalTok{ torch.mean(}\DecValTok{2}\OperatorTok{*}\NormalTok{torch.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat)}\OperatorTok{/}\NormalTok{(torch.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{torch.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps))}

\KeywordTok{def}\NormalTok{ train\_one\_epoch(model, loader, optimizer, scaler, device, use\_amp}\OperatorTok{=}\VariableTok{True}\NormalTok{):}
\NormalTok{    model.train()}\OperatorTok{;}\NormalTok{ tot}\OperatorTok{=}\FloatTok{0.0}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ xb, yb, tid, sid }\KeywordTok{in}\NormalTok{ loader:}
\NormalTok{        xb }\OperatorTok{=}\NormalTok{ xb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        yb }\OperatorTok{=}\NormalTok{ yb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        tid }\OperatorTok{=}\NormalTok{ tid.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        sid }\OperatorTok{=}\NormalTok{ sid.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        optimizer.zero\_grad(set\_to\_none}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ use\_amp }\KeywordTok{and}\NormalTok{ device.}\BuiltInTok{type}\OperatorTok{==}\StringTok{"cuda"}\NormalTok{:}
            \ControlFlowTok{with}\NormalTok{ autocast(dtype}\OperatorTok{=}\NormalTok{torch.float16):}
\NormalTok{                pred }\OperatorTok{=}\NormalTok{ model(xb, tid, sid)}
\NormalTok{                loss }\OperatorTok{=}\NormalTok{ mae\_t(yb, pred)}
\NormalTok{            scaler.scale(loss).backward()}\OperatorTok{;}\NormalTok{ scaler.step(optimizer)}\OperatorTok{;}\NormalTok{ scaler.update()}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            pred }\OperatorTok{=}\NormalTok{ model(xb, tid, sid)}\OperatorTok{;}\NormalTok{ loss }\OperatorTok{=}\NormalTok{ mae\_t(yb, pred)}\OperatorTok{;}\NormalTok{ loss.backward()}\OperatorTok{;}\NormalTok{ optimizer.step()}
\NormalTok{        bs }\OperatorTok{=}\NormalTok{ xb.size(}\DecValTok{0}\NormalTok{)}\OperatorTok{;}\NormalTok{ tot }\OperatorTok{+=}\NormalTok{ loss.item()}\OperatorTok{*}\NormalTok{bs}\OperatorTok{;}\NormalTok{ n }\OperatorTok{+=}\NormalTok{ bs}
    \ControlFlowTok{return}\NormalTok{ tot}\OperatorTok{/}\BuiltInTok{max}\NormalTok{(n,}\DecValTok{1}\NormalTok{)}

\AttributeTok{@torch.no\_grad}\NormalTok{()}
\KeywordTok{def}\NormalTok{ evaluate(model, loader, device, return\_preds}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
\NormalTok{    model.}\BuiltInTok{eval}\NormalTok{()}\OperatorTok{;}\NormalTok{ t\_mae}\OperatorTok{=}\NormalTok{t\_smape}\OperatorTok{=}\FloatTok{0.0}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\DecValTok{0}
\NormalTok{    all\_rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ xb, yb, tid, sid }\KeywordTok{in}\NormalTok{ loader:}
\NormalTok{        xb }\OperatorTok{=}\NormalTok{ xb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        yb }\OperatorTok{=}\NormalTok{ yb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        tid }\OperatorTok{=}\NormalTok{ tid.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        sid }\OperatorTok{=}\NormalTok{ sid.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        pred }\OperatorTok{=}\NormalTok{ model(xb, tid, sid)}
\NormalTok{        bs }\OperatorTok{=}\NormalTok{ xb.size(}\DecValTok{0}\NormalTok{)}\OperatorTok{;}\NormalTok{ t\_mae }\OperatorTok{+=}\NormalTok{ mae\_t(yb, pred).item()}\OperatorTok{*}\NormalTok{bs}\OperatorTok{;}\NormalTok{ t\_smape }\OperatorTok{+=}\NormalTok{ smape\_t(yb, pred).item()}\OperatorTok{*}\NormalTok{bs}\OperatorTok{;}\NormalTok{ n}\OperatorTok{+=}\NormalTok{bs}
        \ControlFlowTok{if}\NormalTok{ return\_preds:}
\NormalTok{            all\_rows.append((yb.detach().cpu().numpy(), pred.detach().cpu().numpy(), tid.detach().cpu().numpy()))}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ \{}\StringTok{"mae"}\NormalTok{: t\_mae}\OperatorTok{/}\BuiltInTok{max}\NormalTok{(n,}\DecValTok{1}\NormalTok{), }\StringTok{"smape"}\NormalTok{: t\_smape}\OperatorTok{/}\BuiltInTok{max}\NormalTok{(n,}\DecValTok{1}\NormalTok{)\}}
    \ControlFlowTok{if}\NormalTok{ return\_preds:}
\NormalTok{        ys }\OperatorTok{=}\NormalTok{ np.concatenate([r[}\DecValTok{0}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ r }\KeywordTok{in}\NormalTok{ all\_rows])}\OperatorTok{;}\NormalTok{ yh }\OperatorTok{=}\NormalTok{ np.concatenate([r[}\DecValTok{1}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ r }\KeywordTok{in}\NormalTok{ all\_rows])}\OperatorTok{;}\NormalTok{ tids }\OperatorTok{=}\NormalTok{ np.concatenate([r[}\DecValTok{2}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ r }\KeywordTok{in}\NormalTok{ all\_rows])}
\NormalTok{        out[}\StringTok{"y\_true"}\NormalTok{] }\OperatorTok{=}\NormalTok{ ys}\OperatorTok{;}\NormalTok{ out[}\StringTok{"y\_pred"}\NormalTok{] }\OperatorTok{=}\NormalTok{ yh}\OperatorTok{;}\NormalTok{ out[}\StringTok{"ticker\_id"}\NormalTok{] }\OperatorTok{=}\NormalTok{ tids}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ fit\_unified(model, train\_loader, val\_loader, epochs}\OperatorTok{=}\DecValTok{12}\NormalTok{, lr}\OperatorTok{=}\FloatTok{1e{-}3}\NormalTok{, wd}\OperatorTok{=}\FloatTok{1e{-}5}\NormalTok{, patience}\OperatorTok{=}\DecValTok{3}\NormalTok{, use\_amp}\OperatorTok{=}\VariableTok{True}\NormalTok{):}
\NormalTok{    opt }\OperatorTok{=}\NormalTok{ AdamW(model.parameters(), lr}\OperatorTok{=}\NormalTok{lr, weight\_decay}\OperatorTok{=}\NormalTok{wd)}
\NormalTok{    scaler }\OperatorTok{=}\NormalTok{ GradScaler(enabled}\OperatorTok{=}\NormalTok{(use\_amp }\KeywordTok{and}\NormalTok{ device.}\BuiltInTok{type}\OperatorTok{==}\StringTok{"cuda"}\NormalTok{))}
\NormalTok{    best}\OperatorTok{=}\NormalTok{math.inf}\OperatorTok{;}\NormalTok{ best\_ep}\OperatorTok{={-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ ckpt }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"models/unified\_gru\_split1.pt"}\NormalTok{)}
\NormalTok{    hist}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ ep }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, epochs}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{        t0}\OperatorTok{=}\NormalTok{time.time()}
\NormalTok{        tr }\OperatorTok{=}\NormalTok{ train\_one\_epoch(model, train\_loader, opt, scaler, device, use\_amp)}
\NormalTok{        val }\OperatorTok{=}\NormalTok{ evaluate(model, val\_loader, device)}
\NormalTok{        dt}\OperatorTok{=}\NormalTok{time.time()}\OperatorTok{{-}}\NormalTok{t0}
\NormalTok{        hist.append(\{}\StringTok{"epoch"}\NormalTok{:ep,}\StringTok{"train\_mae"}\NormalTok{:tr,}\StringTok{"val\_mae"}\NormalTok{:val[}\StringTok{"mae"}\NormalTok{],}\StringTok{"val\_smape"}\NormalTok{:val[}\StringTok{"smape"}\NormalTok{],}\StringTok{"sec"}\NormalTok{:dt\})}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Epoch }\SpecialCharTok{\{}\NormalTok{ep}\SpecialCharTok{:02d\}}\SpecialStringTok{  train\_mae=}\SpecialCharTok{\{}\NormalTok{tr}\SpecialCharTok{:.5f\}}\SpecialStringTok{  val\_mae=}\SpecialCharTok{\{}\NormalTok{val[}\StringTok{\textquotesingle{}mae\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.5f\}}\SpecialStringTok{  val\_sMAPE=}\SpecialCharTok{\{}\NormalTok{val[}\StringTok{\textquotesingle{}smape\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.5f\}}\SpecialStringTok{  (}\SpecialCharTok{\{}\NormalTok{dt}\SpecialCharTok{:.1f\}}\SpecialStringTok{s)"}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ val[}\StringTok{"mae"}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ best }\OperatorTok{{-}} \FloatTok{1e{-}6}\NormalTok{:}
\NormalTok{            best }\OperatorTok{=}\NormalTok{ val[}\StringTok{"mae"}\NormalTok{]}\OperatorTok{;}\NormalTok{ best\_ep}\OperatorTok{=}\NormalTok{ep}
\NormalTok{            torch.save(\{}\StringTok{"model"}\NormalTok{: model.state\_dict(),}
                        \StringTok{"epoch"}\NormalTok{: ep,}
                        \StringTok{"config"}\NormalTok{: \{}\StringTok{"feats"}\NormalTok{: FEATS, }\StringTok{"T"}\NormalTok{: T, }\StringTok{"d\_ticker"}\NormalTok{: }\DecValTok{12}\NormalTok{\}\}, ckpt)}
        \ControlFlowTok{elif}\NormalTok{ ep }\OperatorTok{{-}}\NormalTok{ best\_ep }\OperatorTok{\textgreater{}=}\NormalTok{ patience:}
            \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Early stopping at epoch }\SpecialCharTok{\{}\NormalTok{ep}\SpecialCharTok{\}}\SpecialStringTok{ (best }\SpecialCharTok{\{}\NormalTok{best}\SpecialCharTok{:.5f\}}\SpecialStringTok{ @ }\SpecialCharTok{\{}\NormalTok{best\_ep}\SpecialCharTok{\}}\SpecialStringTok{)"}\NormalTok{)}\OperatorTok{;} \ControlFlowTok{break}
    \ControlFlowTok{return}\NormalTok{ hist, best, best\_ep, ckpt}

\NormalTok{model }\OperatorTok{=}\NormalTok{ make\_model().to(device)}
\NormalTok{hist, best, best\_ep, ckpt }\OperatorTok{=}\NormalTok{ fit\_unified(model, train\_loader, val\_loader, epochs}\OperatorTok{=}\DecValTok{10}\NormalTok{, lr}\OperatorTok{=}\FloatTok{1e{-}3}\NormalTok{, wd}\OperatorTok{=}\FloatTok{1e{-}5}\NormalTok{, patience}\OperatorTok{=}\DecValTok{3}\NormalTok{, use\_amp}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Best val\_mae:"}\NormalTok{, best, }\StringTok{"| epoch:"}\NormalTok{, best\_ep, }\StringTok{"| saved:"}\NormalTok{, ckpt.exists())}
\end{Highlighting}
\end{Shaded}

\subsubsection{Per‑ticker metrics \& CSVs}\label{perticker-metrics-csvs}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Reload best and compute per{-}ticker metrics}
\NormalTok{ckpt }\OperatorTok{=}\NormalTok{ torch.load(}\StringTok{"models/unified\_gru\_split1.pt"}\NormalTok{, map\_location}\OperatorTok{=}\NormalTok{device)}
\NormalTok{model.load\_state\_dict(ckpt[}\StringTok{"model"}\NormalTok{])}\OperatorTok{;}\NormalTok{ model.to(device)}

\CommentTok{\# Evaluate with predictions and map back to ticker symbols}
\NormalTok{res }\OperatorTok{=}\NormalTok{ evaluate(model, val\_loader, device, return\_preds}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{id2ticker }\OperatorTok{=}\NormalTok{ \{v:k }\ControlFlowTok{for}\NormalTok{ k,v }\KeywordTok{in}\NormalTok{ train\_ds.ticker2id.items()\}}
\NormalTok{pt\_rows}\OperatorTok{=}\NormalTok{[]}
\ControlFlowTok{for}\NormalTok{ tid }\KeywordTok{in}\NormalTok{ np.unique(res[}\StringTok{"ticker\_id"}\NormalTok{]):}
\NormalTok{    m }\OperatorTok{=}\NormalTok{ res[}\StringTok{"ticker\_id"}\NormalTok{]}\OperatorTok{==}\NormalTok{tid}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ res[}\StringTok{"y\_true"}\NormalTok{][m]}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ res[}\StringTok{"y\_pred"}\NormalTok{][m]}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(y)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{    pt\_rows.append(\{}\StringTok{"ticker"}\NormalTok{: id2ticker[}\BuiltInTok{int}\NormalTok{(tid)], }\StringTok{"n"}\NormalTok{: }\BuiltInTok{int}\NormalTok{(}\BuiltInTok{len}\NormalTok{(y)),}
                    \StringTok{"mae"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat))),}
                    \StringTok{"smape"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.mean(}\DecValTok{2}\OperatorTok{*}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat)}\OperatorTok{/}\NormalTok{(np.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\FloatTok{1e{-}8}\NormalTok{)))\})}
\NormalTok{per\_ticker }\OperatorTok{=}\NormalTok{ pd.DataFrame(pt\_rows).sort\_values(}\StringTok{"mae"}\NormalTok{)}
\NormalTok{per\_ticker.to\_csv(}\StringTok{"reports/unified\_gru\_split1\_per\_ticker.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\CommentTok{\# Overall micro metrics (pooled)}
\NormalTok{overall }\OperatorTok{=}\NormalTok{ pd.DataFrame([\{}
    \StringTok{"split"}\NormalTok{: }\DecValTok{1}\NormalTok{, }\StringTok{"model"}\NormalTok{: }\StringTok{"unified\_gru\_id"}\NormalTok{, }\StringTok{"context"}\NormalTok{: T, }\StringTok{"feats"}\NormalTok{: }\StringTok{","}\NormalTok{.join(FEATS),}
    \StringTok{"val\_mae"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(res[}\StringTok{"y\_true"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ res[}\StringTok{"y\_pred"}\NormalTok{]))),}
    \StringTok{"val\_smape"}\NormalTok{: }\BuiltInTok{float}\NormalTok{(np.mean(}\DecValTok{2}\OperatorTok{*}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(res[}\StringTok{"y\_true"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ res[}\StringTok{"y\_pred"}\NormalTok{])}\OperatorTok{/}\NormalTok{(np.}\BuiltInTok{abs}\NormalTok{(res[}\StringTok{"y\_true"}\NormalTok{])}\OperatorTok{+}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(res[}\StringTok{"y\_pred"}\NormalTok{])}\OperatorTok{+}\FloatTok{1e{-}8}\NormalTok{))),}
    \StringTok{"best\_epoch"}\NormalTok{: ckpt.get(}\StringTok{"epoch"}\NormalTok{, }\VariableTok{None}\NormalTok{),}
    \StringTok{"params\_M"}\NormalTok{: }\BuiltInTok{round}\NormalTok{(}\BuiltInTok{sum}\NormalTok{(p.numel() }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ model.parameters())}\OperatorTok{/}\FloatTok{1e6}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{\}])}
\NormalTok{overall.to\_csv(}\StringTok{"reports/unified\_gru\_split1\_metrics.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{(per\_ticker.head(), overall)}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Time check:} With \textasciitilde8--10 tickers, \texttt{T=64},
and 10 epochs, this should finish in a couple of minutes on Colab CPU;
faster on GPU.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min) --- key
points}\label{wrapup-10-min-key-points}

\begin{itemize}
\tightlist
\item
  \textbf{Unified} models share information across assets and adapt via
  \textbf{ID embeddings}.
\item
  Embedding dims should be \textbf{small} (8--16) to avoid overfitting;
  they act like \textbf{bias + style} vectors.
\item
  Keep the \textbf{same splits} and \textbf{train‑fit scaler} to avoid
  leakage.
\item
  Always log \textbf{per‑ticker} metrics to check that no specific asset
  collapses.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
21)}\label{homework-due-before-session-21}

\textbf{Goal:} Compare \textbf{unified (ID‑augmented)} vs
\textbf{per‑ticker} models on \textbf{split 1}. Produce a single table
\texttt{reports/unified\_vs\_per\_ticker\_split1.csv} and a short
paragraph in your Quarto report.

\subsection{Part A --- Train per‑ticker GRU baselines and
compare}\label{part-a-train-perticker-gru-baselines-and-compare}

Create \textbf{\texttt{scripts/compare\_unified\_vs\_per\_ticker.py}}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/usr/bin/env python}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd, torch, torch.nn }\ImportTok{as}\NormalTok{ nn}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{from}\NormalTok{ torch.utils.data }\ImportTok{import}\NormalTok{ Dataset, DataLoader}
\ImportTok{from}\NormalTok{ torch.optim }\ImportTok{import}\NormalTok{ AdamW}
\ImportTok{from}\NormalTok{ torch.cuda.amp }\ImportTok{import}\NormalTok{ autocast, GradScaler}

\CommentTok{\# {-}{-}{-}{-} Utilities reused from class {-}{-}{-}{-}}
\KeywordTok{def}\NormalTok{ make\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ out}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        a,b}\OperatorTok{=}\NormalTok{u[}\DecValTok{0}\NormalTok{],u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val\_size}\OperatorTok{{-}}\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        out.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+=}\NormalTok{step}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{class}\NormalTok{ FeatureScaler:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\VariableTok{None}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\VariableTok{None}
    \KeywordTok{def}\NormalTok{ fit(}\VariableTok{self}\NormalTok{, X): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\NormalTok{X.mean(}\DecValTok{0}\NormalTok{)}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\NormalTok{X.std(}\DecValTok{0}\NormalTok{)}\OperatorTok{+}\FloatTok{1e{-}8}\OperatorTok{;} \ControlFlowTok{return} \VariableTok{self}
    \KeywordTok{def}\NormalTok{ transform(}\VariableTok{self}\NormalTok{, X): }\ControlFlowTok{return}\NormalTok{ (X}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.mean\_)}\OperatorTok{/}\VariableTok{self}\NormalTok{.std\_}

\KeywordTok{class}\NormalTok{ WindowedDataset(Dataset):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, df, feats, T}\OperatorTok{=}\DecValTok{64}\NormalTok{, scaler}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
        \VariableTok{self}\NormalTok{.feats}\OperatorTok{=}\NormalTok{feats}\OperatorTok{;} \VariableTok{self}\NormalTok{.T}\OperatorTok{=}\NormalTok{T}\OperatorTok{;} \VariableTok{self}\NormalTok{.idx}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;} \VariableTok{self}\NormalTok{.X}\OperatorTok{=}\VariableTok{None}\OperatorTok{;} \VariableTok{self}\NormalTok{.y}\OperatorTok{=}\VariableTok{None}
\NormalTok{        g}\OperatorTok{=}\NormalTok{df.sort\_values(}\StringTok{"date"}\NormalTok{).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
        \VariableTok{self}\NormalTok{.X }\OperatorTok{=}\NormalTok{ g[feats].to\_numpy(}\StringTok{"float32"}\NormalTok{)}\OperatorTok{;} \VariableTok{self}\NormalTok{.y }\OperatorTok{=}\NormalTok{ g[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy(}\StringTok{"float32"}\NormalTok{)}
        \ControlFlowTok{for}\NormalTok{ end }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(T}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(g)):}
            \ControlFlowTok{if}\NormalTok{ np.isfinite(}\VariableTok{self}\NormalTok{.y[end]): }\VariableTok{self}\NormalTok{.idx.append(end)}
        \VariableTok{self}\NormalTok{.scaler }\OperatorTok{=}\NormalTok{ scaler }\KeywordTok{or}\NormalTok{ FeatureScaler().fit(}\VariableTok{self}\NormalTok{.X)}
    \KeywordTok{def} \FunctionTok{\_\_len\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(}\VariableTok{self}\NormalTok{.idx)}
    \KeywordTok{def} \FunctionTok{\_\_getitem\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{,i):}
\NormalTok{        end}\OperatorTok{=}\VariableTok{self}\NormalTok{.idx[i]}\OperatorTok{;}\NormalTok{ X}\OperatorTok{=}\VariableTok{self}\NormalTok{.scaler.transform(}\VariableTok{self}\NormalTok{.X[end}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.T}\OperatorTok{+}\DecValTok{1}\NormalTok{:end}\OperatorTok{+}\DecValTok{1}\NormalTok{])}
        \ControlFlowTok{return}\NormalTok{ torch.from\_numpy(X), torch.tensor(}\VariableTok{self}\NormalTok{.y[end], dtype}\OperatorTok{=}\NormalTok{torch.float32)}

\KeywordTok{class}\NormalTok{ GRUReg(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_f, h}\OperatorTok{=}\DecValTok{64}\NormalTok{, L}\OperatorTok{=}\DecValTok{2}\NormalTok{, p}\OperatorTok{=}\FloatTok{0.1}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.gru }\OperatorTok{=}\NormalTok{ nn.GRU(in\_f, h, num\_layers}\OperatorTok{=}\NormalTok{L, batch\_first}\OperatorTok{=}\VariableTok{True}\NormalTok{, dropout}\OperatorTok{=}\NormalTok{p }\ControlFlowTok{if}\NormalTok{ L}\OperatorTok{\textgreater{}}\DecValTok{1} \ControlFlowTok{else} \FloatTok{0.}\NormalTok{)}
        \VariableTok{self}\NormalTok{.head}\OperatorTok{=}\NormalTok{ nn.Sequential(nn.Linear(h,h), nn.ReLU(), nn.Dropout(p), nn.Linear(h,}\DecValTok{1}\NormalTok{))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):}
\NormalTok{        \_,hN }\OperatorTok{=} \VariableTok{self}\NormalTok{.gru(x)}\OperatorTok{;} \ControlFlowTok{return} \VariableTok{self}\NormalTok{.head(hN[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]).squeeze(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}

\KeywordTok{def}\NormalTok{ mae(y,yhat): }\ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(np.asarray(y)}\OperatorTok{{-}}\NormalTok{np.asarray(yhat))))}
\KeywordTok{def}\NormalTok{ smape(y,yhat,eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{):}
\NormalTok{    y}\OperatorTok{=}\NormalTok{np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat}\OperatorTok{=}\NormalTok{np.asarray(yhat)}\OperatorTok{;} \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(}\DecValTok{2}\OperatorTok{*}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(y}\OperatorTok{{-}}\NormalTok{yhat)}\OperatorTok{/}\NormalTok{(np.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps)))}

\KeywordTok{def}\NormalTok{ train\_eval\_one\_ticker(df\_t, df\_v, feats, T}\OperatorTok{=}\DecValTok{64}\NormalTok{, epochs}\OperatorTok{=}\DecValTok{10}\NormalTok{, lr}\OperatorTok{=}\FloatTok{1e{-}3}\NormalTok{, batch}\OperatorTok{=}\DecValTok{128}\NormalTok{, device}\OperatorTok{=}\StringTok{"cpu"}\NormalTok{):}
\NormalTok{    tr\_ds }\OperatorTok{=}\NormalTok{ WindowedDataset(df\_t, feats, T}\OperatorTok{=}\NormalTok{T)}\OperatorTok{;}\NormalTok{ va\_ds }\OperatorTok{=}\NormalTok{ WindowedDataset(df\_v, feats, T}\OperatorTok{=}\NormalTok{T, scaler}\OperatorTok{=}\NormalTok{tr\_ds.scaler)}
\NormalTok{    tr\_ld }\OperatorTok{=}\NormalTok{ DataLoader(tr\_ds, batch\_size}\OperatorTok{=}\NormalTok{batch, shuffle}\OperatorTok{=}\VariableTok{True}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    va\_ld }\OperatorTok{=}\NormalTok{ DataLoader(va\_ds, batch\_size}\OperatorTok{=}\NormalTok{batch, shuffle}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{    net }\OperatorTok{=}\NormalTok{ GRUReg(}\BuiltInTok{len}\NormalTok{(feats)).to(device)}\OperatorTok{;}\NormalTok{ opt }\OperatorTok{=}\NormalTok{ AdamW(net.parameters(), lr}\OperatorTok{=}\NormalTok{lr, weight\_decay}\OperatorTok{=}\FloatTok{1e{-}5}\NormalTok{)}
\NormalTok{    scaler }\OperatorTok{=}\NormalTok{ GradScaler(enabled}\OperatorTok{=}\NormalTok{(device}\OperatorTok{==}\StringTok{"cuda"}\NormalTok{))}
\NormalTok{    best}\OperatorTok{=}\FloatTok{1e9}
    \ControlFlowTok{for}\NormalTok{ ep }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, epochs}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{        net.train()}
        \ControlFlowTok{for}\NormalTok{ xb,yb }\KeywordTok{in}\NormalTok{ tr\_ld:}
\NormalTok{            xb}\OperatorTok{=}\NormalTok{xb.to(device).}\BuiltInTok{float}\NormalTok{()}\OperatorTok{;}\NormalTok{ yb}\OperatorTok{=}\NormalTok{yb.to(device).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{            opt.zero\_grad(set\_to\_none}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
            \ControlFlowTok{with}\NormalTok{ autocast(enabled}\OperatorTok{=}\NormalTok{(device}\OperatorTok{==}\StringTok{"cuda"}\NormalTok{), dtype}\OperatorTok{=}\NormalTok{torch.float16):}
\NormalTok{                yhat }\OperatorTok{=}\NormalTok{ net(xb)}\OperatorTok{;}\NormalTok{ loss }\OperatorTok{=}\NormalTok{ torch.mean(torch.}\BuiltInTok{abs}\NormalTok{(yb }\OperatorTok{{-}}\NormalTok{ yhat))}
\NormalTok{            scaler.scale(loss).backward()}\OperatorTok{;}\NormalTok{ scaler.step(opt)}\OperatorTok{;}\NormalTok{ scaler.update()}
        \CommentTok{\# quick val}
\NormalTok{        net.}\BuiltInTok{eval}\NormalTok{()}\OperatorTok{;}\NormalTok{ preds}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;}\NormalTok{ ys}\OperatorTok{=}\NormalTok{[]}
        \ControlFlowTok{with}\NormalTok{ torch.no\_grad():}
            \ControlFlowTok{for}\NormalTok{ xb,yb }\KeywordTok{in}\NormalTok{ va\_ld:}
\NormalTok{                xb}\OperatorTok{=}\NormalTok{xb.to(device).}\BuiltInTok{float}\NormalTok{()}\OperatorTok{;}\NormalTok{ yb}\OperatorTok{=}\NormalTok{yb.to(device).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{                preds.append(net(xb).cpu().numpy())}\OperatorTok{;}\NormalTok{ ys.append(yb.cpu().numpy())}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ np.concatenate(ys)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.concatenate(preds)}
\NormalTok{        best }\OperatorTok{=} \BuiltInTok{min}\NormalTok{(best, mae(y,yhat))}
    \ControlFlowTok{return}\NormalTok{ best, smape(y,yhat)}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    device }\OperatorTok{=} \StringTok{"cuda"} \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"cpu"}
\NormalTok{    f\_static }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1\_static.parquet"}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(f\_static }\ControlFlowTok{if}\NormalTok{ f\_static.exists() }\ControlFlowTok{else} \StringTok{"data/processed/features\_v1.parquet"}\NormalTok{).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    CAND }\OperatorTok{=}\NormalTok{ [}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{,}\StringTok{"zscore\_20"}\NormalTok{,}\StringTok{"roll\_std\_20"}\NormalTok{]}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ CAND }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ df.columns]}\OperatorTok{;} \ControlFlowTok{assert} \StringTok{"r\_1d"} \KeywordTok{in}\NormalTok{ df.columns}
\NormalTok{    splits }\OperatorTok{=}\NormalTok{ make\_splits(df[}\StringTok{"date"}\NormalTok{])}\OperatorTok{;}\NormalTok{ a,b,c,d }\OperatorTok{=}\NormalTok{ splits[}\DecValTok{0}\NormalTok{]}
\NormalTok{    tr\_all }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)]}\OperatorTok{;}\NormalTok{ va\_all }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)]}
\NormalTok{    tickers }\OperatorTok{=}\NormalTok{ tr\_all[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{).unique().tolist()}
\NormalTok{    rows}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ tickers:}
\NormalTok{        tr }\OperatorTok{=}\NormalTok{ tr\_all[tr\_all[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{t]}\OperatorTok{;}\NormalTok{ va }\OperatorTok{=}\NormalTok{ va\_all[va\_all[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{t]}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(tr)}\OperatorTok{\textless{}}\DecValTok{100} \KeywordTok{or} \BuiltInTok{len}\NormalTok{(va)}\OperatorTok{\textless{}}\DecValTok{20}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{        vmae, vsmape }\OperatorTok{=}\NormalTok{ train\_eval\_one\_ticker(tr, va, feats, T}\OperatorTok{=}\DecValTok{64}\NormalTok{, epochs}\OperatorTok{=}\DecValTok{10}\NormalTok{, device}\OperatorTok{=}\NormalTok{device)}
\NormalTok{        rows.append(\{}\StringTok{"ticker"}\NormalTok{:t, }\StringTok{"model"}\NormalTok{:}\StringTok{"per\_ticker\_gru"}\NormalTok{, }\StringTok{"val\_mae"}\NormalTok{:vmae, }\StringTok{"val\_smape"}\NormalTok{:vsmape\})}
\NormalTok{    per\_ticker }\OperatorTok{=}\NormalTok{ pd.DataFrame(rows)}
    \CommentTok{\# Load unified results written in class}
\NormalTok{    uni\_pt }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"reports/unified\_gru\_split1\_per\_ticker.csv"}\NormalTok{).rename(columns}\OperatorTok{=}\NormalTok{\{}\StringTok{"mae"}\NormalTok{:}\StringTok{"val\_mae"}\NormalTok{,}\StringTok{"smape"}\NormalTok{:}\StringTok{"val\_smape"}\NormalTok{\})}
\NormalTok{    uni\_pt[}\StringTok{"model"}\NormalTok{] }\OperatorTok{=} \StringTok{"unified\_gru\_id"}
    \CommentTok{\# Join and compare}
\NormalTok{    comp }\OperatorTok{=}\NormalTok{ per\_ticker.merge(uni\_pt[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"model"}\NormalTok{,}\StringTok{"val\_mae"}\NormalTok{,}\StringTok{"val\_smape"}\NormalTok{]], on}\OperatorTok{=}\StringTok{"ticker"}\NormalTok{, how}\OperatorTok{=}\StringTok{"outer"}\NormalTok{, suffixes}\OperatorTok{=}\NormalTok{(}\StringTok{"\_per"}\NormalTok{,}\StringTok{"\_uni"}\NormalTok{))}
\NormalTok{    comp.to\_csv(}\StringTok{"reports/unified\_vs\_per\_ticker\_split1.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote reports/unified\_vs\_per\_ticker\_split1.csv"}\NormalTok{)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/compare\_unified\_vs\_per\_ticker.py}
\ExtensionTok{python}\NormalTok{ scripts/compare\_unified\_vs\_per\_ticker.py}
\end{Highlighting}
\end{Shaded}

\subsection{Part B --- Add a Makefile target and a minimal
test}\label{part-b-add-a-makefile-target-and-a-minimal-test}

Append to \textbf{\texttt{Makefile}}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.PHONY: train{-}unified compare{-}unified}
\NormalTok{train{-}unified: \#\# Train unified GRU with ticker embeddings on split 1}
\NormalTok{\textbackslash{}tpython {-} \textless{}\textless{}\textquotesingle{}PY\textquotesingle{}}
\NormalTok{from pathlib import Path}
\NormalTok{import runpy}
\NormalTok{runpy.run\_module(\textquotesingle{}scripts.\_\_init\_\_\textquotesingle{}, run\_name=\textquotesingle{}\_\_main\_\_\textquotesingle{}) if Path(\textquotesingle{}scripts/\_\_init\_\_.py\textquotesingle{}).exists() else None}
\NormalTok{PY}

\NormalTok{compare{-}unified: \#\# Compare unified vs per{-}ticker baselines}
\NormalTok{\textbackslash{}tpython scripts/compare\_unified\_vs\_per\_ticker.py}
\end{Highlighting}
\end{Shaded}

\emph{(If you prefer, replace \texttt{train-unified} with a thin wrapper
to re-run the in‑class cells as a script.)}

\textbf{Test:} ensure per‑ticker comparison file exists and has required
columns.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_unified\_outputs.py}
\ImportTok{import}\NormalTok{ os, pandas }\ImportTok{as}\NormalTok{ pd}

\KeywordTok{def}\NormalTok{ test\_unified\_vs\_per\_ticker\_table():}
    \ControlFlowTok{assert}\NormalTok{ os.path.exists(}\StringTok{"reports/unified\_vs\_per\_ticker\_split1.csv"}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"reports/unified\_vs\_per\_ticker\_split1.csv"}\NormalTok{)}
\NormalTok{    need }\OperatorTok{=}\NormalTok{ \{}\StringTok{"ticker"}\NormalTok{,}\StringTok{"val\_mae\_per"}\NormalTok{,}\StringTok{"val\_mae\_uni"}\NormalTok{\}}
    \ControlFlowTok{assert}\NormalTok{ need.issubset(df.columns)}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}k}\NormalTok{ unified\_outputs}
\end{Highlighting}
\end{Shaded}

\subsection{Part C --- Add a short paragraph + table to your Quarto
report}\label{part-c-add-a-short-paragraph-table-to-your-quarto-report}

In \texttt{reports/eda.qmd} (or a new \texttt{reports/unified.qmd}),
add:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# Unified vs Per‑Ticker}

\NormalTok{We trained a **unified GRU with ticker embeddings** and compared it to **per‑ticker GRUs** on Split 1.}

\NormalTok{::: \{.cell execution\_count=1\}}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{} \{.python .cell{-}code\}}
\InformationTok{import pandas as pd}
\InformationTok{pd.read\_csv("reports/unified\_vs\_per\_ticker\_split1.csv").head(10)}
\end{Highlighting}
\end{Shaded}

\textbf{Note.} Unified models can outperform when data per asset is
limited, but may underperform on idiosyncratic assets. Keep the
embedding \textbf{small} to limit overfitting.

\begin{verbatim}
:::


---

## Instructor notes / gotchas

- **Embedding dimension**: start small (8–16). Larger dims can overfit and memorize IDs.  
- **Scaler**: Fit on TRAIN only; reuse on VAL. It prevents target leakage through normalization.  
- **Per‑ticker metrics**: Always report them to avoid hiding a few failing assets inside a good aggregate.  
- **Sector embedding** (optional): If you have `sector` from Session 12, set `d_sector>0` in the model and pass `sector_ids` from the dataset.

---

## Grading (pass/revise)

- Unified model with **ticker embeddings** trains and writes:
  - `models/unified_gru_split1.pt`  
  - `reports/unified_gru_split1_metrics.csv` (overall)  
  - `reports/unified_gru_split1_per_ticker.csv` (per‑ticker)  
- Comparison table `reports/unified_vs_per_ticker_split1.csv` exists.  
- Quarto report updated with the comparison and a short discussion.

---

### Optional extensions (if students finish early)

- **Ablate** embedding size: d=0 (no ID) vs 8 vs 16.  
- Add **dropout** on embeddings or **L2** weight decay on embedding parameters only.  
- Try **concatenating embeddings at the head** (after GRU) instead of at input, and compare.  
- Try **sector embeddings** (`d_sector=4`) if you have sector metadata.  

You now have a single **multi‑asset** model with **tickers encoded as embeddings**—the foundation for Session 21, where you’ll implement attention and a **tiny GPT** on toy data before adapting it to time series.
```



`<!-- quarto-file-metadata: eyJyZXNvdXJjZURpciI6Ii4ifQ== -->`{=html}

```{=html}
<!-- quarto-file-metadata: eyJyZXNvdXJjZURpciI6Ii4iLCJib29rSXRlbVR5cGUiOiJjaGFwdGVyIiwiYm9va0l0ZW1OdW1iZXIiOjIxLCJib29rSXRlbUZpbGUiOiJsZWMyMS5xbWQiLCJib29rSXRlbURlcHRoIjowfQ== -->
```

# Session 21 — Attention & Tiny GPT on Toy Data 

```````{.quarto-title-block template='/Users/yiwang/Applications/quarto/share/projects/book/pandoc/title-block.md'}
---
title: Session 21 — Attention & Tiny GPT on Toy Data

---
\end{verbatim}

Below is a complete lecture package for \textbf{Session 21 --- Attention
\& Tiny GPT on Toy Data} (75 minutes). It includes a timed agenda, slide
talking points, a \textbf{Colab‑friendly in‑class lab with copy‑paste
code}, and \textbf{homework with copy‑paste code}. In class you'll
implement a \textbf{tiny GPT} (token + positional embeddings → stacked
Transformer blocks → LM head) and verify learning on a \textbf{toy
character‑level next‑token task}.

\begin{quote}
\textbf{Educational use only.} Assumes your Drive‑mounted repo (e.g.,
\texttt{unified-stocks-teamX}). No finance data needed today; we train
on a tiny public‑domain‑friendly toy corpus embedded in the notebook
(with fallbacks).
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 21 --- Attention \& Tiny GPT on Toy Data (75
min)}\label{session-21-attention-tiny-gpt-on-toy-data-75-min}

\subsection{Learning goals}\label{learning-goals-20}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Explain the core pieces of GPT: \textbf{token embeddings},
  \textbf{positional embeddings}, \textbf{multi‑head causal
  self‑attention}, \textbf{MLP}, \textbf{residual + LayerNorm}.
\item
  Implement a \textbf{causal mask} (no look‑ahead).
\item
  Train a \textbf{tiny GPT} (≈100--300k parameters) on a toy corpus and
  monitor \textbf{loss/perplexity}.
\item
  Generate text samples and diagnose \textbf{calibration/overfit}
  qualitatively.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-18}

\begin{itemize}
\tightlist
\item
  \textbf{(12 min)} Slides: attention recap; Transformer block anatomy;
  causal masking
\item
  \textbf{(8 min)} Slides: next‑token objective, cross‑entropy,
  perplexity; weight tying; tiny configs
\item
  \textbf{(35 min)} \textbf{In‑class lab}: build \texttt{TinyGPT} →
  train on toy corpus → plot train/val loss → sample text
\item
  \textbf{(10 min)} Wrap‑up + homework brief
\item
  \textbf{(10 min)} Buffer / Q\&A
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides / talking points (drop into your
deck)}\label{slides-talking-points-drop-into-your-deck-3}

\subsection{Scaled dot‑product attention (single
head)}\label{scaled-dotproduct-attention-single-head}

\begin{itemize}
\tightlist
\item
  Queries \textbf{Q}, keys \textbf{K}, values \textbf{V} from input
  \textbf{X} via linear projections.
\item
  Scores = \(QK^\top / \sqrt{d_k}\); apply \textbf{causal mask} to set
  future positions to \(-\infty\); softmax over last dim; output
  \(A = \text{softmax}(\text{masked scores})V\).
\end{itemize}

\subsection{Multi‑head + block}\label{multihead-block}

\begin{itemize}
\tightlist
\item
  Parallel heads capture different patterns; concat and project.
\item
  \textbf{Pre‑norm} block (LayerNorm → Attention → residual; LayerNorm →
  MLP → residual) is stable and common.
\end{itemize}

\subsection{Next‑token objective}\label{nexttoken-objective}

\begin{itemize}
\tightlist
\item
  Given context of length \textbf{T}, predict token \(x_{t+1}\) from
  \(x_{\le t}\) using \textbf{cross‑entropy}.
\item
  Report \textbf{loss} and \textbf{perplexity} \(=\exp(\text{loss})\).
\end{itemize}

\subsection{Tiny GPT config (fits in
Colab/CPU)}\label{tiny-gpt-config-fits-in-colabcpu}

\begin{itemize}
\tightlist
\item
  \texttt{d\_model=64}, \texttt{n\_head=2}, \texttt{n\_layer=2},
  \texttt{ffn=128}, \texttt{ctx=64}, batch 64--128, \textasciitilde1--3
  minutes on CPU (faster on GPU).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min,
Colab‑friendly)}\label{inclass-lab-35-min-colabfriendly-7}

\begin{quote}
Run each block as its \textbf{own cell}. Update \texttt{REPO\_NAME} to
your repo.
\end{quote}

\subsection{0) Setup \& folders}\label{setup-folders}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}  \CommentTok{\# \textless{}{-} change if needed}
\NormalTok{BASE\_DIR  }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR  }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, sys, platform, random, math, time}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"models"}\NormalTok{,}\StringTok{"reports"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{,}\StringTok{"data/raw"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd(), }\StringTok{"| Python"}\NormalTok{, sys.version.split()[}\DecValTok{0}\NormalTok{], }\StringTok{"| OS"}\NormalTok{, platform.system())}
\end{Highlighting}
\end{Shaded}

\subsection{1) Tiny toy corpus (char‑level), encoding, and
splits}\label{tiny-toy-corpus-charlevel-encoding-and-splits}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd, torch}

\CommentTok{\# Try to load an existing text; else use a small public‑domain‑friendly snippet}
\NormalTok{txt\_path }\OperatorTok{=}\NormalTok{ pathlib.Path(}\StringTok{"data/raw/tiny\_text.txt"}\NormalTok{)}
\ControlFlowTok{if}\NormalTok{ txt\_path.exists():}
\NormalTok{    text }\OperatorTok{=}\NormalTok{ txt\_path.read\_text(encoding}\OperatorTok{=}\StringTok{"utf{-}8"}\NormalTok{)}
\ControlFlowTok{else}\NormalTok{:}
\NormalTok{    text }\OperatorTok{=}\NormalTok{ (}
        \StringTok{"To be, or not to be, that is the question:}\CharTok{\textbackslash{}n}\StringTok{"}
        \StringTok{"Whether \textquotesingle{}tis nobler in the mind to suffer}\CharTok{\textbackslash{}n}\StringTok{"}
        \StringTok{"The slings and arrows of outrageous fortune,}\CharTok{\textbackslash{}n}\StringTok{"}
        \StringTok{"Or to take arms against a sea of troubles}\CharTok{\textbackslash{}n}\StringTok{"}
        \StringTok{"And by opposing end them.}\CharTok{\textbackslash{}n}\StringTok{"}
\NormalTok{    ) }\OperatorTok{*} \DecValTok{50}  \CommentTok{\# repeat to make a few thousand chars}

\CommentTok{\# Build vocabulary}
\NormalTok{chars }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(}\BuiltInTok{list}\NormalTok{(}\BuiltInTok{set}\NormalTok{(text)))}
\NormalTok{stoi  }\OperatorTok{=}\NormalTok{ \{ch:i }\ControlFlowTok{for}\NormalTok{ i,ch }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(chars)\}}
\NormalTok{itos  }\OperatorTok{=}\NormalTok{ \{i:ch }\ControlFlowTok{for}\NormalTok{ ch,i }\KeywordTok{in}\NormalTok{ stoi.items()\}}
\NormalTok{vocab\_size }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(chars)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Vocab size:"}\NormalTok{, vocab\_size, }\StringTok{"| Text length:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(text))}

\KeywordTok{def}\NormalTok{ encode(s: }\BuiltInTok{str}\NormalTok{): }\ControlFlowTok{return}\NormalTok{ torch.tensor([stoi[c] }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ s], dtype}\OperatorTok{=}\NormalTok{torch.}\BuiltInTok{long}\NormalTok{)}
\KeywordTok{def}\NormalTok{ decode(t: torch.Tensor): }\ControlFlowTok{return} \StringTok{""}\NormalTok{.join(itos[}\BuiltInTok{int}\NormalTok{(i)] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ t)}

\CommentTok{\# Train/val split (90/10 by characters)}
\NormalTok{data }\OperatorTok{=}\NormalTok{ encode(text)}
\NormalTok{split }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(}\FloatTok{0.9} \OperatorTok{*} \BuiltInTok{len}\NormalTok{(data))}
\NormalTok{train\_data }\OperatorTok{=}\NormalTok{ data[:split]}
\NormalTok{val\_data   }\OperatorTok{=}\NormalTok{ data[split:]}
\BuiltInTok{len}\NormalTok{(train\_data), }\BuiltInTok{len}\NormalTok{(val\_data)}
\end{Highlighting}
\end{Shaded}

\subsection{2) Batch generator (random contiguous
chunks)}\label{batch-generator-random-contiguous-chunks}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{torch.manual\_seed(}\DecValTok{1337}\NormalTok{)}\OperatorTok{;}\NormalTok{ np.random.seed(}\DecValTok{1337}\NormalTok{)}\OperatorTok{;}\NormalTok{ random.seed(}\DecValTok{1337}\NormalTok{)}
\NormalTok{device }\OperatorTok{=}\NormalTok{ torch.device(}\StringTok{"cuda"} \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"cpu"}\NormalTok{)}

\NormalTok{block\_size }\OperatorTok{=} \DecValTok{64}   \CommentTok{\# context length}
\NormalTok{batch\_size }\OperatorTok{=} \DecValTok{128}  \CommentTok{\# reduce to 64 if CPU is slow}

\KeywordTok{def}\NormalTok{ get\_batch(split}\OperatorTok{=}\StringTok{"train"}\NormalTok{):}
\NormalTok{    src }\OperatorTok{=}\NormalTok{ train\_data }\ControlFlowTok{if}\NormalTok{ split}\OperatorTok{==}\StringTok{"train"} \ControlFlowTok{else}\NormalTok{ val\_data}
\NormalTok{    ix }\OperatorTok{=}\NormalTok{ torch.randint(low}\OperatorTok{=}\DecValTok{0}\NormalTok{, high}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(src) }\OperatorTok{{-}}\NormalTok{ block\_size }\OperatorTok{{-}} \DecValTok{1}\NormalTok{, size}\OperatorTok{=}\NormalTok{(batch\_size,))}
\NormalTok{    x  }\OperatorTok{=}\NormalTok{ torch.stack([src[i:i}\OperatorTok{+}\NormalTok{block\_size] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ ix])}
\NormalTok{    y  }\OperatorTok{=}\NormalTok{ torch.stack([src[i}\OperatorTok{+}\DecValTok{1}\NormalTok{:i}\OperatorTok{+}\NormalTok{block\_size}\OperatorTok{+}\DecValTok{1}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ ix])}
    \ControlFlowTok{return}\NormalTok{ x.to(device), y.to(device)}

\NormalTok{xb, yb }\OperatorTok{=}\NormalTok{ get\_batch(}\StringTok{"train"}\NormalTok{)}
\NormalTok{xb.shape, yb.shape}
\end{Highlighting}
\end{Shaded}

\subsection{3) Tiny GPT model (causal mask, multi‑head attention,
pre‑norm)}\label{tiny-gpt-model-causal-mask-multihead-attention-prenorm}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ torch.nn }\ImportTok{as}\NormalTok{ nn}
\ImportTok{from}\NormalTok{ torch.nn }\ImportTok{import}\NormalTok{ functional }\ImportTok{as}\NormalTok{ F}

\KeywordTok{class}\NormalTok{ CausalSelfAttention(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model: }\BuiltInTok{int}\NormalTok{, n\_head: }\BuiltInTok{int}\NormalTok{, dropout: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \ControlFlowTok{assert}\NormalTok{ d\_model }\OperatorTok{\%}\NormalTok{ n\_head }\OperatorTok{==} \DecValTok{0}
        \VariableTok{self}\NormalTok{.n\_head }\OperatorTok{=}\NormalTok{ n\_head}
        \VariableTok{self}\NormalTok{.d\_head }\OperatorTok{=}\NormalTok{ d\_model }\OperatorTok{//}\NormalTok{ n\_head}
        \VariableTok{self}\NormalTok{.qkv }\OperatorTok{=}\NormalTok{ nn.Linear(d\_model, }\DecValTok{3} \OperatorTok{*}\NormalTok{ d\_model, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \VariableTok{self}\NormalTok{.proj }\OperatorTok{=}\NormalTok{ nn.Linear(d\_model, d\_model, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \VariableTok{self}\NormalTok{.attn\_drop }\OperatorTok{=}\NormalTok{ nn.Dropout(dropout)}
        \VariableTok{self}\NormalTok{.resid\_drop }\OperatorTok{=}\NormalTok{ nn.Dropout(dropout)}
        \CommentTok{\# Causal mask buffer (max at runtime = block\_size we train with)}
        \VariableTok{self}\NormalTok{.register\_buffer(}\StringTok{"mask"}\NormalTok{, torch.tril(torch.ones(block\_size, block\_size)).unsqueeze(}\DecValTok{0}\NormalTok{).unsqueeze(}\DecValTok{0}\NormalTok{))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):}
\NormalTok{        B, T, C }\OperatorTok{=}\NormalTok{ x.size()}
\NormalTok{        qkv }\OperatorTok{=} \VariableTok{self}\NormalTok{.qkv(x)                            }\CommentTok{\# (B,T,3C)}
\NormalTok{        q, k, v }\OperatorTok{=}\NormalTok{ qkv.split(C, dim}\OperatorTok{=}\DecValTok{2}\NormalTok{)                }\CommentTok{\# (B,T,C) each}
        \CommentTok{\# reshape to heads}
\NormalTok{        q }\OperatorTok{=}\NormalTok{ q.view(B, T, }\VariableTok{self}\NormalTok{.n\_head, }\VariableTok{self}\NormalTok{.d\_head).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)  }\CommentTok{\# (B,H,T,d)}
\NormalTok{        k }\OperatorTok{=}\NormalTok{ k.view(B, T, }\VariableTok{self}\NormalTok{.n\_head, }\VariableTok{self}\NormalTok{.d\_head).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{        v }\OperatorTok{=}\NormalTok{ v.view(B, T, }\VariableTok{self}\NormalTok{.n\_head, }\VariableTok{self}\NormalTok{.d\_head).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
        \CommentTok{\# attention scores}
\NormalTok{        att }\OperatorTok{=}\NormalTok{ (q }\OperatorTok{@}\NormalTok{ k.transpose(}\OperatorTok{{-}}\DecValTok{2}\NormalTok{, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{)) }\OperatorTok{/}\NormalTok{ math.sqrt(}\VariableTok{self}\NormalTok{.d\_head)   }\CommentTok{\# (B,H,T,T)}
\NormalTok{        att }\OperatorTok{=}\NormalTok{ att.masked\_fill(}\VariableTok{self}\NormalTok{.mask[:,:,:T,:T] }\OperatorTok{==} \DecValTok{0}\NormalTok{, }\BuiltInTok{float}\NormalTok{(}\StringTok{"{-}inf"}\NormalTok{))}
\NormalTok{        att }\OperatorTok{=}\NormalTok{ F.softmax(att, dim}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}
\NormalTok{        att }\OperatorTok{=} \VariableTok{self}\NormalTok{.attn\_drop(att)}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ att }\OperatorTok{@}\NormalTok{ v                                                }\CommentTok{\# (B,H,T,d)}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ y.transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{).contiguous().view(B, T, C)            }\CommentTok{\# (B,T,C)}
\NormalTok{        y }\OperatorTok{=} \VariableTok{self}\NormalTok{.resid\_drop(}\VariableTok{self}\NormalTok{.proj(y))}
        \ControlFlowTok{return}\NormalTok{ y}

\KeywordTok{class}\NormalTok{ MLP(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model: }\BuiltInTok{int}\NormalTok{, d\_ff: }\BuiltInTok{int}\NormalTok{, dropout: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.net }\OperatorTok{=}\NormalTok{ nn.Sequential(}
\NormalTok{            nn.Linear(d\_model, d\_ff),}
\NormalTok{            nn.GELU(),}
\NormalTok{            nn.Dropout(dropout),}
\NormalTok{            nn.Linear(d\_ff, d\_model),}
\NormalTok{            nn.Dropout(dropout),}
\NormalTok{        )}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x): }\ControlFlowTok{return} \VariableTok{self}\NormalTok{.net(x)}

\KeywordTok{class}\NormalTok{ Block(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model: }\BuiltInTok{int}\NormalTok{, n\_head: }\BuiltInTok{int}\NormalTok{, d\_ff: }\BuiltInTok{int}\NormalTok{, dropout: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.ln1 }\OperatorTok{=}\NormalTok{ nn.LayerNorm(d\_model)}
        \VariableTok{self}\NormalTok{.attn }\OperatorTok{=}\NormalTok{ CausalSelfAttention(d\_model, n\_head, dropout)}
        \VariableTok{self}\NormalTok{.ln2 }\OperatorTok{=}\NormalTok{ nn.LayerNorm(d\_model)}
        \VariableTok{self}\NormalTok{.mlp }\OperatorTok{=}\NormalTok{ MLP(d\_model, d\_ff, dropout)}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+} \VariableTok{self}\NormalTok{.attn(}\VariableTok{self}\NormalTok{.ln1(x))}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+} \VariableTok{self}\NormalTok{.mlp(}\VariableTok{self}\NormalTok{.ln2(x))}
        \ControlFlowTok{return}\NormalTok{ x}

\KeywordTok{class}\NormalTok{ TinyGPT(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, vocab\_size: }\BuiltInTok{int}\NormalTok{, d\_model}\OperatorTok{=}\DecValTok{64}\NormalTok{, n\_head}\OperatorTok{=}\DecValTok{2}\NormalTok{, n\_layer}\OperatorTok{=}\DecValTok{2}\NormalTok{, d\_ff}\OperatorTok{=}\DecValTok{128}\NormalTok{, block\_size}\OperatorTok{=}\DecValTok{64}\NormalTok{, dropout}\OperatorTok{=}\FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.block\_size }\OperatorTok{=}\NormalTok{ block\_size}
        \VariableTok{self}\NormalTok{.tok\_emb }\OperatorTok{=}\NormalTok{ nn.Embedding(vocab\_size, d\_model)}
        \VariableTok{self}\NormalTok{.pos\_emb }\OperatorTok{=}\NormalTok{ nn.Embedding(block\_size, d\_model)}
        \VariableTok{self}\NormalTok{.blocks  }\OperatorTok{=}\NormalTok{ nn.ModuleList([Block(d\_model, n\_head, d\_ff, dropout) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n\_layer)])}
        \VariableTok{self}\NormalTok{.ln\_f    }\OperatorTok{=}\NormalTok{ nn.LayerNorm(d\_model)}
        \VariableTok{self}\NormalTok{.lm\_head }\OperatorTok{=}\NormalTok{ nn.Linear(d\_model, vocab\_size, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \CommentTok{\# Weight tying (common trick)}
        \VariableTok{self}\NormalTok{.lm\_head.weight }\OperatorTok{=} \VariableTok{self}\NormalTok{.tok\_emb.weight}
        \CommentTok{\# Init}
        \VariableTok{self}\NormalTok{.}\BuiltInTok{apply}\NormalTok{(}\VariableTok{self}\NormalTok{.\_init\_weights)}
    \KeywordTok{def}\NormalTok{ \_init\_weights(}\VariableTok{self}\NormalTok{, m):}
        \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(m, nn.Linear):}
\NormalTok{            nn.init.xavier\_uniform\_(m.weight)}
            \ControlFlowTok{if}\NormalTok{ m.bias }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{: nn.init.zeros\_(m.bias)}
        \ControlFlowTok{elif} \BuiltInTok{isinstance}\NormalTok{(m, nn.Embedding):}
\NormalTok{            nn.init.normal\_(m.weight, mean}\OperatorTok{=}\FloatTok{0.0}\NormalTok{, std}\OperatorTok{=}\FloatTok{0.02}\NormalTok{)}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, idx, targets}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
\NormalTok{        B, T }\OperatorTok{=}\NormalTok{ idx.size()}
        \ControlFlowTok{assert}\NormalTok{ T }\OperatorTok{\textless{}=} \VariableTok{self}\NormalTok{.block\_size, }\StringTok{"Sequence length \textgreater{} block size"}
\NormalTok{        pos }\OperatorTok{=}\NormalTok{ torch.arange(}\DecValTok{0}\NormalTok{, T, device}\OperatorTok{=}\NormalTok{idx.device)}
\NormalTok{        x }\OperatorTok{=} \VariableTok{self}\NormalTok{.tok\_emb(idx) }\OperatorTok{+} \VariableTok{self}\NormalTok{.pos\_emb(pos)[}\VariableTok{None}\NormalTok{, :, :]}
        \ControlFlowTok{for}\NormalTok{ blk }\KeywordTok{in} \VariableTok{self}\NormalTok{.blocks:}
\NormalTok{            x }\OperatorTok{=}\NormalTok{ blk(x)}
\NormalTok{        x }\OperatorTok{=} \VariableTok{self}\NormalTok{.ln\_f(x)}
\NormalTok{        logits }\OperatorTok{=} \VariableTok{self}\NormalTok{.lm\_head(x)                      }\CommentTok{\# (B,T,vocab)}
\NormalTok{        loss }\OperatorTok{=} \VariableTok{None}
        \ControlFlowTok{if}\NormalTok{ targets }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{            loss }\OperatorTok{=}\NormalTok{ F.cross\_entropy(logits.view(B}\OperatorTok{*}\NormalTok{T, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{), targets.view(B}\OperatorTok{*}\NormalTok{T))}
        \ControlFlowTok{return}\NormalTok{ logits, loss}
    \AttributeTok{@torch.no\_grad}\NormalTok{()}
    \KeywordTok{def}\NormalTok{ generate(}\VariableTok{self}\NormalTok{, idx, max\_new\_tokens}\OperatorTok{=}\DecValTok{100}\NormalTok{, temperature}\OperatorTok{=}\FloatTok{1.0}\NormalTok{, top\_k}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
        \ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(max\_new\_tokens):}
\NormalTok{            idx\_cond }\OperatorTok{=}\NormalTok{ idx[:, }\OperatorTok{{-}}\VariableTok{self}\NormalTok{.block\_size:]      }\CommentTok{\# crop to block size}
\NormalTok{            logits, \_ }\OperatorTok{=} \VariableTok{self}\NormalTok{(idx\_cond)}
\NormalTok{            logits }\OperatorTok{=}\NormalTok{ logits[:, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{, :] }\OperatorTok{/}\NormalTok{ temperature   }\CommentTok{\# last time step}
            \ControlFlowTok{if}\NormalTok{ top\_k }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{                v, \_ }\OperatorTok{=}\NormalTok{ torch.topk(logits, top\_k)}
\NormalTok{                logits[logits }\OperatorTok{\textless{}}\NormalTok{ v[:, [}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]]] }\OperatorTok{=} \OperatorTok{{-}}\BuiltInTok{float}\NormalTok{(}\StringTok{"inf"}\NormalTok{)}
\NormalTok{            probs }\OperatorTok{=}\NormalTok{ F.softmax(logits, dim}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}
\NormalTok{            next\_id }\OperatorTok{=}\NormalTok{ torch.multinomial(probs, num\_samples}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
\NormalTok{            idx }\OperatorTok{=}\NormalTok{ torch.cat([idx, next\_id], dim}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
        \ControlFlowTok{return}\NormalTok{ idx}

\CommentTok{\# Instantiate model}
\NormalTok{d\_model, n\_head, n\_layer, d\_ff }\OperatorTok{=} \DecValTok{64}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{128}
\NormalTok{model }\OperatorTok{=}\NormalTok{ TinyGPT(vocab\_size, d\_model, n\_head, n\_layer, d\_ff, block\_size, dropout}\OperatorTok{=}\FloatTok{0.0}\NormalTok{).to(device)}
\BuiltInTok{sum}\NormalTok{(p.numel() }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ model.parameters())}\OperatorTok{/}\FloatTok{1e6}
\end{Highlighting}
\end{Shaded}

\subsection{4) Training loop (cross‑entropy), eval, and
sampling}\label{training-loop-crossentropy-eval-and-sampling}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ torch.optim }\ImportTok{import}\NormalTok{ AdamW}
\ImportTok{from}\NormalTok{ math }\ImportTok{import}\NormalTok{ exp}

\NormalTok{max\_steps     }\OperatorTok{=} \DecValTok{1200}          \CommentTok{\# keep small for class; \textasciitilde{}1–3 min on CPU}
\NormalTok{eval\_interval }\OperatorTok{=} \DecValTok{100}
\NormalTok{lr            }\OperatorTok{=} \FloatTok{3e{-}3}
\NormalTok{torch.manual\_seed(}\DecValTok{1337}\NormalTok{)}
\NormalTok{optimizer }\OperatorTok{=}\NormalTok{ AdamW(model.parameters(), lr}\OperatorTok{=}\NormalTok{lr, betas}\OperatorTok{=}\NormalTok{(}\FloatTok{0.9}\NormalTok{, }\FloatTok{0.99}\NormalTok{), weight\_decay}\OperatorTok{=}\FloatTok{0.01}\NormalTok{)}

\AttributeTok{@torch.no\_grad}\NormalTok{()}
\KeywordTok{def}\NormalTok{ estimate\_loss(iters}\OperatorTok{=}\DecValTok{200}\NormalTok{):}
\NormalTok{    model.}\BuiltInTok{eval}\NormalTok{()}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ \{\}}
    \ControlFlowTok{for}\NormalTok{ split }\KeywordTok{in}\NormalTok{ [}\StringTok{"train"}\NormalTok{,}\StringTok{"val"}\NormalTok{]:}
\NormalTok{        losses }\OperatorTok{=}\NormalTok{ torch.zeros(iters, device}\OperatorTok{=}\NormalTok{device)}
        \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(iters):}
\NormalTok{            xb, yb }\OperatorTok{=}\NormalTok{ get\_batch(split)}
\NormalTok{            \_, loss }\OperatorTok{=}\NormalTok{ model(xb, yb)}
\NormalTok{            losses[k] }\OperatorTok{=}\NormalTok{ loss}
\NormalTok{        out[split] }\OperatorTok{=}\NormalTok{ losses.mean().item()}
\NormalTok{    model.train()}
    \ControlFlowTok{return}\NormalTok{ out}

\NormalTok{loss\_history }\OperatorTok{=}\NormalTok{ []}
\NormalTok{t0 }\OperatorTok{=}\NormalTok{ time.time()}
\ControlFlowTok{for}\NormalTok{ step }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, max\_steps}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{    xb, yb }\OperatorTok{=}\NormalTok{ get\_batch(}\StringTok{"train"}\NormalTok{)}
\NormalTok{    logits, loss }\OperatorTok{=}\NormalTok{ model(xb, yb)}
\NormalTok{    optimizer.zero\_grad(set\_to\_none}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    loss.backward()}
\NormalTok{    torch.nn.utils.clip\_grad\_norm\_(model.parameters(), }\FloatTok{1.0}\NormalTok{)}
\NormalTok{    optimizer.step()}

    \ControlFlowTok{if}\NormalTok{ step }\OperatorTok{\%}\NormalTok{ eval\_interval }\OperatorTok{==} \DecValTok{0} \KeywordTok{or}\NormalTok{ step }\OperatorTok{==} \DecValTok{1} \KeywordTok{or}\NormalTok{ step }\OperatorTok{==}\NormalTok{ max\_steps:}
\NormalTok{        est }\OperatorTok{=}\NormalTok{ estimate\_loss(}\DecValTok{50}\NormalTok{)}
\NormalTok{        loss\_history.append(\{}\StringTok{"step"}\NormalTok{: step, }\StringTok{"train\_loss"}\NormalTok{: est[}\StringTok{"train"}\NormalTok{], }\StringTok{"val\_loss"}\NormalTok{: est[}\StringTok{"val"}\NormalTok{],}
                             \StringTok{"train\_ppl"}\NormalTok{: exp(est[}\StringTok{"train"}\NormalTok{]), }\StringTok{"val\_ppl"}\NormalTok{: exp(est[}\StringTok{"val"}\NormalTok{])\})}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"step }\SpecialCharTok{\{}\NormalTok{step}\SpecialCharTok{:4d\}}\SpecialStringTok{ | train loss }\SpecialCharTok{\{}\NormalTok{est[}\StringTok{\textquotesingle{}train\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{ (ppl }\SpecialCharTok{\{}\NormalTok{exp(est[}\StringTok{\textquotesingle{}train\textquotesingle{}}\NormalTok{])}\SpecialCharTok{:.1f\}}\SpecialStringTok{) "}
              \SpecialStringTok{f"| val loss }\SpecialCharTok{\{}\NormalTok{est[}\StringTok{\textquotesingle{}val\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.3f\}}\SpecialStringTok{ (ppl }\SpecialCharTok{\{}\NormalTok{exp(est[}\StringTok{\textquotesingle{}val\textquotesingle{}}\NormalTok{])}\SpecialCharTok{:.1f\}}\SpecialStringTok{)"}\NormalTok{)}

\BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Done in }\SpecialCharTok{\{}\NormalTok{time}\SpecialCharTok{.}\NormalTok{time()}\OperatorTok{{-}}\NormalTok{t0}\SpecialCharTok{:.1f\}}\SpecialStringTok{s"}\NormalTok{)}
\NormalTok{pd.DataFrame(loss\_history).to\_csv(}\StringTok{"reports/tinygpt\_train\_curve.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Quick plots and sampling}\label{quick-plots-and-sampling}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt, pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{df }\OperatorTok{=}\NormalTok{ pd.DataFrame(loss\_history)}
\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{6}\NormalTok{,}\FloatTok{3.5}\NormalTok{))}
\NormalTok{plt.plot(df[}\StringTok{"step"}\NormalTok{], df[}\StringTok{"train\_loss"}\NormalTok{], marker}\OperatorTok{=}\StringTok{"o"}\NormalTok{)}
\NormalTok{plt.plot(df[}\StringTok{"step"}\NormalTok{], df[}\StringTok{"val\_loss"}\NormalTok{], marker}\OperatorTok{=}\StringTok{"s"}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{"Step"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.ylabel(}\StringTok{"Loss"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.title(}\StringTok{"TinyGPT train/val loss"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.tight\_layout()}
\NormalTok{plt.show()}

\CommentTok{\# Sample text}
\NormalTok{start\_prompt }\OperatorTok{=} \StringTok{"To be"}
\NormalTok{start\_ids }\OperatorTok{=}\NormalTok{ encode(start\_prompt)[}\VariableTok{None}\NormalTok{, :].to(device)}
\NormalTok{sample\_ids }\OperatorTok{=}\NormalTok{ model.generate(start\_ids, max\_new\_tokens}\OperatorTok{=}\DecValTok{200}\NormalTok{, temperature}\OperatorTok{=}\FloatTok{0.8}\NormalTok{, top\_k}\OperatorTok{=}\DecValTok{40}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(decode(sample\_ids[}\DecValTok{0}\NormalTok{].tolist()))}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Sanity checks:} • \textbf{Loss should fall} and val perplexity
should be reasonable (\textgreater1, \textless{} vocab\_size). •
Generated text should \textbf{mimic} the corpus style (not necessarily
coherent).
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min) --- key points to
emphasize}\label{wrapup-10-min-key-points-to-emphasize-1}

\begin{itemize}
\tightlist
\item
  \textbf{Causal mask} prevents look‑ahead; this mirrors leakage
  controls from Sessions 17--18.
\item
  \textbf{Weight tying} reduces params and often helps.
\item
  \textbf{Positional embeddings} are required for order; we used simple
  learned absolute positions today.
\item
  This tiny model is a \textbf{teaching scaffold}---Session 22 adapts
  the embedding to \textbf{real‑valued features} for time‑series
  forecasting.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
22)}\label{homework-due-before-session-22}

\textbf{Goal:} Explore how \textbf{depth (layers)}, \textbf{width
(heads/hidden)}, and \textbf{context length} affect tiny GPT's learning
on the toy corpus. Produce a one‑page table and a short reflection
(≈300--500 words).

\subsection{\texorpdfstring{A. Script:
\texttt{scripts/tinygpt\_train.py} (configurable tiny
GPT)}{A. Script: scripts/tinygpt\_train.py (configurable tiny GPT)}}\label{a.-script-scriptstinygpt_train.py-configurable-tiny-gpt}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/usr/bin/env python}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ argparse, time, math, random, pathlib}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, torch, torch.nn }\ImportTok{as}\NormalTok{ nn}
\ImportTok{from}\NormalTok{ torch.nn }\ImportTok{import}\NormalTok{ functional }\ImportTok{as}\NormalTok{ F}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\CommentTok{\# {-}{-}{-}{-} Model components from class (compact) {-}{-}{-}{-}}
\KeywordTok{class}\NormalTok{ CausalSelfAttention(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model, n\_head, ctx, p}\OperatorTok{=}\FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \ControlFlowTok{assert}\NormalTok{ d\_model }\OperatorTok{\%}\NormalTok{ n\_head }\OperatorTok{==} \DecValTok{0}
        \VariableTok{self}\NormalTok{.n\_head }\OperatorTok{=}\NormalTok{ n\_head}\OperatorTok{;} \VariableTok{self}\NormalTok{.d\_head }\OperatorTok{=}\NormalTok{ d\_model }\OperatorTok{//}\NormalTok{ n\_head}
        \VariableTok{self}\NormalTok{.qkv }\OperatorTok{=}\NormalTok{ nn.Linear(d\_model, }\DecValTok{3}\OperatorTok{*}\NormalTok{d\_model, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \VariableTok{self}\NormalTok{.proj }\OperatorTok{=}\NormalTok{ nn.Linear(d\_model, d\_model, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \VariableTok{self}\NormalTok{.attn\_drop }\OperatorTok{=}\NormalTok{ nn.Dropout(p)}\OperatorTok{;} \VariableTok{self}\NormalTok{.resid\_drop }\OperatorTok{=}\NormalTok{ nn.Dropout(p)}
        \VariableTok{self}\NormalTok{.register\_buffer(}\StringTok{"mask"}\NormalTok{, torch.tril(torch.ones(ctx, ctx)).unsqueeze(}\DecValTok{0}\NormalTok{).unsqueeze(}\DecValTok{0}\NormalTok{))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):}
\NormalTok{        B,T,C}\OperatorTok{=}\NormalTok{x.size()}
\NormalTok{        qkv}\OperatorTok{=}\VariableTok{self}\NormalTok{.qkv(x)}\OperatorTok{;}\NormalTok{ q,k,v}\OperatorTok{=}\NormalTok{qkv.split(C,dim}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{        q}\OperatorTok{=}\NormalTok{q.view(B,T,}\VariableTok{self}\NormalTok{.n\_head,}\VariableTok{self}\NormalTok{.d\_head).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{        k}\OperatorTok{=}\NormalTok{k.view(B,T,}\VariableTok{self}\NormalTok{.n\_head,}\VariableTok{self}\NormalTok{.d\_head).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{        v}\OperatorTok{=}\NormalTok{v.view(B,T,}\VariableTok{self}\NormalTok{.n\_head,}\VariableTok{self}\NormalTok{.d\_head).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{        att}\OperatorTok{=}\NormalTok{(q }\OperatorTok{@}\NormalTok{ k.transpose(}\OperatorTok{{-}}\DecValTok{2}\NormalTok{,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)) }\OperatorTok{/}\NormalTok{ math.sqrt(}\VariableTok{self}\NormalTok{.d\_head)}
\NormalTok{        att}\OperatorTok{=}\NormalTok{att.masked\_fill(}\VariableTok{self}\NormalTok{.mask[:,:,:T,:T]}\OperatorTok{==}\DecValTok{0}\NormalTok{, }\BuiltInTok{float}\NormalTok{(}\StringTok{"{-}inf"}\NormalTok{))}
\NormalTok{        att}\OperatorTok{=}\NormalTok{att.softmax(dim}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}\OperatorTok{;}\NormalTok{ att}\OperatorTok{=}\VariableTok{self}\NormalTok{.attn\_drop(att)}
\NormalTok{        y}\OperatorTok{=}\NormalTok{att }\OperatorTok{@}\NormalTok{ v}\OperatorTok{;}\NormalTok{ y}\OperatorTok{=}\NormalTok{y.transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{).contiguous().view(B,T,C)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.resid\_drop(}\VariableTok{self}\NormalTok{.proj(y))}

\KeywordTok{class}\NormalTok{ Block(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model, n\_head, d\_ff, ctx, p}\OperatorTok{=}\FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.ln1}\OperatorTok{=}\NormalTok{nn.LayerNorm(d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.attn}\OperatorTok{=}\NormalTok{CausalSelfAttention(d\_model,n\_head,ctx,p)}
        \VariableTok{self}\NormalTok{.ln2}\OperatorTok{=}\NormalTok{nn.LayerNorm(d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.mlp}\OperatorTok{=}\NormalTok{nn.Sequential(nn.Linear(d\_model,d\_ff), nn.GELU(), nn.Dropout(p), nn.Linear(d\_ff,d\_model), nn.Dropout(p))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{,x):}
\NormalTok{        x}\OperatorTok{=}\NormalTok{x}\OperatorTok{+}\VariableTok{self}\NormalTok{.attn(}\VariableTok{self}\NormalTok{.ln1(x))}\OperatorTok{;}\NormalTok{ x}\OperatorTok{=}\NormalTok{x}\OperatorTok{+}\VariableTok{self}\NormalTok{.mlp(}\VariableTok{self}\NormalTok{.ln2(x))}\OperatorTok{;} \ControlFlowTok{return}\NormalTok{ x}

\KeywordTok{class}\NormalTok{ TinyGPT(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, vocab, d\_model}\OperatorTok{=}\DecValTok{64}\NormalTok{, n\_head}\OperatorTok{=}\DecValTok{2}\NormalTok{, n\_layer}\OperatorTok{=}\DecValTok{2}\NormalTok{, d\_ff}\OperatorTok{=}\DecValTok{128}\NormalTok{, ctx}\OperatorTok{=}\DecValTok{64}\NormalTok{, p}\OperatorTok{=}\FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.ctx}\OperatorTok{=}\NormalTok{ctx}
        \VariableTok{self}\NormalTok{.tok}\OperatorTok{=}\NormalTok{nn.Embedding(vocab,d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.pos}\OperatorTok{=}\NormalTok{nn.Embedding(ctx,d\_model)}
        \VariableTok{self}\NormalTok{.blocks}\OperatorTok{=}\NormalTok{nn.ModuleList([Block(d\_model,n\_head,d\_ff,ctx,p) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n\_layer)])}
        \VariableTok{self}\NormalTok{.ln}\OperatorTok{=}\NormalTok{nn.LayerNorm(d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.head}\OperatorTok{=}\NormalTok{nn.Linear(d\_model,vocab,bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \VariableTok{self}\NormalTok{.head.weight }\OperatorTok{=} \VariableTok{self}\NormalTok{.tok.weight}
        \VariableTok{self}\NormalTok{.}\BuiltInTok{apply}\NormalTok{(}\VariableTok{self}\NormalTok{.\_init)}
    \KeywordTok{def}\NormalTok{ \_init(}\VariableTok{self}\NormalTok{,m):}
        \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(m, nn.Linear): nn.init.xavier\_uniform\_(m.weight)}\OperatorTok{;} 
        \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(m, nn.Embedding): nn.init.normal\_(m.weight, }\FloatTok{0.0}\NormalTok{, }\FloatTok{0.02}\NormalTok{)}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, idx, targets}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
\NormalTok{        B,T}\OperatorTok{=}\NormalTok{idx.size()}\OperatorTok{;}\NormalTok{ pos}\OperatorTok{=}\NormalTok{torch.arange(T, device}\OperatorTok{=}\NormalTok{idx.device)}
\NormalTok{        x}\OperatorTok{=}\VariableTok{self}\NormalTok{.tok(idx)}\OperatorTok{+}\VariableTok{self}\NormalTok{.pos(pos)[}\VariableTok{None}\NormalTok{,:,:]}
        \ControlFlowTok{for}\NormalTok{ b }\KeywordTok{in} \VariableTok{self}\NormalTok{.blocks: x}\OperatorTok{=}\NormalTok{b(x)}
\NormalTok{        x}\OperatorTok{=}\VariableTok{self}\NormalTok{.ln(x)}\OperatorTok{;}\NormalTok{ logits}\OperatorTok{=}\VariableTok{self}\NormalTok{.head(x)}
\NormalTok{        loss}\OperatorTok{=}\VariableTok{None}
        \ControlFlowTok{if}\NormalTok{ targets }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{: loss}\OperatorTok{=}\NormalTok{F.cross\_entropy(logits.view(B}\OperatorTok{*}\NormalTok{T,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{), targets.view(B}\OperatorTok{*}\NormalTok{T))}
        \ControlFlowTok{return}\NormalTok{ logits, loss}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    ap}\OperatorTok{=}\NormalTok{argparse.ArgumentParser()}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}text"}\NormalTok{, default}\OperatorTok{=}\StringTok{"data/raw/tiny\_text.txt"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}d\_model"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{64}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}n\_head"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}n\_layer"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}d\_ff"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{128}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}ctx"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{64}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}batch"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{128}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}steps"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{1200}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}lr"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{float}\NormalTok{, default}\OperatorTok{=}\FloatTok{3e{-}3}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}seed"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{1337}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}out"}\NormalTok{, default}\OperatorTok{=}\StringTok{"reports/tinygpt\_run.csv"}\NormalTok{)}
\NormalTok{    args}\OperatorTok{=}\NormalTok{ap.parse\_args()}

    \CommentTok{\# Load or synthesize text}
\NormalTok{    p}\OperatorTok{=}\NormalTok{pathlib.Path(args.text)}
    \ControlFlowTok{if}\NormalTok{ p.exists(): text}\OperatorTok{=}\NormalTok{p.read\_text(encoding}\OperatorTok{=}\StringTok{"utf{-}8"}\NormalTok{)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        text}\OperatorTok{=}\NormalTok{(}\StringTok{"To be, or not to be: that is the question.}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}\OperatorTok{*}\DecValTok{50}
\NormalTok{        pathlib.Path(p.parent).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}\OperatorTok{;}\NormalTok{ p.write\_text(text)}

    \CommentTok{\# Vocab/encode}
\NormalTok{    chars}\OperatorTok{=}\BuiltInTok{sorted}\NormalTok{(}\BuiltInTok{list}\NormalTok{(}\BuiltInTok{set}\NormalTok{(text)))}\OperatorTok{;}\NormalTok{ stoi}\OperatorTok{=}\NormalTok{\{c:i }\ControlFlowTok{for}\NormalTok{ i,c }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(chars)\}}\OperatorTok{;}\NormalTok{ itos}\OperatorTok{=}\NormalTok{\{i:c }\ControlFlowTok{for}\NormalTok{ c,i }\KeywordTok{in}\NormalTok{ stoi.items()\}}
    \KeywordTok{def}\NormalTok{ enc(s): }\ControlFlowTok{return}\NormalTok{ torch.tensor([stoi[c] }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ s], dtype}\OperatorTok{=}\NormalTok{torch.}\BuiltInTok{long}\NormalTok{)}
\NormalTok{    data}\OperatorTok{=}\NormalTok{enc(text)}\OperatorTok{;}\NormalTok{ split}\OperatorTok{=}\BuiltInTok{int}\NormalTok{(}\FloatTok{0.9}\OperatorTok{*}\BuiltInTok{len}\NormalTok{(data))}\OperatorTok{;}\NormalTok{ train, val }\OperatorTok{=}\NormalTok{ data[:split], data[split:]}

    \CommentTok{\# Batching}
\NormalTok{    device}\OperatorTok{=}\NormalTok{torch.device(}\StringTok{"cuda"} \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"cpu"}\NormalTok{)}
\NormalTok{    random.seed(args.seed)}\OperatorTok{;}\NormalTok{ np.random.seed(args.seed)}\OperatorTok{;}\NormalTok{ torch.manual\_seed(args.seed)}
    \KeywordTok{def}\NormalTok{ batch(src):}
\NormalTok{        ix}\OperatorTok{=}\NormalTok{torch.randint(}\DecValTok{0}\NormalTok{, }\BuiltInTok{len}\NormalTok{(src)}\OperatorTok{{-}}\NormalTok{args.ctx}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, (args.batch,))}
\NormalTok{        x}\OperatorTok{=}\NormalTok{torch.stack([src[i:i}\OperatorTok{+}\NormalTok{args.ctx] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ ix])}
\NormalTok{        y}\OperatorTok{=}\NormalTok{torch.stack([src[i}\OperatorTok{+}\DecValTok{1}\NormalTok{:i}\OperatorTok{+}\NormalTok{args.ctx}\OperatorTok{+}\DecValTok{1}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ ix])}
        \ControlFlowTok{return}\NormalTok{ x.to(device), y.to(device)}

    \CommentTok{\# Model/opt}
\NormalTok{    net}\OperatorTok{=}\NormalTok{TinyGPT(vocab}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(chars), d\_model}\OperatorTok{=}\NormalTok{args.d\_model, n\_head}\OperatorTok{=}\NormalTok{args.n\_head, n\_layer}\OperatorTok{=}\NormalTok{args.n\_layer,}
\NormalTok{                d\_ff}\OperatorTok{=}\NormalTok{args.d\_ff, ctx}\OperatorTok{=}\NormalTok{args.ctx, p}\OperatorTok{=}\FloatTok{0.0}\NormalTok{).to(device)}
\NormalTok{    opt}\OperatorTok{=}\NormalTok{torch.optim.AdamW(net.parameters(), lr}\OperatorTok{=}\NormalTok{args.lr, betas}\OperatorTok{=}\NormalTok{(}\FloatTok{0.9}\NormalTok{,}\FloatTok{0.99}\NormalTok{), weight\_decay}\OperatorTok{=}\FloatTok{0.01}\NormalTok{)}

    \AttributeTok{@torch.no\_grad}\NormalTok{()}
    \KeywordTok{def}\NormalTok{ eval\_loss(iters}\OperatorTok{=}\DecValTok{100}\NormalTok{):}
\NormalTok{        net.}\BuiltInTok{eval}\NormalTok{()}\OperatorTok{;} \ImportTok{import}\NormalTok{ math}
        \KeywordTok{def}\NormalTok{ run(src):}
\NormalTok{            losses}\OperatorTok{=}\NormalTok{[]}
            \ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(iters):}
\NormalTok{                xb, yb }\OperatorTok{=}\NormalTok{ batch(src)}
\NormalTok{                \_, loss }\OperatorTok{=}\NormalTok{ net(xb, yb)}\OperatorTok{;}\NormalTok{ losses.append(loss.item())}
\NormalTok{            m}\OperatorTok{=}\NormalTok{np.mean(losses)}\OperatorTok{;} \ControlFlowTok{return}\NormalTok{ m, math.exp(m)}
\NormalTok{        tr, trp }\OperatorTok{=}\NormalTok{ run(train)}\OperatorTok{;}\NormalTok{ va, vap }\OperatorTok{=}\NormalTok{ run(val)}\OperatorTok{;}\NormalTok{ net.train()}
        \ControlFlowTok{return}\NormalTok{ tr, trp, va, vap}

\NormalTok{    hist}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ step }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, args.steps}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{        xb,yb }\OperatorTok{=}\NormalTok{ batch(train)}
\NormalTok{        \_,loss }\OperatorTok{=}\NormalTok{ net(xb,yb)}
\NormalTok{        opt.zero\_grad(set\_to\_none}\OperatorTok{=}\VariableTok{True}\NormalTok{)}\OperatorTok{;}\NormalTok{ loss.backward()}
\NormalTok{        torch.nn.utils.clip\_grad\_norm\_(net.parameters(), }\FloatTok{1.0}\NormalTok{)}
\NormalTok{        opt.step()}
        \ControlFlowTok{if}\NormalTok{ step}\OperatorTok{\%}\DecValTok{100}\OperatorTok{==}\DecValTok{0} \KeywordTok{or}\NormalTok{ step}\OperatorTok{==}\DecValTok{1} \KeywordTok{or}\NormalTok{ step}\OperatorTok{==}\NormalTok{args.steps:}
\NormalTok{            tr,trp,va,vap }\OperatorTok{=}\NormalTok{ eval\_loss(}\DecValTok{50}\NormalTok{)}
\NormalTok{            hist.append(\{}\StringTok{"step"}\NormalTok{:step,}\StringTok{"train\_loss"}\NormalTok{:tr,}\StringTok{"train\_ppl"}\NormalTok{:trp,}\StringTok{"val\_loss"}\NormalTok{:va,}\StringTok{"val\_ppl"}\NormalTok{:vap,}
                         \StringTok{"d\_model"}\NormalTok{:args.d\_model,}\StringTok{"n\_head"}\NormalTok{:args.n\_head,}\StringTok{"n\_layer"}\NormalTok{:args.n\_layer,}
                         \StringTok{"ctx"}\NormalTok{:args.ctx\})}
            \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"step }\SpecialCharTok{\{}\NormalTok{step}\SpecialCharTok{:4d\}}\SpecialStringTok{  train }\SpecialCharTok{\{}\NormalTok{tr}\SpecialCharTok{:.3f\}}\SpecialStringTok{ (ppl }\SpecialCharTok{\{}\NormalTok{trp}\SpecialCharTok{:.1f\}}\SpecialStringTok{) | val }\SpecialCharTok{\{}\NormalTok{va}\SpecialCharTok{:.3f\}}\SpecialStringTok{ (ppl }\SpecialCharTok{\{}\NormalTok{vap}\SpecialCharTok{:.1f\}}\SpecialStringTok{)"}\NormalTok{)}

\NormalTok{    pd.DataFrame(hist).to\_csv(args.out, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, args.out)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Run examples:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/tinygpt\_train.py}
\ExtensionTok{python}\NormalTok{ scripts/tinygpt\_train.py }\AttributeTok{{-}{-}n\_head}\NormalTok{ 1 }\AttributeTok{{-}{-}n\_layer}\NormalTok{ 1 }\AttributeTok{{-}{-}ctx}\NormalTok{ 32  }\AttributeTok{{-}{-}steps}\NormalTok{ 600  }\AttributeTok{{-}{-}out}\NormalTok{ reports/tinygpt\_run\_a.csv}
\ExtensionTok{python}\NormalTok{ scripts/tinygpt\_train.py }\AttributeTok{{-}{-}n\_head}\NormalTok{ 2 }\AttributeTok{{-}{-}n\_layer}\NormalTok{ 2 }\AttributeTok{{-}{-}ctx}\NormalTok{ 64  }\AttributeTok{{-}{-}steps}\NormalTok{ 1200 }\AttributeTok{{-}{-}out}\NormalTok{ reports/tinygpt\_run\_b.csv}
\end{Highlighting}
\end{Shaded}

\subsection{B. Summarize runs into a table for your
report}\label{b.-summarize-runs-into-a-table-for-your-report}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{runs }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ f }\KeywordTok{in}\NormalTok{ [}\StringTok{"reports/tinygpt\_run\_a.csv"}\NormalTok{,}\StringTok{"reports/tinygpt\_run\_b.csv"}\NormalTok{]:}
    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.read\_csv(f)}
\NormalTok{        last }\OperatorTok{=}\NormalTok{ df.sort\_values(}\StringTok{"step"}\NormalTok{).iloc[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{].to\_dict()}
\NormalTok{        last[}\StringTok{"run"}\NormalTok{] }\OperatorTok{=}\NormalTok{ f}
\NormalTok{        runs.append(last)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Skip"}\NormalTok{, f, e)}
\NormalTok{pd.DataFrame(runs).to\_csv(}\StringTok{"reports/tinygpt\_ablation\_summary.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{pd.read\_csv(}\StringTok{"reports/tinygpt\_ablation\_summary.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{C. Reflection prompts (≈300--500
words)}\label{c.-reflection-prompts-300500-words}

\begin{itemize}
\tightlist
\item
  How did \textbf{context length} (32 → 64) affect \textbf{val
  perplexity}?
\item
  Did additional \textbf{heads} or \textbf{layers} help consistently?
  Where did \textbf{overfitting} show up?
\item
  What happened to \textbf{training speed} and \textbf{stability} as you
  increased model size?
\item
  One paragraph on how you expect to \textbf{adapt embeddings} for
  \textbf{time‑series} in Session 22 (hint: replace token embedding with
  a linear projection of features; keep positional encodings and causal
  mask).
\end{itemize}

\begin{quote}
Submit \texttt{reports/tinygpt\_ablation\_summary.csv} and a short
Quarto section with your table + reflection.
\end{quote}

\subsection{D. (Optional) Tiny test for the causal
mask}\label{d.-optional-tiny-test-for-the-causal-mask}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# tests/test\_causal\_mask.py}
\ImportTok{import}\NormalTok{ torch}
\ImportTok{from}\NormalTok{ scripts.tinygpt\_train }\ImportTok{import}\NormalTok{ TinyGPT}
\KeywordTok{def}\NormalTok{ test\_mask\_is\_causal():}
\NormalTok{    m }\OperatorTok{=}\NormalTok{ TinyGPT(vocab}\OperatorTok{=}\DecValTok{10}\NormalTok{, ctx}\OperatorTok{=}\DecValTok{16}\NormalTok{, d\_model}\OperatorTok{=}\DecValTok{32}\NormalTok{, n\_head}\OperatorTok{=}\DecValTok{2}\NormalTok{, n\_layer}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
    \CommentTok{\# Find an attention module and check its mask upper triangle is zero}
\NormalTok{    att }\OperatorTok{=}\NormalTok{ [mod.attn }\ControlFlowTok{for}\NormalTok{ mod }\KeywordTok{in}\NormalTok{ m.blocks][:}\DecValTok{1}\NormalTok{][}\DecValTok{0}\NormalTok{]}
\NormalTok{    M }\OperatorTok{=}\NormalTok{ att.mask[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{]  }\CommentTok{\# (T,T)}
    \ControlFlowTok{assert}\NormalTok{ torch.}\BuiltInTok{all}\NormalTok{(M.triu(diagonal}\OperatorTok{=}\DecValTok{1}\NormalTok{)}\OperatorTok{==}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}k}\NormalTok{ causal\_mask}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-10}

\begin{itemize}
\tightlist
\item
  Dry‑run the in‑class script on CPU; confirm loss decreases within
  \textasciitilde1--3 minutes.
\item
  Prepare a slide showing \textbf{attention mask} visually
  (upper‑triangle masked).
\item
  (Optional) Show a single head's attention weights on a short prompt
  for intuition.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-10}

\begin{itemize}
\tightlist
\item
  \textbf{Causal masking} is the Transformer's built‑in ``no leakage''
  rule---maps directly to Sessions 17--18.
\item
  \textbf{Smaller is fine}: We use tiny configs to teach mechanics and
  keep run times short.
\item
  \textbf{Next session} swaps token embeddings for \textbf{real‑valued
  feature projections} and a regression head.
\end{itemize}

\section{Grading (pass/revise)}\label{grading-passrevise-9}

\begin{itemize}
\tightlist
\item
  TinyGPT trains; \texttt{reports/tinygpt\_train\_curve.csv} exists;
  curve shows decreasing val loss.
\item
  Student ran at least \textbf{two configurations} via
  \texttt{scripts/tinygpt\_train.py} and produced
  \texttt{reports/tinygpt\_ablation\_summary.csv}.
\item
  Reflection answers the prompts with evidence from the runs.
\end{itemize}

You now have a working \textbf{Tiny GPT} on toy data. In \textbf{Session
22}, you'll adapt this architecture to \textbf{time‑series returns} by
replacing the token embedding with a linear projection of features and
keeping the causal machinery.

\bookmarksetup{startatroot}

\chapter{Session 22 --- Adapting GPT to Time
Series}\label{session-22-adapting-gpt-to-time-series}

Below is a complete lecture package for \textbf{Session 22 --- Adapting
GPT to Time Series} (75 minutes). It includes a timed agenda, slide
talking points, a \textbf{Colab‑friendly in‑class lab with copy‑paste
code}, and \textbf{homework with copy‑paste code}. In class you'll
\textbf{replace token embeddings with a linear projection of real‑valued
features}, keep \textbf{positional embeddings} and a \textbf{causal
mask}, and train a \textbf{tiny Transformer (GPT‑style)} to predict
\textbf{next‑day return}.

\begin{quote}
\textbf{Educational use only --- not trading advice.} Assumes your
Drive‑mounted repo (e.g., \texttt{unified-stocks-teamX}) and
availability of \texttt{data/processed/features\_v1.parquet} (or
\texttt{features\_v1\_static.parquet}) with columns like
\texttt{ticker}, \texttt{date}, \texttt{log\_return}, \texttt{r\_1d},
plus features (\texttt{lag1..lag3}, \texttt{roll\_std\_20},
\texttt{zscore\_20}, \ldots). Cells include \textbf{safe fallbacks} so
the class can run even if files are missing.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 22 --- Adapting GPT to Time Series (75
min)}\label{session-22-adapting-gpt-to-time-series-75-min}

\subsection{Learning goals}\label{learning-goals-21}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Convert a \textbf{window of real‑valued features} into a sequence
  input for a GPT‑style model.
\item
  Use \textbf{positional embeddings} and \textbf{causal self‑attention}
  for \textbf{sequence‑to‑one regression} (predict \texttt{r\_1d{[}t{]}}
  from \texttt{x{[}≤t{]}}).
\item
  Train with \textbf{MAE/Huber} loss, \textbf{early stopping}, and
  \textbf{AMP} (optional on CUDA).
\item
  Save reproducible artifacts (checkpoint + metrics CSV) and produce a
  quick loss plot.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-19}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: from tokens to real‑valued features; causal
  masking \& alignment; loss choices
\item
  \textbf{(10 min)} Slides: tiny TS‑GPT architecture (feature projector
  → pos emb → blocks → head)
\item
  \textbf{(35 min)} \textbf{In‑class lab}: dataset → TS‑GPT →
  train/validate → save metrics \& checkpoint → quick plots
\item
  \textbf{(10 min)} Wrap‑up + homework brief
\item
  \textbf{(10 min)} Buffer / Q\&A
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slide talking points (drop into your
deck)}\label{slide-talking-points-drop-into-your-deck}

\subsection{1) From characters to
features}\label{from-characters-to-features}

\begin{itemize}
\item
  Char‑GPT maps \textbf{discrete tokens → embeddings}.
\item
  \textbf{TS‑GPT} maps \textbf{real‑valued features \texttt{x\_t∈ℝ\^{}F}
  → \texttt{ℝ\^{}d\_model}} via a \textbf{linear projection} at each
  time step:

  \[
  h_t^{(0)} = W_\text{proj} x_t + b + \text{pos\_emb}(t).
  \]
\end{itemize}

\subsection{2) Labels \& alignment (no
leakage)}\label{labels-alignment-no-leakage}

\begin{itemize}
\tightlist
\item
  \textbf{Input window:} \(X_{t-T+1:t}\) (length \(T\)).
\item
  \textbf{Target:} \(y_t = r\_1d[t]\) (next‑day log return), computed
  \textbf{outside} the model and \textbf{shifted by −1}.
\item
  \textbf{Causal mask} ensures the block at step \(t\) cannot see
  \(>t\).
\end{itemize}

\subsection{3) Loss \& scaling}\label{loss-scaling}

\begin{itemize}
\tightlist
\item
  \textbf{Loss:} MAE or \textbf{Huber} (robust to outliers in returns);
  report \textbf{MAE} and \textbf{sMAPE}.
\item
  \textbf{Scaling:} Fit a \textbf{feature scaler on TRAIN only}, reuse
  for VAL/TEST.
\end{itemize}

\subsection{4) Tiny TS‑GPT config
(Colab‑friendly)}\label{tiny-tsgpt-config-colabfriendly}

\begin{itemize}
\tightlist
\item
  \texttt{d\_model=64}, \texttt{n\_head=2}, \texttt{n\_layer=2},
  \texttt{d\_ff=128}, \texttt{ctx=64}, dropout 0.0--0.1, batch 128--256.
\item
  Save: \texttt{models/tsgpt\_split1.pt} and
  \texttt{reports/tsgpt\_split1\_metrics.csv}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min,
Colab‑friendly)}\label{inclass-lab-35-min-colabfriendly-8}

\begin{quote}
Run each block as its \textbf{own cell}. Update \texttt{REPO\_NAME} if
needed.
\end{quote}

\subsection{0) Setup \& device}\label{setup-device-1}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}  \CommentTok{\# \textless{}{-} change if needed}
\NormalTok{BASE\_DIR  }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR  }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, sys, platform, random, math, time}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"models"}\NormalTok{,}\StringTok{"reports"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{,}\StringTok{"docs/figs"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd(), }\StringTok{"| Python"}\NormalTok{, sys.version.split()[}\DecValTok{0}\NormalTok{], }\StringTok{"| OS"}\NormalTok{, platform.system())}

\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd, torch}
\NormalTok{device }\OperatorTok{=}\NormalTok{ torch.device(}\StringTok{"cuda"} \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"cpu"}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Torch:"}\NormalTok{, torch.\_\_version\_\_, }\StringTok{"| CUDA:"}\NormalTok{, torch.cuda.is\_available(), }\StringTok{"| Device:"}\NormalTok{, device)}

\KeywordTok{def}\NormalTok{ seed\_everything(seed}\OperatorTok{=}\DecValTok{2222}\NormalTok{):}
\NormalTok{    random.seed(seed)}\OperatorTok{;}\NormalTok{ np.random.seed(seed)}\OperatorTok{;}\NormalTok{ torch.manual\_seed(seed)}
    \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available():}
\NormalTok{        torch.cuda.manual\_seed\_all(seed)}
\NormalTok{        torch.backends.cudnn.benchmark }\OperatorTok{=} \VariableTok{False}
\NormalTok{        torch.backends.cudnn.deterministic }\OperatorTok{=} \VariableTok{True}
\NormalTok{seed\_everything()}
\end{Highlighting}
\end{Shaded}

\subsection{1) Load features; build split; TRAIN‑fit scaler (with
fallbacks)}\label{load-features-build-split-trainfit-scaler-with-fallbacks}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\CommentTok{\# Prefer static universe from Session 17}
\NormalTok{f\_static }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1\_static.parquet"}\NormalTok{)}
\NormalTok{f\_base   }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}

\ControlFlowTok{if}\NormalTok{ f\_static.exists():}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(f\_static)}
\ControlFlowTok{elif}\NormalTok{ f\_base.exists():}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(f\_base)}
\ControlFlowTok{else}\NormalTok{:}
    \CommentTok{\# Fallback from returns; add minimal features}
\NormalTok{    rpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/returns.parquet"}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ rpath.exists():}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(rpath).sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{])}
    \ControlFlowTok{else}\NormalTok{:}
        \CommentTok{\# synthesize small dataset}
\NormalTok{        rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\NormalTok{        dates }\OperatorTok{=}\NormalTok{ pd.bdate\_range(}\StringTok{"2022{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\DecValTok{320}\NormalTok{)}
\NormalTok{        frames}\OperatorTok{=}\NormalTok{[]}
        \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ [}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{,}\StringTok{"META"}\NormalTok{]:}
\NormalTok{            eps }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.012}\NormalTok{, size}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(dates)).astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{            adj }\OperatorTok{=} \DecValTok{100}\OperatorTok{*}\NormalTok{np.exp(np.cumsum(eps))}
\NormalTok{            g }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}
                \StringTok{"date"}\NormalTok{: dates, }\StringTok{"ticker"}\NormalTok{: t,}
                \StringTok{"adj\_close"}\NormalTok{: adj.astype(}\StringTok{"float32"}\NormalTok{),}
                \StringTok{"log\_return"}\NormalTok{: np.r\_[np.nan, np.diff(np.log(adj))].astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{            \})}
\NormalTok{            g[}\StringTok{"r\_1d"}\NormalTok{] }\OperatorTok{=}\NormalTok{ g[}\StringTok{"log\_return"}\NormalTok{].shift(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{            frames.append(g)}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.concat(frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{).dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
    \CommentTok{\# add basic features}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ k }\KeywordTok{in}\NormalTok{ [}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{]:}
\NormalTok{        df[}\SpecialStringTok{f"lag}\SpecialCharTok{\{}\NormalTok{k}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].shift(k)}
\NormalTok{    df[}\StringTok{"roll\_std\_20"}\NormalTok{]  }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    df[}\StringTok{"zscore\_20"}\NormalTok{]    }\OperatorTok{=}\NormalTok{ (df[}\StringTok{"log\_return"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).mean().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{, drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)) }\OperatorTok{/}\NormalTok{ (df[}\StringTok{"roll\_std\_20"}\NormalTok{] }\OperatorTok{+} \FloatTok{1e{-}8}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ df.dropna().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\CommentTok{\# Harmonize and subset for speed}
\NormalTok{df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{])}\OperatorTok{;}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{df }\OperatorTok{=}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{keep }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].cat.categories.tolist()[:}\DecValTok{10}\NormalTok{]  }\CommentTok{\# up to 10 tickers for class}
\NormalTok{df }\OperatorTok{=}\NormalTok{ df[df[}\StringTok{"ticker"}\NormalTok{].isin(keep)].copy()}

\CommentTok{\# Choose features (keep small \& causal)}
\NormalTok{CAND }\OperatorTok{=}\NormalTok{ [}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{,}\StringTok{"zscore\_20"}\NormalTok{,}\StringTok{"roll\_std\_20"}\NormalTok{,}\StringTok{"weekday"}\NormalTok{,}\StringTok{"month"}\NormalTok{]}
\NormalTok{FEATS }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ CAND }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ df.columns]}
\ControlFlowTok{assert} \StringTok{"r\_1d"} \KeywordTok{in}\NormalTok{ df.columns }\KeywordTok{and} \BuiltInTok{len}\NormalTok{(FEATS)}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{, }\StringTok{"Missing label or features."}

\KeywordTok{def}\NormalTok{ make\_rolling\_origin\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ out}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        a,b}\OperatorTok{=}\NormalTok{u[}\DecValTok{0}\NormalTok{],u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val\_size}\OperatorTok{{-}}\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        out.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+=}\NormalTok{step}
    \ControlFlowTok{return}\NormalTok{ out}

\NormalTok{splits }\OperatorTok{=}\NormalTok{ make\_rolling\_origin\_splits(df[}\StringTok{"date"}\NormalTok{], }\DecValTok{252}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{63}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\ControlFlowTok{assert}\NormalTok{ splits, }\StringTok{"Not enough history."}
\NormalTok{a,b,c,d }\OperatorTok{=}\NormalTok{ splits[}\DecValTok{0}\NormalTok{]}
\NormalTok{train\_df }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)].copy()}
\NormalTok{val\_df   }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)].copy()}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Split1: train"}\NormalTok{, a.date(), }\StringTok{"→"}\NormalTok{, b.date(), }\StringTok{"| val"}\NormalTok{, c.date(), }\StringTok{"→"}\NormalTok{, d.date(),}
      \StringTok{"| train rows:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(train\_df), }\StringTok{"| val rows:"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(val\_df))}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Dataset with \textbf{feature projection}
targetting
\texttt{r\_1d}}{2) Dataset with feature projection targetting r\_1d}}\label{dataset-with-feature-projection-targetting-r_1d}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ torch.utils.data }\ImportTok{import}\NormalTok{ Dataset, DataLoader}
\ImportTok{import}\NormalTok{ json}

\KeywordTok{class}\NormalTok{ FeatureScaler:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\VariableTok{None}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\VariableTok{None}
    \KeywordTok{def}\NormalTok{ fit(}\VariableTok{self}\NormalTok{, X): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\NormalTok{X.mean(}\DecValTok{0}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\NormalTok{X.std(}\DecValTok{0}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}\OperatorTok{+}\FloatTok{1e{-}8}\OperatorTok{;} \ControlFlowTok{return} \VariableTok{self}
    \KeywordTok{def}\NormalTok{ transform(}\VariableTok{self}\NormalTok{, X): }\ControlFlowTok{return}\NormalTok{ (X }\OperatorTok{{-}} \VariableTok{self}\NormalTok{.mean\_) }\OperatorTok{/} \VariableTok{self}\NormalTok{.std\_}
    \KeywordTok{def}\NormalTok{ state\_dict(}\VariableTok{self}\NormalTok{): }\ControlFlowTok{return}\NormalTok{ \{}\StringTok{"mean"}\NormalTok{: }\VariableTok{self}\NormalTok{.mean\_.tolist(), }\StringTok{"std"}\NormalTok{: }\VariableTok{self}\NormalTok{.std\_.tolist()\}}
    \KeywordTok{def}\NormalTok{ load\_state\_dict(}\VariableTok{self}\NormalTok{, d): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\NormalTok{np.array(d[}\StringTok{"mean"}\NormalTok{])}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\NormalTok{np.array(d[}\StringTok{"std"}\NormalTok{])}

\KeywordTok{class}\NormalTok{ WindowedTS(Dataset):}
    \CommentTok{"""}
\CommentTok{    Sliding windows per ticker. Each item:}
\CommentTok{      X\_scaled: (T, F), y: scalar r\_1d at window end, ticker\_id: long}
\CommentTok{    """}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, frame: pd.DataFrame, feats, T}\OperatorTok{=}\DecValTok{64}\NormalTok{, scaler: FeatureScaler}\OperatorTok{|}\VariableTok{None}\OperatorTok{=}\VariableTok{None}\NormalTok{,}
\NormalTok{                 ticker2id: }\BuiltInTok{dict}\OperatorTok{|}\VariableTok{None}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
        \VariableTok{self}\NormalTok{.T }\OperatorTok{=} \BuiltInTok{int}\NormalTok{(T)}\OperatorTok{;} \VariableTok{self}\NormalTok{.feats}\OperatorTok{=}\BuiltInTok{list}\NormalTok{(feats)}\OperatorTok{;} \VariableTok{self}\NormalTok{.idx}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;} \VariableTok{self}\NormalTok{.groups}\OperatorTok{=}\NormalTok{\{\}}
        \CommentTok{\# Build ticker ids (frozen on TRAIN)}
        \ControlFlowTok{if}\NormalTok{ ticker2id }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{            cats }\OperatorTok{=}\NormalTok{ frame[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{).cat.categories.tolist()}
            \VariableTok{self}\NormalTok{.ticker2id }\OperatorTok{=}\NormalTok{ \{t:i }\ControlFlowTok{for}\NormalTok{ i,t }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(cats)\}}
        \ControlFlowTok{else}\NormalTok{:}
            \VariableTok{self}\NormalTok{.ticker2id }\OperatorTok{=} \BuiltInTok{dict}\NormalTok{(ticker2id)}
        \CommentTok{\# Per‑ticker arrays and index of valid windows}
        \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ frame.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{            g }\OperatorTok{=}\NormalTok{ g.sort\_values(}\StringTok{"date"}\NormalTok{).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{            X }\OperatorTok{=}\NormalTok{ g[}\VariableTok{self}\NormalTok{.feats].to\_numpy(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{            y }\OperatorTok{=}\NormalTok{ g[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{            tid }\OperatorTok{=} \VariableTok{self}\NormalTok{.ticker2id[}\BuiltInTok{str}\NormalTok{(tkr)]}
            \ControlFlowTok{for}\NormalTok{ end }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\VariableTok{self}\NormalTok{.T}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(g)):}
                \ControlFlowTok{if}\NormalTok{ np.isfinite(y[end]): }\VariableTok{self}\NormalTok{.idx.append((}\BuiltInTok{str}\NormalTok{(tkr), end, tid))}
            \VariableTok{self}\NormalTok{.groups[}\BuiltInTok{str}\NormalTok{(tkr)] }\OperatorTok{=}\NormalTok{ \{}\StringTok{"X"}\NormalTok{: X, }\StringTok{"y"}\NormalTok{: y\}}
        \CommentTok{\# Fit scaler on TRAIN if not provided}
        \VariableTok{self}\NormalTok{.scaler }\OperatorTok{=}\NormalTok{ scaler }\KeywordTok{or}\NormalTok{ FeatureScaler().fit(np.concatenate([}\VariableTok{self}\NormalTok{.groups[t][}\StringTok{"X"}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in} \VariableTok{self}\NormalTok{.groups], }\DecValTok{0}\NormalTok{))}

    \KeywordTok{def} \FunctionTok{\_\_len\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(}\VariableTok{self}\NormalTok{.idx)}
    \KeywordTok{def} \FunctionTok{\_\_getitem\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, i):}
\NormalTok{        tkr, end, tid }\OperatorTok{=} \VariableTok{self}\NormalTok{.idx[i]}
\NormalTok{        g }\OperatorTok{=} \VariableTok{self}\NormalTok{.groups[tkr]}
\NormalTok{        X }\OperatorTok{=}\NormalTok{ g[}\StringTok{"X"}\NormalTok{][end}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.T}\OperatorTok{+}\DecValTok{1}\NormalTok{:end}\OperatorTok{+}\DecValTok{1}\NormalTok{]}
\NormalTok{        X }\OperatorTok{=} \VariableTok{self}\NormalTok{.scaler.transform(X)}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ g[}\StringTok{"y"}\NormalTok{][end]}
        \ControlFlowTok{return}\NormalTok{ torch.from\_numpy(X), torch.tensor(y, dtype}\OperatorTok{=}\NormalTok{torch.float32), torch.tensor(tid, dtype}\OperatorTok{=}\NormalTok{torch.}\BuiltInTok{long}\NormalTok{)}

\CommentTok{\# Build TRAIN/VAL datasets \& loaders}
\NormalTok{CTX }\OperatorTok{=} \DecValTok{64}\OperatorTok{;}\NormalTok{ BATCH}\OperatorTok{=}\DecValTok{256}\OperatorTok{;}\NormalTok{ WORKERS}\OperatorTok{=}\DecValTok{2}\OperatorTok{;}\NormalTok{ PIN}\OperatorTok{=}\NormalTok{torch.cuda.is\_available()}

\NormalTok{train\_ds }\OperatorTok{=}\NormalTok{ WindowedTS(train\_df, FEATS, T}\OperatorTok{=}\NormalTok{CTX)}
\NormalTok{val\_ds   }\OperatorTok{=}\NormalTok{ WindowedTS(val\_df,   FEATS, T}\OperatorTok{=}\NormalTok{CTX, scaler}\OperatorTok{=}\NormalTok{train\_ds.scaler, ticker2id}\OperatorTok{=}\NormalTok{train\_ds.ticker2id)}

\CommentTok{\# Persist scaler (reproducibility)}
\NormalTok{Path(}\StringTok{"models"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{Path(}\StringTok{"models/tsgpt\_scaler\_split1.json"}\NormalTok{).write\_text(json.dumps(train\_ds.scaler.state\_dict()))}

\KeywordTok{def}\NormalTok{ \_seed\_worker(\_):}
\NormalTok{    ws }\OperatorTok{=}\NormalTok{ torch.initial\_seed() }\OperatorTok{\%}\NormalTok{ (}\DecValTok{2}\OperatorTok{**}\DecValTok{32}\NormalTok{)}
\NormalTok{    np.random.seed(ws)}\OperatorTok{;}\NormalTok{ random.seed(ws)}

\NormalTok{g }\OperatorTok{=}\NormalTok{ torch.Generator()}\OperatorTok{;}\NormalTok{ g.manual\_seed(}\DecValTok{42}\NormalTok{)}
\NormalTok{train\_loader }\OperatorTok{=}\NormalTok{ DataLoader(train\_ds, batch\_size}\OperatorTok{=}\NormalTok{BATCH, shuffle}\OperatorTok{=}\VariableTok{True}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{True}\NormalTok{,}
\NormalTok{                          num\_workers}\OperatorTok{=}\NormalTok{WORKERS, pin\_memory}\OperatorTok{=}\NormalTok{PIN, persistent\_workers}\OperatorTok{=}\NormalTok{(WORKERS}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{),}
\NormalTok{                          worker\_init\_fn}\OperatorTok{=}\NormalTok{\_seed\_worker, generator}\OperatorTok{=}\NormalTok{g)}
\NormalTok{val\_loader   }\OperatorTok{=}\NormalTok{ DataLoader(val\_ds, batch\_size}\OperatorTok{=}\NormalTok{BATCH, shuffle}\OperatorTok{=}\VariableTok{False}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{False}\NormalTok{,}
\NormalTok{                          num\_workers}\OperatorTok{=}\NormalTok{WORKERS, pin\_memory}\OperatorTok{=}\NormalTok{PIN, persistent\_workers}\OperatorTok{=}\NormalTok{(WORKERS}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{),}
\NormalTok{                          worker\_init\_fn}\OperatorTok{=}\NormalTok{\_seed\_worker)}

\BuiltInTok{len}\NormalTok{(train\_ds), }\BuiltInTok{len}\NormalTok{(val\_ds), }\BuiltInTok{next}\NormalTok{(}\BuiltInTok{iter}\NormalTok{(train\_loader))[}\DecValTok{0}\NormalTok{].shape}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) \textbf{Time‑Series GPT} (feature
projector + pos emb + Transformer blocks + regression
head)}{3) Time‑Series GPT (feature projector + pos emb + Transformer blocks + regression head)}}\label{timeseries-gpt-feature-projector-pos-emb-transformer-blocks-regression-head}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ torch.nn }\ImportTok{as}\NormalTok{ nn}
\ImportTok{from}\NormalTok{ torch.nn }\ImportTok{import}\NormalTok{ functional }\ImportTok{as}\NormalTok{ F}

\NormalTok{BLOCK\_SIZE }\OperatorTok{=}\NormalTok{ CTX  }\CommentTok{\# maximum context supported}

\KeywordTok{class}\NormalTok{ CausalSelfAttention(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model: }\BuiltInTok{int}\NormalTok{, n\_head: }\BuiltInTok{int}\NormalTok{, dropout: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \ControlFlowTok{assert}\NormalTok{ d\_model }\OperatorTok{\%}\NormalTok{ n\_head }\OperatorTok{==} \DecValTok{0}
        \VariableTok{self}\NormalTok{.n\_head }\OperatorTok{=}\NormalTok{ n\_head}\OperatorTok{;} \VariableTok{self}\NormalTok{.d\_head }\OperatorTok{=}\NormalTok{ d\_model }\OperatorTok{//}\NormalTok{ n\_head}
        \VariableTok{self}\NormalTok{.qkv }\OperatorTok{=}\NormalTok{ nn.Linear(d\_model, }\DecValTok{3}\OperatorTok{*}\NormalTok{d\_model, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \VariableTok{self}\NormalTok{.proj }\OperatorTok{=}\NormalTok{ nn.Linear(d\_model, d\_model, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \VariableTok{self}\NormalTok{.attn\_drop }\OperatorTok{=}\NormalTok{ nn.Dropout(dropout)}\OperatorTok{;} \VariableTok{self}\NormalTok{.resid\_drop }\OperatorTok{=}\NormalTok{ nn.Dropout(dropout)}
        \VariableTok{self}\NormalTok{.register\_buffer(}\StringTok{"mask"}\NormalTok{, torch.tril(torch.ones(BLOCK\_SIZE, BLOCK\_SIZE)).unsqueeze(}\DecValTok{0}\NormalTok{).unsqueeze(}\DecValTok{0}\NormalTok{))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):}
\NormalTok{        B,T,C }\OperatorTok{=}\NormalTok{ x.size()}
\NormalTok{        qkv }\OperatorTok{=} \VariableTok{self}\NormalTok{.qkv(x)}\OperatorTok{;}\NormalTok{ q,k,v }\OperatorTok{=}\NormalTok{ qkv.split(C, dim}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{        q }\OperatorTok{=}\NormalTok{ q.view(B,T,}\VariableTok{self}\NormalTok{.n\_head,}\VariableTok{self}\NormalTok{.d\_head).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{        k }\OperatorTok{=}\NormalTok{ k.view(B,T,}\VariableTok{self}\NormalTok{.n\_head,}\VariableTok{self}\NormalTok{.d\_head).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{        v }\OperatorTok{=}\NormalTok{ v.view(B,T,}\VariableTok{self}\NormalTok{.n\_head,}\VariableTok{self}\NormalTok{.d\_head).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{        att }\OperatorTok{=}\NormalTok{ (q }\OperatorTok{@}\NormalTok{ k.transpose(}\OperatorTok{{-}}\DecValTok{2}\NormalTok{,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)) }\OperatorTok{/}\NormalTok{ math.sqrt(}\VariableTok{self}\NormalTok{.d\_head)}
\NormalTok{        att }\OperatorTok{=}\NormalTok{ att.masked\_fill(}\VariableTok{self}\NormalTok{.mask[:,:,:T,:T]}\OperatorTok{==}\DecValTok{0}\NormalTok{, }\BuiltInTok{float}\NormalTok{(}\StringTok{"{-}inf"}\NormalTok{))}
\NormalTok{        att }\OperatorTok{=}\NormalTok{ F.softmax(att, dim}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}\OperatorTok{;}\NormalTok{ att }\OperatorTok{=} \VariableTok{self}\NormalTok{.attn\_drop(att)}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ att }\OperatorTok{@}\NormalTok{ v}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ y.transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{).contiguous().view(B,T,C)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.resid\_drop(}\VariableTok{self}\NormalTok{.proj(y))}

\KeywordTok{class}\NormalTok{ Block(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model: }\BuiltInTok{int}\NormalTok{, n\_head: }\BuiltInTok{int}\NormalTok{, d\_ff: }\BuiltInTok{int}\NormalTok{, dropout: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.ln1 }\OperatorTok{=}\NormalTok{ nn.LayerNorm(d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.attn }\OperatorTok{=}\NormalTok{ CausalSelfAttention(d\_model, n\_head, dropout)}
        \VariableTok{self}\NormalTok{.ln2 }\OperatorTok{=}\NormalTok{ nn.LayerNorm(d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.mlp  }\OperatorTok{=}\NormalTok{ nn.Sequential(}
\NormalTok{            nn.Linear(d\_model, d\_ff), nn.GELU(), nn.Dropout(dropout), nn.Linear(d\_ff, d\_model), nn.Dropout(dropout)}
\NormalTok{        )}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+} \VariableTok{self}\NormalTok{.attn(}\VariableTok{self}\NormalTok{.ln1(x))}
\NormalTok{        x }\OperatorTok{=}\NormalTok{ x }\OperatorTok{+} \VariableTok{self}\NormalTok{.mlp(}\VariableTok{self}\NormalTok{.ln2(x))}
        \ControlFlowTok{return}\NormalTok{ x}

\KeywordTok{class}\NormalTok{ TimeSeriesGPT(nn.Module):}
    \CommentTok{"""}
\CommentTok{    Real{-}valued sequence → regression (predict r\_1d at last step).}
\CommentTok{    """}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_features: }\BuiltInTok{int}\NormalTok{, d\_model}\OperatorTok{=}\DecValTok{64}\NormalTok{, n\_head}\OperatorTok{=}\DecValTok{2}\NormalTok{, n\_layer}\OperatorTok{=}\DecValTok{2}\NormalTok{, d\_ff}\OperatorTok{=}\DecValTok{128}\NormalTok{, ctx}\OperatorTok{=}\DecValTok{64}\NormalTok{, dropout}\OperatorTok{=}\FloatTok{0.0}\NormalTok{,}
\NormalTok{                 n\_tickers: }\BuiltInTok{int}\OperatorTok{|}\VariableTok{None}\OperatorTok{=}\VariableTok{None}\NormalTok{, d\_ticker: }\BuiltInTok{int}\OperatorTok{=}\DecValTok{0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.ctx }\OperatorTok{=}\NormalTok{ ctx}
        \VariableTok{self}\NormalTok{.proj }\OperatorTok{=}\NormalTok{ nn.Linear(in\_features, d\_model)        }\CommentTok{\# FEATURE PROJECTION}
        \VariableTok{self}\NormalTok{.pos  }\OperatorTok{=}\NormalTok{ nn.Embedding(ctx, d\_model)             }\CommentTok{\# POSITIONAL EMBEDDINGS}
        \VariableTok{self}\NormalTok{.id\_emb }\OperatorTok{=}\NormalTok{ nn.Embedding(n\_tickers, d\_ticker) }\ControlFlowTok{if}\NormalTok{ (n\_tickers }\KeywordTok{and}\NormalTok{ d\_ticker}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{) }\ControlFlowTok{else} \VariableTok{None}
\NormalTok{        augmented }\OperatorTok{=}\NormalTok{ d\_model }\OperatorTok{+}\NormalTok{ (d\_ticker }\ControlFlowTok{if} \VariableTok{self}\NormalTok{.id\_emb }\ControlFlowTok{else} \DecValTok{0}\NormalTok{)}
        \VariableTok{self}\NormalTok{.blocks }\OperatorTok{=}\NormalTok{ nn.ModuleList([Block(augmented, n\_head, d\_ff, dropout) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n\_layer)])}
        \VariableTok{self}\NormalTok{.ln }\OperatorTok{=}\NormalTok{ nn.LayerNorm(augmented)}
        \VariableTok{self}\NormalTok{.head }\OperatorTok{=}\NormalTok{ nn.Linear(augmented, }\DecValTok{1}\NormalTok{)                }\CommentTok{\# REGRESSION HEAD}

        \VariableTok{self}\NormalTok{.}\BuiltInTok{apply}\NormalTok{(}\VariableTok{self}\NormalTok{.\_init)}
    \KeywordTok{def}\NormalTok{ \_init(}\VariableTok{self}\NormalTok{, m):}
        \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(m, nn.Linear): nn.init.xavier\_uniform\_(m.weight)}\OperatorTok{;} 
        \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(m, nn.Embedding): nn.init.normal\_(m.weight, }\FloatTok{0.0}\NormalTok{, }\FloatTok{0.02}\NormalTok{)}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x, ticker\_ids}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
        \CommentTok{\# x: (B,T,F)}
\NormalTok{        B,T,F }\OperatorTok{=}\NormalTok{ x.size()}
\NormalTok{        pos }\OperatorTok{=}\NormalTok{ torch.arange(T, device}\OperatorTok{=}\NormalTok{x.device)}
\NormalTok{        h }\OperatorTok{=} \VariableTok{self}\NormalTok{.proj(x) }\OperatorTok{+} \VariableTok{self}\NormalTok{.pos(pos)[}\VariableTok{None}\NormalTok{,:,:]         }\CommentTok{\# (B,T,d\_model)}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.id\_emb }\KeywordTok{is} \KeywordTok{not} \VariableTok{None} \KeywordTok{and}\NormalTok{ ticker\_ids }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{            e }\OperatorTok{=} \VariableTok{self}\NormalTok{.id\_emb(ticker\_ids).unsqueeze(}\DecValTok{1}\NormalTok{).expand(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, T, }\OperatorTok{{-}}\DecValTok{1}\NormalTok{)   }\CommentTok{\# (B,T,d\_ticker)}
\NormalTok{            h }\OperatorTok{=}\NormalTok{ torch.cat([h, e], dim}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)                                 }\CommentTok{\# (B,T,d\_model+d\_ticker)}
        \ControlFlowTok{for}\NormalTok{ blk }\KeywordTok{in} \VariableTok{self}\NormalTok{.blocks: h }\OperatorTok{=}\NormalTok{ blk(h)}
\NormalTok{        h }\OperatorTok{=} \VariableTok{self}\NormalTok{.ln(h)}
\NormalTok{        yhat }\OperatorTok{=} \VariableTok{self}\NormalTok{.head(h[:,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,:]).squeeze(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)            }\CommentTok{\# use last time step’s hidden state}
        \ControlFlowTok{return}\NormalTok{ yhat}

\CommentTok{\# Instantiate tiny model (no ticker embedding for baseline)}
\NormalTok{D\_MODEL, N\_HEAD, N\_LAYER, D\_FF, DROPOUT }\OperatorTok{=} \DecValTok{64}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{128}\NormalTok{, }\FloatTok{0.0}
\NormalTok{model }\OperatorTok{=}\NormalTok{ TimeSeriesGPT(in\_features}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(FEATS), d\_model}\OperatorTok{=}\NormalTok{D\_MODEL, n\_head}\OperatorTok{=}\NormalTok{N\_HEAD,}
\NormalTok{                      n\_layer}\OperatorTok{=}\NormalTok{N\_LAYER, d\_ff}\OperatorTok{=}\NormalTok{D\_FF, ctx}\OperatorTok{=}\NormalTok{CTX, dropout}\OperatorTok{=}\NormalTok{DROPOUT,}
\NormalTok{                      n\_tickers}\OperatorTok{=}\VariableTok{None}\NormalTok{, d\_ticker}\OperatorTok{=}\DecValTok{0}\NormalTok{).to(device)}
\BuiltInTok{sum}\NormalTok{(p.numel() }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ model.parameters())}\OperatorTok{/}\FloatTok{1e6}\NormalTok{, device}
\end{Highlighting}
\end{Shaded}

\subsection{4) Train (MAE or Huber), early stop, checkpoint, and
metrics}\label{train-mae-or-huber-early-stop-checkpoint-and-metrics}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ torch.optim }\ImportTok{import}\NormalTok{ AdamW}
\ImportTok{from}\NormalTok{ torch.cuda.amp }\ImportTok{import}\NormalTok{ autocast, GradScaler}

\KeywordTok{def}\NormalTok{ mae\_t(y, yhat): }\ControlFlowTok{return}\NormalTok{ torch.mean(torch.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat))}
\KeywordTok{def}\NormalTok{ smape\_t(y, yhat, eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{): }\ControlFlowTok{return}\NormalTok{ torch.mean(}\FloatTok{2.0}\OperatorTok{*}\NormalTok{torch.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat)}\OperatorTok{/}\NormalTok{(torch.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{torch.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps))}

\NormalTok{USE\_HUBER }\OperatorTok{=} \VariableTok{True}
\NormalTok{huber\_delta }\OperatorTok{=} \FloatTok{0.01}
\NormalTok{huber }\OperatorTok{=}\NormalTok{ torch.nn.HuberLoss(delta}\OperatorTok{=}\NormalTok{huber\_delta, reduction}\OperatorTok{=}\StringTok{"mean"}\NormalTok{)}

\KeywordTok{def}\NormalTok{ train\_one\_epoch(model, loader, opt, scaler, device, use\_amp}\OperatorTok{=}\VariableTok{True}\NormalTok{):}
\NormalTok{    model.train()}\OperatorTok{;}\NormalTok{ tot}\OperatorTok{=}\FloatTok{0.0}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ xb, yb, \_ }\KeywordTok{in}\NormalTok{ loader:}
\NormalTok{        xb }\OperatorTok{=}\NormalTok{ xb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        yb }\OperatorTok{=}\NormalTok{ yb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        opt.zero\_grad(set\_to\_none}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ use\_amp }\KeywordTok{and}\NormalTok{ device.}\BuiltInTok{type}\OperatorTok{==}\StringTok{"cuda"}\NormalTok{:}
            \ControlFlowTok{with}\NormalTok{ autocast(dtype}\OperatorTok{=}\NormalTok{torch.float16):}
\NormalTok{                yhat }\OperatorTok{=}\NormalTok{ model(xb)}
\NormalTok{                loss }\OperatorTok{=}\NormalTok{ huber(yhat, yb) }\ControlFlowTok{if}\NormalTok{ USE\_HUBER }\ControlFlowTok{else}\NormalTok{ mae\_t(yb, yhat)}
\NormalTok{            scaler.scale(loss).backward()}\OperatorTok{;}\NormalTok{ scaler.step(opt)}\OperatorTok{;}\NormalTok{ scaler.update()}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            yhat }\OperatorTok{=}\NormalTok{ model(xb)}\OperatorTok{;}\NormalTok{ loss }\OperatorTok{=}\NormalTok{ huber(yhat, yb) }\ControlFlowTok{if}\NormalTok{ USE\_HUBER }\ControlFlowTok{else}\NormalTok{ mae\_t(yb, yhat)}
\NormalTok{            loss.backward()}\OperatorTok{;}\NormalTok{ opt.step()}
\NormalTok{        bs }\OperatorTok{=}\NormalTok{ xb.size(}\DecValTok{0}\NormalTok{)}\OperatorTok{;}\NormalTok{ tot }\OperatorTok{+=}\NormalTok{ loss.item()}\OperatorTok{*}\NormalTok{bs}\OperatorTok{;}\NormalTok{ n }\OperatorTok{+=}\NormalTok{ bs}
    \ControlFlowTok{return}\NormalTok{ tot}\OperatorTok{/}\BuiltInTok{max}\NormalTok{(n,}\DecValTok{1}\NormalTok{)}

\AttributeTok{@torch.no\_grad}\NormalTok{()}
\KeywordTok{def}\NormalTok{ evaluate(model, loader, device):}
\NormalTok{    model.}\BuiltInTok{eval}\NormalTok{()}\OperatorTok{;}\NormalTok{ m\_mae}\OperatorTok{=}\NormalTok{m\_smape}\OperatorTok{=}\FloatTok{0.0}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ xb, yb, \_ }\KeywordTok{in}\NormalTok{ loader:}
\NormalTok{        xb}\OperatorTok{=}\NormalTok{xb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        yb}\OperatorTok{=}\NormalTok{yb.to(device, non\_blocking}\OperatorTok{=}\VariableTok{True}\NormalTok{).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{        yhat }\OperatorTok{=}\NormalTok{ model(xb)}
\NormalTok{        bs}\OperatorTok{=}\NormalTok{xb.size(}\DecValTok{0}\NormalTok{)}
\NormalTok{        m\_mae }\OperatorTok{+=}\NormalTok{ mae\_t(yb, yhat).item()}\OperatorTok{*}\NormalTok{bs}
\NormalTok{        m\_smape }\OperatorTok{+=}\NormalTok{ smape\_t(yb, yhat).item()}\OperatorTok{*}\NormalTok{bs}
\NormalTok{        n}\OperatorTok{+=}\NormalTok{bs}
    \ControlFlowTok{return}\NormalTok{ \{}\StringTok{"mae"}\NormalTok{: m\_mae}\OperatorTok{/}\BuiltInTok{max}\NormalTok{(n,}\DecValTok{1}\NormalTok{), }\StringTok{"smape"}\NormalTok{: m\_smape}\OperatorTok{/}\BuiltInTok{max}\NormalTok{(n,}\DecValTok{1}\NormalTok{)\}}

\KeywordTok{def}\NormalTok{ fit(model, train\_loader, val\_loader, epochs}\OperatorTok{=}\DecValTok{12}\NormalTok{, lr}\OperatorTok{=}\FloatTok{2e{-}3}\NormalTok{, wd}\OperatorTok{=}\FloatTok{1e{-}5}\NormalTok{, patience}\OperatorTok{=}\DecValTok{3}\NormalTok{, use\_amp}\OperatorTok{=}\VariableTok{True}\NormalTok{):}
\NormalTok{    opt }\OperatorTok{=}\NormalTok{ AdamW(model.parameters(), lr}\OperatorTok{=}\NormalTok{lr, weight\_decay}\OperatorTok{=}\NormalTok{wd, betas}\OperatorTok{=}\NormalTok{(}\FloatTok{0.9}\NormalTok{,}\FloatTok{0.99}\NormalTok{))}
\NormalTok{    scaler }\OperatorTok{=}\NormalTok{ GradScaler(enabled}\OperatorTok{=}\NormalTok{(use\_amp }\KeywordTok{and}\NormalTok{ device.}\BuiltInTok{type}\OperatorTok{==}\StringTok{"cuda"}\NormalTok{))}
\NormalTok{    best}\OperatorTok{=}\BuiltInTok{float}\NormalTok{(}\StringTok{"inf"}\NormalTok{)}\OperatorTok{;}\NormalTok{ best\_ep}\OperatorTok{={-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ ckpt}\OperatorTok{=}\NormalTok{Path(}\StringTok{"models/tsgpt\_split1.pt"}\NormalTok{)}
\NormalTok{    history}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ ep }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, epochs}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{        tr }\OperatorTok{=}\NormalTok{ train\_one\_epoch(model, train\_loader, opt, scaler, device, use\_amp)}
\NormalTok{        val }\OperatorTok{=}\NormalTok{ evaluate(model, val\_loader, device)}
\NormalTok{        history.append(\{}\StringTok{"epoch"}\NormalTok{:ep,}\StringTok{"train\_mae"}\NormalTok{:tr,}\StringTok{"val\_mae"}\NormalTok{:val[}\StringTok{"mae"}\NormalTok{],}\StringTok{"val\_smape"}\NormalTok{:val[}\StringTok{"smape"}\NormalTok{]\})}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Epoch }\SpecialCharTok{\{}\NormalTok{ep}\SpecialCharTok{:02d\}}\SpecialStringTok{  train\_mae=}\SpecialCharTok{\{}\NormalTok{tr}\SpecialCharTok{:.5f\}}\SpecialStringTok{  val\_mae=}\SpecialCharTok{\{}\NormalTok{val[}\StringTok{\textquotesingle{}mae\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.5f\}}\SpecialStringTok{  val\_sMAPE=}\SpecialCharTok{\{}\NormalTok{val[}\StringTok{\textquotesingle{}smape\textquotesingle{}}\NormalTok{]}\SpecialCharTok{:.5f\}}\SpecialStringTok{"}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ val[}\StringTok{"mae"}\NormalTok{] }\OperatorTok{\textless{}}\NormalTok{ best }\OperatorTok{{-}} \FloatTok{1e{-}6}\NormalTok{:}
\NormalTok{            best }\OperatorTok{=}\NormalTok{ val[}\StringTok{"mae"}\NormalTok{]}\OperatorTok{;}\NormalTok{ best\_ep}\OperatorTok{=}\NormalTok{ep}
\NormalTok{            torch.save(\{}\StringTok{"model"}\NormalTok{: model.state\_dict(),}
                        \StringTok{"epoch"}\NormalTok{: ep,}
                        \StringTok{"config"}\NormalTok{: \{}\StringTok{"ctx"}\NormalTok{:CTX,}\StringTok{"d\_model"}\NormalTok{:D\_MODEL,}\StringTok{"n\_head"}\NormalTok{:N\_HEAD,}\StringTok{"n\_layer"}\NormalTok{:N\_LAYER,}
                                   \StringTok{"d\_ff"}\NormalTok{:D\_FF,}\StringTok{"dropout"}\NormalTok{:DROPOUT,}\StringTok{"feats"}\NormalTok{:FEATS,}\StringTok{"huber"}\NormalTok{:USE\_HUBER\}\}, ckpt)}
        \ControlFlowTok{elif}\NormalTok{ ep }\OperatorTok{{-}}\NormalTok{ best\_ep }\OperatorTok{\textgreater{}=}\NormalTok{ patience:}
            \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Early stopping at epoch }\SpecialCharTok{\{}\NormalTok{ep}\SpecialCharTok{\}}\SpecialStringTok{ (best }\SpecialCharTok{\{}\NormalTok{best}\SpecialCharTok{:.5f\}}\SpecialStringTok{ @ }\SpecialCharTok{\{}\NormalTok{best\_ep}\SpecialCharTok{\}}\SpecialStringTok{)"}\NormalTok{)}
            \ControlFlowTok{break}
    \ControlFlowTok{return}\NormalTok{ history, best, best\_ep, ckpt}

\NormalTok{history, best, best\_ep, ckpt }\OperatorTok{=}\NormalTok{ fit(model, train\_loader, val\_loader, epochs}\OperatorTok{=}\DecValTok{10}\NormalTok{, lr}\OperatorTok{=}\FloatTok{2e{-}3}\NormalTok{, wd}\OperatorTok{=}\FloatTok{1e{-}5}\NormalTok{, patience}\OperatorTok{=}\DecValTok{3}\NormalTok{, use\_amp}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Best val\_mae:"}\NormalTok{, best, }\StringTok{"| epoch:"}\NormalTok{, best\_ep, }\StringTok{"| saved:"}\NormalTok{, ckpt.exists())}

\CommentTok{\# Save metrics CSV \& quick plot data}
\NormalTok{pd.DataFrame(history).to\_csv(}\StringTok{"reports/tsgpt\_train\_curve.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{final }\OperatorTok{=}\NormalTok{ evaluate(model, val\_loader, device)}
\NormalTok{pd.DataFrame([\{}\StringTok{"split"}\NormalTok{:}\DecValTok{1}\NormalTok{,}\StringTok{"model"}\NormalTok{:}\StringTok{"tsgpt"}\NormalTok{,}\StringTok{"ctx"}\NormalTok{:CTX,}\StringTok{"val\_mae"}\NormalTok{:final[}\StringTok{"mae"}\NormalTok{],}\StringTok{"val\_smape"}\NormalTok{:final[}\StringTok{"smape"}\NormalTok{],}
               \StringTok{"params\_M"}\NormalTok{: }\BuiltInTok{round}\NormalTok{(}\BuiltInTok{sum}\NormalTok{(p.numel() }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ model.parameters())}\OperatorTok{/}\FloatTok{1e6}\NormalTok{, }\DecValTok{3}\NormalTok{),}\StringTok{"best\_epoch"}\NormalTok{:best\_ep\}]).to\_csv(}
    \StringTok{"reports/tsgpt\_split1\_metrics.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{final}
\end{Highlighting}
\end{Shaded}

\subsection{5) Quick loss plot (optional in‑class
visualization)}\label{quick-loss-plot-optional-inclass-visualization}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt, pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{cur }\OperatorTok{=}\NormalTok{ pd.read\_csv(}\StringTok{"reports/tsgpt\_train\_curve.csv"}\NormalTok{)}
\NormalTok{plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{6}\NormalTok{,}\FloatTok{3.5}\NormalTok{))}
\NormalTok{plt.plot(cur[}\StringTok{"epoch"}\NormalTok{], cur[}\StringTok{"train\_mae"}\NormalTok{], marker}\OperatorTok{=}\StringTok{"o"}\NormalTok{, label}\OperatorTok{=}\StringTok{"train MAE"}\NormalTok{)}
\NormalTok{plt.plot(cur[}\StringTok{"epoch"}\NormalTok{], cur[}\StringTok{"val\_mae"}\NormalTok{], marker}\OperatorTok{=}\StringTok{"s"}\NormalTok{, label}\OperatorTok{=}\StringTok{"val MAE"}\NormalTok{)}
\NormalTok{plt.xlabel(}\StringTok{"Epoch"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.ylabel(}\StringTok{"MAE"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.title(}\StringTok{"TS{-}GPT training"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.legend()}\OperatorTok{;}\NormalTok{ plt.tight\_layout()}
\NormalTok{plt.savefig(}\StringTok{"docs/figs/tsgpt\_train\_curve.png"}\NormalTok{, dpi}\OperatorTok{=}\DecValTok{160}\NormalTok{)}
\CommentTok{"Saved docs/figs/tsgpt\_train\_curve.png"}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min) --- emphasize these
points}\label{wrapup-10-min-emphasize-these-points-1}

\begin{itemize}
\tightlist
\item
  \textbf{Feature projection ≈ token embeddings} for real‑valued inputs;
  \textbf{positional embeddings + causal mask} stay the same.
\item
  Use \textbf{TRAIN‑fit scaler} to avoid leakage; keep the
  \textbf{rolling‑origin split} and \textbf{embargo} from previous
  sessions.
\item
  For noisy returns, \textbf{Huber/MAE} often stabilize training better
  than MSE.
\item
  Save checkpoints \& metrics; we'll ablate config choices
  (context/head/dropout) in the homework.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
23)}\label{homework-due-before-session-23}

\textbf{Goal:} Run a small ablation on \textbf{context length (32 vs
64)}, \textbf{dropout (0.0 vs 0.1)}, and \textbf{heads (2 vs 4)}, then
summarize results in one table and add a short discussion to your Quarto
report.

\subsection{\texorpdfstring{A. Training script:
\texttt{scripts/tsgpt\_train.py} (configurable
TS‑GPT)}{A. Training script: scripts/tsgpt\_train.py (configurable TS‑GPT)}}\label{a.-training-script-scriptstsgpt_train.py-configurable-tsgpt}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/usr/bin/env python}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ argparse, json, math, random}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd, torch, torch.nn }\ImportTok{as}\NormalTok{ nn}
\ImportTok{from}\NormalTok{ torch.nn }\ImportTok{import}\NormalTok{ functional }\ImportTok{as}\NormalTok{ F}
\ImportTok{from}\NormalTok{ torch.utils.data }\ImportTok{import}\NormalTok{ Dataset, DataLoader}

\CommentTok{\# {-}{-}{-}{-}{-}{-}{-}{-}{-} Dataset \& scaler (compact) {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{class}\NormalTok{ FeatureScaler:}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\VariableTok{None}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\VariableTok{None}
    \KeywordTok{def}\NormalTok{ fit(}\VariableTok{self}\NormalTok{, X): }\VariableTok{self}\NormalTok{.mean\_}\OperatorTok{=}\NormalTok{X.mean(}\DecValTok{0}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}\OperatorTok{;} \VariableTok{self}\NormalTok{.std\_}\OperatorTok{=}\NormalTok{X.std(}\DecValTok{0}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}\OperatorTok{+}\FloatTok{1e{-}8}\OperatorTok{;} \ControlFlowTok{return} \VariableTok{self}
    \KeywordTok{def}\NormalTok{ transform(}\VariableTok{self}\NormalTok{, X): }\ControlFlowTok{return}\NormalTok{ (X }\OperatorTok{{-}} \VariableTok{self}\NormalTok{.mean\_) }\OperatorTok{/} \VariableTok{self}\NormalTok{.std\_}

\KeywordTok{class}\NormalTok{ WindowedTS(Dataset):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, df, feats, T}\OperatorTok{=}\DecValTok{64}\NormalTok{, scaler}\OperatorTok{=}\VariableTok{None}\NormalTok{, ticker2id}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
        \VariableTok{self}\NormalTok{.T}\OperatorTok{=}\NormalTok{T}\OperatorTok{;} \VariableTok{self}\NormalTok{.feats}\OperatorTok{=}\BuiltInTok{list}\NormalTok{(feats)}\OperatorTok{;} \VariableTok{self}\NormalTok{.idx}\OperatorTok{=}\NormalTok{[]}\OperatorTok{;} \VariableTok{self}\NormalTok{.g}\OperatorTok{=}\NormalTok{\{\}}
        \ControlFlowTok{if}\NormalTok{ ticker2id }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{            cats}\OperatorTok{=}\NormalTok{df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{).cat.categories.tolist()}
            \VariableTok{self}\NormalTok{.ticker2id}\OperatorTok{=}\NormalTok{\{t:i }\ControlFlowTok{for}\NormalTok{ i,t }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(cats)\}}
        \ControlFlowTok{else}\NormalTok{: }\VariableTok{self}\NormalTok{.ticker2id}\OperatorTok{=}\BuiltInTok{dict}\NormalTok{(ticker2id)}
        \ControlFlowTok{for}\NormalTok{ tkr,g }\KeywordTok{in}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{            g}\OperatorTok{=}\NormalTok{g.sort\_values(}\StringTok{"date"}\NormalTok{).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{            X}\OperatorTok{=}\NormalTok{g[}\VariableTok{self}\NormalTok{.feats].to\_numpy(}\StringTok{"float32"}\NormalTok{)}\OperatorTok{;}\NormalTok{ y}\OperatorTok{=}\NormalTok{g[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy(}\StringTok{"float32"}\NormalTok{)}
            \ControlFlowTok{for}\NormalTok{ end }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(T}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,}\BuiltInTok{len}\NormalTok{(g)):}
                \ControlFlowTok{if}\NormalTok{ np.isfinite(y[end]): }\VariableTok{self}\NormalTok{.idx.append((}\BuiltInTok{str}\NormalTok{(tkr), end, }\VariableTok{self}\NormalTok{.ticker2id[}\BuiltInTok{str}\NormalTok{(tkr)]))}
            \VariableTok{self}\NormalTok{.g[}\BuiltInTok{str}\NormalTok{(tkr)]}\OperatorTok{=}\NormalTok{\{}\StringTok{"X"}\NormalTok{:X,}\StringTok{"y"}\NormalTok{:y\}}
        \VariableTok{self}\NormalTok{.scaler }\OperatorTok{=}\NormalTok{ scaler }\KeywordTok{or}\NormalTok{ FeatureScaler().fit(np.concatenate([}\VariableTok{self}\NormalTok{.g[t][}\StringTok{"X"}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in} \VariableTok{self}\NormalTok{.g],}\DecValTok{0}\NormalTok{))}
    \KeywordTok{def} \FunctionTok{\_\_len\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{): }\ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(}\VariableTok{self}\NormalTok{.idx)}
    \KeywordTok{def} \FunctionTok{\_\_getitem\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{,i):}
\NormalTok{        tkr,end,tid}\OperatorTok{=}\VariableTok{self}\NormalTok{.idx[i]}\OperatorTok{;}\NormalTok{ g}\OperatorTok{=}\VariableTok{self}\NormalTok{.g[tkr]}
\NormalTok{        X}\OperatorTok{=}\VariableTok{self}\NormalTok{.scaler.transform(g[}\StringTok{"X"}\NormalTok{][end}\OperatorTok{{-}}\VariableTok{self}\NormalTok{.T}\OperatorTok{+}\DecValTok{1}\NormalTok{:end}\OperatorTok{+}\DecValTok{1}\NormalTok{])}\OperatorTok{;}\NormalTok{ y}\OperatorTok{=}\NormalTok{g[}\StringTok{"y"}\NormalTok{][end]}
        \ControlFlowTok{return}\NormalTok{ torch.from\_numpy(X), torch.tensor(y, dtype}\OperatorTok{=}\NormalTok{torch.float32), torch.tensor(tid, dtype}\OperatorTok{=}\NormalTok{torch.}\BuiltInTok{long}\NormalTok{)}

\KeywordTok{def}\NormalTok{ make\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u}\OperatorTok{=}\NormalTok{np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ out}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        a,b}\OperatorTok{=}\NormalTok{u[}\DecValTok{0}\NormalTok{],u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val\_size}\OperatorTok{{-}}\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{        out.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+=}\NormalTok{step}
    \ControlFlowTok{return}\NormalTok{ out}

\CommentTok{\# {-}{-}{-}{-}{-}{-}{-}{-}{-} Model {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\KeywordTok{class}\NormalTok{ CausalSelfAttention(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model, n\_head, ctx, p}\OperatorTok{=}\FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}\OperatorTok{;} \ControlFlowTok{assert}\NormalTok{ d\_model }\OperatorTok{\%}\NormalTok{ n\_head }\OperatorTok{==} \DecValTok{0}
        \VariableTok{self}\NormalTok{.nh}\OperatorTok{=}\NormalTok{n\_head}\OperatorTok{;}\NormalTok{ dh}\OperatorTok{=}\NormalTok{d\_model}\OperatorTok{//}\NormalTok{n\_head}\OperatorTok{;} \VariableTok{self}\NormalTok{.dh}\OperatorTok{=}\NormalTok{dh}\OperatorTok{;} \VariableTok{self}\NormalTok{.ctx}\OperatorTok{=}\NormalTok{ctx}
        \VariableTok{self}\NormalTok{.qkv}\OperatorTok{=}\NormalTok{nn.Linear(d\_model,}\DecValTok{3}\OperatorTok{*}\NormalTok{d\_model,bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}\OperatorTok{;} \VariableTok{self}\NormalTok{.proj}\OperatorTok{=}\NormalTok{nn.Linear(d\_model,d\_model,bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \VariableTok{self}\NormalTok{.ad}\OperatorTok{=}\NormalTok{nn.Dropout(p)}\OperatorTok{;} \VariableTok{self}\NormalTok{.rd}\OperatorTok{=}\NormalTok{nn.Dropout(p)}
        \VariableTok{self}\NormalTok{.register\_buffer(}\StringTok{"mask"}\NormalTok{, torch.tril(torch.ones(ctx,ctx)).unsqueeze(}\DecValTok{0}\NormalTok{).unsqueeze(}\DecValTok{0}\NormalTok{))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{,x):}
\NormalTok{        B,T,C}\OperatorTok{=}\NormalTok{x.shape}\OperatorTok{;}\NormalTok{ qkv}\OperatorTok{=}\VariableTok{self}\NormalTok{.qkv(x)}\OperatorTok{;}\NormalTok{ q,k,v}\OperatorTok{=}\NormalTok{qkv.split(C,dim}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{        q}\OperatorTok{=}\NormalTok{q.view(B,T,}\VariableTok{self}\NormalTok{.nh,}\VariableTok{self}\NormalTok{.dh).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{;}\NormalTok{ k}\OperatorTok{=}\NormalTok{k.view(B,T,}\VariableTok{self}\NormalTok{.nh,}\VariableTok{self}\NormalTok{.dh).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{;}\NormalTok{ v}\OperatorTok{=}\NormalTok{v.view(B,T,}\VariableTok{self}\NormalTok{.nh,}\VariableTok{self}\NormalTok{.dh).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{        att}\OperatorTok{=}\NormalTok{(q }\OperatorTok{@}\NormalTok{ k.transpose(}\OperatorTok{{-}}\DecValTok{2}\NormalTok{,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{))}\OperatorTok{/}\NormalTok{math.sqrt(}\VariableTok{self}\NormalTok{.dh)}\OperatorTok{;}\NormalTok{ att}\OperatorTok{=}\NormalTok{att.masked\_fill(}\VariableTok{self}\NormalTok{.mask[:,:,:T,:T]}\OperatorTok{==}\DecValTok{0}\NormalTok{, }\BuiltInTok{float}\NormalTok{(}\StringTok{"{-}inf"}\NormalTok{))}
\NormalTok{        att}\OperatorTok{=}\NormalTok{att.softmax(dim}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}\OperatorTok{;}\NormalTok{ att}\OperatorTok{=}\VariableTok{self}\NormalTok{.ad(att)}\OperatorTok{;}\NormalTok{ y}\OperatorTok{=}\NormalTok{att }\OperatorTok{@}\NormalTok{ v}\OperatorTok{;}\NormalTok{ y}\OperatorTok{=}\NormalTok{y.transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{).contiguous().view(B,T,C)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.rd(}\VariableTok{self}\NormalTok{.proj(y))}

\KeywordTok{class}\NormalTok{ Block(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model, n\_head, ctx, d\_ff, p}\OperatorTok{=}\FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.ln1}\OperatorTok{=}\NormalTok{nn.LayerNorm(d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.att}\OperatorTok{=}\NormalTok{CausalSelfAttention(d\_model,n\_head,ctx,p)}
        \VariableTok{self}\NormalTok{.ln2}\OperatorTok{=}\NormalTok{nn.LayerNorm(d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.mlp}\OperatorTok{=}\NormalTok{nn.Sequential(nn.Linear(d\_model,d\_ff), nn.GELU(), nn.Dropout(p), nn.Linear(d\_ff,d\_model), nn.Dropout(p))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{,x): x}\OperatorTok{=}\NormalTok{x}\OperatorTok{+}\VariableTok{self}\NormalTok{.att(}\VariableTok{self}\NormalTok{.ln1(x))}\OperatorTok{;}\NormalTok{ x}\OperatorTok{=}\NormalTok{x}\OperatorTok{+}\VariableTok{self}\NormalTok{.mlp(}\VariableTok{self}\NormalTok{.ln2(x))}\OperatorTok{;} \ControlFlowTok{return}\NormalTok{ x}

\KeywordTok{class}\NormalTok{ TimeSeriesGPT(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_f, ctx}\OperatorTok{=}\DecValTok{64}\NormalTok{, d\_model}\OperatorTok{=}\DecValTok{64}\NormalTok{, n\_head}\OperatorTok{=}\DecValTok{2}\NormalTok{, n\_layer}\OperatorTok{=}\DecValTok{2}\NormalTok{, d\_ff}\OperatorTok{=}\DecValTok{128}\NormalTok{, p}\OperatorTok{=}\FloatTok{0.0}\NormalTok{, n\_tickers}\OperatorTok{=}\VariableTok{None}\NormalTok{, d\_ticker}\OperatorTok{=}\DecValTok{0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}\OperatorTok{;} \VariableTok{self}\NormalTok{.ctx}\OperatorTok{=}\NormalTok{ctx}
        \VariableTok{self}\NormalTok{.proj}\OperatorTok{=}\NormalTok{nn.Linear(in\_f,d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.pos}\OperatorTok{=}\NormalTok{nn.Embedding(ctx,d\_model)}
        \VariableTok{self}\NormalTok{.id\_emb}\OperatorTok{=}\NormalTok{nn.Embedding(n\_tickers,d\_ticker) }\ControlFlowTok{if}\NormalTok{ (n\_tickers }\KeywordTok{and}\NormalTok{ d\_ticker}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{) }\ControlFlowTok{else} \VariableTok{None}
\NormalTok{        aug}\OperatorTok{=}\NormalTok{d\_model}\OperatorTok{+}\NormalTok{(d\_ticker }\ControlFlowTok{if} \VariableTok{self}\NormalTok{.id\_emb }\ControlFlowTok{else} \DecValTok{0}\NormalTok{)}
        \VariableTok{self}\NormalTok{.blocks}\OperatorTok{=}\NormalTok{nn.ModuleList([Block(aug,n\_head,ctx,d\_ff,p) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n\_layer)])}
        \VariableTok{self}\NormalTok{.ln}\OperatorTok{=}\NormalTok{nn.LayerNorm(aug)}\OperatorTok{;} \VariableTok{self}\NormalTok{.head}\OperatorTok{=}\NormalTok{nn.Linear(aug,}\DecValTok{1}\NormalTok{)}
        \VariableTok{self}\NormalTok{.}\BuiltInTok{apply}\NormalTok{(}\VariableTok{self}\NormalTok{.\_init)}
    \KeywordTok{def}\NormalTok{ \_init(}\VariableTok{self}\NormalTok{,m):}
        \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(m,nn.Linear): nn.init.xavier\_uniform\_(m.weight)}
        \ControlFlowTok{if} \BuiltInTok{isinstance}\NormalTok{(m,nn.Embedding): nn.init.normal\_(m.weight,}\FloatTok{0.0}\NormalTok{,}\FloatTok{0.02}\NormalTok{)}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{,x,tid}\OperatorTok{=}\VariableTok{None}\NormalTok{):}
\NormalTok{        B,T,F}\OperatorTok{=}\NormalTok{x.shape}\OperatorTok{;}\NormalTok{ pos}\OperatorTok{=}\NormalTok{torch.arange(T, device}\OperatorTok{=}\NormalTok{x.device)}
\NormalTok{        h}\OperatorTok{=}\VariableTok{self}\NormalTok{.proj(x)}\OperatorTok{+}\VariableTok{self}\NormalTok{.pos(pos)[}\VariableTok{None}\NormalTok{,:,:]}
        \ControlFlowTok{if} \VariableTok{self}\NormalTok{.id\_emb }\KeywordTok{is} \KeywordTok{not} \VariableTok{None} \KeywordTok{and}\NormalTok{ tid }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:}
\NormalTok{            e}\OperatorTok{=}\VariableTok{self}\NormalTok{.id\_emb(tid).unsqueeze(}\DecValTok{1}\NormalTok{).expand(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,T,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}\OperatorTok{;}\NormalTok{ h}\OperatorTok{=}\NormalTok{torch.cat([h,e],dim}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}
        \ControlFlowTok{for}\NormalTok{ blk }\KeywordTok{in} \VariableTok{self}\NormalTok{.blocks: h}\OperatorTok{=}\NormalTok{blk(h)}
\NormalTok{        h}\OperatorTok{=}\VariableTok{self}\NormalTok{.ln(h)}\OperatorTok{;} \ControlFlowTok{return} \VariableTok{self}\NormalTok{.head(h[:,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,:]).squeeze(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    ap}\OperatorTok{=}\NormalTok{argparse.ArgumentParser()}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}features"}\NormalTok{, default}\OperatorTok{=}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}context"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{64}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}d\_model"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{64}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}n\_head"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}n\_layer"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}d\_ff"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{128}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}dropout"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{float}\NormalTok{, default}\OperatorTok{=}\FloatTok{0.0}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}epochs"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{10}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}batch"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{256}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}lr"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{float}\NormalTok{, default}\OperatorTok{=}\FloatTok{2e{-}3}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}patience"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}tickers"}\NormalTok{, }\BuiltInTok{type}\OperatorTok{=}\BuiltInTok{int}\NormalTok{, default}\OperatorTok{=}\DecValTok{10}\NormalTok{)}
\NormalTok{    ap.add\_argument(}\StringTok{"{-}{-}out"}\NormalTok{, default}\OperatorTok{=}\StringTok{"reports/tsgpt\_metrics.csv"}\NormalTok{)}
\NormalTok{    args}\OperatorTok{=}\NormalTok{ap.parse\_args()}

    \CommentTok{\# Load data}
\NormalTok{    f\_static }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"data/processed/features\_v1\_static.parquet"}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(f\_static) }\ControlFlowTok{if}\NormalTok{ f\_static.exists() }\ControlFlowTok{else}\NormalTok{ pd.read\_parquet(args.features)}
\NormalTok{    df}\OperatorTok{=}\NormalTok{df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}\OperatorTok{;}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{=}\NormalTok{df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
\NormalTok{    cand}\OperatorTok{=}\NormalTok{[}\StringTok{"log\_return"}\NormalTok{,}\StringTok{"lag1"}\NormalTok{,}\StringTok{"lag2"}\NormalTok{,}\StringTok{"lag3"}\NormalTok{,}\StringTok{"zscore\_20"}\NormalTok{,}\StringTok{"roll\_std\_20"}\NormalTok{,}\StringTok{"weekday"}\NormalTok{,}\StringTok{"month"}\NormalTok{]}
\NormalTok{    feats}\OperatorTok{=}\NormalTok{[c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ cand }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ df.columns]}\OperatorTok{;} \ControlFlowTok{assert} \StringTok{"r\_1d"} \KeywordTok{in}\NormalTok{ df.columns }\KeywordTok{and}\NormalTok{ feats}
\NormalTok{    keep}\OperatorTok{=}\NormalTok{df[}\StringTok{"ticker"}\NormalTok{].cat.categories.tolist()[:args.tickers]}\OperatorTok{;}\NormalTok{ df}\OperatorTok{=}\NormalTok{df[df[}\StringTok{"ticker"}\NormalTok{].isin(keep)].copy()}

    \CommentTok{\# Split}
    \KeywordTok{def}\NormalTok{ splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{        u}\OperatorTok{=}\NormalTok{np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{=}\NormalTok{train\_min}\OperatorTok{{-}}\DecValTok{1}\OperatorTok{;}\NormalTok{ out}\OperatorTok{=}\NormalTok{[]}
        \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
            \ControlFlowTok{if}\NormalTok{ i}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{            a,b}\OperatorTok{=}\NormalTok{u[}\DecValTok{0}\NormalTok{],u[i]}\OperatorTok{;}\NormalTok{ vs}\OperatorTok{=}\NormalTok{i}\OperatorTok{+}\NormalTok{embargo}\OperatorTok{+}\DecValTok{1}\OperatorTok{;}\NormalTok{ ve}\OperatorTok{=}\NormalTok{vs}\OperatorTok{+}\NormalTok{val}\OperatorTok{{-}}\DecValTok{1}
            \ControlFlowTok{if}\NormalTok{ ve}\OperatorTok{\textgreater{}=}\BuiltInTok{len}\NormalTok{(u): }\ControlFlowTok{break}
\NormalTok{            out.append((a,b,u[vs],u[ve]))}\OperatorTok{;}\NormalTok{ i}\OperatorTok{+=}\NormalTok{step}
        \ControlFlowTok{return}\NormalTok{ out}
\NormalTok{    a,b,c,d }\OperatorTok{=}\NormalTok{ splits(df[}\StringTok{"date"}\NormalTok{])[}\DecValTok{0}\NormalTok{]}
\NormalTok{    tr}\OperatorTok{=}\NormalTok{df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{a)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{b)]}\OperatorTok{;}\NormalTok{ va}\OperatorTok{=}\NormalTok{df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{c)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{d)]}

    \CommentTok{\# Datasets}
\NormalTok{    tr\_ds}\OperatorTok{=}\NormalTok{WindowedTS(tr, feats, T}\OperatorTok{=}\NormalTok{args.context)}\OperatorTok{;}\NormalTok{ va\_ds}\OperatorTok{=}\NormalTok{WindowedTS(va, feats, T}\OperatorTok{=}\NormalTok{args.context, scaler}\OperatorTok{=}\NormalTok{tr\_ds.scaler, ticker2id}\OperatorTok{=}\NormalTok{tr\_ds.ticker2id)}
\NormalTok{    pin}\OperatorTok{=}\NormalTok{torch.cuda.is\_available()}
    \KeywordTok{def}\NormalTok{ \_seed(\_): ws}\OperatorTok{=}\NormalTok{torch.initial\_seed()}\OperatorTok{\%}\DecValTok{2}\OperatorTok{**}\DecValTok{32}\OperatorTok{;}\NormalTok{ np.random.seed(ws)}\OperatorTok{;}\NormalTok{ random.seed(ws)}
\NormalTok{    g}\OperatorTok{=}\NormalTok{torch.Generator()}\OperatorTok{;}\NormalTok{ g.manual\_seed(}\DecValTok{42}\NormalTok{)}
\NormalTok{    tr\_ld}\OperatorTok{=}\NormalTok{DataLoader(tr\_ds, batch\_size}\OperatorTok{=}\NormalTok{args.batch, shuffle}\OperatorTok{=}\VariableTok{True}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{True}\NormalTok{, num\_workers}\OperatorTok{=}\DecValTok{2}\NormalTok{, pin\_memory}\OperatorTok{=}\NormalTok{pin, worker\_init\_fn}\OperatorTok{=}\NormalTok{\_seed, generator}\OperatorTok{=}\NormalTok{g)}
\NormalTok{    va\_ld}\OperatorTok{=}\NormalTok{DataLoader(va\_ds, batch\_size}\OperatorTok{=}\NormalTok{args.batch, shuffle}\OperatorTok{=}\VariableTok{False}\NormalTok{, drop\_last}\OperatorTok{=}\VariableTok{False}\NormalTok{, num\_workers}\OperatorTok{=}\DecValTok{2}\NormalTok{, pin\_memory}\OperatorTok{=}\NormalTok{pin, worker\_init\_fn}\OperatorTok{=}\NormalTok{\_seed)}

\NormalTok{    device}\OperatorTok{=}\NormalTok{torch.device(}\StringTok{"cuda"} \ControlFlowTok{if}\NormalTok{ torch.cuda.is\_available() }\ControlFlowTok{else} \StringTok{"cpu"}\NormalTok{)}
\NormalTok{    net}\OperatorTok{=}\NormalTok{TimeSeriesGPT(}\BuiltInTok{len}\NormalTok{(feats), ctx}\OperatorTok{=}\NormalTok{args.context, d\_model}\OperatorTok{=}\NormalTok{args.d\_model, n\_head}\OperatorTok{=}\NormalTok{args.n\_head, n\_layer}\OperatorTok{=}\NormalTok{args.n\_layer, d\_ff}\OperatorTok{=}\NormalTok{args.d\_ff, p}\OperatorTok{=}\NormalTok{args.dropout).to(device)}
\NormalTok{    opt}\OperatorTok{=}\NormalTok{torch.optim.AdamW(net.parameters(), lr}\OperatorTok{=}\NormalTok{args.lr, weight\_decay}\OperatorTok{=}\FloatTok{1e{-}5}\NormalTok{, betas}\OperatorTok{=}\NormalTok{(}\FloatTok{0.9}\NormalTok{,}\FloatTok{0.99}\NormalTok{))}
\NormalTok{    huber}\OperatorTok{=}\NormalTok{torch.nn.HuberLoss(delta}\OperatorTok{=}\FloatTok{0.01}\NormalTok{)}

    \KeywordTok{def}\NormalTok{ mae\_t(y,yhat): }\ControlFlowTok{return}\NormalTok{ torch.mean(torch.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat))}
    \KeywordTok{def}\NormalTok{ smape\_t(y,yhat,eps}\OperatorTok{=}\FloatTok{1e{-}8}\NormalTok{): }\ControlFlowTok{return}\NormalTok{ torch.mean(}\DecValTok{2}\OperatorTok{*}\NormalTok{torch.}\BuiltInTok{abs}\NormalTok{(y}\OperatorTok{{-}}\NormalTok{yhat)}\OperatorTok{/}\NormalTok{(torch.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{torch.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps))}

\NormalTok{    best}\OperatorTok{=}\FloatTok{1e9}\OperatorTok{;}\NormalTok{ best\_ep}\OperatorTok{=}\DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ ep }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\DecValTok{1}\NormalTok{, args.epochs}\OperatorTok{+}\DecValTok{1}\NormalTok{):}
\NormalTok{        net.train()}
        \ControlFlowTok{for}\NormalTok{ xb,yb,\_ }\KeywordTok{in}\NormalTok{ tr\_ld:}
\NormalTok{            xb}\OperatorTok{=}\NormalTok{xb.to(device).}\BuiltInTok{float}\NormalTok{()}\OperatorTok{;}\NormalTok{ yb}\OperatorTok{=}\NormalTok{yb.to(device).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{            opt.zero\_grad(set\_to\_none}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{            yhat}\OperatorTok{=}\NormalTok{net(xb)}\OperatorTok{;}\NormalTok{ loss}\OperatorTok{=}\NormalTok{huber(yhat,yb)}\OperatorTok{;}\NormalTok{ loss.backward()}
\NormalTok{            torch.nn.utils.clip\_grad\_norm\_(net.parameters(), }\FloatTok{1.0}\NormalTok{)}
\NormalTok{            opt.step()}
        \CommentTok{\# val}
\NormalTok{        net.}\BuiltInTok{eval}\NormalTok{()}\OperatorTok{;}\NormalTok{ m\_mae}\OperatorTok{=}\NormalTok{m\_smape}\OperatorTok{=}\FloatTok{0.0}\OperatorTok{;}\NormalTok{ n}\OperatorTok{=}\DecValTok{0}
        \ControlFlowTok{with}\NormalTok{ torch.no\_grad():}
            \ControlFlowTok{for}\NormalTok{ xb,yb,\_ }\KeywordTok{in}\NormalTok{ va\_ld:}
\NormalTok{                xb}\OperatorTok{=}\NormalTok{xb.to(device).}\BuiltInTok{float}\NormalTok{()}\OperatorTok{;}\NormalTok{ yb}\OperatorTok{=}\NormalTok{yb.to(device).}\BuiltInTok{float}\NormalTok{()}
\NormalTok{                yhat}\OperatorTok{=}\NormalTok{net(xb)}\OperatorTok{;}\NormalTok{ bs}\OperatorTok{=}\NormalTok{xb.size(}\DecValTok{0}\NormalTok{)}
\NormalTok{                m\_mae }\OperatorTok{+=}\NormalTok{ mae\_t(yb,yhat).item()}\OperatorTok{*}\NormalTok{bs}\OperatorTok{;}\NormalTok{ m\_smape }\OperatorTok{+=}\NormalTok{ smape\_t(yb,yhat).item()}\OperatorTok{*}\NormalTok{bs}\OperatorTok{;}\NormalTok{ n}\OperatorTok{+=}\NormalTok{bs}
\NormalTok{        val\_mae}\OperatorTok{=}\NormalTok{m\_mae}\OperatorTok{/}\NormalTok{n}\OperatorTok{;}\NormalTok{ val\_smape}\OperatorTok{=}\NormalTok{m\_smape}\OperatorTok{/}\NormalTok{n}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Epoch }\SpecialCharTok{\{}\NormalTok{ep}\SpecialCharTok{:02d\}}\SpecialStringTok{  val\_mae=}\SpecialCharTok{\{}\NormalTok{val\_mae}\SpecialCharTok{:.5f\}}\SpecialStringTok{  val\_sMAPE=}\SpecialCharTok{\{}\NormalTok{val\_smape}\SpecialCharTok{:.5f\}}\SpecialStringTok{"}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ val\_mae }\OperatorTok{\textless{}}\NormalTok{ best}\OperatorTok{{-}}\FloatTok{1e{-}6}\NormalTok{: best}\OperatorTok{=}\NormalTok{val\_mae}\OperatorTok{;}\NormalTok{ best\_ep}\OperatorTok{=}\NormalTok{ep}
        \ControlFlowTok{elif}\NormalTok{ ep}\OperatorTok{{-}}\NormalTok{best\_ep }\OperatorTok{\textgreater{}=}\NormalTok{ args.patience: }\ControlFlowTok{break}

\NormalTok{    Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    pd.DataFrame([\{}\StringTok{"model"}\NormalTok{:}\StringTok{"tsgpt"}\NormalTok{,}\StringTok{"ctx"}\NormalTok{:args.context,}\StringTok{"d\_model"}\NormalTok{:args.d\_model,}\StringTok{"n\_head"}\NormalTok{:args.n\_head,}
                   \StringTok{"n\_layer"}\NormalTok{:args.n\_layer,}\StringTok{"dropout"}\NormalTok{:args.dropout,}\StringTok{"val\_mae"}\NormalTok{:best,}\StringTok{"best\_epoch"}\NormalTok{:best\_ep\}]).to\_csv(args.out, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, args.out)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Run examples:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/tsgpt\_train.py}
\ExtensionTok{python}\NormalTok{ scripts/tsgpt\_train.py }\AttributeTok{{-}{-}context}\NormalTok{ 32 }\AttributeTok{{-}{-}dropout}\NormalTok{ 0.0 }\AttributeTok{{-}{-}n\_head}\NormalTok{ 2 }\AttributeTok{{-}{-}n\_layer}\NormalTok{ 2 }\AttributeTok{{-}{-}out}\NormalTok{ reports/tsgpt\_run\_a.csv}
\ExtensionTok{python}\NormalTok{ scripts/tsgpt\_train.py }\AttributeTok{{-}{-}context}\NormalTok{ 64 }\AttributeTok{{-}{-}dropout}\NormalTok{ 0.1 }\AttributeTok{{-}{-}n\_head}\NormalTok{ 4 }\AttributeTok{{-}{-}n\_layer}\NormalTok{ 2 }\AttributeTok{{-}{-}out}\NormalTok{ reports/tsgpt\_run\_b.csv}
\end{Highlighting}
\end{Shaded}

\subsection{B. Summarize ablations into one
table}\label{b.-summarize-ablations-into-one-table}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, glob}
\NormalTok{paths }\OperatorTok{=}\NormalTok{ glob.glob(}\StringTok{"reports/tsgpt\_run\_*.csv"}\NormalTok{)}
\NormalTok{rows }\OperatorTok{=}\NormalTok{ []}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ paths:}
    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        r }\OperatorTok{=}\NormalTok{ pd.read\_csv(p).iloc[}\DecValTok{0}\NormalTok{].to\_dict()}\OperatorTok{;}\NormalTok{ r[}\StringTok{"run"}\NormalTok{] }\OperatorTok{=}\NormalTok{ p}\OperatorTok{;}\NormalTok{ rows.append(r)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Skip"}\NormalTok{, p, e)}
\NormalTok{ab }\OperatorTok{=}\NormalTok{ pd.DataFrame(rows).sort\_values(}\StringTok{"val\_mae"}\NormalTok{)}
\NormalTok{ab.to\_csv(}\StringTok{"reports/tsgpt\_ablation\_summary.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{ab.head(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{C. Add to Quarto report (one
section)}\label{c.-add-to-quarto-report-one-section}

In \texttt{reports/eda.qmd} (or \texttt{reports/ts\_gpt.qmd}), add:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# Tiny Transformer for Time Series}

\NormalTok{**Split 1** results for TS‑GPT (sequence‑to‑one regression).}

\NormalTok{::: \{.cell execution\_count=1\}}
\InformationTok{\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{}\textasciigrave{} \{.python .cell{-}code\}}
\InformationTok{import pandas as pd}
\InformationTok{print(pd.read\_csv("reports/tsgpt\_split1\_metrics.csv"))}
\InformationTok{print(pd.read\_csv("reports/tsgpt\_ablation\_summary.csv").sort\_values("val\_mae").head(8))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \pandocbounded{\includegraphics[keepaspectratio]{../docs/figs/tsgpt_train_curve.png}}

}

\caption{TS‑GPT training curve}

\end{figure}%

\begin{verbatim}

### D. Minimal tests (protect causal mask & window shapes)
```python
# tests/test_tsgpt_mask_and_shapes.py
import torch, pandas as pd
from pathlib import Path

def test_mask_is_causal():
    from scripts.tsgpt_train import TimeSeriesGPT
    m = TimeSeriesGPT(in_f=4, ctx=16, d_model=32, n_head=2, n_layer=1, d_ff=64, p=0.0)
    att = [b.att for b in m.blocks][0]
    M = att.mask[0,0]
    assert torch.all(M.triu(diagonal=1)==0)

def test_window_shape():
    df = pd.read_parquet("data/processed/features_v1.parquet").sort_values(["ticker","date"])
    feats = [c for c in ["log_return","lag1","lag2","lag3"] if c in df.columns]
    assert feats
    from scripts.tsgpt_train import WindowedTS, make_splits
    a,b,c,d = make_splits(df["date"])[0]
    ds = WindowedTS(df[(df["date"]>=a)&(df["date"]<=b)], feats, T=32)
    X, y, tid = ds[0]
    assert X.shape == (32, len(feats))
    assert torch.isfinite(torch.tensor(y)).item() == 1
\end{verbatim}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}k}\NormalTok{ tsgpt\_mask\_and\_shapes}
\end{Highlighting}
\end{Shaded}

:::

\subsection{E. (Optional) Makefile
targets}\label{e.-optional-makefile-targets}

Append to \texttt{Makefile}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.PHONY: train{-}tsgpt ablate{-}tsgpt}
\NormalTok{train{-}tsgpt: \#\# Train TS{-}GPT on split 1 (tiny config)}
\NormalTok{\textbackslash{}tpython scripts/tsgpt\_train.py {-}{-}context 64 {-}{-}n\_head 2 {-}{-}n\_layer 2 {-}{-}dropout 0.0 {-}{-}out reports/tsgpt\_run\_base.csv}

\NormalTok{ablate{-}tsgpt: \#\# Run two small ablations}
\NormalTok{\textbackslash{}tpython scripts/tsgpt\_train.py {-}{-}context 32 {-}{-}n\_head 2 {-}{-}dropout 0.0 {-}{-}out reports/tsgpt\_run\_a.csv}
\NormalTok{\textbackslash{}tpython scripts/tsgpt\_train.py {-}{-}context 64 {-}{-}n\_head 4 {-}{-}dropout 0.1 {-}{-}out reports/tsgpt\_run\_b.csv}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-11}

\begin{itemize}
\tightlist
\item
  Ensure at least \texttt{log\_return}, \texttt{r\_1d}, and a few lags
  are present, or rely on fallback generation.
\item
  Dry‑run the tiny config on CPU or GPU; confirm val MAE decreases in
  \textless5 minutes.
\item
  Prepare one slide mapping ``char embedding'' → ``feature projection''.
\end{itemize}

\section{Emphasize while teaching}\label{emphasize-while-teaching-11}

\begin{itemize}
\tightlist
\item
  \textbf{Causality and alignment} are unchanged from char‑GPT; only the
  \textbf{input embedding} changes.
\item
  \textbf{Scaling on TRAIN only}; never refit on VAL/TEST.
\item
  Report at least \textbf{MAE and sMAPE}; add calibration by regime
  later if desired.
\end{itemize}

\section{Grading (pass/revise)}\label{grading-passrevise-10}

\begin{itemize}
\tightlist
\item
  \texttt{models/tsgpt\_split1.pt} and
  \texttt{reports/tsgpt\_split1\_metrics.csv} exist.
\item
  Students ran at least \textbf{two ablations} and wrote
  \texttt{reports/tsgpt\_ablation\_summary.csv}.
\item
  Tests pass (\texttt{test\_tsgpt\_mask\_and\_shapes}).
\item
  Quarto report updated with numbers and the training curve.
\end{itemize}

You now have a \textbf{tiny GPT adapted to time series}, ready to be
compared to your GRU/LSTM baselines and incorporated into the unified
multi‑asset pipeline.

\bookmarksetup{startatroot}

\chapter{Session 23 --- Packaging \& CLI
(Typer)}\label{session-23-packaging-cli-typer}

Below is a complete lecture package for \textbf{Session 23 --- Packaging
\& CLI (Typer)} (75 minutes). It includes a timed agenda, slide talking
points, a \textbf{Colab‑friendly in‑class lab with copy‑paste code}, and
\textbf{homework with copy‑paste code}. You'll package your repo into a
proper Python project using a \texttt{src/} layout, add a minimal
\textbf{Typer} CLI, and wire it to score models over a date range using
your existing \textbf{features Parquet} and saved checkpoints.

\begin{quote}
\textbf{Assumptions} • Students use Colab (Drive mounted). • Repo
already has \texttt{data/processed/features\_v1(.parquet)},
\texttt{data/processed/returns.parquet}; and (ideally)
\texttt{models/gru\_split1.pt} and/or \texttt{models/tsgpt\_split1.pt}
from Sessions 19 \& 22. • If checkpoints are missing, the CLI
\textbf{falls back} to baselines (\texttt{naive}, \texttt{lin\_lags}). •
This is \textbf{educational}, not trading advice.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 23 --- Packaging \& CLI (Typer) (75
min)}\label{session-23-packaging-cli-typer-75-min}

\subsection{Learning goals}\label{learning-goals-22}

By the end, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Convert a research repo into an \textbf{installable package} with a
  \texttt{src/} layout and \texttt{pyproject.toml}.
\item
  Create a \textbf{Typer} CLI (\texttt{python\ -m\ projectname.cli\ …})
  that reads config, loads data, and \textbf{scores} a model over a date
  range.
\item
  Centralize config in \textbf{YAML}, keep paths tidy, and write results
  to \texttt{reports/}.
\item
  Run a \textbf{fresh‑clone} smoke test:
  \texttt{make\ env\ \&\&\ pip\ install\ -e\ .\ \&\&\ python\ -m\ projectname.cli\ score\ …}.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-20}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: why package? \texttt{src/} layout;
  \texttt{pyproject.toml}; editable installs
  (\texttt{pip\ install\ -e\ .}).
\item
  \textbf{(10 min)} Slides: CLI ergonomics with \textbf{Typer}; single
  binary vs \texttt{python\ -m}; structured logging \& exit codes.
\item
  \textbf{(40 min)} \textbf{In‑class lab}: add package skeleton →
  \texttt{pyproject.toml} → config YAML → CLI with \texttt{score} and
  \texttt{split-info} → run end‑to‑end.
\item
  \textbf{(15 min)} Wrap‑up, Makefile targets, homework brief.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides --- talking points (paste into
deck)}\label{slides-talking-points-paste-into-deck}

\textbf{Why package your project?}

\begin{itemize}
\tightlist
\item
  Import your code anywhere (\texttt{import\ projectname…}) → reliable
  relative imports, easier testing/CI, cleaner notebooks.
\item
  ``\texttt{src/} layout'' prevents accidental imports from the working
  dir; forces \textbf{installed} code to be used.
\end{itemize}

\textbf{\texttt{pyproject.toml} essentials}

\begin{itemize}
\tightlist
\item
  \texttt{{[}build-system{]}} selects backend (\texttt{setuptools},
  \texttt{hatchling}, \ldots).
\item
  \texttt{{[}project{]}} declares name, version, dependencies.
\item
  Use \textbf{editable install} during research:
  \texttt{pip\ install\ -e\ .{[}dev{]}}.
\end{itemize}

\textbf{Typer for CLIs}

\begin{itemize}
\tightlist
\item
  Declarative options \& automatic help (\texttt{-\/-help}).
\item
  Compose commands: \texttt{score}, \texttt{split-info},
  \texttt{show-config}.
\item
  Return \textbf{non‑zero} exit codes on errors; don't hide failures.
\end{itemize}

\textbf{Config in YAML}

\begin{itemize}
\tightlist
\item
  One \texttt{config/config.yaml} to centralize paths, features, split
  params.
\item
  Parse with \texttt{yaml.safe\_load}; add a tiny typed wrapper.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class Lab (40 min)}\label{inclass-lab-40-min}

\begin{quote}
Run each block as its own cell (or file creation step). Update
\texttt{REPO\_NAME} as needed.
\end{quote}

\subsection{0) Mount Drive \& cd to repo}\label{mount-drive-cd-to-repo}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}  \CommentTok{\# \textless{}{-} change}
\NormalTok{BASE\_DIR  }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR  }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, sys, platform}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd(), }\StringTok{"| Python:"}\NormalTok{, sys.version.split()[}\DecValTok{0}\NormalTok{], }\StringTok{"| OS:"}\NormalTok{, platform.system())}

\CommentTok{\# Create standard dirs if missing}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"src/projectname"}\NormalTok{, }\StringTok{"src/projectname/data"}\NormalTok{, }\StringTok{"src/projectname/features"}\NormalTok{,}
          \StringTok{"src/projectname/models"}\NormalTok{, }\StringTok{"src/projectname/utils"}\NormalTok{, }\StringTok{"config"}\NormalTok{,}
          \StringTok{"reports"}\NormalTok{, }\StringTok{"models"}\NormalTok{, }\StringTok{"tests"}\NormalTok{, }\StringTok{"docs/figs"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{1) Create \texttt{pyproject.toml} (packaging
metadata)}{1) Create pyproject.toml (packaging metadata)}}\label{create-pyproject.toml-packaging-metadata}

\begin{quote}
\textbf{Tip}: We keep \texttt{requirements.txt} for now, but the package
will also declare dependencies.
\end{quote}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# pyproject.toml  (place at repo root)}
\KeywordTok{[build{-}system]}
\DataTypeTok{requires} \OperatorTok{=} \OperatorTok{[}\StringTok{"setuptools\textgreater{}=68"}\OperatorTok{,} \StringTok{"wheel"}\OperatorTok{]}
\DataTypeTok{build{-}backend} \OperatorTok{=} \StringTok{"setuptools.build\_meta"}

\KeywordTok{[project]}
\DataTypeTok{name} \OperatorTok{=} \StringTok{"projectname"}                \CommentTok{\# rename if you like; keep it simple \& lowercase}
\DataTypeTok{version} \OperatorTok{=} \StringTok{"0.1.0"}
\DataTypeTok{description} \OperatorTok{=} \StringTok{"Unified stock forecasting pipeline (teaching)"}
\DataTypeTok{readme} \OperatorTok{=} \StringTok{"README.md"}
\DataTypeTok{requires{-}python} \OperatorTok{=} \StringTok{"\textgreater{}=3.10"}
\DataTypeTok{dependencies} \OperatorTok{=} \OperatorTok{[}
  \StringTok{"pandas\textgreater{}=2.1"}\OperatorTok{,}
  \StringTok{"numpy\textgreater{}=1.25"}\OperatorTok{,}
  \StringTok{"pyarrow\textgreater{}=14"}\OperatorTok{,}
  \StringTok{"typer[all]\textgreater{}=0.9"}\OperatorTok{,}
  \StringTok{"rich\textgreater{}=13.3"}\OperatorTok{,}
  \StringTok{"PyYAML\textgreater{}=6.0"}\OperatorTok{,}
  \StringTok{"scikit{-}learn\textgreater{}=1.3"}\OperatorTok{,}
  \StringTok{"torch\textgreater{}=2.1"}\OperatorTok{,}
\OperatorTok{]}
\KeywordTok{[project.optional{-}dependencies]}
\DataTypeTok{dev} \OperatorTok{=} \OperatorTok{[}\StringTok{"pytest\textgreater{}=7"}\OperatorTok{,} \StringTok{"pytest{-}cov\textgreater{}=4"}\OperatorTok{]}

\KeywordTok{[tool.setuptools]}
\DataTypeTok{package{-}dir} \OperatorTok{=} \OperatorTok{\{}\DataTypeTok{""}\OperatorTok{ =} \StringTok{"src"}\OperatorTok{\}}

\KeywordTok{[tool.setuptools.packages.find]}
\DataTypeTok{where} \OperatorTok{=} \OperatorTok{[}\StringTok{"src"}\OperatorTok{]}

\KeywordTok{[project.scripts]}
\CommentTok{\# Optional console entrypoint (\textasciigrave{}projectname\textasciigrave{}); we also support \textasciigrave{}python {-}m projectname.cli\textasciigrave{}}
\DataTypeTok{projectname} \OperatorTok{=} \StringTok{"projectname.cli:main"}
\end{Highlighting}
\end{Shaded}

\subsection{2) Add a default config
YAML}\label{add-a-default-config-yaml}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# config/config.yaml}
\FunctionTok{data}\KeywordTok{:}
\AttributeTok{  }\FunctionTok{processed\_dir}\KeywordTok{:}\AttributeTok{ }\StringTok{"data/processed"}
\AttributeTok{  }\FunctionTok{features\_file}\KeywordTok{:}\AttributeTok{ }\StringTok{"data/processed/features\_v1.parquet"}
\AttributeTok{  }\FunctionTok{returns\_file}\KeywordTok{:}\AttributeTok{  }\StringTok{"data/processed/returns.parquet"}
\AttributeTok{  }\FunctionTok{models\_dir}\KeywordTok{:}\AttributeTok{    }\StringTok{"models"}
\AttributeTok{  }\FunctionTok{reports\_dir}\KeywordTok{:}\AttributeTok{   }\StringTok{"reports"}

\FunctionTok{eval}\KeywordTok{:}
\AttributeTok{  }\FunctionTok{train\_min}\KeywordTok{:}\AttributeTok{ }\DecValTok{252}
\AttributeTok{  }\FunctionTok{val\_size}\KeywordTok{:}\AttributeTok{ }\DecValTok{63}
\AttributeTok{  }\FunctionTok{embargo}\KeywordTok{:}\AttributeTok{ }\DecValTok{5}
\AttributeTok{  }\FunctionTok{context}\KeywordTok{:}\AttributeTok{ }\DecValTok{64}

\FunctionTok{features}\KeywordTok{:}
\AttributeTok{  }\FunctionTok{use}\KeywordTok{:}\AttributeTok{ }\KeywordTok{[}\StringTok{"log\_return"}\KeywordTok{,}\AttributeTok{ }\StringTok{"lag1"}\KeywordTok{,}\AttributeTok{ }\StringTok{"lag2"}\KeywordTok{,}\AttributeTok{ }\StringTok{"lag3"}\KeywordTok{,}\AttributeTok{ }\StringTok{"zscore\_20"}\KeywordTok{,}\AttributeTok{ }\StringTok{"roll\_std\_20"}\KeywordTok{]}\CommentTok{  \# only those present will be used}
\end{Highlighting}
\end{Shaded}

\subsection{3) Package boilerplate}\label{package-boilerplate}

\textbf{\texttt{src/projectname/\_\_init\_\_.py}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\_\_all\_\_ }\OperatorTok{=}\NormalTok{ [}\StringTok{"config"}\NormalTok{, }\StringTok{"utils"}\NormalTok{, }\StringTok{"models"}\NormalTok{]}
\NormalTok{\_\_version\_\_ }\OperatorTok{=} \StringTok{"0.1.0"}
\end{Highlighting}
\end{Shaded}

\textbf{\texttt{src/projectname/config.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{from}\NormalTok{ dataclasses }\ImportTok{import}\NormalTok{ dataclass}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ yaml}

\NormalTok{DEFAULT\_CFG }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"config/config.yaml"}\NormalTok{)}

\AttributeTok{@dataclass}
\KeywordTok{class}\NormalTok{ DataPaths:}
\NormalTok{    processed\_dir: Path}
\NormalTok{    features\_file: Path}
\NormalTok{    returns\_file: Path}
\NormalTok{    models\_dir: Path}
\NormalTok{    reports\_dir: Path}

\AttributeTok{@dataclass}
\KeywordTok{class}\NormalTok{ EvalCfg:}
\NormalTok{    train\_min: }\BuiltInTok{int}
\NormalTok{    val\_size: }\BuiltInTok{int}
\NormalTok{    embargo: }\BuiltInTok{int}
\NormalTok{    context: }\BuiltInTok{int}

\AttributeTok{@dataclass}
\KeywordTok{class}\NormalTok{ Config:}
\NormalTok{    data: DataPaths}
    \BuiltInTok{eval}\NormalTok{: EvalCfg}
\NormalTok{    features\_use: }\BuiltInTok{list}\NormalTok{[}\BuiltInTok{str}\NormalTok{]}

\KeywordTok{def}\NormalTok{ load\_config(path: }\BuiltInTok{str} \OperatorTok{|}\NormalTok{ Path }\OperatorTok{=}\NormalTok{ DEFAULT\_CFG) }\OperatorTok{{-}\textgreater{}}\NormalTok{ Config:}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ Path(path)}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ p.exists():}
        \ControlFlowTok{raise} \PreprocessorTok{FileNotFoundError}\NormalTok{(}\SpecialStringTok{f"Config not found: }\SpecialCharTok{\{}\NormalTok{p}\SpecialCharTok{.}\NormalTok{resolve()}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    cfg }\OperatorTok{=}\NormalTok{ yaml.safe\_load(p.read\_text())}
\NormalTok{    data }\OperatorTok{=}\NormalTok{ cfg.get(}\StringTok{"data"}\NormalTok{, \{\})}
\NormalTok{    ev   }\OperatorTok{=}\NormalTok{ cfg.get(}\StringTok{"eval"}\NormalTok{, \{\})}
\NormalTok{    feats}\OperatorTok{=}\NormalTok{ cfg.get(}\StringTok{"features"}\NormalTok{, \{\}).get(}\StringTok{"use"}\NormalTok{, [])}
    \ControlFlowTok{return}\NormalTok{ Config(}
\NormalTok{        data}\OperatorTok{=}\NormalTok{DataPaths(}
\NormalTok{            processed\_dir}\OperatorTok{=}\NormalTok{Path(data[}\StringTok{"processed\_dir"}\NormalTok{]),}
\NormalTok{            features\_file}\OperatorTok{=}\NormalTok{Path(data[}\StringTok{"features\_file"}\NormalTok{]),}
\NormalTok{            returns\_file}\OperatorTok{=}\NormalTok{Path(data[}\StringTok{"returns\_file"}\NormalTok{]),}
\NormalTok{            models\_dir}\OperatorTok{=}\NormalTok{Path(data[}\StringTok{"models\_dir"}\NormalTok{]),}
\NormalTok{            reports\_dir}\OperatorTok{=}\NormalTok{Path(data[}\StringTok{"reports\_dir"}\NormalTok{]),}
\NormalTok{        ),}
        \BuiltInTok{eval}\OperatorTok{=}\NormalTok{EvalCfg(}
\NormalTok{            train\_min}\OperatorTok{=}\BuiltInTok{int}\NormalTok{(ev[}\StringTok{"train\_min"}\NormalTok{]),}
\NormalTok{            val\_size}\OperatorTok{=}\BuiltInTok{int}\NormalTok{(ev[}\StringTok{"val\_size"}\NormalTok{]),}
\NormalTok{            embargo}\OperatorTok{=}\BuiltInTok{int}\NormalTok{(ev[}\StringTok{"embargo"}\NormalTok{]),}
\NormalTok{            context}\OperatorTok{=}\BuiltInTok{int}\NormalTok{(ev[}\StringTok{"context"}\NormalTok{]),}
\NormalTok{        ),}
\NormalTok{        features\_use}\OperatorTok{=}\BuiltInTok{list}\NormalTok{(feats),}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\textbf{\texttt{src/projectname/utils/splits.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\KeywordTok{def}\NormalTok{ make\_rolling\_origin\_splits(dates, train\_min}\OperatorTok{=}\DecValTok{252}\NormalTok{, val\_size}\OperatorTok{=}\DecValTok{63}\NormalTok{, step}\OperatorTok{=}\DecValTok{63}\NormalTok{, embargo}\OperatorTok{=}\DecValTok{5}\NormalTok{):}
\NormalTok{    u }\OperatorTok{=}\NormalTok{ np.array(}\BuiltInTok{sorted}\NormalTok{(pd.to\_datetime(pd.Series(dates).unique())))}
\NormalTok{    i }\OperatorTok{=}\NormalTok{ train\_min }\OperatorTok{{-}} \DecValTok{1}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ []}
    \ControlFlowTok{while} \VariableTok{True}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ i }\OperatorTok{\textgreater{}=} \BuiltInTok{len}\NormalTok{(u):}
            \ControlFlowTok{break}
\NormalTok{        a, b }\OperatorTok{=}\NormalTok{ u[}\DecValTok{0}\NormalTok{], u[i]}
\NormalTok{        vs }\OperatorTok{=}\NormalTok{ i }\OperatorTok{+}\NormalTok{ embargo }\OperatorTok{+} \DecValTok{1}
\NormalTok{        ve }\OperatorTok{=}\NormalTok{ vs }\OperatorTok{+}\NormalTok{ val\_size }\OperatorTok{{-}} \DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ ve }\OperatorTok{\textgreater{}=} \BuiltInTok{len}\NormalTok{(u):}
            \ControlFlowTok{break}
\NormalTok{        out.append((a, b, u[vs], u[ve]))}
\NormalTok{        i }\OperatorTok{+=}\NormalTok{ step}
    \ControlFlowTok{return}\NormalTok{ out}
\end{Highlighting}
\end{Shaded}

\textbf{\texttt{src/projectname/utils/metrics.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\KeywordTok{def}\NormalTok{ mae(y, yhat) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{float}\NormalTok{:}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.asarray(yhat)}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat)))}

\KeywordTok{def}\NormalTok{ smape(y, yhat, eps: }\BuiltInTok{float} \OperatorTok{=} \FloatTok{1e{-}8}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{float}\NormalTok{:}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ np.asarray(y)}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ np.asarray(yhat)}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(}\FloatTok{2.0}\OperatorTok{*}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(y }\OperatorTok{{-}}\NormalTok{ yhat)}\OperatorTok{/}\NormalTok{(np.}\BuiltInTok{abs}\NormalTok{(y)}\OperatorTok{+}\NormalTok{np.}\BuiltInTok{abs}\NormalTok{(yhat)}\OperatorTok{+}\NormalTok{eps)))}

\KeywordTok{def}\NormalTok{ mase\_scale\_train(train\_df: pd.DataFrame) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{dict}\NormalTok{[}\BuiltInTok{str}\NormalTok{, }\BuiltInTok{float}\NormalTok{]:}
    \CommentTok{\# per{-}ticker naive MAE scale on TRAIN only}
\NormalTok{    scales}\OperatorTok{=}\NormalTok{\{\}}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ train\_df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        g }\OperatorTok{=}\NormalTok{ g.dropna(subset}\OperatorTok{=}\NormalTok{[}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{])}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(g)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{        scales[}\BuiltInTok{str}\NormalTok{(tkr)] }\OperatorTok{=}\NormalTok{ mae(g[}\StringTok{"r\_1d"}\NormalTok{], g[}\StringTok{"log\_return"}\NormalTok{])}
    \ControlFlowTok{return}\NormalTok{ scales}

\KeywordTok{def}\NormalTok{ mase(y\_true, y\_pred, tickers, scale: }\BuiltInTok{dict}\NormalTok{[}\BuiltInTok{str}\NormalTok{, }\BuiltInTok{float}\NormalTok{]) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{float}\NormalTok{:}
\NormalTok{    y\_true }\OperatorTok{=}\NormalTok{ np.asarray(y\_true)}\OperatorTok{;}\NormalTok{ y\_pred }\OperatorTok{=}\NormalTok{ np.asarray(y\_pred)}
\NormalTok{    tickers }\OperatorTok{=}\NormalTok{ np.asarray(tickers).astype(}\BuiltInTok{str}\NormalTok{)}
\NormalTok{    den }\OperatorTok{=}\NormalTok{ np.array([scale.get(t, np.nan) }\ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ tickers], dtype}\OperatorTok{=}\BuiltInTok{float}\NormalTok{)}
    \ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.nanmean(np.}\BuiltInTok{abs}\NormalTok{(y\_true }\OperatorTok{{-}}\NormalTok{ y\_pred)}\OperatorTok{/}\NormalTok{(den }\OperatorTok{+} \FloatTok{1e{-}12}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\textbf{\texttt{src/projectname/models/baselines.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ sklearn.preprocessing }\ImportTok{import}\NormalTok{ StandardScaler}
\ImportTok{from}\NormalTok{ sklearn.linear\_model }\ImportTok{import}\NormalTok{ LinearRegression}
\ImportTok{from}\NormalTok{ sklearn.pipeline }\ImportTok{import}\NormalTok{ Pipeline}

\KeywordTok{def}\NormalTok{ predict\_naive(val\_df: pd.DataFrame) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame:}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ val\_df[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{]].copy()}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ out.rename(columns}\OperatorTok{=}\NormalTok{\{}\StringTok{"r\_1d"}\NormalTok{:}\StringTok{"y\_true"}\NormalTok{,}\StringTok{"log\_return"}\NormalTok{:}\StringTok{"yhat"}\NormalTok{\})}
\NormalTok{    out[}\StringTok{"method"}\NormalTok{] }\OperatorTok{=} \StringTok{"naive"}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ predict\_lin\_lags(train\_df: pd.DataFrame, val\_df: pd.DataFrame, feats: }\BuiltInTok{list}\NormalTok{[}\BuiltInTok{str}\NormalTok{]) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame:}
\NormalTok{    preds}\OperatorTok{=}\NormalTok{[]}
\NormalTok{    xcols }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ feats }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ val\_df.columns]}
    \ControlFlowTok{for}\NormalTok{ tkr, tr }\KeywordTok{in}\NormalTok{ train\_df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        va }\OperatorTok{=}\NormalTok{ val\_df[val\_df[}\StringTok{"ticker"}\NormalTok{]}\OperatorTok{==}\NormalTok{tkr]}
        \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(tr)}\OperatorTok{==}\DecValTok{0} \KeywordTok{or} \BuiltInTok{len}\NormalTok{(va)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{continue}
\NormalTok{        pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{"scaler"}\NormalTok{, StandardScaler()), (}\StringTok{"lr"}\NormalTok{, LinearRegression())])}
\NormalTok{        pipe.fit(tr[xcols].values, tr[}\StringTok{"r\_1d"}\NormalTok{].values)}
\NormalTok{        yhat }\OperatorTok{=}\NormalTok{ pipe.predict(va[xcols].values)}
\NormalTok{        g }\OperatorTok{=}\NormalTok{ va[[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"r\_1d"}\NormalTok{]].copy()}
\NormalTok{        g[}\StringTok{"yhat"}\NormalTok{] }\OperatorTok{=}\NormalTok{ yhat}
\NormalTok{        g[}\StringTok{"method"}\NormalTok{] }\OperatorTok{=} \StringTok{"lin\_lags"}
\NormalTok{        preds.append(g)}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ pd.concat(preds, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{) }\ControlFlowTok{if}\NormalTok{ preds }\ControlFlowTok{else}\NormalTok{ pd.DataFrame(columns}\OperatorTok{=}\NormalTok{[}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"y\_true"}\NormalTok{,}\StringTok{"yhat"}\NormalTok{,}\StringTok{"method"}\NormalTok{])}
    \ControlFlowTok{return}\NormalTok{ out.rename(columns}\OperatorTok{=}\NormalTok{\{}\StringTok{"r\_1d"}\NormalTok{:}\StringTok{"y\_true"}\NormalTok{\})}
\end{Highlighting}
\end{Shaded}

\textbf{\texttt{src/projectname/models/torch\_infer.py}} (tiny inference
wrappers; safe if ckpt missing)

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ json}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ torch, torch.nn }\ImportTok{as}\NormalTok{ nn}

\CommentTok{\# Reuse tiny GRU and TS{-}GPT definitions (matching Sessions 19 \& 22)}
\KeywordTok{class}\NormalTok{ GRURegressor(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_features: }\BuiltInTok{int}\NormalTok{, hidden}\OperatorTok{=}\DecValTok{64}\NormalTok{, layers}\OperatorTok{=}\DecValTok{2}\NormalTok{, dropout}\OperatorTok{=}\FloatTok{0.1}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.gru }\OperatorTok{=}\NormalTok{ nn.GRU(in\_features, hidden, num\_layers}\OperatorTok{=}\NormalTok{layers, batch\_first}\OperatorTok{=}\VariableTok{True}\NormalTok{, dropout}\OperatorTok{=}\NormalTok{dropout }\ControlFlowTok{if}\NormalTok{ layers}\OperatorTok{\textgreater{}}\DecValTok{1} \ControlFlowTok{else} \FloatTok{0.}\NormalTok{)}
        \VariableTok{self}\NormalTok{.head }\OperatorTok{=}\NormalTok{ nn.Sequential(nn.Linear(hidden, hidden), nn.ReLU(), nn.Dropout(dropout), nn.Linear(hidden,}\DecValTok{1}\NormalTok{))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):}
\NormalTok{        \_, hN }\OperatorTok{=} \VariableTok{self}\NormalTok{.gru(x)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.head(hN[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]).squeeze(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}

\KeywordTok{class}\NormalTok{ CausalSelfAttention(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model, n\_head, ctx, p}\OperatorTok{=}\FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}\OperatorTok{;} \ControlFlowTok{assert}\NormalTok{ d\_model }\OperatorTok{\%}\NormalTok{ n\_head }\OperatorTok{==} \DecValTok{0}
        \VariableTok{self}\NormalTok{.nh }\OperatorTok{=}\NormalTok{ n\_head}\OperatorTok{;} \VariableTok{self}\NormalTok{.dh }\OperatorTok{=}\NormalTok{ d\_model}\OperatorTok{//}\NormalTok{n\_head}
        \VariableTok{self}\NormalTok{.qkv }\OperatorTok{=}\NormalTok{ nn.Linear(d\_model, }\DecValTok{3}\OperatorTok{*}\NormalTok{d\_model, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \VariableTok{self}\NormalTok{.proj}\OperatorTok{=}\NormalTok{ nn.Linear(d\_model, d\_model, bias}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
        \VariableTok{self}\NormalTok{.ad }\OperatorTok{=}\NormalTok{ nn.Dropout(p)}\OperatorTok{;} \VariableTok{self}\NormalTok{.rd }\OperatorTok{=}\NormalTok{ nn.Dropout(p)}
        \VariableTok{self}\NormalTok{.register\_buffer(}\StringTok{"mask"}\NormalTok{, torch.tril(torch.ones(ctx,ctx)).unsqueeze(}\DecValTok{0}\NormalTok{).unsqueeze(}\DecValTok{0}\NormalTok{))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{, x):}
\NormalTok{        B,T,C}\OperatorTok{=}\NormalTok{x.shape}\OperatorTok{;}\NormalTok{ qkv}\OperatorTok{=}\VariableTok{self}\NormalTok{.qkv(x)}\OperatorTok{;}\NormalTok{ q,k,v}\OperatorTok{=}\NormalTok{qkv.split(C,dim}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{        q}\OperatorTok{=}\NormalTok{q.view(B,T,}\VariableTok{self}\NormalTok{.nh,}\VariableTok{self}\NormalTok{.dh).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{;}\NormalTok{ k}\OperatorTok{=}\NormalTok{k.view(B,T,}\VariableTok{self}\NormalTok{.nh,}\VariableTok{self}\NormalTok{.dh).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}\OperatorTok{;}\NormalTok{ v}\OperatorTok{=}\NormalTok{v.view(B,T,}\VariableTok{self}\NormalTok{.nh,}\VariableTok{self}\NormalTok{.dh).transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{        att}\OperatorTok{=}\NormalTok{(q }\OperatorTok{@}\NormalTok{ k.transpose(}\OperatorTok{{-}}\DecValTok{2}\NormalTok{,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{))}\OperatorTok{/}\NormalTok{np.sqrt(}\VariableTok{self}\NormalTok{.dh)}\OperatorTok{;}\NormalTok{ att}\OperatorTok{=}\NormalTok{att.masked\_fill(}\VariableTok{self}\NormalTok{.mask[:,:,:T,:T]}\OperatorTok{==}\DecValTok{0}\NormalTok{, }\BuiltInTok{float}\NormalTok{(}\StringTok{"{-}inf"}\NormalTok{))}
\NormalTok{        att}\OperatorTok{=}\NormalTok{att.softmax(dim}\OperatorTok{={-}}\DecValTok{1}\NormalTok{)}\OperatorTok{;}\NormalTok{ att}\OperatorTok{=}\VariableTok{self}\NormalTok{.ad(att)}\OperatorTok{;}\NormalTok{ y}\OperatorTok{=}\NormalTok{att }\OperatorTok{@}\NormalTok{ v}\OperatorTok{;}\NormalTok{ y}\OperatorTok{=}\NormalTok{y.transpose(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{).contiguous().view(B,T,C)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.rd(}\VariableTok{self}\NormalTok{.proj(y))}

\KeywordTok{class}\NormalTok{ Block(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, d\_model, n\_head, ctx, d\_ff, p}\OperatorTok{=}\FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}
        \VariableTok{self}\NormalTok{.ln1}\OperatorTok{=}\NormalTok{nn.LayerNorm(d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.att}\OperatorTok{=}\NormalTok{CausalSelfAttention(d\_model,n\_head,ctx,p)}
        \VariableTok{self}\NormalTok{.ln2}\OperatorTok{=}\NormalTok{nn.LayerNorm(d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.mlp}\OperatorTok{=}\NormalTok{nn.Sequential(nn.Linear(d\_model,d\_ff), nn.GELU(), nn.Dropout(p), nn.Linear(d\_ff,d\_model), nn.Dropout(p))}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{,x): x}\OperatorTok{=}\NormalTok{x}\OperatorTok{+}\VariableTok{self}\NormalTok{.att(}\VariableTok{self}\NormalTok{.ln1(x))}\OperatorTok{;}\NormalTok{ x}\OperatorTok{=}\NormalTok{x}\OperatorTok{+}\VariableTok{self}\NormalTok{.mlp(}\VariableTok{self}\NormalTok{.ln2(x))}\OperatorTok{;} \ControlFlowTok{return}\NormalTok{ x}

\KeywordTok{class}\NormalTok{ TimeSeriesGPT(nn.Module):}
    \KeywordTok{def} \FunctionTok{\_\_init\_\_}\NormalTok{(}\VariableTok{self}\NormalTok{, in\_features, ctx}\OperatorTok{=}\DecValTok{64}\NormalTok{, d\_model}\OperatorTok{=}\DecValTok{64}\NormalTok{, n\_head}\OperatorTok{=}\DecValTok{2}\NormalTok{, n\_layer}\OperatorTok{=}\DecValTok{2}\NormalTok{, d\_ff}\OperatorTok{=}\DecValTok{128}\NormalTok{, p}\OperatorTok{=}\FloatTok{0.0}\NormalTok{):}
        \BuiltInTok{super}\NormalTok{().}\FunctionTok{\_\_init\_\_}\NormalTok{()}\OperatorTok{;} \VariableTok{self}\NormalTok{.ctx}\OperatorTok{=}\NormalTok{ctx}
        \VariableTok{self}\NormalTok{.proj}\OperatorTok{=}\NormalTok{nn.Linear(in\_features,d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.pos}\OperatorTok{=}\NormalTok{nn.Embedding(ctx,d\_model)}
        \VariableTok{self}\NormalTok{.blocks}\OperatorTok{=}\NormalTok{nn.ModuleList([Block(d\_model,n\_head,ctx,d\_ff,p) }\ControlFlowTok{for}\NormalTok{ \_ }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(n\_layer)])}
        \VariableTok{self}\NormalTok{.ln}\OperatorTok{=}\NormalTok{nn.LayerNorm(d\_model)}\OperatorTok{;} \VariableTok{self}\NormalTok{.head}\OperatorTok{=}\NormalTok{nn.Linear(d\_model,}\DecValTok{1}\NormalTok{)}
    \KeywordTok{def}\NormalTok{ forward(}\VariableTok{self}\NormalTok{,x):}
\NormalTok{        B,T,F}\OperatorTok{=}\NormalTok{x.shape}\OperatorTok{;}\NormalTok{ pos}\OperatorTok{=}\NormalTok{torch.arange(T, device}\OperatorTok{=}\NormalTok{x.device)}
\NormalTok{        h}\OperatorTok{=}\VariableTok{self}\NormalTok{.proj(x)}\OperatorTok{+}\VariableTok{self}\NormalTok{.pos(pos)[}\VariableTok{None}\NormalTok{,:,:]}
        \ControlFlowTok{for}\NormalTok{ blk }\KeywordTok{in} \VariableTok{self}\NormalTok{.blocks: h}\OperatorTok{=}\NormalTok{blk(h)}
\NormalTok{        h}\OperatorTok{=}\VariableTok{self}\NormalTok{.ln(h)}
        \ControlFlowTok{return} \VariableTok{self}\NormalTok{.head(h[:,}\OperatorTok{{-}}\DecValTok{1}\NormalTok{,:]).squeeze(}\OperatorTok{{-}}\DecValTok{1}\NormalTok{)}

\KeywordTok{def}\NormalTok{ \_windowize(df: pd.DataFrame, feats: }\BuiltInTok{list}\NormalTok{[}\BuiltInTok{str}\NormalTok{], T: }\BuiltInTok{int}\NormalTok{):}
\NormalTok{    Xs, ys, tk }\OperatorTok{=}\NormalTok{ [], [], []}
    \ControlFlowTok{for}\NormalTok{ tkr, g }\KeywordTok{in}\NormalTok{ df.groupby(}\StringTok{"ticker"}\NormalTok{):}
\NormalTok{        g }\OperatorTok{=}\NormalTok{ g.sort\_values(}\StringTok{"date"}\NormalTok{).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        X }\OperatorTok{=}\NormalTok{ g[feats].to\_numpy(}\StringTok{"float32"}\NormalTok{)}\OperatorTok{;}\NormalTok{ y }\OperatorTok{=}\NormalTok{ g[}\StringTok{"r\_1d"}\NormalTok{].to\_numpy(}\StringTok{"float32"}\NormalTok{)}
        \ControlFlowTok{for}\NormalTok{ end }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(T}\OperatorTok{{-}}\DecValTok{1}\NormalTok{, }\BuiltInTok{len}\NormalTok{(g)):}
\NormalTok{            Xs.append(X[end}\OperatorTok{{-}}\NormalTok{T}\OperatorTok{+}\DecValTok{1}\NormalTok{:end}\OperatorTok{+}\DecValTok{1}\NormalTok{])}\OperatorTok{;}\NormalTok{ ys.append(y[end])}\OperatorTok{;}\NormalTok{ tk.append(}\BuiltInTok{str}\NormalTok{(tkr))}
\NormalTok{    Xs }\OperatorTok{=}\NormalTok{ np.stack(Xs,}\DecValTok{0}\NormalTok{)}\OperatorTok{;}\NormalTok{ ys }\OperatorTok{=}\NormalTok{ np.array(ys)}\OperatorTok{;}\NormalTok{ tk }\OperatorTok{=}\NormalTok{ np.array(tk)}
    \ControlFlowTok{return}\NormalTok{ Xs, ys, tk}

\KeywordTok{def}\NormalTok{ predict\_with\_gru(val\_df: pd.DataFrame, feats: }\BuiltInTok{list}\NormalTok{[}\BuiltInTok{str}\NormalTok{], models\_dir: Path, T: }\BuiltInTok{int}\OperatorTok{=}\DecValTok{64}\NormalTok{):}
\NormalTok{    ckpt }\OperatorTok{=}\NormalTok{ models\_dir }\OperatorTok{/} \StringTok{"gru\_split1.pt"}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ ckpt.exists():}
        \ControlFlowTok{raise} \PreprocessorTok{FileNotFoundError}\NormalTok{(}\StringTok{"Missing models/gru\_split1.pt (train in Session 19)"}\NormalTok{)}

\NormalTok{    meta }\OperatorTok{=}\NormalTok{ torch.load(ckpt, map\_location}\OperatorTok{=}\StringTok{"cpu"}\NormalTok{)}
\NormalTok{    in\_f }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(feats)}
\NormalTok{    net }\OperatorTok{=}\NormalTok{ GRURegressor(in\_features}\OperatorTok{=}\NormalTok{in\_f)}
\NormalTok{    net.load\_state\_dict(meta[}\StringTok{"model\_state"}\NormalTok{])}\OperatorTok{;}\NormalTok{ net.}\BuiltInTok{eval}\NormalTok{()}
\NormalTok{    Xs, ys, tk }\OperatorTok{=}\NormalTok{ \_windowize(val\_df, feats, T)}
    \ControlFlowTok{with}\NormalTok{ torch.no\_grad():}
\NormalTok{        yhat }\OperatorTok{=}\NormalTok{ net(torch.from\_numpy(Xs).}\BuiltInTok{float}\NormalTok{()).cpu().numpy()}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ val\_df.iloc[T}\OperatorTok{{-}}\DecValTok{1}\NormalTok{:].copy().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{).loc[:, [}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{]]}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ out.assign(y\_true}\OperatorTok{=}\NormalTok{ys, yhat}\OperatorTok{=}\NormalTok{yhat, method}\OperatorTok{=}\StringTok{"gru"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ predict\_with\_tsgpt(val\_df: pd.DataFrame, feats: }\BuiltInTok{list}\NormalTok{[}\BuiltInTok{str}\NormalTok{], models\_dir: Path, T: }\BuiltInTok{int}\OperatorTok{=}\DecValTok{64}\NormalTok{):}
\NormalTok{    ckpt }\OperatorTok{=}\NormalTok{ models\_dir }\OperatorTok{/} \StringTok{"tsgpt\_split1.pt"}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ ckpt.exists():}
        \ControlFlowTok{raise} \PreprocessorTok{FileNotFoundError}\NormalTok{(}\StringTok{"Missing models/tsgpt\_split1.pt (train in Session 22)"}\NormalTok{)}

\NormalTok{    meta }\OperatorTok{=}\NormalTok{ torch.load(ckpt, map\_location}\OperatorTok{=}\StringTok{"cpu"}\NormalTok{)}
\NormalTok{    in\_f }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(feats)}
\NormalTok{    net }\OperatorTok{=}\NormalTok{ TimeSeriesGPT(in\_features}\OperatorTok{=}\NormalTok{in\_f, ctx}\OperatorTok{=}\NormalTok{T)}
\NormalTok{    net.load\_state\_dict(meta[}\StringTok{"model"}\NormalTok{])}\OperatorTok{;}\NormalTok{ net.}\BuiltInTok{eval}\NormalTok{()}
\NormalTok{    Xs, ys, tk }\OperatorTok{=}\NormalTok{ \_windowize(val\_df, feats, T)}
    \ControlFlowTok{with}\NormalTok{ torch.no\_grad():}
\NormalTok{        yhat }\OperatorTok{=}\NormalTok{ net(torch.from\_numpy(Xs).}\BuiltInTok{float}\NormalTok{()).cpu().numpy()}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ val\_df.iloc[T}\OperatorTok{{-}}\DecValTok{1}\NormalTok{:].copy().reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{).loc[:, [}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{]]}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ out.assign(y\_true}\OperatorTok{=}\NormalTok{ys, yhat}\OperatorTok{=}\NormalTok{yhat, method}\OperatorTok{=}\StringTok{"tsgpt"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ out}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{4) The CLI (Typer):
\texttt{src/projectname/cli.py}}{4) The CLI (Typer): src/projectname/cli.py}}\label{the-cli-typer-srcprojectnamecli.py}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ sys}
\ImportTok{from}\NormalTok{ datetime }\ImportTok{import}\NormalTok{ date}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{from}\NormalTok{ typing }\ImportTok{import}\NormalTok{ Optional, Literal}

\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ typer}
\ImportTok{from}\NormalTok{ rich }\ImportTok{import} \BuiltInTok{print} \ImportTok{as}\NormalTok{ rprint}
\ImportTok{from}\NormalTok{ rich.table }\ImportTok{import}\NormalTok{ Table}

\ImportTok{from}\NormalTok{ projectname.config }\ImportTok{import}\NormalTok{ load\_config}
\ImportTok{from}\NormalTok{ projectname.utils.splits }\ImportTok{import}\NormalTok{ make\_rolling\_origin\_splits}
\ImportTok{from}\NormalTok{ projectname.utils.metrics }\ImportTok{import}\NormalTok{ mae, smape, mase\_scale\_train, mase}
\ImportTok{from}\NormalTok{ projectname.models.baselines }\ImportTok{import}\NormalTok{ predict\_naive, predict\_lin\_lags}

\CommentTok{\# Optional imports for torch models (graceful fallback)}
\ControlFlowTok{try}\NormalTok{:}
    \ImportTok{from}\NormalTok{ projectname.models.torch\_infer }\ImportTok{import}\NormalTok{ predict\_with\_gru, predict\_with\_tsgpt}
\ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
\NormalTok{    predict\_with\_gru }\OperatorTok{=}\NormalTok{ predict\_with\_tsgpt }\OperatorTok{=} \VariableTok{None}  \CommentTok{\# type: ignore}

\NormalTok{app }\OperatorTok{=}\NormalTok{ typer.Typer(add\_completion}\OperatorTok{=}\VariableTok{False}\NormalTok{, }\BuiltInTok{help}\OperatorTok{=}\StringTok{"Project CLI for scoring/evaluation."}\NormalTok{)}

\KeywordTok{def}\NormalTok{ \_load\_features(features\_file: Path) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame:}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(features\_file)}
\NormalTok{    df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{])}
\NormalTok{    df[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\AttributeTok{@app.command}\NormalTok{()}
\KeywordTok{def}\NormalTok{ split\_info(}
\NormalTok{    config: Path }\OperatorTok{=}\NormalTok{ typer.Option(}\StringTok{"config/config.yaml"}\NormalTok{, }\BuiltInTok{help}\OperatorTok{=}\StringTok{"Path to YAML config."}\NormalTok{),}
\NormalTok{):}
    \CommentTok{"Print available rolling{-}origin splits (first 3)."}
\NormalTok{    cfg }\OperatorTok{=}\NormalTok{ load\_config(config)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ \_load\_features(cfg.data.features\_file)}
\NormalTok{    splits }\OperatorTok{=}\NormalTok{ make\_rolling\_origin\_splits(df[}\StringTok{"date"}\NormalTok{], cfg.}\BuiltInTok{eval}\NormalTok{.train\_min, cfg.}\BuiltInTok{eval}\NormalTok{.val\_size, cfg.}\BuiltInTok{eval}\NormalTok{.val\_size, cfg.}\BuiltInTok{eval}\NormalTok{.embargo)}
\NormalTok{    table }\OperatorTok{=}\NormalTok{ Table(title}\OperatorTok{=}\StringTok{"Rolling{-}origin splits (first 3)"}\NormalTok{)}
\NormalTok{    table.add\_column(}\StringTok{"id"}\NormalTok{)}\OperatorTok{;}\NormalTok{ table.add\_column(}\StringTok{"train\_start"}\NormalTok{)}\OperatorTok{;}\NormalTok{ table.add\_column(}\StringTok{"train\_end"}\NormalTok{)}\OperatorTok{;}\NormalTok{ table.add\_column(}\StringTok{"val\_start"}\NormalTok{)}\OperatorTok{;}\NormalTok{ table.add\_column(}\StringTok{"val\_end"}\NormalTok{)}
    \ControlFlowTok{for}\NormalTok{ i,(a,b,c,d) }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(splits[:}\DecValTok{3}\NormalTok{], start}\OperatorTok{=}\DecValTok{1}\NormalTok{):}
\NormalTok{        table.add\_row(}\BuiltInTok{str}\NormalTok{(i), }\BuiltInTok{str}\NormalTok{(a.date()), }\BuiltInTok{str}\NormalTok{(b.date()), }\BuiltInTok{str}\NormalTok{(c.date()), }\BuiltInTok{str}\NormalTok{(d.date()))}
\NormalTok{    rprint(table)}

\AttributeTok{@app.command}\NormalTok{()}
\KeywordTok{def}\NormalTok{ show\_config(}
\NormalTok{    config: Path }\OperatorTok{=}\NormalTok{ typer.Option(}\StringTok{"config/config.yaml"}\NormalTok{, }\BuiltInTok{help}\OperatorTok{=}\StringTok{"Path to YAML config."}\NormalTok{)}
\NormalTok{):}
    \CommentTok{"Echo resolved config."}
\NormalTok{    rprint(load\_config(config))}

\AttributeTok{@app.command}\NormalTok{()}
\KeywordTok{def}\NormalTok{ score(}
\NormalTok{    model: Literal[}\StringTok{"naive"}\NormalTok{,}\StringTok{"lin\_lags"}\NormalTok{,}\StringTok{"gru"}\NormalTok{,}\StringTok{"tsgpt"}\NormalTok{] }\OperatorTok{=}\NormalTok{ typer.Option(}\StringTok{"lin\_lags"}\NormalTok{, }\BuiltInTok{help}\OperatorTok{=}\StringTok{"Model to score."}\NormalTok{),}
\NormalTok{    start: Optional[}\BuiltInTok{str}\NormalTok{] }\OperatorTok{=}\NormalTok{ typer.Option(}\VariableTok{None}\NormalTok{, }\BuiltInTok{help}\OperatorTok{=}\StringTok{"Val period start (YYYY{-}MM{-}DD). If omitted, use split 1."}\NormalTok{),}
\NormalTok{    end: Optional[}\BuiltInTok{str}\NormalTok{]   }\OperatorTok{=}\NormalTok{ typer.Option(}\VariableTok{None}\NormalTok{, }\BuiltInTok{help}\OperatorTok{=}\StringTok{"Val period end (YYYY{-}MM{-}DD)."}\NormalTok{),}
\NormalTok{    split: }\BuiltInTok{int} \OperatorTok{=}\NormalTok{ typer.Option(}\DecValTok{1}\NormalTok{, }\BuiltInTok{help}\OperatorTok{=}\StringTok{"Use this split if {-}{-}start/{-}{-}end not provided."}\NormalTok{),}
\NormalTok{    out: Path }\OperatorTok{=}\NormalTok{ typer.Option(}\StringTok{"reports/cli\_score.csv"}\NormalTok{, }\BuiltInTok{help}\OperatorTok{=}\StringTok{"Output CSV path."}\NormalTok{),}
\NormalTok{    config: Path }\OperatorTok{=}\NormalTok{ typer.Option(}\StringTok{"config/config.yaml"}\NormalTok{, }\BuiltInTok{help}\OperatorTok{=}\StringTok{"Path to YAML config."}\NormalTok{),}
\NormalTok{):}
    \CommentTok{"""}
\CommentTok{    Score a model over a date range; write tidy predictions with metrics.}
\CommentTok{    """}
\NormalTok{    cfg }\OperatorTok{=}\NormalTok{ load\_config(config)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ \_load\_features(cfg.data.features\_file)}

    \CommentTok{\# Pick features present in the file}
\NormalTok{    feat\_cols }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ cfg.features\_use }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ df.columns]}
    \ControlFlowTok{if}\NormalTok{ model }\KeywordTok{in}\NormalTok{ (}\StringTok{"lin\_lags"}\NormalTok{,}\StringTok{"gru"}\NormalTok{,}\StringTok{"tsgpt"}\NormalTok{) }\KeywordTok{and} \KeywordTok{not}\NormalTok{ feat\_cols:}
\NormalTok{        typer.echo(}\StringTok{"No requested features found in features parquet."}\NormalTok{, err}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
        \ControlFlowTok{raise}\NormalTok{ typer.Exit(code}\OperatorTok{=}\DecValTok{2}\NormalTok{)}

    \CommentTok{\# Build split}
    \ControlFlowTok{if}\NormalTok{ start }\KeywordTok{and}\NormalTok{ end:}
\NormalTok{        vstart }\OperatorTok{=}\NormalTok{ pd.to\_datetime(start)}\OperatorTok{;}\NormalTok{ vend }\OperatorTok{=}\NormalTok{ pd.to\_datetime(end)}
        \CommentTok{\# Train = everything strictly before val start, respecting train\_min}
\NormalTok{        dates }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(df[}\StringTok{"date"}\NormalTok{].unique())}
\NormalTok{        idx }\OperatorTok{=} \BuiltInTok{next}\NormalTok{(i }\ControlFlowTok{for}\NormalTok{ i,d }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(dates) }\ControlFlowTok{if}\NormalTok{ d}\OperatorTok{\textgreater{}=}\NormalTok{vstart)}
        \ControlFlowTok{if}\NormalTok{ idx }\OperatorTok{\textless{}}\NormalTok{ cfg.}\BuiltInTok{eval}\NormalTok{.train\_min: }
\NormalTok{            typer.echo(}\StringTok{"Not enough history before val start for train\_min."}\NormalTok{, err}\OperatorTok{=}\VariableTok{True}\NormalTok{)}\OperatorTok{;} \ControlFlowTok{raise}\NormalTok{ typer.Exit(code}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{        tstart }\OperatorTok{=}\NormalTok{ dates[}\DecValTok{0}\NormalTok{]}\OperatorTok{;}\NormalTok{ tend }\OperatorTok{=}\NormalTok{ dates[idx}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        splits }\OperatorTok{=}\NormalTok{ make\_rolling\_origin\_splits(df[}\StringTok{"date"}\NormalTok{], cfg.}\BuiltInTok{eval}\NormalTok{.train\_min, cfg.}\BuiltInTok{eval}\NormalTok{.val\_size, cfg.}\BuiltInTok{eval}\NormalTok{.val\_size, cfg.}\BuiltInTok{eval}\NormalTok{.embargo)}
        \ControlFlowTok{try}\NormalTok{:}
\NormalTok{            tstart, tend, vstart, vend }\OperatorTok{=}\NormalTok{ splits[split}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{except} \PreprocessorTok{IndexError}\NormalTok{:}
\NormalTok{            typer.echo(}\SpecialStringTok{f"Split }\SpecialCharTok{\{}\NormalTok{split}\SpecialCharTok{\}}\SpecialStringTok{ not available."}\NormalTok{, err}\OperatorTok{=}\VariableTok{True}\NormalTok{)}\OperatorTok{;} \ControlFlowTok{raise}\NormalTok{ typer.Exit(code}\OperatorTok{=}\DecValTok{2}\NormalTok{)}

\NormalTok{    train\_df }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{tstart)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{tend)].copy()}
\NormalTok{    val\_df   }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{vstart)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{vend)].copy()}

    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(val\_df)}\OperatorTok{==}\DecValTok{0} \KeywordTok{or} \BuiltInTok{len}\NormalTok{(train\_df)}\OperatorTok{==}\DecValTok{0}\NormalTok{:}
\NormalTok{        typer.echo(}\StringTok{"Empty train/val after slicing. Check dates."}\NormalTok{, err}\OperatorTok{=}\VariableTok{True}\NormalTok{)}\OperatorTok{;} \ControlFlowTok{raise}\NormalTok{ typer.Exit(code}\OperatorTok{=}\DecValTok{2}\NormalTok{)}

    \CommentTok{\# Produce predictions}
    \ControlFlowTok{try}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ model }\OperatorTok{==} \StringTok{"naive"}\NormalTok{:}
\NormalTok{            preds }\OperatorTok{=}\NormalTok{ predict\_naive(val\_df)}
        \ControlFlowTok{elif}\NormalTok{ model }\OperatorTok{==} \StringTok{"lin\_lags"}\NormalTok{:}
\NormalTok{            preds }\OperatorTok{=}\NormalTok{ predict\_lin\_lags(train\_df, val\_df, feat\_cols)}
        \ControlFlowTok{elif}\NormalTok{ model }\OperatorTok{==} \StringTok{"gru"}\NormalTok{:}
            \ControlFlowTok{if}\NormalTok{ predict\_with\_gru }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{                typer.echo(}\StringTok{"Torch not available in this environment."}\NormalTok{, err}\OperatorTok{=}\VariableTok{True}\NormalTok{)}\OperatorTok{;} \ControlFlowTok{raise}\NormalTok{ typer.Exit(code}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{            preds }\OperatorTok{=}\NormalTok{ predict\_with\_gru(val\_df, feat\_cols, cfg.data.models\_dir, T}\OperatorTok{=}\NormalTok{cfg.}\BuiltInTok{eval}\NormalTok{.context)}
        \ControlFlowTok{elif}\NormalTok{ model }\OperatorTok{==} \StringTok{"tsgpt"}\NormalTok{:}
            \ControlFlowTok{if}\NormalTok{ predict\_with\_tsgpt }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{                typer.echo(}\StringTok{"Torch not available in this environment."}\NormalTok{, err}\OperatorTok{=}\VariableTok{True}\NormalTok{)}\OperatorTok{;} \ControlFlowTok{raise}\NormalTok{ typer.Exit(code}\OperatorTok{=}\DecValTok{2}\NormalTok{)}
\NormalTok{            preds }\OperatorTok{=}\NormalTok{ predict\_with\_tsgpt(val\_df, feat\_cols, cfg.data.models\_dir, T}\OperatorTok{=}\NormalTok{cfg.}\BuiltInTok{eval}\NormalTok{.context)}
        \ControlFlowTok{else}\NormalTok{:}
            \ControlFlowTok{raise} \PreprocessorTok{ValueError}\NormalTok{(model)}
    \ControlFlowTok{except} \PreprocessorTok{FileNotFoundError} \ImportTok{as}\NormalTok{ e:}
\NormalTok{        typer.echo(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{e}\SpecialCharTok{\}}\SpecialStringTok{. Falling back to lin\_lags."}\NormalTok{, err}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{        preds }\OperatorTok{=}\NormalTok{ predict\_lin\_lags(train\_df, val\_df, feat\_cols)}

    \CommentTok{\# Metrics (micro; and MASE using train scale)}
\NormalTok{    scale }\OperatorTok{=}\NormalTok{ mase\_scale\_train(train\_df)}
\NormalTok{    y }\OperatorTok{=}\NormalTok{ preds[}\StringTok{"y\_true"}\NormalTok{]}\OperatorTok{;}\NormalTok{ yhat }\OperatorTok{=}\NormalTok{ preds[}\StringTok{"yhat"}\NormalTok{]}\OperatorTok{;}\NormalTok{ tick }\OperatorTok{=}\NormalTok{ preds[}\StringTok{"ticker"}\NormalTok{].astype(}\BuiltInTok{str}\NormalTok{)}
\NormalTok{    m\_mae }\OperatorTok{=}\NormalTok{ mae(y,yhat)}\OperatorTok{;}\NormalTok{ m\_smape }\OperatorTok{=}\NormalTok{ smape(y,yhat)}\OperatorTok{;}\NormalTok{ m\_mase }\OperatorTok{=}\NormalTok{ mase(y,yhat,tick, scale)}

    \CommentTok{\# Save predictions and print summary}
\NormalTok{    out.parent.mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    preds.to\_csv(out, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\NormalTok{    rprint(}\SpecialStringTok{f"[bold green]Wrote[/bold green] }\SpecialCharTok{\{}\NormalTok{out}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    table }\OperatorTok{=}\NormalTok{ Table(title}\OperatorTok{=}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{model}\SpecialCharTok{\}}\SpecialStringTok{ — }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(vstart.date())}\SpecialCharTok{\}}\SpecialStringTok{ → }\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(vend.date())}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    table.add\_column(}\StringTok{"metric"}\NormalTok{)}\OperatorTok{;}\NormalTok{ table.add\_column(}\StringTok{"value"}\NormalTok{)}
\NormalTok{    table.add\_row(}\StringTok{"MAE"}\NormalTok{, }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{m\_mae}\SpecialCharTok{:.6f\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    table.add\_row(}\StringTok{"sMAPE"}\NormalTok{, }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{m\_smape}\SpecialCharTok{:.6f\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    table.add\_row(}\StringTok{"MASE"}\NormalTok{, }\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{m\_mase}\SpecialCharTok{:.6f\}}\SpecialStringTok{"}\NormalTok{)}
\NormalTok{    rprint(table)}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    app()}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

\subsection{5) Install the package (editable) \& quick smoke
test}\label{install-the-package-editable-quick-smoke-test}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pip}\NormalTok{ install }\AttributeTok{{-}e} \StringTok{".[dev]"} \AttributeTok{{-}q}
\ExtensionTok{python} \AttributeTok{{-}m}\NormalTok{ projectname.cli }\AttributeTok{{-}{-}help} \KeywordTok{|} \FunctionTok{head} \AttributeTok{{-}n}\NormalTok{ 20}
\ExtensionTok{python} \AttributeTok{{-}m}\NormalTok{ projectname.cli split{-}info}
\ExtensionTok{python} \AttributeTok{{-}m}\NormalTok{ projectname.cli score }\AttributeTok{{-}{-}model}\NormalTok{ lin\_lags }\AttributeTok{{-}{-}out}\NormalTok{ reports/cli\_linlags.csv}
\end{Highlighting}
\end{Shaded}

You should see a metrics table and a saved CSV under \texttt{reports/}.

\subsection{6) Makefile additions}\label{makefile-additions}

Append to your existing \textbf{Makefile}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.PHONY: install score{-}lin}
\NormalTok{install: \#\# Editable install of the package}
\NormalTok{\textbackslash{}tpip install {-}e ".[dev]"}

\NormalTok{score{-}lin: \#\# Score lin\_lags on split 1, save predictions}
\NormalTok{\textbackslash{}tpython {-}m projectname.cli score {-}{-}model lin\_lags {-}{-}out reports/cli\_linlags.csv}
\end{Highlighting}
\end{Shaded}

\subsection{7) Minimal test for the CLI}\label{minimal-test-for-the-cli}

\textbf{\texttt{tests/test\_cli\_score.py}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ typer.testing }\ImportTok{import}\NormalTok{ CliRunner}
\ImportTok{from}\NormalTok{ projectname.cli }\ImportTok{import}\NormalTok{ app}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\NormalTok{runner }\OperatorTok{=}\NormalTok{ CliRunner()}

\KeywordTok{def}\NormalTok{ test\_score\_lin\_lags(tmp\_path: Path):}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ tmp\_path}\OperatorTok{/}\StringTok{"preds.csv"}
\NormalTok{    result }\OperatorTok{=}\NormalTok{ runner.invoke(app, [}\StringTok{"score"}\NormalTok{, }\StringTok{"{-}{-}model"}\NormalTok{, }\StringTok{"lin\_lags"}\NormalTok{, }\StringTok{"{-}{-}out"}\NormalTok{, }\BuiltInTok{str}\NormalTok{(out)])}
    \ControlFlowTok{assert}\NormalTok{ result.exit\_code }\OperatorTok{==} \DecValTok{0}
    \ControlFlowTok{assert}\NormalTok{ out.exists()}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_csv(out)}
    \ControlFlowTok{assert}\NormalTok{ \{}\StringTok{"date"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{,}\StringTok{"y\_true"}\NormalTok{,}\StringTok{"yhat"}\NormalTok{,}\StringTok{"method"}\NormalTok{\}.issubset(df.columns)}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}k}\NormalTok{ cli\_score}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (15 min)}\label{wrapup-15-min}

\begin{itemize}
\tightlist
\item
  \textbf{Package once, reuse everywhere}: notebooks, scripts, CI.
\item
  \textbf{CLI is the user surface}: deterministic, scriptable, easy to
  test.
\item
  \textbf{Centralized config} prevents duplicated paths and parameters.
\item
  Keep the CLI \textbf{fast} (no training). Scoring should finish in
  seconds to a couple minutes.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
24)}\label{homework-due-before-session-24}

\textbf{Goal:} Prove your repo is \textbf{reproducible from a fresh
clone} and your CLI works end‑to‑end.

\subsection{A. Fresh‑clone smoke test script (Colab
cell)}\label{a.-freshclone-smoke-test-script-colab-cell}

Paste this into a fresh Colab (or a new runtime):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# {-}{-}{-} variables {-}{-}{-}}
\VariableTok{REPO\_SSH\_OR\_HTTPS}\OperatorTok{=}\StringTok{"\textless{}YOUR REPO URL\textgreater{}"}   \CommentTok{\# e.g. https://github.com/you/unified{-}stocks{-}teamX.git}
\VariableTok{REPO\_DIR}\OperatorTok{=}\StringTok{"unified{-}stocks{-}teamX"}

\CommentTok{\# {-}{-}{-} run {-}{-}{-}}
\FunctionTok{rm} \AttributeTok{{-}rf} \StringTok{"}\VariableTok{$REPO\_DIR}\StringTok{"}
\FunctionTok{git}\NormalTok{ clone }\StringTok{"}\VariableTok{$REPO\_SSH\_OR\_HTTPS}\StringTok{"} \StringTok{"}\VariableTok{$REPO\_DIR}\StringTok{"}
\BuiltInTok{cd} \StringTok{"}\VariableTok{$REPO\_DIR}\StringTok{"}

\CommentTok{\# env + editable install + report + score}
\FunctionTok{make}\NormalTok{ env              }\CommentTok{\# from Session 2 (installs requirements.txt)}
\ExtensionTok{pip}\NormalTok{ install }\AttributeTok{{-}e} \StringTok{".[dev]"}
\ExtensionTok{quarto} \AttributeTok{{-}{-}version} \OperatorTok{\textgreater{}}\NormalTok{/dev/null }\DecValTok{2}\OperatorTok{\textgreater{}\&}\DecValTok{1} \KeywordTok{||} \BuiltInTok{echo} \StringTok{"Quarto optional; skipping render."}
\ExtensionTok{python} \AttributeTok{{-}m}\NormalTok{ projectname.cli split{-}info}
\ExtensionTok{python} \AttributeTok{{-}m}\NormalTok{ projectname.cli score }\AttributeTok{{-}{-}model}\NormalTok{ lin\_lags }\AttributeTok{{-}{-}out}\NormalTok{ reports/cli\_linlags.csv}

\CommentTok{\# show outputs}
\ExtensionTok{python} \AttributeTok{{-}} \OperatorTok{\textless{}\textless{}\textquotesingle{}PY\textquotesingle{}}
\StringTok{import pandas as pd}
\StringTok{print(pd.read\_csv("reports/cli\_linlags.csv").head())}
\OperatorTok{PY}
\end{Highlighting}
\end{Shaded}

\textbf{Deliverables:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A short note in README: ``Fresh‑clone test (date), environment, and
  exact commands used.''
\item
  The file \texttt{reports/cli\_linlags.csv} committed (small).
\item
  Optional: run
  \texttt{python\ -m\ projectname.cli\ score\ -\/-model\ tsgpt\ -\/-out\ reports/cli\_tsgpt.csv}
  if \texttt{models/tsgpt\_split1.pt} exists, and include that CSV too.
\end{enumerate}

\subsection{B. Tiny CI check (optional but
recommended)}\label{b.-tiny-ci-check-optional-but-recommended}

Add this job to \texttt{.github/workflows/ci.yml} after tests:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{name}\KeywordTok{:}\AttributeTok{ CLI smoke test}
\FunctionTok{  run}\KeywordTok{: }\CharTok{|}
\NormalTok{    pip install {-}e ".[dev]"}
\NormalTok{    python {-}m projectname.cli split{-}info}
\NormalTok{    python {-}m projectname.cli score {-}{-}model lin\_lags {-}{-}out reports/cli\_ci.csv}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor notes / gotchas}\label{instructor-notes-gotchas}

\begin{itemize}
\tightlist
\item
  In Colab, after modifying \texttt{pyproject.toml} or code under
  \texttt{src/}, re‑run \texttt{pip\ install\ -e\ .} or restart the
  kernel to pick up changes.
\item
  If \textbf{Torch} isn't available, the CLI still works with
  \texttt{naive}/\texttt{lin\_lags}.
\item
  If students renamed the package (not \texttt{projectname}), update
  imports and \texttt{pyproject.toml} accordingly.
\item
  Keep the CLI's error messages \textbf{actionable} (e.g., ``missing
  models/tsgpt\_split1.pt; falling back to lin\_lags'').
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Grading (pass/revise)}\label{grading-passrevise-11}

\begin{itemize}
\tightlist
\item
  \texttt{pip\ install\ -e\ .} succeeds; \texttt{import\ projectname}
  works.
\item
  \texttt{python\ -m\ projectname.cli\ split-info} prints splits.
\item
  \texttt{python\ -m\ projectname.cli\ score\ -\/-model\ lin\_lags}
  writes \texttt{reports/cli\_linlags.csv} and prints metrics.
\item
  README includes a \textbf{fresh‑clone} reproduction section.
\item
  (Optional) A simple CLI test passes in CI.
\end{itemize}

This session leaves you with a clean, \textbf{installable} project and a
\textbf{Typer CLI} that others (or future‑you) can run in one command,
setting you up for Session 24's \textbf{reproducibility audit} (and
optional FastAPI demo).

\bookmarksetup{startatroot}

\chapter{Session 24 --- Reproducibility audit \& optional
FastAPI}\label{session-24-reproducibility-audit-optional-fastapi}

Below is a complete lecture package for \textbf{Session 24 ---
Reproducibility audit \& optional FastAPI} (75 minutes). It includes a
timed agenda, slide talking points, a \textbf{Colab‑friendly in‑class
lab with copy‑paste code}, a lightweight \textbf{reproducibility audit
script}, and \textbf{homework with code} (tagging \texttt{v1.0-rc} + a
simple changelog generator + optional FastAPI ``hello score'' service).

\begin{quote}
\textbf{Assumptions}

\begin{itemize}
\tightlist
\item
  You've packaged your repo in Session 23 (editable install works:
  \texttt{pip\ install\ -e\ .}).
\item
  You have a working CLI (\texttt{python\ -m\ projectname.cli\ ...}).
\item
  Students are on Colab (Drive mounted) or local. We'll keep everything
  CPU‑fast.
\item
  Finance content remains \textbf{educational}, not trading advice.
\end{itemize}
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 24 --- Reproducibility audit \& optional FastAPI (75
min)}\label{session-24-reproducibility-audit-optional-fastapi-75-min}

\subsection{Learning goals}\label{learning-goals-23}

By the end, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Verify \textbf{end‑to‑end} reproducibility from a clean environment
  using a checklist and an automated script.
\item
  Create and persist a \textbf{run manifest} (commit hash, env, data
  checksums, seeds).
\item
  (Optional) Stand up a \textbf{FastAPI} ``hello score'' endpoint that
  wraps the package scoring logic.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-21}

\begin{itemize}
\tightlist
\item
  \textbf{(12 min)} Slides: what ``reproducible'' means; seeds,
  lockfiles, data snapshots, deterministic flags.
\item
  \textbf{(8 min)} Slides: manifests \& checksums; common pitfalls; CI
  scope (keep fast).
\item
  \textbf{(35 min)} \textbf{In‑class lab}: run the audit, generate a
  manifest, compare two runs, file issues.
\item
  \textbf{(10 min)} (Optional) FastAPI ``hello score'' demo.
\item
  \textbf{(10 min)} Wrap‑up \& homework brief.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slide notes (paste into your
deck)}\label{slide-notes-paste-into-your-deck}

\subsection{What ``reproducible'' means for this
course}\label{what-reproducible-means-for-this-course}

\begin{itemize}
\tightlist
\item
  Fresh‑clone →
  \texttt{make\ env\ \&\&\ pip\ install\ -e\ .\ \&\&\ python\ -m\ projectname.cli\ score\ ...}
  \textbf{succeeds}.
\item
  Outputs (metrics/CSV) are \textbf{identical} or within a \textbf{tiny
  tolerance} on the same hardware/runtime.
\item
  \textbf{Seeds} set consistently; \textbf{deterministic flags} used
  where available (Torch).
\item
  \textbf{Data is fixed}: versioned snapshot (in repo or via LFS)
  \textbf{or} cached API responses with \textbf{checksums}.
\end{itemize}

\subsection{Lockfiles \& manifests}\label{lockfiles-manifests}

\begin{itemize}
\tightlist
\item
  Keep \textbf{requirements.txt pinned} (exact versions) and also store
  a \textbf{freeze}:
  \texttt{pip\ freeze\ \textgreater{}\ requirements-lock.txt}.
\item
  Record a \textbf{manifest} per run: Git commit, dirty flag, Python \&
  lib versions, seed values, config, data file hashes, CLI args. Save as
  \texttt{reports/manifest.json}.
\end{itemize}

\subsection{Deterministic training \&
scoring}\label{deterministic-training-scoring}

\begin{itemize}
\tightlist
\item
  Torch: \texttt{torch.backends.cudnn.deterministic=True},
  \texttt{benchmark=False},
  \texttt{torch.use\_deterministic\_algorithms(True)} (when possible).
\item
  DataLoader: seeded generator + \texttt{worker\_init\_fn} to seed
  workers.
\item
  Sort/group data deterministically
  (\texttt{sort\_values({[}"ticker","date"{]})}).
\end{itemize}

\subsection{Common pitfalls}\label{common-pitfalls}

\begin{itemize}
\tightlist
\item
  Hidden internet calls (APIs) during scoring.
\item
  Unpinned dependencies.
\item
  Missing seeds in numpy, random, torch.
\item
  Dirty working tree (uncommitted changes).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (35 min)}\label{inclass-lab-35-min-8}

\begin{quote}
Run each block as its \textbf{own cell} in Colab. Replace
\texttt{REPO\_NAME} if needed. Partners \textbf{pair‑audit} and open
issues for anything not reproducible.
\end{quote}

\subsection{0) Mount \& prepare dirs}\label{mount-prepare-dirs}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}  \CommentTok{\# \textless{}{-} change}
\NormalTok{BASE\_DIR  }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR  }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, sys, platform, subprocess, json, hashlib, time}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"reports"}\NormalTok{,}\StringTok{"models"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"docs"}\NormalTok{,}\StringTok{"docs/figs"}\NormalTok{,}\StringTok{"data/processed"}\NormalTok{,}\StringTok{"data/raw"}\NormalTok{,}\StringTok{".github/workflows"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd(), }\StringTok{"| Python:"}\NormalTok{, sys.version.split()[}\DecValTok{0}\NormalTok{], }\StringTok{"| OS:"}\NormalTok{, platform.system())}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{1) Add a \textbf{Repro Audit Checklist} to
the
repo}{1) Add a Repro Audit Checklist to the repo}}\label{add-a-repro-audit-checklist-to-the-repo}

Create \texttt{docs/repro\_audit\_checklist.md}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\# Reproducibility Audit Checklist (Session 24)}

\FunctionTok{\#\# Environment}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Repo fresh{-}clones and installs: }\InformationTok{\textasciigrave{}make env \&\& pip install {-}e .\textasciigrave{}}
\SpecialStringTok{{-} }\VariableTok{[ ]} \InformationTok{\textasciigrave{}requirements.txt\textasciigrave{}}\NormalTok{ is pinned (== versions); }\InformationTok{\textasciigrave{}requirements{-}lock.txt\textasciigrave{}}\NormalTok{ exists}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Python version and OS noted in README}

\FunctionTok{\#\# Data}
\SpecialStringTok{{-} }\VariableTok{[ ]} \InformationTok{\textasciigrave{}data/processed/*\textasciigrave{}}\NormalTok{ has checksums recorded}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ No hidden network calls during scoring (}\InformationTok{\textasciigrave{}offline\textasciigrave{}}\NormalTok{/cached)}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Train/val split code is deterministic and documented}

\FunctionTok{\#\# Seeds \& determinism}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Seeds set for }\InformationTok{\textasciigrave{}random\textasciigrave{}}\NormalTok{, }\InformationTok{\textasciigrave{}numpy\textasciigrave{}}\NormalTok{, }\InformationTok{\textasciigrave{}torch\textasciigrave{}}\NormalTok{; DataLoader worker init seeded}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Torch deterministic flags set; no non{-}deterministic ops used}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Sorting by }\InformationTok{\textasciigrave{}["ticker","date"]\textasciigrave{}}\NormalTok{ before windowing}

\FunctionTok{\#\# CLI \& artifacts}
\SpecialStringTok{{-} }\VariableTok{[ ]} \InformationTok{\textasciigrave{}python {-}m projectname.cli split{-}info\textasciigrave{}}\NormalTok{ works}
\SpecialStringTok{{-} }\VariableTok{[ ]} \InformationTok{\textasciigrave{}python {-}m projectname.cli score {-}{-}model lin\_lags\textasciigrave{}}\NormalTok{ writes CSV}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ Two back{-}to{-}back runs produce identical metrics (within tolerance)}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ A }\InformationTok{\textasciigrave{}reports/manifest.json\textasciigrave{}}\NormalTok{ records commit hash, env, checksums, CLI args}

\FunctionTok{\#\# CI (fast)}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ A small CI job runs }\InformationTok{\textasciigrave{}python {-}m projectname.cli score {-}{-}model lin\_lags\textasciigrave{}}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ CI artifacts uploaded or printed}

\FunctionTok{\#\# Known deviations (explain/ticket links)}
\SpecialStringTok{{-} }\VariableTok{[ ]}\NormalTok{ ...}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Add a \textbf{simple data checksum}
helper (one cell to create the
file)}{2) Add a simple data checksum helper (one cell to create the file)}}\label{add-a-simple-data-checksum-helper-one-cell-to-create-the-file}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ hashlib, json, glob}

\KeywordTok{def}\NormalTok{ file\_sha256(path: }\BuiltInTok{str}\OperatorTok{|}\NormalTok{Path) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{str}\NormalTok{:}
\NormalTok{    h }\OperatorTok{=}\NormalTok{ hashlib.sha256()}
    \ControlFlowTok{with} \BuiltInTok{open}\NormalTok{(path, }\StringTok{"rb"}\NormalTok{) }\ImportTok{as}\NormalTok{ f:}
        \ControlFlowTok{for}\NormalTok{ chunk }\KeywordTok{in} \BuiltInTok{iter}\NormalTok{(}\KeywordTok{lambda}\NormalTok{: f.read(}\DecValTok{1}\OperatorTok{\textless{}\textless{}}\DecValTok{20}\NormalTok{), }\StringTok{b""}\NormalTok{):}
\NormalTok{            h.update(chunk)}
    \ControlFlowTok{return}\NormalTok{ h.hexdigest()}

\NormalTok{checks }\OperatorTok{=}\NormalTok{ \{\}}
\ControlFlowTok{for}\NormalTok{ pat }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/processed/*.parquet"}\NormalTok{,}\StringTok{"data/raw/*.parquet"}\NormalTok{,}\StringTok{"data/*.db"}\NormalTok{]:}
    \ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ glob.glob(pat):}
\NormalTok{        checks[p] }\OperatorTok{=}\NormalTok{ \{}\StringTok{"sha256"}\NormalTok{: file\_sha256(p), }\StringTok{"bytes"}\NormalTok{: Path(p).stat().st\_size\}}

\NormalTok{Path(}\StringTok{"reports/data\_checksums.json"}\NormalTok{).write\_text(json.dumps(checks, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote reports/data\_checksums.json with"}\NormalTok{, }\BuiltInTok{len}\NormalTok{(checks), }\StringTok{"entries"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) \textbf{Automated reproducibility audit}
script}{3) Automated reproducibility audit script}}\label{automated-reproducibility-audit-script}

Create \texttt{scripts/repro\_audit.py}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/usr/bin/env python}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ os, sys, json, time, platform, subprocess, hashlib, glob}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\NormalTok{TOL }\OperatorTok{=} \FloatTok{1e{-}12}  \CommentTok{\# numerical tolerance for equality of metrics}

\KeywordTok{def}\NormalTok{ sha256\_text(s: }\BuiltInTok{str}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{str}\NormalTok{:}
    \ImportTok{import}\NormalTok{ hashlib}
    \ControlFlowTok{return}\NormalTok{ hashlib.sha256(s.encode(}\StringTok{"utf{-}8"}\NormalTok{)).hexdigest()}

\KeywordTok{def}\NormalTok{ run(cmd: }\BuiltInTok{list}\NormalTok{[}\BuiltInTok{str}\NormalTok{]) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{tuple}\NormalTok{[}\BuiltInTok{int}\NormalTok{, }\BuiltInTok{str}\NormalTok{, }\BuiltInTok{str}\NormalTok{]:}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ subprocess.run(cmd, capture\_output}\OperatorTok{=}\VariableTok{True}\NormalTok{, text}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ p.returncode, p.stdout.strip(), p.stderr.strip()}

\KeywordTok{def}\NormalTok{ git\_info() }\OperatorTok{{-}\textgreater{}} \BuiltInTok{dict}\NormalTok{:}
    \KeywordTok{def}\NormalTok{ \_get(args):}
\NormalTok{        rc,out,err }\OperatorTok{=}\NormalTok{ run([}\StringTok{"git"}\NormalTok{]}\OperatorTok{+}\NormalTok{args)}
        \ControlFlowTok{return}\NormalTok{ out }\ControlFlowTok{if}\NormalTok{ rc}\OperatorTok{==}\DecValTok{0} \ControlFlowTok{else} \SpecialStringTok{f"NA(}\SpecialCharTok{\{}\NormalTok{err}\SpecialCharTok{\}}\SpecialStringTok{)"}
    \ControlFlowTok{return}\NormalTok{ \{}
        \StringTok{"commit"}\NormalTok{: \_get([}\StringTok{"rev{-}parse"}\NormalTok{,}\StringTok{"HEAD"}\NormalTok{]),}
        \StringTok{"dirty"}\NormalTok{: \_get([}\StringTok{"status"}\NormalTok{,}\StringTok{"{-}{-}porcelain"}\NormalTok{]) }\OperatorTok{!=} \StringTok{""}\NormalTok{,}
        \StringTok{"branch"}\NormalTok{: \_get([}\StringTok{"rev{-}parse"}\NormalTok{,}\StringTok{"{-}{-}abbrev{-}ref"}\NormalTok{,}\StringTok{"HEAD"}\NormalTok{]),}
        \StringTok{"remote"}\NormalTok{: \_get([}\StringTok{"remote"}\NormalTok{,}\StringTok{"{-}v"}\NormalTok{]),}
\NormalTok{    \}}

\KeywordTok{def}\NormalTok{ pip\_freeze() }\OperatorTok{{-}\textgreater{}} \BuiltInTok{str}\NormalTok{:}
\NormalTok{    rc,out,err }\OperatorTok{=}\NormalTok{ run([sys.executable,}\StringTok{"{-}m"}\NormalTok{,}\StringTok{"pip"}\NormalTok{,}\StringTok{"freeze"}\NormalTok{,}\StringTok{"{-}{-}exclude{-}editable"}\NormalTok{])}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ read\_csv\_first\_row(path: Path) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{dict}\NormalTok{:}
    \ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_csv(path)}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(df)}\OperatorTok{==}\DecValTok{0}\NormalTok{:}
        \ControlFlowTok{return}\NormalTok{ \{\}}
    \ControlFlowTok{return}\NormalTok{ df.iloc[:}\DecValTok{1}\NormalTok{].to\_dict(orient}\OperatorTok{=}\StringTok{"records"}\NormalTok{)[}\DecValTok{0}\NormalTok{]}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    start }\OperatorTok{=}\NormalTok{ time.time()}
\NormalTok{    manifest }\OperatorTok{=}\NormalTok{ \{}
        \StringTok{"ts"}\NormalTok{: time.strftime(}\StringTok{"\%Y{-}\%m{-}}\SpecialCharTok{\%d}\StringTok{ \%H:\%M:\%S"}\NormalTok{),}
        \StringTok{"python"}\NormalTok{: sys.version.split()[}\DecValTok{0}\NormalTok{],}
        \StringTok{"platform"}\NormalTok{: platform.platform(),}
        \StringTok{"git"}\NormalTok{: git\_info(),}
\NormalTok{    \}}

    \CommentTok{\# Add freeze \& hash}
\NormalTok{    freeze }\OperatorTok{=}\NormalTok{ pip\_freeze()}
\NormalTok{    Path(}\StringTok{"reports"}\NormalTok{).mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    Path(}\StringTok{"requirements{-}lock.txt"}\NormalTok{).write\_text(freeze)}
\NormalTok{    manifest[}\StringTok{"pip\_freeze\_sha256"}\NormalTok{] }\OperatorTok{=}\NormalTok{ sha256\_text(freeze)}

    \CommentTok{\# Data checksums (optional precomputed)}
\NormalTok{    checks\_path }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"reports/data\_checksums.json"}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ checks\_path.exists():}
\NormalTok{        manifest[}\StringTok{"data\_checksums"}\NormalTok{] }\OperatorTok{=}\NormalTok{ json.loads(checks\_path.read\_text())}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        manifest[}\StringTok{"data\_checksums"}\NormalTok{] }\OperatorTok{=}\NormalTok{ \{\}}

    \CommentTok{\# 1) Split info should work}
\NormalTok{    rc,out,err }\OperatorTok{=}\NormalTok{ run([sys.executable,}\StringTok{"{-}m"}\NormalTok{,}\StringTok{"projectname.cli"}\NormalTok{,}\StringTok{"split{-}info"}\NormalTok{])}
\NormalTok{    manifest[}\StringTok{"split\_info\_ok"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (rc}\OperatorTok{==}\DecValTok{0}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ rc}\OperatorTok{!=}\DecValTok{0}\NormalTok{:}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"split{-}info failed:"}\NormalTok{, err, }\BuiltInTok{file}\OperatorTok{=}\NormalTok{sys.stderr)}

    \CommentTok{\# 2) Score twice (lin\_lags) and compare metrics}
\NormalTok{    out1 }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"reports/cli\_linlags\_run1.csv"}\NormalTok{)}\OperatorTok{;}\NormalTok{ out2 }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"reports/cli\_linlags\_run2.csv"}\NormalTok{)}
\NormalTok{    cmd }\OperatorTok{=}\NormalTok{ [sys.executable,}\StringTok{"{-}m"}\NormalTok{,}\StringTok{"projectname.cli"}\NormalTok{,}\StringTok{"score"}\NormalTok{,}\StringTok{"{-}{-}model"}\NormalTok{,}\StringTok{"lin\_lags"}\NormalTok{,}\StringTok{"{-}{-}out"}\NormalTok{,}\BuiltInTok{str}\NormalTok{(out1)]}
\NormalTok{    rc1,\_,err1 }\OperatorTok{=}\NormalTok{ run(cmd)}
\NormalTok{    rc2,\_,err2 }\OperatorTok{=}\NormalTok{ run([}\OperatorTok{*}\NormalTok{cmd[:}\OperatorTok{{-}}\DecValTok{1}\NormalTok{], }\BuiltInTok{str}\NormalTok{(out2)])}
\NormalTok{    manifest[}\StringTok{"score\_run1\_ok"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (rc1}\OperatorTok{==}\DecValTok{0}\NormalTok{)}\OperatorTok{;}\NormalTok{ manifest[}\StringTok{"score\_run2\_ok"}\NormalTok{] }\OperatorTok{=}\NormalTok{ (rc2}\OperatorTok{==}\DecValTok{0}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ rc1}\OperatorTok{!=}\DecValTok{0} \KeywordTok{or}\NormalTok{ rc2}\OperatorTok{!=}\DecValTok{0}\NormalTok{:}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"score failed:"}\NormalTok{, err1 }\KeywordTok{or}\NormalTok{ err2, }\BuiltInTok{file}\OperatorTok{=}\NormalTok{sys.stderr)}

    \CommentTok{\# Compare metrics (read printed CSVs)}
    \ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\NormalTok{    ok\_equal }\OperatorTok{=} \VariableTok{True}
    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        d1 }\OperatorTok{=}\NormalTok{ pd.read\_csv(out1)}
\NormalTok{        d2 }\OperatorTok{=}\NormalTok{ pd.read\_csv(out2)}
        \CommentTok{\# Aggregate micro MAE across both runs}
        \ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{        mae1 }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(d1[}\StringTok{"y\_true"}\NormalTok{].values }\OperatorTok{{-}}\NormalTok{ d1[}\StringTok{"yhat"}\NormalTok{].values)))}
\NormalTok{        mae2 }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(d2[}\StringTok{"y\_true"}\NormalTok{].values }\OperatorTok{{-}}\NormalTok{ d2[}\StringTok{"yhat"}\NormalTok{].values)))}
\NormalTok{        manifest[}\StringTok{"metrics"}\NormalTok{] }\OperatorTok{=}\NormalTok{ \{}\StringTok{"run1\_mae"}\NormalTok{: mae1, }\StringTok{"run2\_mae"}\NormalTok{: mae2, }\StringTok{"abs\_diff"}\NormalTok{: }\BuiltInTok{abs}\NormalTok{(mae1}\OperatorTok{{-}}\NormalTok{mae2)\}}
\NormalTok{        ok\_equal }\OperatorTok{=} \BuiltInTok{abs}\NormalTok{(mae1 }\OperatorTok{{-}}\NormalTok{ mae2) }\OperatorTok{\textless{}=}\NormalTok{ TOL}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
\NormalTok{        ok\_equal }\OperatorTok{=} \VariableTok{False}
\NormalTok{        manifest[}\StringTok{"metrics\_error"}\NormalTok{] }\OperatorTok{=} \BuiltInTok{repr}\NormalTok{(e)}

\NormalTok{    manifest[}\StringTok{"ok\_equal\_within\_tol"}\NormalTok{] }\OperatorTok{=}\NormalTok{ ok\_equal}
\NormalTok{    manifest[}\StringTok{"elapsed\_sec"}\NormalTok{] }\OperatorTok{=} \BuiltInTok{round}\NormalTok{(time.time()}\OperatorTok{{-}}\NormalTok{start, }\DecValTok{2}\NormalTok{)}

\NormalTok{    mpath }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"reports/manifest.json"}\NormalTok{)}
\NormalTok{    mpath.write\_text(json.dumps(manifest, indent}\OperatorTok{=}\DecValTok{2}\NormalTok{))}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, mpath)}

    \CommentTok{\# Non{-}zero exit on failure}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ (manifest[}\StringTok{"split\_info\_ok"}\NormalTok{] }\KeywordTok{and}\NormalTok{ manifest[}\StringTok{"score\_run1\_ok"}\NormalTok{] }\KeywordTok{and}\NormalTok{ manifest[}\StringTok{"score\_run2\_ok"}\NormalTok{] }\KeywordTok{and}\NormalTok{ ok\_equal):}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Repro audit FAILED (see reports/manifest.json)."}\NormalTok{, }\BuiltInTok{file}\OperatorTok{=}\NormalTok{sys.stderr)}
\NormalTok{        sys.exit(}\DecValTok{2}\NormalTok{)}
    \ControlFlowTok{else}\NormalTok{:}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Repro audit PASSED."}\NormalTok{)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Make it executable and run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/repro\_audit.py}
\ExtensionTok{python}\NormalTok{ scripts/repro\_audit.py }\KeywordTok{||} \FunctionTok{true}
\end{Highlighting}
\end{Shaded}

You should see \texttt{reports/manifest.json},
\texttt{requirements-lock.txt}, and two
\texttt{reports/cli\_linlags\_run*.csv}. If the audit fails,
\textbf{open a GitHub issue} with the error and your manifest attached.

\subsection{4) Add Makefile + CI snippets
(fast)}\label{add-makefile-ci-snippets-fast}

Append to \texttt{Makefile}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.PHONY: lock repro{-}audit}
\NormalTok{lock: \#\# Write requirements{-}lock.txt from pip freeze}
\NormalTok{\textbackslash{}tpip freeze {-}{-}exclude{-}editable \textgreater{} requirements{-}lock.txt}

\NormalTok{repro{-}audit: \#\# Run fast reproducibility audit (lin\_lags only)}
\NormalTok{\textbackslash{}tpython scripts/repro\_audit.py}
\end{Highlighting}
\end{Shaded}

Add a tiny CI job (append to \texttt{.github/workflows/ci.yml}):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{name}\KeywordTok{:}\AttributeTok{ Repro audit (fast)}
\FunctionTok{  run}\KeywordTok{: }\CharTok{|}
\NormalTok{    pip install {-}e ".[dev]"}
\NormalTok{    python scripts/repro\_audit.py}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{(Optional) FastAPI ``hello score'' (10 min in class; copy‑paste
runnable)}\label{optional-fastapi-hello-score-10-min-in-class-copypaste-runnable}

\subsection{A. Minimal service}\label{a.-minimal-service}

Create \texttt{serve/app.py}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# serve/app.py}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{from}\NormalTok{ fastapi }\ImportTok{import}\NormalTok{ FastAPI, HTTPException, Query}
\ImportTok{from}\NormalTok{ pydantic }\ImportTok{import}\NormalTok{ BaseModel}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{from}\NormalTok{ projectname.config }\ImportTok{import}\NormalTok{ load\_config}
\ImportTok{from}\NormalTok{ projectname.utils.splits }\ImportTok{import}\NormalTok{ make\_rolling\_origin\_splits}
\ImportTok{from}\NormalTok{ projectname.utils.metrics }\ImportTok{import}\NormalTok{ mae, smape}
\ImportTok{from}\NormalTok{ projectname.models.baselines }\ImportTok{import}\NormalTok{ predict\_naive, predict\_lin\_lags}

\NormalTok{app }\OperatorTok{=}\NormalTok{ FastAPI(title}\OperatorTok{=}\StringTok{"Unified Stocks Scoring (Educational)"}\NormalTok{)}

\KeywordTok{class}\NormalTok{ ScoreRequest(BaseModel):}
\NormalTok{    model: }\BuiltInTok{str} \OperatorTok{=} \StringTok{"lin\_lags"}          \CommentTok{\# "naive" | "lin\_lags"}
\NormalTok{    split: }\BuiltInTok{int} \OperatorTok{=} \DecValTok{1}                   \CommentTok{\# use rolling{-}origin split id}
\NormalTok{    start: }\BuiltInTok{str} \OperatorTok{|} \VariableTok{None} \OperatorTok{=} \VariableTok{None}         \CommentTok{\# optional override}
\NormalTok{    end: }\BuiltInTok{str} \OperatorTok{|} \VariableTok{None} \OperatorTok{=} \VariableTok{None}

\KeywordTok{def}\NormalTok{ \_load\_df(cfg):}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.read\_parquet(cfg.data.features\_file)}
\NormalTok{    df[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.to\_datetime(df[}\StringTok{"date"}\NormalTok{])}
\NormalTok{    df[}\StringTok{"ticker"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"ticker"}\NormalTok{].astype(}\StringTok{"category"}\NormalTok{)}
    \ControlFlowTok{return}\NormalTok{ df.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).reset\_index(drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\AttributeTok{@app.get}\NormalTok{(}\StringTok{"/health"}\NormalTok{)}
\KeywordTok{def}\NormalTok{ health():}
    \ImportTok{import}\NormalTok{ subprocess}
    \KeywordTok{def}\NormalTok{ \_g(args): }
        \ControlFlowTok{try}\NormalTok{: }\ControlFlowTok{return}\NormalTok{ subprocess.check\_output([}\StringTok{"git"}\NormalTok{]}\OperatorTok{+}\NormalTok{args, text}\OperatorTok{=}\VariableTok{True}\NormalTok{).strip()}
        \ControlFlowTok{except} \PreprocessorTok{Exception}\NormalTok{: }\ControlFlowTok{return} \StringTok{"NA"}
    \ControlFlowTok{return}\NormalTok{ \{}\StringTok{"status"}\NormalTok{:}\StringTok{"ok"}\NormalTok{,}\StringTok{"commit"}\NormalTok{:\_g([}\StringTok{"rev{-}parse"}\NormalTok{,}\StringTok{"HEAD"}\NormalTok{])\}}

\AttributeTok{@app.post}\NormalTok{(}\StringTok{"/score"}\NormalTok{)}
\KeywordTok{def}\NormalTok{ score(req: ScoreRequest):}
\NormalTok{    cfg }\OperatorTok{=}\NormalTok{ load\_config(}\StringTok{"config/config.yaml"}\NormalTok{)}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ \_load\_df(cfg)}
\NormalTok{    feats }\OperatorTok{=}\NormalTok{ [c }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ cfg.features\_use }\ControlFlowTok{if}\NormalTok{ c }\KeywordTok{in}\NormalTok{ df.columns]}

    \ControlFlowTok{if}\NormalTok{ req.start }\KeywordTok{and}\NormalTok{ req.end:}
\NormalTok{        vstart, vend }\OperatorTok{=}\NormalTok{ pd.to\_datetime(req.start), pd.to\_datetime(req.end)}
\NormalTok{        dates }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(df[}\StringTok{"date"}\NormalTok{].unique())}
        \CommentTok{\# train = everything before vstart respecting train\_min (no embargo here for simplicity)}
\NormalTok{        idx }\OperatorTok{=} \BuiltInTok{next}\NormalTok{((i }\ControlFlowTok{for}\NormalTok{ i,d }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(dates) }\ControlFlowTok{if}\NormalTok{ d}\OperatorTok{\textgreater{}=}\NormalTok{vstart), }\VariableTok{None}\NormalTok{)}
        \ControlFlowTok{if}\NormalTok{ idx }\KeywordTok{is} \VariableTok{None} \KeywordTok{or}\NormalTok{ idx }\OperatorTok{\textless{}}\NormalTok{ cfg.}\BuiltInTok{eval}\NormalTok{.train\_min:}
            \ControlFlowTok{raise}\NormalTok{ HTTPException(}\DecValTok{400}\NormalTok{, detail}\OperatorTok{=}\StringTok{"Not enough history before start."}\NormalTok{)}
\NormalTok{        tstart, tend }\OperatorTok{=}\NormalTok{ dates[}\DecValTok{0}\NormalTok{], dates[idx}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        splits }\OperatorTok{=}\NormalTok{ make\_rolling\_origin\_splits(df[}\StringTok{"date"}\NormalTok{], cfg.}\BuiltInTok{eval}\NormalTok{.train\_min, cfg.}\BuiltInTok{eval}\NormalTok{.val\_size, cfg.}\BuiltInTok{eval}\NormalTok{.val\_size, cfg.}\BuiltInTok{eval}\NormalTok{.embargo)}
        \ControlFlowTok{try}\NormalTok{: tstart, tend, vstart, vend }\OperatorTok{=}\NormalTok{ splits[req.split}\OperatorTok{{-}}\DecValTok{1}\NormalTok{]}
        \ControlFlowTok{except} \PreprocessorTok{IndexError}\NormalTok{: }\ControlFlowTok{raise}\NormalTok{ HTTPException(}\DecValTok{400}\NormalTok{, detail}\OperatorTok{=}\StringTok{"Split not available."}\NormalTok{)}

\NormalTok{    train\_df }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{tstart)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{tend)].copy()}
\NormalTok{    val\_df   }\OperatorTok{=}\NormalTok{ df[(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textgreater{}=}\NormalTok{vstart)}\OperatorTok{\&}\NormalTok{(df[}\StringTok{"date"}\NormalTok{]}\OperatorTok{\textless{}=}\NormalTok{vend)].copy()}
    \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(val\_df)}\OperatorTok{==}\DecValTok{0}\NormalTok{: }\ControlFlowTok{raise}\NormalTok{ HTTPException(}\DecValTok{400}\NormalTok{, detail}\OperatorTok{=}\StringTok{"Empty validation slice"}\NormalTok{)}

    \ControlFlowTok{if}\NormalTok{ req.model }\OperatorTok{==} \StringTok{"naive"}\NormalTok{:}
\NormalTok{        preds }\OperatorTok{=}\NormalTok{ predict\_naive(val\_df)}
    \ControlFlowTok{elif}\NormalTok{ req.model }\OperatorTok{==} \StringTok{"lin\_lags"}\NormalTok{:}
        \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ feats: }\ControlFlowTok{raise}\NormalTok{ HTTPException(}\DecValTok{400}\NormalTok{, detail}\OperatorTok{=}\StringTok{"No feature columns available."}\NormalTok{)}
\NormalTok{        preds }\OperatorTok{=}\NormalTok{ predict\_lin\_lags(train\_df, val\_df, feats)}
    \ControlFlowTok{else}\NormalTok{:}
        \ControlFlowTok{raise}\NormalTok{ HTTPException(}\DecValTok{400}\NormalTok{, detail}\OperatorTok{=}\StringTok{"Model not supported in demo service"}\NormalTok{)}

\NormalTok{    y, yhat }\OperatorTok{=}\NormalTok{ preds[}\StringTok{"y\_true"}\NormalTok{], preds[}\StringTok{"yhat"}\NormalTok{]}
    \ControlFlowTok{return}\NormalTok{ \{}\StringTok{"model"}\NormalTok{: req.model,}
            \StringTok{"split"}\NormalTok{: req.split,}
            \StringTok{"start"}\NormalTok{: }\BuiltInTok{str}\NormalTok{(vstart.date()), }\StringTok{"end"}\NormalTok{: }\BuiltInTok{str}\NormalTok{(vend.date()),}
            \StringTok{"n"}\NormalTok{: }\BuiltInTok{int}\NormalTok{(}\BuiltInTok{len}\NormalTok{(preds)),}
            \StringTok{"mae"}\NormalTok{: mae(y,yhat), }\StringTok{"smape"}\NormalTok{: smape(y,yhat)\}}
\end{Highlighting}
\end{Shaded}

Install \& run locally:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{pip}\NormalTok{ install fastapi }\StringTok{"uvicorn[standard]"}
\ExtensionTok{python} \AttributeTok{{-}m}\NormalTok{ uvicorn serve.app:app }\AttributeTok{{-}{-}reload} \AttributeTok{{-}{-}port}\NormalTok{ 8000}
\end{Highlighting}
\end{Shaded}

Test (from another shell):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# health}
\ExtensionTok{curl} \AttributeTok{{-}s}\NormalTok{ localhost:8000/health }\KeywordTok{|} \ExtensionTok{jq}
\CommentTok{\# score}
\ExtensionTok{curl} \AttributeTok{{-}s} \AttributeTok{{-}X}\NormalTok{ POST localhost:8000/score }\AttributeTok{{-}H} \StringTok{"Content{-}Type: application/json"} \DataTypeTok{\textbackslash{}}
     \AttributeTok{{-}d} \StringTok{\textquotesingle{}\{"model":"lin\_lags","split":1\}\textquotesingle{}} \KeywordTok{|} \ExtensionTok{jq}
\end{Highlighting}
\end{Shaded}

\begin{quote}
\textbf{Note:} In Colab you can run uvicorn, but exposing the port
publicly requires a tunnel; treat this as \textbf{local optional}.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-11}

\begin{itemize}
\tightlist
\item
  Reproducibility is a \textbf{discipline}, not an afterthought: lock
  the env, freeze data, write manifests, and keep the audit
  \textbf{fast}.
\item
  CI should run the \textbf{fast path} (lin\_lags) to guard your repo.
\item
  Optional FastAPI shows how to wrap your scoring pipeline for
  interactive demos.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due before Session
25)}\label{homework-due-before-session-25}

\textbf{Goal:} Produce a \textbf{release candidate} with a
reproducibility statement, tag \texttt{v1.0-rc}, and resolve/triage
audit issues.

\subsection{A. Update README (repro
statement)}\label{a.-update-readme-repro-statement}

Add a ``Reproducibility'' section to \texttt{README.md}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{\#\# Reproducibility}

\SpecialStringTok{{-} }\NormalTok{Fresh clone:}
\end{Highlighting}
\end{Shaded}

make env pip install -e ``.{[}dev{]}'' python -m projectname.cli
split-info python -m projectname.cli score --model lin\_lags --out
reports/cli\_linlags.csv

\begin{verbatim}
- Audit:
\end{verbatim}

python scripts/repro\_audit.py

\begin{verbatim}
- We commit `requirements.txt` (pinned) and `requirements-lock.txt` (pip freeze hash: see `reports/manifest.json`).
- Data checksums in `reports/data_checksums.json`.
\end{verbatim}

\subsection{B. Generate a simple changelog
automatically}\label{b.-generate-a-simple-changelog-automatically}

Create \texttt{scripts/make\_changelog.py}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/usr/bin/env python}
\ImportTok{import}\NormalTok{ subprocess, datetime}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\KeywordTok{def}\NormalTok{ run(args): }
    \ControlFlowTok{return}\NormalTok{ subprocess.check\_output(args, text}\OperatorTok{=}\VariableTok{True}\NormalTok{).strip()}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    since }\OperatorTok{=} \StringTok{"v0.0.0"}
    \CommentTok{\# If previous tag exists, use it}
    \ControlFlowTok{try}\NormalTok{:}
\NormalTok{        last }\OperatorTok{=}\NormalTok{ run([}\StringTok{"git"}\NormalTok{,}\StringTok{"describe"}\NormalTok{,}\StringTok{"{-}{-}tags"}\NormalTok{,}\StringTok{"{-}{-}abbrev=0"}\NormalTok{])}
\NormalTok{        since }\OperatorTok{=}\NormalTok{ last}
    \ControlFlowTok{except} \PreprocessorTok{Exception}\NormalTok{:}
        \ControlFlowTok{pass}
\NormalTok{    log }\OperatorTok{=}\NormalTok{ run([}\StringTok{"git"}\NormalTok{,}\StringTok{"log"}\NormalTok{,}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{since}\SpecialCharTok{\}}\SpecialStringTok{..HEAD"}\NormalTok{,}\StringTok{"{-}{-}pretty=format:{-} \%h }\SpecialCharTok{\%s}\StringTok{ (\%an)"}\NormalTok{])}
\NormalTok{    today }\OperatorTok{=}\NormalTok{ datetime.date.today().isoformat()}
\NormalTok{    header }\OperatorTok{=} \SpecialStringTok{f"\#\# }\SpecialCharTok{\{}\NormalTok{today}\SpecialCharTok{\}}\SpecialStringTok{ v1.0{-}rc}\CharTok{\textbackslash{}n\textbackslash{}n}\SpecialStringTok{"}
\NormalTok{    body }\OperatorTok{=}\NormalTok{ header }\OperatorTok{+}\NormalTok{ (log }\ControlFlowTok{if}\NormalTok{ log }\ControlFlowTok{else} \StringTok{"{-} Initial release candidate}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"CHANGELOG.md"}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ p.exists():}
\NormalTok{        old }\OperatorTok{=}\NormalTok{ p.read\_text()}
\NormalTok{        p.write\_text(body }\OperatorTok{+} \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"} \OperatorTok{+}\NormalTok{ old)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        p.write\_text(}\StringTok{"\# Changelog}\CharTok{\textbackslash{}n\textbackslash{}n}\StringTok{"} \OperatorTok{+}\NormalTok{ body)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Updated CHANGELOG.md"}\NormalTok{)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\end{Highlighting}
\end{Shaded}

Run:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{chmod}\NormalTok{ +x scripts/make\_changelog.py}
\ExtensionTok{python}\NormalTok{ scripts/make\_changelog.py}
\FunctionTok{git}\NormalTok{ add CHANGELOG.md}
\FunctionTok{git}\NormalTok{ commit }\AttributeTok{{-}m} \StringTok{"chore: update changelog for v1.0{-}rc"}
\end{Highlighting}
\end{Shaded}

\subsection{C. Create \& push the tag}\label{c.-create-push-the-tag}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{git}\NormalTok{ tag }\AttributeTok{{-}a}\NormalTok{ v1.0{-}rc }\AttributeTok{{-}m} \StringTok{"Release candidate for reproducible pipeline"}
\FunctionTok{git}\NormalTok{ push origin v1.0{-}rc}
\end{Highlighting}
\end{Shaded}

\subsection{D. Close or triage audit
issues}\label{d.-close-or-triage-audit-issues}

\begin{itemize}
\item
  For each checklist failure, open or update a GitHub issue with:

  \begin{itemize}
  \tightlist
  \item
    Error snippet, your \texttt{reports/manifest.json}, steps to
    reproduce.
  \item
    Label: \texttt{repro}, \texttt{rc}.
  \item
    Either \textbf{closed} with a fix (commit hash referenced) or
    \textbf{triaged} with scope and owner.
  \end{itemize}
\end{itemize}

\subsection{E. (Optional) Add a CI artifact step to upload the
manifest}\label{e.-optional-add-a-ci-artifact-step-to-upload-the-manifest}

Append to \texttt{.github/workflows/ci.yml}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{name}\KeywordTok{:}\AttributeTok{ Upload manifest}
\AttributeTok{  }\FunctionTok{uses}\KeywordTok{:}\AttributeTok{ actions/upload{-}artifact@v4}
\AttributeTok{  }\FunctionTok{with}\KeywordTok{:}
\AttributeTok{    }\FunctionTok{name}\KeywordTok{:}\AttributeTok{ repro{-}manifest}
\AttributeTok{    }\FunctionTok{path}\KeywordTok{:}\AttributeTok{ reports/manifest.json}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor checklist (before
class)}\label{instructor-checklist-before-class-12}

\begin{itemize}
\tightlist
\item
  Dry‑run \texttt{scripts/repro\_audit.py} on a fresh runtime; verify it
  passes.
\item
  Ensure \texttt{projectname.cli} works without internet (no hidden API
  calls).
\item
  Be ready to demo FastAPI locally if time permits.
\end{itemize}

\section{Grading (pass/revise)}\label{grading-passrevise-12}

\begin{itemize}
\tightlist
\item
  \texttt{scripts/repro\_audit.py} runs and writes
  \texttt{reports/manifest.json}.
\item
  \texttt{requirements-lock.txt} present and hash recorded in manifest.
\item
  At least one \textbf{issue} opened (if a failure) or a note ``All
  checks passed'' with manifest attached.
\item
  \texttt{CHANGELOG.md} updated by script; tag \texttt{v1.0-rc} exists
  and is pushed.
\item
  README has a clear \textbf{repro statement}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Notes and gotchas}\label{notes-and-gotchas}

\begin{itemize}
\tightlist
\item
  \textbf{Tolerance} for metric equality is set very tight
  (\texttt{1e-12}). If your environment shows tiny FP drift, relax to
  \texttt{1e-9}.
\item
  If you rely on \textbf{GPU} kernels that are non‑deterministic, keep
  the audit on \textbf{CPU} or replace those ops.
\item
  If any \textbf{models/\ldots pt} checkpoints are referenced, keep them
  out of the audit path (we only audit \textbf{scoring with lin\_lags}
  here to keep CI fast).
\end{itemize}

This session gets you to a \textbf{release‑candidate} state: a repo that
\textbf{fresh‑clones and scores deterministically}, with a
\textbf{manifest}, a \textbf{changelog}, and an optional \textbf{service
wrapper}, ready for Session 25's communication \& poster work.

\bookmarksetup{startatroot}

\chapter{Session 25 --- Poster + Abstract
Workshop}\label{session-25-poster-abstract-workshop}

Below is a complete lecture package for \textbf{Session 25 --- Poster +
Abstract Workshop} (75 minutes). It includes a timed agenda, instructor
talking points (slides outline), a \textbf{Colab‑friendly in‑class lab
with copy‑paste code} that generates three polished figures and a Quarto
poster skeleton, plus \textbf{homework with copy‑paste code} to validate
the abstract length and render a draft poster.

\begin{quote}
\textbf{Educational use only --- not trading advice.} Assumes your
Drive‑mounted repo (e.g., \texttt{unified-stocks-teamX}), and that you
have at least one set of predictions/metrics from earlier sessions
(e.g., \texttt{reports/cli\_linlags.csv},
\texttt{reports/unified\_gru\_split1\_per\_ticker.csv},
\texttt{reports/tsgpt\_split1\_metrics.csv}). All code includes
\textbf{safe fallbacks} that synthesize minimal data so the lab runs
even if files are missing.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 25 --- Poster + Abstract Workshop (75
min)}\label{session-25-poster-abstract-workshop-75-min}

\subsection{Learning goals}\label{learning-goals-24}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Craft a concise \textbf{story arc} (Problem → Data → Method →
  Evaluation → Results → Limits → Takeaways).
\item
  Produce and polish \textbf{three key figures}:

  \begin{itemize}
  \tightlist
  \item
    \textbf{Model comparison} (baseline vs LSTM/GRU vs
    tiny‑Transformer/TS‑GPT).
  \item
    \textbf{Regime breakdown} (errors by volatility regime).
  \item
    \textbf{Ablation} (TS‑GPT hyperparam sweep).
  \end{itemize}
\item
  Assemble a \textbf{one‑page poster} (Quarto HTML or PDF) and draft a
  \textbf{250‑word abstract}.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-22}

\begin{itemize}
\tightlist
\item
  \textbf{(10 min)} Slides: poster anatomy, audience \& narrative,
  figure design rules.
\item
  \textbf{(10 min)} Slides: abstract structure, model‑card notes \&
  caveats.
\item
  \textbf{(40 min)} \textbf{In‑class lab}: generate three figures →
  create \texttt{reports/poster.qmd} → render draft.
\item
  \textbf{(15 min)} Share \& critique: 3‑minute lightning review per
  team; assign homework.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides --- talking points (drop into your
deck)}\label{slides-talking-points-drop-into-your-deck-4}

\subsection{1) Poster anatomy (for
non‑experts)}\label{poster-anatomy-for-nonexperts}

\begin{itemize}
\tightlist
\item
  \textbf{Title} (problem \& claim), \textbf{Authors/Affiliation},
  \textbf{Contact}.
\item
  \textbf{Left column:} Problem \& Data (1--2 bullets each),
  \textbf{Method sketch} (one diagram).
\item
  \textbf{Center:} \textbf{Key results} (3 figures), 1--2 sentences per
  figure (what/why it matters).
\item
  \textbf{Right column:} \textbf{Limits} (leakage, data shifts),
  \textbf{Ethics \& caveats}, \textbf{Takeaways}.
\end{itemize}

\subsection{2) Figure design (fast
rules)}\label{figure-design-fast-rules}

\begin{itemize}
\tightlist
\item
  Use \textbf{clear labels/units}, readable fonts (≥ 11--12 pt on
  poster), concise legends.
\item
  Order bars left→right by magnitude; add \textbf{error bars} where
  possible.
\item
  Avoid clutter: minimal grid; \textbf{colorblind‑safe} if you pick
  colors; don't rely only on color (shapes/line styles help).
\item
  Always include a 10‑word \textbf{caption} and a one‑line
  \textbf{takeaway} near the figure.
\end{itemize}

\subsection{3) Abstract (≈250 words, plain
English)}\label{abstract-250-words-plain-english}

\begin{itemize}
\tightlist
\item
  \textbf{Motivation} in 1--2 sentences; \textbf{data \& setup} in 1--2;
  \textbf{methods} in 2--3; \textbf{results} with numbers;
  \textbf{limits} and \textbf{next steps}.
\item
  No internal jargon; define acronyms (e.g., MAE = mean absolute error)
  on first use.
\end{itemize}

\subsection{4) Model card essentials (1 small box on the
poster)}\label{model-card-essentials-1-small-box-on-the-poster}

\begin{itemize}
\tightlist
\item
  \textbf{Intended use} (educational baseline forecasting).
\item
  \textbf{Data} (tickers \& dates, pre‑processing, leakage controls).
\item
  \textbf{Metrics} (MAE, sMAPE, by regime).
\item
  \textbf{Limitations} (non‑stationarity, survivorship bias, no live
  trading).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (40 min,
Colab‑friendly)}\label{inclass-lab-40-min-colabfriendly}

\begin{quote}
Run each block as its \textbf{own cell}. Change \texttt{REPO\_NAME} if
needed.
\end{quote}

\subsection{0) Setup \& folders}\label{setup-folders-1}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}  \CommentTok{\# \textless{}{-} change to your repo name}
\NormalTok{BASE\_DIR  }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR  }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, sys, platform}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"reports"}\NormalTok{,}\StringTok{"docs/figs"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd(), }\StringTok{"| Python:"}\NormalTok{, sys.version.split()[}\DecValTok{0}\NormalTok{], }\StringTok{"| OS:"}\NormalTok{, platform.system())}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{1) Script to build poster figures (create
\texttt{scripts/make\_poster\_figs.py})}{1) Script to build poster figures (create scripts/make\_poster\_figs.py)}}\label{script-to-build-poster-figures-create-scriptsmake_poster_figs.py}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\%\%}\NormalTok{bash}
\NormalTok{cat }\OperatorTok{\textgreater{}}\NormalTok{ scripts}\OperatorTok{/}\NormalTok{make\_poster\_figs.py }\OperatorTok{\textless{}\textless{}} \StringTok{\textquotesingle{}PY\textquotesingle{}}
\CommentTok{\#!/usr/bin/env python}
\ImportTok{from}\NormalTok{ \_\_future\_\_ }\ImportTok{import}\NormalTok{ annotations}
\ImportTok{import}\NormalTok{ os, math, glob, json}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np, pandas }\ImportTok{as}\NormalTok{ pd}
\ImportTok{import}\NormalTok{ matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt}

\NormalTok{FIGDIR }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"docs/figs"}\NormalTok{)}\OperatorTok{;}\NormalTok{ FIGDIR.mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{REPDIR }\OperatorTok{=}\NormalTok{ Path(}\StringTok{"reports"}\NormalTok{)}\OperatorTok{;}\NormalTok{ REPDIR.mkdir(exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\KeywordTok{def}\NormalTok{ \_safe\_read\_csv(path: }\BuiltInTok{str}\OperatorTok{|}\NormalTok{Path) }\OperatorTok{{-}\textgreater{}}\NormalTok{ pd.DataFrame}\OperatorTok{|}\VariableTok{None}\NormalTok{:}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ Path(path)}
    \ControlFlowTok{try}\NormalTok{:}
        \ControlFlowTok{if}\NormalTok{ p.exists():}
            \ControlFlowTok{return}\NormalTok{ pd.read\_csv(p)}
    \ControlFlowTok{except} \PreprocessorTok{Exception} \ImportTok{as}\NormalTok{ e:}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"WARN cannot read"}\NormalTok{, p, e)}
    \ControlFlowTok{return} \VariableTok{None}

\KeywordTok{def}\NormalTok{ \_synthesize\_predictions(n}\OperatorTok{=}\DecValTok{800}\NormalTok{, tickers}\OperatorTok{=}\NormalTok{(}\StringTok{"AAPL"}\NormalTok{,}\StringTok{"MSFT"}\NormalTok{,}\StringTok{"GOOGL"}\NormalTok{,}\StringTok{"AMZN"}\NormalTok{,}\StringTok{"NVDA"}\NormalTok{,}\StringTok{"META"}\NormalTok{)):}
\NormalTok{    rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{0}\NormalTok{)}
\NormalTok{    frames}\OperatorTok{=}\NormalTok{[]}
    \ControlFlowTok{for}\NormalTok{ t }\KeywordTok{in}\NormalTok{ tickers:}
\NormalTok{        y }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.012}\NormalTok{, size}\OperatorTok{=}\NormalTok{n).astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        e\_lin }\OperatorTok{=}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{, }\FloatTok{0.009}\NormalTok{, size}\OperatorTok{=}\NormalTok{n).astype(}\StringTok{"float32"}\NormalTok{)}
\NormalTok{        df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{"ticker"}\NormalTok{:t, }\StringTok{"y\_true"}\NormalTok{:y, }\StringTok{"yhat"}\NormalTok{:y}\OperatorTok{+}\NormalTok{e\_lin\})}
\NormalTok{        frames.append(df)}
\NormalTok{    out }\OperatorTok{=}\NormalTok{ pd.concat(frames, ignore\_index}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    out[}\StringTok{"date"}\NormalTok{] }\OperatorTok{=}\NormalTok{ pd.date\_range(}\StringTok{"2023{-}01{-}03"}\NormalTok{, periods}\OperatorTok{=}\BuiltInTok{len}\NormalTok{(out), freq}\OperatorTok{=}\StringTok{"B"}\NormalTok{)}
\NormalTok{    out[}\StringTok{"method"}\NormalTok{] }\OperatorTok{=} \StringTok{"lin\_lags"}
    \ControlFlowTok{return}\NormalTok{ out}

\KeywordTok{def}\NormalTok{ \_mae(y,yhat): }\ControlFlowTok{return} \BuiltInTok{float}\NormalTok{(np.mean(np.}\BuiltInTok{abs}\NormalTok{(np.asarray(y)}\OperatorTok{{-}}\NormalTok{np.asarray(yhat))))}

\KeywordTok{def}\NormalTok{ model\_compare():}
    \CommentTok{"""Build a bar chart comparing MAE across models (aggregate \& per{-}ticker if available)."""}
    \CommentTok{\# Load LIN\_LAGS predictions from CLI}
\NormalTok{    lin }\OperatorTok{=}\NormalTok{ \_safe\_read\_csv(}\StringTok{"reports/cli\_linlags.csv"}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ lin }\KeywordTok{is} \VariableTok{None} \KeywordTok{or} \KeywordTok{not}\NormalTok{ \{}\StringTok{"y\_true"}\NormalTok{,}\StringTok{"yhat"}\NormalTok{,}\StringTok{"ticker"}\NormalTok{\}.issubset(lin.columns):}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Using synthetic LIN\_LAGS predictions."}\NormalTok{)}
\NormalTok{        lin }\OperatorTok{=}\NormalTok{ \_synthesize\_predictions()}
\NormalTok{    lin[}\StringTok{"model"}\NormalTok{] }\OperatorTok{=} \StringTok{"lin\_lags"}
\NormalTok{    m\_lin }\OperatorTok{=}\NormalTok{ \_mae(lin[}\StringTok{"y\_true"}\NormalTok{], lin[}\StringTok{"yhat"}\NormalTok{])}

    \CommentTok{\# GRU (per{-}ticker metrics if available)}
\NormalTok{    gru\_pt }\OperatorTok{=}\NormalTok{ \_safe\_read\_csv(}\StringTok{"reports/unified\_gru\_split1\_per\_ticker.csv"}\NormalTok{)}
\NormalTok{    m\_gru }\OperatorTok{=}\NormalTok{ gru\_pt[}\StringTok{"mae"}\NormalTok{].mean() }\ControlFlowTok{if}\NormalTok{ (gru\_pt }\KeywordTok{is} \KeywordTok{not} \VariableTok{None} \KeywordTok{and} \StringTok{"mae"} \KeywordTok{in}\NormalTok{ gru\_pt.columns }\KeywordTok{and} \BuiltInTok{len}\NormalTok{(gru\_pt)}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{) }\ControlFlowTok{else} \VariableTok{None}

    \CommentTok{\# TS{-}GPT (aggregate metrics)}
\NormalTok{    tsgpt }\OperatorTok{=}\NormalTok{ \_safe\_read\_csv(}\StringTok{"reports/tsgpt\_split1\_metrics.csv"}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ tsgpt }\KeywordTok{is} \KeywordTok{not} \VariableTok{None} \KeywordTok{and} \StringTok{"val\_mae"} \KeywordTok{in}\NormalTok{ tsgpt.columns }\KeywordTok{and} \BuiltInTok{len}\NormalTok{(tsgpt)}\OperatorTok{\textgreater{}}\DecValTok{0}\NormalTok{:}
\NormalTok{        m\_tsgpt }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(tsgpt[}\StringTok{"val\_mae"}\NormalTok{].iloc[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{])}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        m\_tsgpt }\OperatorTok{=} \VariableTok{None}

\NormalTok{    rows}\OperatorTok{=}\NormalTok{[\{}\StringTok{"model"}\NormalTok{:}\StringTok{"lin\_lags"}\NormalTok{,}\StringTok{"val\_mae"}\NormalTok{:m\_lin\}]}
    \ControlFlowTok{if}\NormalTok{ m\_gru }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{:   rows.append(\{}\StringTok{"model"}\NormalTok{:}\StringTok{"gru"}\NormalTok{,}\StringTok{"val\_mae"}\NormalTok{:m\_gru\})}
    \ControlFlowTok{if}\NormalTok{ m\_tsgpt }\KeywordTok{is} \KeywordTok{not} \VariableTok{None}\NormalTok{: rows.append(\{}\StringTok{"model"}\NormalTok{:}\StringTok{"tsgpt"}\NormalTok{,}\StringTok{"val\_mae"}\NormalTok{:m\_tsgpt\})}
\NormalTok{    comp }\OperatorTok{=}\NormalTok{ pd.DataFrame(rows).sort\_values(}\StringTok{"val\_mae"}\NormalTok{)}
\NormalTok{    comp.to\_csv(REPDIR}\OperatorTok{/}\StringTok{"model\_compare.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

    \CommentTok{\# Bar plot}
\NormalTok{    plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{6}\NormalTok{,}\FloatTok{3.2}\NormalTok{))}
\NormalTok{    x }\OperatorTok{=}\NormalTok{ np.arange(}\BuiltInTok{len}\NormalTok{(comp))}
\NormalTok{    plt.bar(x, comp[}\StringTok{"val\_mae"}\NormalTok{].values)}
\NormalTok{    plt.xticks(x, comp[}\StringTok{"model"}\NormalTok{].tolist())}
\NormalTok{    plt.ylabel(}\StringTok{"Validation MAE"}\NormalTok{)}
\NormalTok{    plt.title(}\StringTok{"Model Comparison (lower is better)"}\NormalTok{)}
\NormalTok{    plt.tight\_layout()}
\NormalTok{    plt.savefig(FIGDIR}\OperatorTok{/}\StringTok{"model\_compare.png"}\NormalTok{, dpi}\OperatorTok{=}\DecValTok{160}\NormalTok{)}
\NormalTok{    plt.close()}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, FIGDIR}\OperatorTok{/}\StringTok{"model\_compare.png"}\NormalTok{)}

\KeywordTok{def}\NormalTok{ regime\_breakdown():}
    \CommentTok{"""Compute MAE by volatility regime using LIN\_LAGS predictions + returns variance proxy."""}
\NormalTok{    lin }\OperatorTok{=}\NormalTok{ \_safe\_read\_csv(}\StringTok{"reports/cli\_linlags.csv"}\NormalTok{)}
\NormalTok{    base }\OperatorTok{=} \VariableTok{None}
    \CommentTok{\# Try to load a returns file to compute rolling volatility}
    \ControlFlowTok{for}\NormalTok{ cand }\KeywordTok{in}\NormalTok{ [}\StringTok{"data/processed/features\_v1.parquet"}\NormalTok{,}\StringTok{"data/processed/returns.parquet"}\NormalTok{]:}
        \ControlFlowTok{try}\NormalTok{:}
            \ControlFlowTok{if}\NormalTok{ Path(cand).exists():}
\NormalTok{                base }\OperatorTok{=}\NormalTok{ pd.read\_parquet(cand)}
                \ControlFlowTok{break}
        \ControlFlowTok{except} \PreprocessorTok{Exception}\NormalTok{: }\ControlFlowTok{pass}
    \ControlFlowTok{if}\NormalTok{ lin }\KeywordTok{is} \VariableTok{None}\NormalTok{:}
\NormalTok{        lin }\OperatorTok{=}\NormalTok{ \_synthesize\_predictions(n}\OperatorTok{=}\DecValTok{400}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ base }\KeywordTok{is} \VariableTok{None} \KeywordTok{or} \KeywordTok{not}\NormalTok{ \{}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{\}.issubset(base.columns):}
        \CommentTok{\# fabricate a simple volatility proxy from y\_true}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Volatility base missing — using synthetic regimes from residual std."}\NormalTok{)}
\NormalTok{        tmp }\OperatorTok{=}\NormalTok{ lin.copy()}
\NormalTok{        tmp[}\StringTok{"resid"}\NormalTok{] }\OperatorTok{=}\NormalTok{ lin[}\StringTok{"y\_true"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ lin[}\StringTok{"yhat"}\NormalTok{]}
\NormalTok{        tmp[}\StringTok{"vol"}\NormalTok{] }\OperatorTok{=}\NormalTok{ tmp.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"resid"}\NormalTok{].transform(}\KeywordTok{lambda}\NormalTok{ s: s.rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std())}
\NormalTok{        base }\OperatorTok{=}\NormalTok{ tmp[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{,}\StringTok{"vol"}\NormalTok{]]}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        base }\OperatorTok{=}\NormalTok{ base.sort\_values([}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{]).copy()}
        \ControlFlowTok{if} \StringTok{"log\_return"} \KeywordTok{in}\NormalTok{ base.columns:}
\NormalTok{            base[}\StringTok{"vol"}\NormalTok{] }\OperatorTok{=}\NormalTok{ base.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"log\_return"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{,drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
        \ControlFlowTok{elif} \StringTok{"r\_1d"} \KeywordTok{in}\NormalTok{ base.columns:}
\NormalTok{            base[}\StringTok{"vol"}\NormalTok{] }\OperatorTok{=}\NormalTok{ base.groupby(}\StringTok{"ticker"}\NormalTok{)[}\StringTok{"r\_1d"}\NormalTok{].rolling(}\DecValTok{20}\NormalTok{, min\_periods}\OperatorTok{=}\DecValTok{20}\NormalTok{).std().reset\_index(level}\OperatorTok{=}\DecValTok{0}\NormalTok{,drop}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
        \ControlFlowTok{else}\NormalTok{:}
\NormalTok{            base[}\StringTok{"vol"}\NormalTok{] }\OperatorTok{=}\NormalTok{ base.groupby(}\StringTok{"ticker"}\NormalTok{).cumcount() }\OperatorTok{*} \FloatTok{0.0}  \CommentTok{\# fallback}
\NormalTok{        base }\OperatorTok{=}\NormalTok{ base[[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{,}\StringTok{"vol"}\NormalTok{]]}
    \CommentTok{\# Merge}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ lin.merge(base, on}\OperatorTok{=}\NormalTok{[}\StringTok{"ticker"}\NormalTok{,}\StringTok{"date"}\NormalTok{], how}\OperatorTok{=}\StringTok{"left"}\NormalTok{)}
\NormalTok{    q1, q2 }\OperatorTok{=}\NormalTok{ df[}\StringTok{"vol"}\NormalTok{].quantile([}\DecValTok{1}\OperatorTok{/}\DecValTok{3}\NormalTok{, }\DecValTok{2}\OperatorTok{/}\DecValTok{3}\NormalTok{])}
    \KeywordTok{def}\NormalTok{ regime(v):}
        \ControlFlowTok{if}\NormalTok{ v}\OperatorTok{\textless{}=}\NormalTok{q1: }\ControlFlowTok{return} \StringTok{"low"}
        \ControlFlowTok{if}\NormalTok{ v}\OperatorTok{\textless{}=}\NormalTok{q2: }\ControlFlowTok{return} \StringTok{"med"}
        \ControlFlowTok{return} \StringTok{"high"}
\NormalTok{    df[}\StringTok{"regime"}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{"vol"}\NormalTok{].}\BuiltInTok{apply}\NormalTok{(regime)}
\NormalTok{    agg }\OperatorTok{=}\NormalTok{ df.groupby(}\StringTok{"regime"}\NormalTok{).}\BuiltInTok{apply}\NormalTok{(}\KeywordTok{lambda}\NormalTok{ g: \_mae(g[}\StringTok{"y\_true"}\NormalTok{], g[}\StringTok{"yhat"}\NormalTok{])).reset\_index(name}\OperatorTok{=}\StringTok{"mae"}\NormalTok{)}
\NormalTok{    agg }\OperatorTok{=}\NormalTok{ agg.sort\_values(}\StringTok{"mae"}\NormalTok{)}
\NormalTok{    agg.to\_csv(REPDIR}\OperatorTok{/}\StringTok{"regime\_breakdown.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

    \CommentTok{\# Bar plot}
\NormalTok{    plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{6}\NormalTok{,}\FloatTok{3.2}\NormalTok{))}
\NormalTok{    x }\OperatorTok{=}\NormalTok{ np.arange(}\BuiltInTok{len}\NormalTok{(agg))}
\NormalTok{    plt.bar(x, agg[}\StringTok{"mae"}\NormalTok{].values)}
\NormalTok{    plt.xticks(x, agg[}\StringTok{"regime"}\NormalTok{].tolist())}
\NormalTok{    plt.ylabel(}\StringTok{"MAE"}\NormalTok{)}
\NormalTok{    plt.title(}\StringTok{"Error by Volatility Regime"}\NormalTok{)}
\NormalTok{    plt.tight\_layout()}
\NormalTok{    plt.savefig(FIGDIR}\OperatorTok{/}\StringTok{"regime\_breakdown.png"}\NormalTok{, dpi}\OperatorTok{=}\DecValTok{160}\NormalTok{)}
\NormalTok{    plt.close()}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, FIGDIR}\OperatorTok{/}\StringTok{"regime\_breakdown.png"}\NormalTok{)}

\KeywordTok{def}\NormalTok{ ablation\_plot():}
    \CommentTok{"""Plot a simple heatmap for TS{-}GPT ablations if available; else synthesize."""}
\NormalTok{    paths }\OperatorTok{=}\NormalTok{ [p }\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"reports/tsgpt\_ablation\_summary.csv"}\NormalTok{,}\StringTok{"reports/tinygpt\_ablation\_summary.csv"}\NormalTok{] }\ControlFlowTok{if}\NormalTok{ Path(p).exists()]}
    \ControlFlowTok{if}\NormalTok{ paths:}
\NormalTok{        ab }\OperatorTok{=}\NormalTok{ pd.read\_csv(paths[}\DecValTok{0}\NormalTok{])}
    \ControlFlowTok{else}\NormalTok{:}
        \CommentTok{\# synthesize small ablation grid}
\NormalTok{        rng }\OperatorTok{=}\NormalTok{ np.random.default\_rng(}\DecValTok{1}\NormalTok{)}
\NormalTok{        ab }\OperatorTok{=}\NormalTok{ pd.DataFrame([}
\NormalTok{            \{}\StringTok{"ctx"}\NormalTok{: c, }\StringTok{"n\_head"}\NormalTok{: h, }\StringTok{"dropout"}\NormalTok{: d, }\StringTok{"val\_mae"}\NormalTok{: }\FloatTok{0.010} \OperatorTok{+}\NormalTok{ rng.normal(}\DecValTok{0}\NormalTok{,}\FloatTok{0.0008}\NormalTok{)\}}
            \ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ [}\DecValTok{32}\NormalTok{,}\DecValTok{64}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ h }\KeywordTok{in}\NormalTok{ [}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{] }\ControlFlowTok{for}\NormalTok{ d }\KeywordTok{in}\NormalTok{ [}\FloatTok{0.0}\NormalTok{,}\FloatTok{0.1}\NormalTok{]}
\NormalTok{        ])}
    \CommentTok{\# Prefer ctx vs n\_head for each dropout (two panels by saving two images)}
    \ControlFlowTok{for}\NormalTok{ d }\KeywordTok{in} \BuiltInTok{sorted}\NormalTok{(ab[}\StringTok{"dropout"}\NormalTok{].unique()):}
\NormalTok{        sub }\OperatorTok{=}\NormalTok{ ab[ab[}\StringTok{"dropout"}\NormalTok{]}\OperatorTok{==}\NormalTok{d].copy()}
\NormalTok{        ctxs }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(sub[}\StringTok{"ctx"}\NormalTok{].unique())}
\NormalTok{        heads }\OperatorTok{=} \BuiltInTok{sorted}\NormalTok{(sub[}\StringTok{"n\_head"}\NormalTok{].unique())}
\NormalTok{        grid }\OperatorTok{=}\NormalTok{ np.full((}\BuiltInTok{len}\NormalTok{(ctxs), }\BuiltInTok{len}\NormalTok{(heads)), np.nan)}
        \ControlFlowTok{for}\NormalTok{ i,c }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(ctxs):}
            \ControlFlowTok{for}\NormalTok{ j,h }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(heads):}
\NormalTok{                rows }\OperatorTok{=}\NormalTok{ sub[(sub[}\StringTok{"ctx"}\NormalTok{]}\OperatorTok{==}\NormalTok{c) }\OperatorTok{\&}\NormalTok{ (sub[}\StringTok{"n\_head"}\NormalTok{]}\OperatorTok{==}\NormalTok{h)]}
                \ControlFlowTok{if} \BuiltInTok{len}\NormalTok{(rows): grid[i,j] }\OperatorTok{=} \BuiltInTok{float}\NormalTok{(rows.iloc[}\OperatorTok{{-}}\DecValTok{1}\NormalTok{][}\StringTok{"val\_mae"}\NormalTok{])}
\NormalTok{        plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\FloatTok{5.2}\NormalTok{,}\FloatTok{3.8}\NormalTok{))}
\NormalTok{        plt.imshow(grid, aspect}\OperatorTok{=}\StringTok{"auto"}\NormalTok{, origin}\OperatorTok{=}\StringTok{"lower"}\NormalTok{)}
\NormalTok{        plt.colorbar(label}\OperatorTok{=}\StringTok{"Val MAE"}\NormalTok{)}
\NormalTok{        plt.xticks(np.arange(}\BuiltInTok{len}\NormalTok{(heads)), [}\BuiltInTok{str}\NormalTok{(h) }\ControlFlowTok{for}\NormalTok{ h }\KeywordTok{in}\NormalTok{ heads])}\OperatorTok{;}\NormalTok{ plt.xlabel(}\StringTok{"n\_head"}\NormalTok{)}
\NormalTok{        plt.yticks(np.arange(}\BuiltInTok{len}\NormalTok{(ctxs)), [}\BuiltInTok{str}\NormalTok{(c) }\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ ctxs])}\OperatorTok{;}\NormalTok{   plt.ylabel(}\StringTok{"context length"}\NormalTok{)}
\NormalTok{        plt.title(}\SpecialStringTok{f"TS{-}GPT Ablation (dropout=}\SpecialCharTok{\{}\NormalTok{d}\SpecialCharTok{\}}\SpecialStringTok{)"}\NormalTok{)}
\NormalTok{        plt.tight\_layout()}
\NormalTok{        fn }\OperatorTok{=}\NormalTok{ FIGDIR}\OperatorTok{/}\SpecialStringTok{f"ablation\_dropout\_}\SpecialCharTok{\{}\BuiltInTok{str}\NormalTok{(d)}\SpecialCharTok{.}\NormalTok{replace(}\StringTok{\textquotesingle{}.\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}\_\textquotesingle{}}\NormalTok{)}\SpecialCharTok{\}}\SpecialStringTok{.png"}
\NormalTok{        plt.savefig(fn, dpi}\OperatorTok{=}\DecValTok{160}\NormalTok{)}
\NormalTok{        plt.close()}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Wrote"}\NormalTok{, fn)}
\NormalTok{    ab.to\_csv(REPDIR}\OperatorTok{/}\StringTok{"ablation\_clean.csv"}\NormalTok{, index}\OperatorTok{=}\VariableTok{False}\NormalTok{)}

\KeywordTok{def}\NormalTok{ main():}
\NormalTok{    model\_compare()}
\NormalTok{    regime\_breakdown()}
\NormalTok{    ablation\_plot()}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"Done. Figures in"}\NormalTok{, FIGDIR)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\NormalTok{PY}
\NormalTok{chmod }\OperatorTok{+}\NormalTok{x scripts}\OperatorTok{/}\NormalTok{make\_poster\_figs.py}
\end{Highlighting}
\end{Shaded}

Run it:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{python}\NormalTok{ scripts/make\_poster\_figs.py}
\FunctionTok{ls} \AttributeTok{{-}l}\NormalTok{ docs/figs }\KeywordTok{|} \FunctionTok{head} \AttributeTok{{-}n}\NormalTok{ 10}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Create a Quarto \textbf{poster skeleton}
(\texttt{reports/poster.qmd})}{2) Create a Quarto poster skeleton (reports/poster.qmd)}}\label{create-a-quarto-poster-skeleton-reportsposter.qmd}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\%\%}\NormalTok{bash}
\NormalTok{cat }\OperatorTok{\textgreater{}}\NormalTok{ reports}\OperatorTok{/}\NormalTok{poster.qmd }\OperatorTok{\textless{}\textless{}} \StringTok{\textquotesingle{}QMD\textquotesingle{}}
\OperatorTok{{-}{-}{-}}
\NormalTok{title: }\StringTok{"Unified Stocks: Tiny Transformers vs Classical Baselines"}
\NormalTok{author: }\StringTok{"Team — Data Science Productivity Tools"}
\NormalTok{date: }\StringTok{"\textasciigrave{}r format(Sys.Date(), \textquotesingle{}\%Y{-}\%m{-}}\SpecialCharTok{\%d}\StringTok{\textquotesingle{})\textasciigrave{}"}
\BuiltInTok{format}\NormalTok{:}
\NormalTok{  html:}
\NormalTok{    page}\OperatorTok{{-}}\NormalTok{layout: full}
\NormalTok{    toc: false}
\NormalTok{    number}\OperatorTok{{-}}\NormalTok{sections: false}
\NormalTok{    theme: default}
\NormalTok{    df}\OperatorTok{{-}}\BuiltInTok{print}\NormalTok{: paged}
\NormalTok{    smooth}\OperatorTok{{-}}\NormalTok{scroll: true}
\NormalTok{engine: knitr}
\NormalTok{editor: source}
\OperatorTok{{-}{-}{-}}

\NormalTok{::: \{.callout}\OperatorTok{{-}}\NormalTok{note\}}
\OperatorTok{**}\NormalTok{Educational project (}\KeywordTok{not}\NormalTok{ trading advice).}\OperatorTok{**}  
\NormalTok{Data }\KeywordTok{and}\NormalTok{ results are }\ControlFlowTok{for}\NormalTok{ demonstration of tools }\KeywordTok{and}\NormalTok{ methodology.}
\NormalTok{:::}

\CommentTok{\#\# Problem}
\NormalTok{Short‑horizon }\ControlFlowTok{return}\NormalTok{ forecasting }\KeywordTok{is}\NormalTok{ noisy. We build a }\OperatorTok{**}\NormalTok{unified model}\OperatorTok{**}\NormalTok{ across multiple tickers }\KeywordTok{and}\NormalTok{ compare }\OperatorTok{**}\NormalTok{classical baselines}\OperatorTok{**} \ControlFlowTok{with}\NormalTok{ a }\OperatorTok{**}\NormalTok{tiny Transformer}\OperatorTok{**}\NormalTok{ under strict leakage controls.}

\CommentTok{\#\# Data}
\OperatorTok{{-}}\NormalTok{ Daily prices }\ControlFlowTok{for}\NormalTok{ a static }\BuiltInTok{list}\NormalTok{ of tickers.  }
\OperatorTok{{-}}\NormalTok{ Features: lags, rolling z‑scores, }\DecValTok{20}\NormalTok{‑day volatility, calendar effects.  }
\OperatorTok{{-}}\NormalTok{ Splits: rolling‑origin }\ControlFlowTok{with}\NormalTok{ embargo}\OperatorTok{;}\NormalTok{ metrics reported on validation slices.}

\CommentTok{\#\# Methods (1‑paragraph sketch)}
\OperatorTok{{-}}\NormalTok{ Baselines: }\OperatorTok{**}\NormalTok{naive}\OperatorTok{**}\NormalTok{ (ŷ }\OperatorTok{=}\NormalTok{ return\_t), }\OperatorTok{**}\NormalTok{lin\_lags}\OperatorTok{**}\NormalTok{ (per‑ticker linear regression).  }
\OperatorTok{{-}}\NormalTok{ Sequence models: }\OperatorTok{**}\NormalTok{GRU}\OperatorTok{**}\NormalTok{ (multi‑asset }\ControlFlowTok{with}\NormalTok{ ticker IDs) }\KeywordTok{and} \OperatorTok{**}\NormalTok{TS‑GPT}\OperatorTok{**}\NormalTok{ (feature projection }\OperatorTok{+}\NormalTok{ causal attention).  }
\OperatorTok{{-}}\NormalTok{ Loss: MAE}\OperatorTok{/}\NormalTok{Huber. No look‑ahead}\OperatorTok{;}\NormalTok{ scaler fit on TRAIN only.}

\CommentTok{\#\# Results}

\CommentTok{\#\#\# Model comparison (MAE)}
\OperatorTok{!}\NormalTok{[Comparison of validation MAE across models. Lower }\KeywordTok{is}\NormalTok{ better.](..}\OperatorTok{/}\NormalTok{docs}\OperatorTok{/}\NormalTok{figs}\OperatorTok{/}\NormalTok{model\_compare.png)\{fig}\OperatorTok{{-}}\NormalTok{alt}\OperatorTok{=}\StringTok{"Bar chart: models vs MAE"}\NormalTok{ width}\OperatorTok{=}\StringTok{"70\%"}\NormalTok{\}}

\OperatorTok{**}\NormalTok{Takeaway.}\OperatorTok{**}\NormalTok{ The unified sequence model improves over lin\_lags on this split (magnitude varies by dataset).}

\CommentTok{\#\#\# Error by volatility regime}
\OperatorTok{!}\NormalTok{[MAE by regime (low}\OperatorTok{/}\NormalTok{med}\OperatorTok{/}\NormalTok{high volatility).](..}\OperatorTok{/}\NormalTok{docs}\OperatorTok{/}\NormalTok{figs}\OperatorTok{/}\NormalTok{regime\_breakdown.png)\{fig}\OperatorTok{{-}}\NormalTok{alt}\OperatorTok{=}\StringTok{"Bar chart: volatility regimes vs MAE"}\NormalTok{ width}\OperatorTok{=}\StringTok{"70\%"}\NormalTok{\}}

\OperatorTok{**}\NormalTok{Takeaway.}\OperatorTok{**}\NormalTok{ Errors increase }\KeywordTok{in}\NormalTok{ high‑volatility regimes}\OperatorTok{;}\NormalTok{ compare models at equal regimes to avoid apples‑to‑oranges.}

\CommentTok{\#\#\# TS‑GPT ablation (context × heads)}
\OperatorTok{!}\NormalTok{[Validation MAE heatmaps across context }\KeywordTok{and}\NormalTok{ heads (one per dropout).](..}\OperatorTok{/}\NormalTok{docs}\OperatorTok{/}\NormalTok{figs}\OperatorTok{/}\NormalTok{ablation\_dropout\_0\_0.png)\{fig}\OperatorTok{{-}}\NormalTok{alt}\OperatorTok{=}\StringTok{"Heatmap: ctx vs n\_head, dropout=0.0"}\NormalTok{ width}\OperatorTok{=}\StringTok{"45\%"}\NormalTok{\}}
\OperatorTok{!}\NormalTok{[Validation MAE heatmaps across context }\KeywordTok{and}\NormalTok{ heads (one per dropout).](..}\OperatorTok{/}\NormalTok{docs}\OperatorTok{/}\NormalTok{figs}\OperatorTok{/}\NormalTok{ablation\_dropout\_0\_1.png)\{fig}\OperatorTok{{-}}\NormalTok{alt}\OperatorTok{=}\StringTok{"Heatmap: ctx vs n\_head, dropout=0.1"}\NormalTok{ width}\OperatorTok{=}\StringTok{"45\%"}\NormalTok{\}}

\OperatorTok{**}\NormalTok{Takeaway.}\OperatorTok{**}\NormalTok{ Longer context }\KeywordTok{or}\NormalTok{ more heads can }\BuiltInTok{help}\NormalTok{ slightly, but returns are noisy—watch }\ControlFlowTok{for}\NormalTok{ overfitting.}

\CommentTok{\#\# Limits \& Ethics}
\OperatorTok{{-}}\NormalTok{ Non‑stationarity}\OperatorTok{;}\NormalTok{ survivorship bias minimized via static }\BuiltInTok{list} \KeywordTok{and}\NormalTok{ fixed history but }\KeywordTok{not}\NormalTok{ eliminated.  }
\OperatorTok{{-}}\NormalTok{ Not suitable }\ControlFlowTok{for}\NormalTok{ trading}\OperatorTok{;}\NormalTok{ missing costs}\OperatorTok{/}\NormalTok{impact}\OperatorTok{;}\NormalTok{ academic metrics only.}

\CommentTok{\#\# Model Card (short)}
\OperatorTok{{-}} \OperatorTok{**}\NormalTok{Intended use:}\OperatorTok{**}\NormalTok{ teaching pipeline}\OperatorTok{/}\NormalTok{tools.  }
\OperatorTok{{-}} \OperatorTok{**}\NormalTok{Data:}\OperatorTok{**}\NormalTok{ daily OHLCV}\OperatorTok{;}\NormalTok{ engineered features}\OperatorTok{;}\NormalTok{ static ticker universe.  }
\OperatorTok{{-}} \OperatorTok{**}\NormalTok{Metrics:}\OperatorTok{**}\NormalTok{ MAE, sMAPE, regime‑wise MAE.  }
\OperatorTok{{-}} \OperatorTok{**}\NormalTok{Limitations:}\OperatorTok{**}\NormalTok{ no risk management}\OperatorTok{;}\NormalTok{ unstable out‑of‑sample.}

\CommentTok{\#\# References}
\OperatorTok{{-}}\NormalTok{ Course repository }\KeywordTok{and}\NormalTok{ documentation}\OperatorTok{;}\NormalTok{ standard ML}\OperatorTok{/}\NormalTok{TS texts.}

\CommentTok{\#\# Contact}
\OperatorTok{{-}}\NormalTok{ Team GitHub }\KeywordTok{and}\NormalTok{ email here.}
\NormalTok{QMD}
\end{Highlighting}
\end{Shaded}

Render (HTML; PDF optional if LaTeX is available):

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\ExtensionTok{quarto}\NormalTok{ render reports/poster.qmd }\KeywordTok{||} \BuiltInTok{echo} \StringTok{"If Quarto not available here, render locally later."}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Seed an \textbf{abstract draft} file and
a \textbf{word‑count
checker}}{3) Seed an abstract draft file and a word‑count checker}}\label{seed-an-abstract-draft-file-and-a-wordcount-checker}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\%\%}\NormalTok{bash}
\NormalTok{cat }\OperatorTok{\textgreater{}}\NormalTok{ reports}\OperatorTok{/}\NormalTok{abstract.md }\OperatorTok{\textless{}\textless{}} \StringTok{\textquotesingle{}MD\textquotesingle{}}
\NormalTok{We study short‑horizon stock }\ControlFlowTok{return}\NormalTok{ forecasting }\ImportTok{as}\NormalTok{ an educational exercise }\KeywordTok{in}\NormalTok{ reproducible data science tooling. Using a static }\BuiltInTok{set}\NormalTok{ of equities }\KeywordTok{and}\NormalTok{ daily bars, we engineer causal features (lags, rolling volatility, calendar effects) }\KeywordTok{and}\NormalTok{ enforce time‑based splits }\ControlFlowTok{with}\NormalTok{ an embargo to prevent leakage. We compare per‑ticker linear baselines to unified sequence models, including a GRU }\ControlFlowTok{with}\NormalTok{ ticker embeddings }\KeywordTok{and}\NormalTok{ a tiny Transformer adapted }\ControlFlowTok{for}\NormalTok{ real‑valued time series (TS‑GPT).}

\NormalTok{Models are trained }\ControlFlowTok{with}\NormalTok{ MAE}\OperatorTok{/}\NormalTok{Huber loss on expanding windows}\OperatorTok{;}\NormalTok{ evaluation uses MAE }\KeywordTok{and}\NormalTok{ sMAPE aggregated across tickers }\KeywordTok{and}\NormalTok{ by volatility regimes. On our validation split, the unified sequence model matches }\KeywordTok{or}\NormalTok{ modestly outperforms the linear baseline, especially }\KeywordTok{in}\NormalTok{ medium‑volatility regimes}\OperatorTok{;}\NormalTok{ effects shrink }\KeywordTok{in}\NormalTok{ high‑volatility periods. Ablations suggest small gains }\ImportTok{from}\NormalTok{ longer context, }\ControlFlowTok{with}\NormalTok{ diminishing returns beyond }\DecValTok{64}\NormalTok{ steps.}

\NormalTok{This course project emphasizes tools over profits: deterministic pipelines, tests, continuous integration, }\KeywordTok{and}\NormalTok{ a Typer CLI that reproduces results }\ImportTok{from}\NormalTok{ a fresh clone. The work }\KeywordTok{is}\NormalTok{ limited by non‑stationarity, survivorship bias, }\KeywordTok{and}\NormalTok{ absence of transaction costs. Future work includes multi‑horizon forecasting, macro features, uncertainty estimates, }\KeywordTok{and}\NormalTok{ broader asset coverage. This }\KeywordTok{is} \KeywordTok{not}\NormalTok{ trading advice.}
\NormalTok{MD}

\NormalTok{cat }\OperatorTok{\textgreater{}}\NormalTok{ scripts}\OperatorTok{/}\NormalTok{check\_abstract\_length.py }\OperatorTok{\textless{}\textless{}} \StringTok{\textquotesingle{}PY\textquotesingle{}}
\CommentTok{\#!/usr/bin/env python}
\ImportTok{import}\NormalTok{ re, sys}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\KeywordTok{def}\NormalTok{ count\_words(text: }\BuiltInTok{str}\NormalTok{) }\OperatorTok{{-}\textgreater{}} \BuiltInTok{int}\NormalTok{:}
\NormalTok{    text }\OperatorTok{=}\NormalTok{ re.sub(}\VerbatimStringTok{r"\textbackslash{}s+"}\NormalTok{, }\StringTok{" "}\NormalTok{, text).strip()}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ text: }\ControlFlowTok{return} \DecValTok{0}
    \ControlFlowTok{return} \BuiltInTok{len}\NormalTok{(text.split(}\StringTok{" "}\NormalTok{))}

\KeywordTok{def}\NormalTok{ main(path}\OperatorTok{=}\StringTok{"reports/abstract.md"}\NormalTok{):}
\NormalTok{    p }\OperatorTok{=}\NormalTok{ Path(path)}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ p.exists():}
        \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"Missing }\SpecialCharTok{\{}\NormalTok{p}\SpecialCharTok{\}}\SpecialStringTok{"}\NormalTok{, }\BuiltInTok{file}\OperatorTok{=}\NormalTok{sys.stderr)}\OperatorTok{;}\NormalTok{ sys.exit(}\DecValTok{2}\NormalTok{)}
\NormalTok{    words }\OperatorTok{=}\NormalTok{ count\_words(p.read\_text(encoding}\OperatorTok{=}\StringTok{"utf{-}8"}\NormalTok{))}
    \BuiltInTok{print}\NormalTok{(}\SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{p}\SpecialCharTok{\}}\SpecialStringTok{: }\SpecialCharTok{\{}\NormalTok{words}\SpecialCharTok{\}}\SpecialStringTok{ words"}\NormalTok{)}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ (}\DecValTok{200} \OperatorTok{\textless{}=}\NormalTok{ words }\OperatorTok{\textless{}=} \DecValTok{300}\NormalTok{):}
        \BuiltInTok{print}\NormalTok{(}\StringTok{"Abstract must be between 200 and 300 words."}\NormalTok{, }\BuiltInTok{file}\OperatorTok{=}\NormalTok{sys.stderr)}
\NormalTok{        sys.exit(}\DecValTok{2}\NormalTok{)}

\ControlFlowTok{if} \VariableTok{\_\_name\_\_} \OperatorTok{==} \StringTok{"\_\_main\_\_"}\NormalTok{:}
\NormalTok{    main()}
\NormalTok{PY}
\NormalTok{chmod }\OperatorTok{+}\NormalTok{x scripts}\OperatorTok{/}\NormalTok{check\_abstract\_length.py}
\NormalTok{python scripts}\OperatorTok{/}\NormalTok{check\_abstract\_length.py }\OperatorTok{||}\NormalTok{ true}
\end{Highlighting}
\end{Shaded}

\subsection{4) Tiny test to ensure figures
exist}\label{tiny-test-to-ensure-figures-exist}

\begin{Shaded}
\begin{Highlighting}[]
\OperatorTok{\%\%}\NormalTok{bash}
\NormalTok{cat }\OperatorTok{\textgreater{}}\NormalTok{ tests}\OperatorTok{/}\NormalTok{test\_poster\_assets.py }\OperatorTok{\textless{}\textless{}} \StringTok{\textquotesingle{}PY\textquotesingle{}}
\ImportTok{from}\NormalTok{ pathlib }\ImportTok{import}\NormalTok{ Path}

\KeywordTok{def}\NormalTok{ test\_poster\_figs\_exist():}
    \ControlFlowTok{for}\NormalTok{ fn }\KeywordTok{in}\NormalTok{ [}\StringTok{"model\_compare.png"}\NormalTok{, }\StringTok{"regime\_breakdown.png"}\NormalTok{]:}
        \ControlFlowTok{assert}\NormalTok{ (Path(}\StringTok{"docs/figs"}\NormalTok{)}\OperatorTok{/}\NormalTok{fn).exists(), }\SpecialStringTok{f"Missing }\SpecialCharTok{\{}\NormalTok{fn}\SpecialCharTok{\}}\SpecialStringTok{ — run scripts/make\_poster\_figs.py"}
\NormalTok{PY}
\NormalTok{pytest }\OperatorTok{{-}}\NormalTok{q }\OperatorTok{{-}}\NormalTok{k poster\_assets }\OperatorTok{||}\NormalTok{ true}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up prompts (15 min)}\label{wrapup-prompts-15-min}

\begin{itemize}
\tightlist
\item
  \textbf{Lightning critique}: Each team shows the \textbf{3 figures}
  (30--60 seconds each).
\item
  Ask: ``What is the \textbf{one sentence} the viewer should remember?''
\item
  Confirm the poster \textbf{story arc} is visible from 6 feet away:
  bold headings; few words; figures big.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (due next session)}\label{homework-due-next-session}

\textbf{Deliverables (push to repo):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{\texttt{reports/poster.html}} (and \texttt{reports/poster.pdf}
  if you can render PDF) with the 3 figures embedded.
\item
  \textbf{\texttt{reports/abstract.md}} (200--300 words) that matches
  the poster's story.
\item
  A short \textbf{commit message}:
  \texttt{docs:\ poster\ draft\ +\ abstract\ (v1)}.
\end{enumerate}

\subsection{\texorpdfstring{A. Makefile targets (append to
\texttt{Makefile})}{A. Makefile targets (append to Makefile)}}\label{a.-makefile-targets-append-to-makefile}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{.PHONY: poster{-}figs poster render{-}poster abstract{-}check}
\NormalTok{poster{-}figs: \#\# Build all poster figures}
\NormalTok{\textbackslash{}tpython scripts/make\_poster\_figs.py}

\NormalTok{poster: poster{-}figs \#\# Render HTML poster}
\NormalTok{\textbackslash{}tquarto render reports/poster.qmd}

\NormalTok{render{-}poster: poster}

\NormalTok{abstract{-}check: \#\# Ensure abstract word count is 200{-}300}
\NormalTok{\textbackslash{}tpython scripts/check\_abstract\_length.py}
\end{Highlighting}
\end{Shaded}

\subsection{B. Optional CI snippet (run only if Quarto
available)}\label{b.-optional-ci-snippet-run-only-if-quarto-available}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Append to .github/workflows/ci.yml}
\KeywordTok{{-}}\AttributeTok{ }\FunctionTok{name}\KeywordTok{:}\AttributeTok{ Poster assets}
\FunctionTok{  run}\KeywordTok{: }\CharTok{|}
\NormalTok{    python scripts/make\_poster\_figs.py}
\NormalTok{    python scripts/check\_abstract\_length.py}
\end{Highlighting}
\end{Shaded}

\subsection{C. (Optional) Extra figure (calibration /
residuals)}\label{c.-optional-extra-figure-calibration-residuals}

Add this cell if you also saved predictions for GRU/TS‑GPT (e.g.,
\texttt{reports/tsgpt\_preds\_split1.csv} with
\texttt{date,ticker,y\_true,yhat}):

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd, numpy }\ImportTok{as}\NormalTok{ np, matplotlib.pyplot }\ImportTok{as}\NormalTok{ plt, pathlib}
\NormalTok{pred }\OperatorTok{=} \VariableTok{None}
\ControlFlowTok{for}\NormalTok{ cand }\KeywordTok{in}\NormalTok{ [}\StringTok{"reports/tsgpt\_preds\_split1.csv"}\NormalTok{,}\StringTok{"reports/cli\_linlags.csv"}\NormalTok{]:}
    \ControlFlowTok{if}\NormalTok{ pathlib.Path(cand).exists():}
\NormalTok{        pred }\OperatorTok{=}\NormalTok{ pd.read\_csv(cand)}\OperatorTok{;} \ControlFlowTok{break}
\ControlFlowTok{if}\NormalTok{ pred }\KeywordTok{is} \KeywordTok{not} \VariableTok{None} \KeywordTok{and}\NormalTok{ \{}\StringTok{"y\_true"}\NormalTok{,}\StringTok{"yhat"}\NormalTok{\}.issubset(pred.columns):}
\NormalTok{    e }\OperatorTok{=}\NormalTok{ pred[}\StringTok{"y\_true"}\NormalTok{] }\OperatorTok{{-}}\NormalTok{ pred[}\StringTok{"yhat"}\NormalTok{]}
\NormalTok{    plt.figure(figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{6}\NormalTok{,}\FloatTok{3.2}\NormalTok{))}
\NormalTok{    plt.hist(e.values, bins}\OperatorTok{=}\DecValTok{50}\NormalTok{)}
\NormalTok{    plt.xlabel(}\StringTok{"Residual"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.ylabel(}\StringTok{"Count"}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.title(}\StringTok{"Residual distribution"}\NormalTok{)}
\NormalTok{    plt.tight\_layout()}\OperatorTok{;}\NormalTok{ pathlib.Path(}\StringTok{"docs/figs"}\NormalTok{).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    plt.savefig(}\StringTok{"docs/figs/residuals\_hist.png"}\NormalTok{, dpi}\OperatorTok{=}\DecValTok{160}\NormalTok{)}\OperatorTok{;}\NormalTok{ plt.close()}
\end{Highlighting}
\end{Shaded}

Then include in \texttt{poster.qmd}:

\begin{Shaded}
\begin{Highlighting}[]
\AlertTok{![Residual distribution (optional).](../docs/figs/residuals\_hist.png)}\NormalTok{\{width="55\%"\}}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor notes / facilitation
tips}\label{instructor-notes-facilitation-tips}

\begin{itemize}
\tightlist
\item
  Encourage \textbf{big, legible figures}. Shrink text elsewhere, not
  the plots.
\item
  If a figure doesn't clearly answer a question, \textbf{cut it}.
\item
  Remind to \textbf{state uncertainty/limits} explicitly (no trading
  claims).
\item
  For the abstract, ban boilerplate like ``significant improvement''
  without \textbf{numbers}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Grading (pass/revise)}\label{grading-passrevise-13}

\begin{itemize}
\tightlist
\item
  \textbf{Poster draft} builds from a \textbf{fresh clone} using
  \texttt{make\ poster} (figures present and render succeeds).
\item
  \textbf{Three key figures} are present and readable, each with a
  concise takeaway.
\item
  \textbf{Abstract} is 200--300 words and consistent with the figures.
\item
  Repo contains \texttt{scripts/make\_poster\_figs.py} and
  \texttt{scripts/check\_abstract\_length.py}; optional test passes.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Appendix --- Figure caption starter lines (you can paste
into the
poster)}\label{appendix-figure-caption-starter-lines-you-can-paste-into-the-poster}

\begin{itemize}
\tightlist
\item
  \textbf{Model comparison:} ``TS‑GPT reduces validation MAE vs
  lin\_lags on Split~1; improvements are modest and vary by ticker.''
\item
  \textbf{Regime breakdown:} ``All models degrade in high volatility;
  report metrics by regime to avoid overstating performance.''
\item
  \textbf{Ablation:} ``Context~64 and heads~4 are a reasonable sweet
  spot under tight budgets; gains diminish beyond this.''
\end{itemize}

This package gives you everything you need to run a productive
\textbf{poster + abstract workshop} in 75 minutes and leave students
with a tangible draft ready for polishing.

\bookmarksetup{startatroot}

\chapter{Session 26 --- In‑class Presentations \& Continuation
Pla}\label{session-26-inclass-presentations-continuation-pla}

Below is a complete lecture package for \textbf{Session 26 --- In‑class
Presentations \& Continuation Plan} (75 minutes). It includes a timed
agenda, slide talking points, a \textbf{Colab‑friendly in‑class lab with
copy‑paste code} (presentation checklists, peer‑feedback forms,
automated backlog builder, issue templates, and a hand‑off zip), plus
\textbf{homework with code} to tag \texttt{v1.0}, publish a continuation
backlog, and prepare for Spring symposium work.

\begin{quote}
\textbf{Assumptions} • You have the repo mounted in Drive (e.g.,
\texttt{unified-stocks-teamX}). • Poster draft and abstract exist from
Session 25 (or will be created today). • This is \textbf{educational};
nothing here is trading advice.
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Session 26 --- In‑class Presentations \& Continuation Plan (75
min)}\label{session-26-inclass-presentations-continuation-plan-75-min}

\subsection{Learning goals}\label{learning-goals-25}

By the end of class, students can:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Deliver a focused \textbf{10‑minute talk} that communicates problem,
  methods, results, and limits.
\item
  Provide / receive \textbf{actionable peer feedback}.
\item
  Convert results into a \textbf{prioritized backlog} (issues +
  milestones) to continue toward the symposium.
\item
  Produce a \textbf{handoff bundle} (poster, abstract, artifacts,
  manifest, backlog) and finalize \texttt{v1.0}.
\end{enumerate}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Agenda (75 min)}\label{agenda-75-min-23}

\begin{itemize}
\tightlist
\item
  \textbf{(5 min)} Setup \& expectations (timing, feedback rules,
  rubric).
\item
  \textbf{(30--40 min)} \textbf{Talks} (≈10 min per team + 5 min Q\&A
  --- adapt to class size).
\item
  \textbf{(20 min)} \textbf{In‑class lab}: feedback capture → automated
  backlog + issues → handoff zip.
\item
  \textbf{(10 min)} Wrap‑up: commit plan, roles, milestones; homework
  brief.
\end{itemize}

\emph{If you have a single team, do a 15--20 min talk and deeper Q\&A;
then use all remaining time for backlog + handoff.}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Slides --- talking points (drop into your
deck)}\label{slides-talking-points-drop-into-your-deck-5}

\subsection{Presentation structure (10
minutes)}\label{presentation-structure-10-minutes}

\begin{itemize}
\tightlist
\item
  \textbf{Title \& claim (30s):} One sentence problem + one sentence
  result.
\item
  \textbf{Setup (1--2 min):} Data (tickers/dates), leakage controls
  (rolling origin + embargo), metrics (MAE, sMAPE).
\item
  \textbf{Methods (2--3 min):} Baselines, GRU/TS‑GPT, any ablations.
\item
  \textbf{Results (3--4 min):} Show 3 figures (model comparison, regime
  breakdown, ablation). Give \textbf{one takeaway each}.
\item
  \textbf{Limits \& ethics (1 min):} Non‑stationarity, survivorship
  bias; not trading advice.
\item
  \textbf{Next steps (30--60s):} 3 prioritized items and why.
\end{itemize}

\subsection{Q\&A best practices}\label{qa-best-practices}

\begin{itemize}
\tightlist
\item
  Repeat the question; answer with evidence; admit unknowns; propose
  next test.
\item
  Avoid ``we might'' without a concrete follow‑up; anchor to a metric,
  data slice, or ablation.
\end{itemize}

\subsection{Reproducibility handoff (what the next team
needs)}\label{reproducibility-handoff-what-the-next-team-needs}

\begin{itemize}
\tightlist
\item
  \textbf{Exact commands} (fresh‑clone steps), \textbf{versions}
  (lockfile), \textbf{manifests}, \textbf{data checksums}, and
  \textbf{known deviations}.
\item
  A backlog labeled by \textbf{Data / Features / Modeling / Evaluation /
  Ops / Docs}.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{In‑class lab (20 min,
Colab‑friendly)}\label{inclass-lab-20-min-colabfriendly}

\begin{quote}
Run each block as its \textbf{own cell}. Update \texttt{REPO\_NAME} if
needed.
\end{quote}

\subsection{0) Mount Drive \& cd into your
repo}\label{mount-drive-cd-into-your-repo}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ google.colab }\ImportTok{import}\NormalTok{ drive}
\NormalTok{drive.mount(}\StringTok{\textquotesingle{}/content/drive\textquotesingle{}}\NormalTok{, force\_remount}\OperatorTok{=}\VariableTok{True}\NormalTok{)}

\NormalTok{REPO\_NAME }\OperatorTok{=} \StringTok{"unified{-}stocks{-}teamX"}  \CommentTok{\# \textless{}{-} change}
\NormalTok{BASE\_DIR  }\OperatorTok{=} \StringTok{"/content/drive/MyDrive/dspt25"}
\NormalTok{REPO\_DIR  }\OperatorTok{=} \SpecialStringTok{f"}\SpecialCharTok{\{}\NormalTok{BASE\_DIR}\SpecialCharTok{\}}\SpecialStringTok{/}\SpecialCharTok{\{}\NormalTok{REPO\_NAME}\SpecialCharTok{\}}\SpecialStringTok{"}

\ImportTok{import}\NormalTok{ os, pathlib, sys, platform, time}
\NormalTok{pathlib.Path(REPO\_DIR).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{os.chdir(REPO\_DIR)}
\ControlFlowTok{for}\NormalTok{ p }\KeywordTok{in}\NormalTok{ [}\StringTok{"reports"}\NormalTok{,}\StringTok{"docs/figs"}\NormalTok{,}\StringTok{"scripts"}\NormalTok{,}\StringTok{"tests"}\NormalTok{,}\StringTok{".github/ISSUE\_TEMPLATE"}\NormalTok{]:}
\NormalTok{    pathlib.Path(p).mkdir(parents}\OperatorTok{=}\VariableTok{True}\NormalTok{, exist\_ok}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{"Working dir:"}\NormalTok{, os.getcwd(), }\StringTok{"| Python:"}\NormalTok{, sys.version.split()[}\DecValTok{0}\NormalTok{], }\StringTok{"| OS:"}\NormalTok{, platform.system())}
\end{Highlighting}
\end{Shaded}

\subsection{1) Presentation checklist \& peer‑feedback
forms}\label{presentation-checklist-peerfeedback-forms}

Create a presenter checklist and a peer feedback form you can fill
post‑talk.

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{cat} \OperatorTok{\textgreater{}}\NormalTok{ docs/present\_checklist.md }\OperatorTok{\textless{}\textless{} \textquotesingle{}MD\textquotesingle{}}
\StringTok{\# Presentation Checklist (10 minutes total)}
\StringTok{{-} [ ] Title \& one‑sentence claim (≤ 30s)}
\StringTok{{-} [ ] Data \& leakage controls (1–2 min): static universe, rolling origin, embargo}
\StringTok{{-} [ ] Methods (2–3 min): baselines; GRU/TS‑GPT; ablations}
\StringTok{{-} [ ] Results (3–4 min): 3 figures with one takeaway each}
\StringTok{{-} [ ] Limits \& ethics (1 min)}
\StringTok{{-} [ ] Next steps (3 bullets; priority + rationale)}
\OperatorTok{MD}

\FunctionTok{cat} \OperatorTok{\textgreater{}}\NormalTok{ docs/peer\_feedback\_template.md }\OperatorTok{\textless{}\textless{} \textquotesingle{}MD\textquotesingle{}}
\StringTok{\# Peer Feedback (fill one per talk)}
\StringTok{**One insight:**  }
\StringTok{**One question:**  }
\StringTok{**One suggestion:**  }
\StringTok{**Clarity (1–5):**  }
\StringTok{**Rigor (1–5):**  }
\StringTok{**Reproducibility (1–5):**  }
\StringTok{**Top risk:**  }
\OperatorTok{MD}
\BuiltInTok{echo} \StringTok{"Wrote docs/present\_checklist.md and docs/peer\_feedback\_template.md"}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{2) Automated \textbf{continuation backlog}
builder}{2) Automated continuation backlog builder}}\label{automated-continuation-backlog-builder}

This script looks at your saved outputs (model comparison, regime
breakdown, ablation summaries, predictions) and \textbf{generates}: •
\texttt{NEXT\_STEPS.md} (prioritized checklists), •
\texttt{reports/issue\_backlog.csv} (ready to paste into GitHub as
issues), • \texttt{docs/figs/opportunity\_by\_ticker.png} (where to
focus), • \texttt{reports/roadmap\_milestones.md} (3‑milestone
mini‑roadmap).

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{cat} \OperatorTok{\textgreater{}}\NormalTok{ scripts/make\_continuation\_backlog.py }\OperatorTok{\textless{}\textless{} \textquotesingle{}PY\textquotesingle{}}
\StringTok{\#!/usr/bin/env python}
\StringTok{from \_\_future\_\_ import annotations}
\StringTok{import os, math, json}
\StringTok{from pathlib import Path}
\StringTok{import numpy as np, pandas as pd}
\StringTok{import matplotlib.pyplot as plt}

\StringTok{FIGDIR = Path("docs/figs"); FIGDIR.mkdir(parents=True, exist\_ok=True)}
\StringTok{REPDIR = Path("reports"); REPDIR.mkdir(parents=True, exist\_ok=True)}

\StringTok{def \_safe\_read\_csv(p): }
\StringTok{    p=Path(p); }
\StringTok{    return pd.read\_csv(p) if p.exists() else None}
\StringTok{def \_safe\_read\_parquet(p):}
\StringTok{    p=Path(p)}
\StringTok{    if p.exists():}
\StringTok{        try: return pd.read\_parquet(p)}
\StringTok{        except Exception: return None}
\StringTok{    return None}
\StringTok{def \_mae(a,b): }
\StringTok{    a=np.asarray(a); b=np.asarray(b); }
\StringTok{    return float(np.mean(np.abs(a{-}b)))}

\StringTok{def load\_artifacts():}
\StringTok{    comp = \_safe\_read\_csv("reports/model\_compare.csv")}
\StringTok{    regime = \_safe\_read\_csv("reports/regime\_breakdown.csv")}
\StringTok{    ab = \_safe\_read\_csv("reports/ablation\_clean.csv")}
\StringTok{    lin = \_safe\_read\_csv("reports/cli\_linlags.csv")      \# per{-}row predictions if available}
\StringTok{    tsgpt\_pred = \_safe\_read\_csv("reports/tsgpt\_preds\_split1.csv")}
\StringTok{    feats = None}
\StringTok{    for p in ["data/processed/features\_v1.parquet","data/processed/returns.parquet"]:}
\StringTok{        feats = \_safe\_read\_parquet(p) or feats}
\StringTok{    return comp, regime, ab, lin, tsgpt\_pred, feats}

\StringTok{def opportunity\_by\_ticker(lin, tsgpt\_pred):}
\StringTok{    """}
\StringTok{    Compute per{-}ticker \textquotesingle{}opportunity\textquotesingle{} = MAE\_lin {-} MAE\_model.}
\StringTok{    If TS{-}GPT preds unavailable, returns lin MAE only.}
\StringTok{    """}
\StringTok{    if lin is None or not \{"ticker","y\_true","yhat"\}.issubset(lin.columns):}
\StringTok{        return pd.DataFrame(columns=["ticker","mae\_lin","mae\_model","opportunity"])}
\StringTok{    lin\_mae = lin.groupby("ticker").apply(lambda g: \_mae(g["y\_true"], g["yhat"])).rename("mae\_lin").reset\_index()}
\StringTok{    if tsgpt\_pred is not None and \{"ticker","y\_true","yhat"\}.issubset(tsgpt\_pred.columns):}
\StringTok{        mod\_mae = tsgpt\_pred.groupby("ticker").apply(lambda g: \_mae(g["y\_true"], g["yhat"])).rename("mae\_model").reset\_index()}
\StringTok{        out = lin\_mae.merge(mod\_mae, on="ticker", how="left")}
\StringTok{        out["opportunity"] = out["mae\_lin"] {-} out["mae\_model"]}
\StringTok{    else:}
\StringTok{        out = lin\_mae}
\StringTok{        out["mae\_model"] = np.nan}
\StringTok{        out["opportunity"] = np.nan}
\StringTok{    return out.sort\_values("opportunity", ascending=False)}

\StringTok{def infer\_actions(comp, regime, ab, opp):}
\StringTok{    actions = \{"Data":[], "Features":[], "Modeling":[], "Evaluation":[], "Ops":[], "Docs":[]\}}
\StringTok{    \# Baseline vs model}
\StringTok{    if comp is not None and "val\_mae" in comp.columns:}
\StringTok{        comp\_sorted = comp.sort\_values("val\_mae")}
\StringTok{        best = comp\_sorted.iloc[0]["model"]}
\StringTok{        actions["Modeling"].append(f"Promote \textasciigrave{}\{best\}\textasciigrave{} as current champion; lock its config in config/config.yaml")}
\StringTok{    \# Regime pain points}
\StringTok{    if regime is not None and "regime" in regime.columns:}
\StringTok{        worst = regime.sort\_values("mae", ascending=False).iloc[0]["regime"]}
\StringTok{        actions["Features"].append(f"Add regime{-}aware features or losses (worst regime: **\{worst\}**); try quantile loss")}
\StringTok{        actions["Evaluation"].append("Report metrics **by regime** in the Quarto report (not only aggregate)")}
\StringTok{    \# Ablation hints}
\StringTok{    if ab is not None and \{"ctx","n\_head","val\_mae"\}.issubset(ab.columns):}
\StringTok{        best\_row = ab.sort\_values("val\_mae").iloc[0]}
\StringTok{        actions["Modeling"].append(f"Use context=\{int(best\_row[\textquotesingle{}ctx\textquotesingle{}])\}, heads=\{int(best\_row[\textquotesingle{}n\_head\textquotesingle{}])\} as starting point; test +/{-} 50\% context")}
\StringTok{    else:}
\StringTok{        actions["Modeling"].append("Run minimal ablation (context \{32,64,96\}, heads \{2,4\}) with fixed seed")}
\StringTok{    \# Opportunity by ticker}
\StringTok{    if len(opp):}
\StringTok{        tops = opp.head(5)["ticker"].tolist()}
\StringTok{        actions["Data"].append(f"Deep{-}dive top underperformers or highest{-}opportunity tickers: \{\textquotesingle{}, \textquotesingle{}.join(map(str,tops))\}")}
\StringTok{        actions["Modeling"].append("Consider per{-}ticker adapters or fine{-}tuning on worst tickers")}
\StringTok{    \# Ops \& Docs}
\StringTok{    actions["Ops"] += [}
\StringTok{        "Schedule CI task to rebuild features weekly (dry run only)",}
\StringTok{        "Cache data checksums and fail CI if changed unexpectedly"}
\StringTok{    ]}
\StringTok{    actions["Docs"] += [}
\StringTok{        "Expand Model Card with training data dates and static universe rationale",}
\StringTok{        "Add \textquotesingle{}How to reproduce\textquotesingle{} section with exact CLI commands"}
\StringTok{    ]}
\StringTok{    return actions}

\StringTok{def write\_next\_steps(actions):}
\StringTok{    md = ["\# NEXT\_STEPS (Symposium Continuation Backlog)\textbackslash{}n"]}
\StringTok{    md.append("\_Prioritize P0 (this week), P1 (this month), P2 (nice{-}to{-}have).\_ \textbackslash{}n")}
\StringTok{    for cat in ["Data","Features","Modeling","Evaluation","Ops","Docs"]:}
\StringTok{        md.append(f"\textbackslash{}n\#\# \{cat\}\textbackslash{}n")}
\StringTok{        for a in actions.get(cat, []):}
\StringTok{            md.append(f"{-} [ ] \{a\}  \textbackslash{}n  {-} Priority: P1  \textbackslash{}n  {-} Owner: TBA  \textbackslash{}n  {-} Evidence: link to figure/result")}
\StringTok{    Path("NEXT\_STEPS.md").write\_text("\textbackslash{}n".join(md))}
\StringTok{    return "NEXT\_STEPS.md"}

\StringTok{def write\_issue\_csv(actions):}
\StringTok{    rows=[]}
\StringTok{    for cat, items in actions.items():}
\StringTok{        for a in items:}
\StringTok{            rows.append(\{}
\StringTok{                "title": f"[\{cat\}] \{a[:80]\}",}
\StringTok{                "body": a + "\textbackslash{}n\textbackslash{}nSee NEXT\_STEPS.md",}
\StringTok{                "labels": f"\{cat.lower()\},backlog",}
\StringTok{                "milestone": "Symposium"}
\StringTok{            \})}
\StringTok{    df = pd.DataFrame(rows)}
\StringTok{    out = REPDIR/"issue\_backlog.csv"}
\StringTok{    df.to\_csv(out, index=False)}
\StringTok{    return out}

\StringTok{def plot\_opportunity(opp):}
\StringTok{    if not len(opp): return None}
\StringTok{    opp2 = opp.copy()}
\StringTok{    opp2["label"] = opp2["ticker"].astype(str)}
\StringTok{    plt.figure(figsize=(7.2,3.4))}
\StringTok{    x = np.arange(len(opp2))}
\StringTok{    vals = opp2["opportunity"].values}
\StringTok{    plt.bar(x, vals)}
\StringTok{    plt.xticks(x, opp2["label"].tolist(), rotation=45, ha="right")}
\StringTok{    plt.axhline(0, lw=1)}
\StringTok{    plt.ylabel("MAE\_baseline {-} MAE\_model")}
\StringTok{    plt.title("Opportunity by ticker (positive = model beats baseline)")}
\StringTok{    plt.tight\_layout()}
\StringTok{    fn = FIGDIR/"opportunity\_by\_ticker.png"}
\StringTok{    plt.savefig(fn, dpi=160); plt.close()}
\StringTok{    return fn}

\StringTok{def write\_roadmap():}
\StringTok{    text = """\# Mini Roadmap (to Spring Symposium)}

\StringTok{\#\# Milestone M1 (2–3 weeks): Stabilize champion model \& metrics}
\StringTok{{-} [ ] Lock config; re‑run split1 with seeds; freeze artifacts}
\StringTok{{-} [ ] Regime‑wise reporting in Quarto}
\StringTok{{-} [ ] Draft updated poster figures}

\StringTok{\#\# Milestone M2 (2–3 weeks): Targeted improvements}
\StringTok{{-} [ ] Focus on top 3 tickers/regimes with worst performance}
\StringTok{{-} [ ] Small ablation: context ±50\%, heads \{2,4\}, dropout \{0.0,0.1\}}
\StringTok{{-} [ ] Optional: add one macro series (rates or volatility)}

\StringTok{\#\# Milestone M3 (1–2 weeks): Packaging \& rehearsal}
\StringTok{{-} [ ] Update NEXT\_STEPS and close P0 tasks}
\StringTok{{-} [ ] Rehearse 10‑min talk; finalize poster}
\StringTok{"""}
\StringTok{    p = REPDIR/"roadmap\_milestones.md"}
\StringTok{    p.write\_text(text); return p}

\StringTok{def main():}
\StringTok{    comp, regime, ab, lin, tsgpt\_pred, feats = load\_artifacts()}
\StringTok{    opp = opportunity\_by\_ticker(lin, tsgpt\_pred)}
\StringTok{    fn = plot\_opportunity(opp)}
\StringTok{    actions = infer\_actions(comp, regime, ab, opp)}
\StringTok{    ns = write\_next\_steps(actions)}
\StringTok{    csv = write\_issue\_csv(actions)}
\StringTok{    rm = write\_roadmap()}
\StringTok{    print("Wrote", ns, csv, rm, "and figure:", fn)}

\StringTok{if \_\_name\_\_ == "\_\_main\_\_":}
\StringTok{    main()}
\OperatorTok{PY}
\FunctionTok{chmod}\NormalTok{ +x scripts/make\_continuation\_backlog.py}
\ExtensionTok{python}\NormalTok{ scripts/make\_continuation\_backlog.py}
\FunctionTok{ls} \AttributeTok{{-}1}\NormalTok{ NEXT\_STEPS.md reports/issue\_backlog.csv reports/roadmap\_milestones.md }\KeywordTok{||} \FunctionTok{true}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{3) Create \textbf{GitHub issue templates}
and \textbf{PR
template}}{3) Create GitHub issue templates and PR template}}\label{create-github-issue-templates-and-pr-template}

These help structure work after today.

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{cat} \OperatorTok{\textgreater{}}\NormalTok{ .github/ISSUE\_TEMPLATE/feature\_request.md }\OperatorTok{\textless{}\textless{} \textquotesingle{}MD\textquotesingle{}}
\StringTok{{-}{-}{-}}
\StringTok{name: "Feature request / Research task"}
\StringTok{about: Propose a new feature or experiment}
\StringTok{labels: "features,backlog"}
\StringTok{{-}{-}{-}}
\StringTok{**What \& why**}
\StringTok{{-} }

\StringTok{**Definition of done**}
\StringTok{{-} }

\StringTok{**Evidence / figure link**}
\StringTok{{-} }

\StringTok{**Risks / leakage concerns**}
\StringTok{{-} }
\OperatorTok{MD}

\FunctionTok{cat} \OperatorTok{\textgreater{}}\NormalTok{ .github/ISSUE\_TEMPLATE/bug\_report.md }\OperatorTok{\textless{}\textless{} \textquotesingle{}MD\textquotesingle{}}
\StringTok{{-}{-}{-}}
\StringTok{name: Bug report}
\StringTok{about: Report a reproducibility or CI failure}
\StringTok{labels: "bug,ops"}
\StringTok{{-}{-}{-}}
\StringTok{**What happened**}
\StringTok{{-} }

\StringTok{**Repro steps**}
\StringTok{{-} }

\StringTok{**Expected vs actual**}
\StringTok{{-} }

\StringTok{**Logs / manifest snippet**}
\StringTok{{-} }
\OperatorTok{MD}

\FunctionTok{cat} \OperatorTok{\textgreater{}}\NormalTok{ .github/PULL\_REQUEST\_TEMPLATE.md }\OperatorTok{\textless{}\textless{} \textquotesingle{}MD\textquotesingle{}}
\StringTok{\#\# What does this PR change?}
\StringTok{{-}}

\StringTok{\#\# How to reproduce the results (exact commands)}
\StringTok{{-}}

\StringTok{\#\# Checklist}
\StringTok{{-} [ ] CI green}
\StringTok{{-} [ ] Updated report/figures if metrics changed}
\StringTok{{-} [ ] No leakage introduced; tests still pass}
\StringTok{{-} [ ] Linked issues closed}
\OperatorTok{MD}
\BuiltInTok{echo} \StringTok{"Wrote issue and PR templates."}
\end{Highlighting}
\end{Shaded}

\subsection{4) Handoff bundle (zip)}\label{handoff-bundle-zip}

Package poster, abstract, manifest, backlog, figures, and key reports
into a single zip to share.

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{cat} \OperatorTok{\textgreater{}}\NormalTok{ scripts/make\_handoff\_zip.py }\OperatorTok{\textless{}\textless{} \textquotesingle{}PY\textquotesingle{}}
\StringTok{\#!/usr/bin/env python}
\StringTok{from pathlib import Path}
\StringTok{import zipfile, time}

\StringTok{INCLUDE = [}
\StringTok{  "README.md",}
\StringTok{  "CHANGELOG.md",}
\StringTok{  "NEXT\_STEPS.md",}
\StringTok{  "reports/poster.html",}
\StringTok{  "reports/abstract.md",}
\StringTok{  "reports/manifest.json",}
\StringTok{  "reports/model\_compare.csv",}
\StringTok{  "reports/regime\_breakdown.csv",}
\StringTok{  "reports/ablation\_clean.csv",}
\StringTok{  "reports/tsgpt\_split1\_metrics.csv",}
\StringTok{  "reports/cli\_linlags.csv",}
\StringTok{  "reports/roadmap\_milestones.md",}
\StringTok{  "docs/figs/model\_compare.png",}
\StringTok{  "docs/figs/regime\_breakdown.png",}
\StringTok{  "docs/figs/ablation\_dropout\_0\_0.png",}
\StringTok{  "docs/figs/ablation\_dropout\_0\_1.png",}
\StringTok{  "docs/figs/opportunity\_by\_ticker.png"}
\StringTok{]}

\StringTok{def main():}
\StringTok{  Path("dist").mkdir(exist\_ok=True)}
\StringTok{  stamp = time.strftime("\%Y\%m\%d\_\%H\%M\%S")}
\StringTok{  out = Path("dist")/f"handoff\_session26\_\{stamp\}.zip"}
\StringTok{  with zipfile.ZipFile(out, "w", zipfile.ZIP\_DEFLATED) as z:}
\StringTok{    for p in INCLUDE:}
\StringTok{      fp = Path(p)}
\StringTok{      if fp.exists():}
\StringTok{        z.write(fp, arcname=str(fp))}
\StringTok{  print("Wrote", out)}

\StringTok{if \_\_name\_\_ == "\_\_main\_\_":}
\StringTok{  main()}
\OperatorTok{PY}
\FunctionTok{chmod}\NormalTok{ +x scripts/make\_handoff\_zip.py}
\ExtensionTok{python}\NormalTok{ scripts/make\_handoff\_zip.py}
\FunctionTok{ls} \AttributeTok{{-}l}\NormalTok{ dist }\KeywordTok{|} \FunctionTok{head} \AttributeTok{{-}n}\NormalTok{ 3}
\end{Highlighting}
\end{Shaded}

\subsection{5) Makefile additions (quality of
life)}\label{makefile-additions-quality-of-life}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\# Append to Makefile}
\NormalTok{.PHONY: backlog handoff}
\NormalTok{backlog: \#\# Generate NEXT\_STEPS and issue\_backlog.csv}
\NormalTok{\textbackslash{}tpython scripts/make\_continuation\_backlog.py}

\NormalTok{handoff: \#\# Build a zip with poster, abstract, manifest, backlog, figures}
\NormalTok{\textbackslash{}tpython scripts/make\_handoff\_zip.py}
\end{Highlighting}
\end{Shaded}

\subsection{6) Tiny test: ensure backlog artifacts
exist}\label{tiny-test-ensure-backlog-artifacts-exist}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{cat} \OperatorTok{\textgreater{}}\NormalTok{ tests/test\_backlog\_exists.py }\OperatorTok{\textless{}\textless{} \textquotesingle{}PY\textquotesingle{}}
\StringTok{from pathlib import Path}
\StringTok{def test\_backlog\_artifacts():}
\StringTok{    assert Path("NEXT\_STEPS.md").exists(), "Run: make backlog"}
\StringTok{    assert Path("reports/issue\_backlog.csv").exists(), "Missing reports/issue\_backlog.csv"}
\OperatorTok{PY}
\ExtensionTok{pytest} \AttributeTok{{-}q} \AttributeTok{{-}k}\NormalTok{ backlog\_exists }\KeywordTok{||} \FunctionTok{true}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Wrap‑up (10 min)}\label{wrapup-10-min-12}

\begin{itemize}
\tightlist
\item
  Show \texttt{NEXT\_STEPS.md} highlights (3 P0 tasks). Assign
  \textbf{owners} and tentative \textbf{dates}.
\item
  Confirm your \textbf{handoff zip} exists in \texttt{dist/}.
\item
  Agree on \textbf{communication cadence} (weekly check‑in, single
  source of truth is the repo).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Homework (final)}\label{homework-final}

\textbf{Deliverables (push before tagging):}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Tag \texttt{v1.0}} (final poster \& abstract committed).
\item
  \textbf{Continuation backlog} present: \texttt{NEXT\_STEPS.md} +
  \texttt{reports/issue\_backlog.csv}.
\item
  \textbf{Handoff zip} built in \texttt{dist/} (commit the manifest of
  its contents; the zip itself can be attached to a GitHub Release).
\item
  Open \textbf{3--5 GitHub issues} from the CSV (copy/paste), assign
  labels \& owners, and add them to a \textbf{Project board} (optional
  via GitHub UI).
\end{enumerate}

\subsection{\texorpdfstring{A. Commands to finalize and tag
\texttt{v1.0}}{A. Commands to finalize and tag v1.0}}\label{a.-commands-to-finalize-and-tag-v1.0}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\CommentTok{\# Ensure poster \& abstract render and backlog exists}
\FunctionTok{make}\NormalTok{ poster }\KeywordTok{||} \BuiltInTok{echo} \StringTok{"Render poster locally if Quarto missing."}
\FunctionTok{make}\NormalTok{ backlog}
\FunctionTok{git}\NormalTok{ add NEXT\_STEPS.md reports/issue\_backlog.csv}
\FunctionTok{git}\NormalTok{ commit }\AttributeTok{{-}m} \StringTok{"docs: NEXT\_STEPS and backlog for continuation"}
\FunctionTok{git}\NormalTok{ tag }\AttributeTok{{-}a}\NormalTok{ v1.0 }\AttributeTok{{-}m} \StringTok{"Final course release (poster, abstract, backlog)"}
\FunctionTok{git}\NormalTok{ push origin v1.0}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{B. (Optional) Create issues automatically if
GitHub CLI (\texttt{gh}) is
available}{B. (Optional) Create issues automatically if GitHub CLI (gh) is available}}\label{b.-optional-create-issues-automatically-if-github-cli-gh-is-available}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\CommentTok{\# Requires: gh auth login (once)}
\ExtensionTok{python} \AttributeTok{{-}} \OperatorTok{\textless{}\textless{}\textquotesingle{}PY\textquotesingle{}}
\StringTok{import csv, os, subprocess}
\StringTok{path = "reports/issue\_backlog.csv"}
\StringTok{if not os.path.exists(path):}
\StringTok{    raise SystemExit("Missing reports/issue\_backlog.csv")}
\StringTok{with open(path) as f:}
\StringTok{    rows = list(csv.DictReader(f))}
\StringTok{for r in rows[:5]:  \# open first 5 to avoid spam}
\StringTok{    title = r["title"]; body = r["body"]; labels = r["labels"]}
\StringTok{    cmd = ["gh","issue","create","{-}{-}title",title,"{-}{-}body",body,"{-}{-}label",labels]}
\StringTok{    print(" ".join(cmd))}
\StringTok{    try:}
\StringTok{        subprocess.check\_call(cmd)}
\StringTok{    except Exception as e:}
\StringTok{        print("Skipping (gh not configured):", e)}
\OperatorTok{PY}
\end{Highlighting}
\end{Shaded}

\subsection{\texorpdfstring{C. (Optional) Project board starter (manual
UI or
\texttt{gh\ project})}{C. (Optional) Project board starter (manual UI or gh project)}}\label{c.-optional-project-board-starter-manual-ui-or-gh-project}

\begin{itemize}
\tightlist
\item
  Columns: \textbf{Backlog}, \textbf{In progress}, \textbf{Review},
  \textbf{Done}.
\item
  Add automation: close issue → moves to \textbf{Done}.
\end{itemize}

\subsection{D. Handoff verification
script}\label{d.-handoff-verification-script}

Run once to confirm the bundle:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{\%\%bash}
\FunctionTok{make}\NormalTok{ handoff}
\ExtensionTok{python} \AttributeTok{{-}} \OperatorTok{\textless{}\textless{}\textquotesingle{}PY\textquotesingle{}}
\StringTok{from zipfile import ZipFile; import glob}
\StringTok{z = sorted(glob.glob("dist/handoff\_session26\_*.zip"))[{-}1]}
\StringTok{with ZipFile(z) as f:}
\StringTok{    print("ZIP entries:", len(f.infolist()))}
\OperatorTok{PY}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Instructor facilitation
tips}\label{instructor-facilitation-tips}

\begin{itemize}
\tightlist
\item
  Timebox talks strictly; use a soft chime at 9 minutes.
\item
  For feedback, enforce ``one insight, one question, one suggestion''.
\item
  Push teams to \textbf{prioritize} (P0 vs P1 vs P2); avoid ``we will do
  everything.''
\item
  If results are weak, frame a \textbf{credible plan}: fix leakage
  risks, add robust baseline, improve regime analysis.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{Grading (pass / revise)}\label{grading-pass-revise}

\begin{itemize}
\tightlist
\item
  \textbf{Talk delivered} within 10 minutes; Q\&A handled
  professionally.
\item
  \textbf{Backlog artifacts} exist and are sensible
  (\texttt{NEXT\_STEPS.md}, \texttt{issue\_backlog.csv}, roadmap).
\item
  \textbf{Handoff zip} produced and contains poster, abstract, figures,
  and manifest.
\item
  Repo \textbf{tags \texttt{v1.0}}; README includes a short
  \textbf{``Next Steps''} section (can link to \texttt{NEXT\_STEPS.md}).
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Appendix --- 1‑slide talk template (you can paste into your
deck)}\label{appendix-1slide-talk-template-you-can-paste-into-your-deck}

\begin{itemize}
\tightlist
\item
  \textbf{Title \& claim}
\item
  \textbf{Data \& controls} (static tickers; rolling origin + embargo)
\item
  \textbf{Method} (lin\_lags vs GRU vs TS‑GPT; loss)
\item
  \textbf{Results} (3 figs; bold takeaways)
\item
  \textbf{Limits \& ethics}
\item
  \textbf{Next steps (3 bullets)}
\end{itemize}

This completes Session 26 and hands off a clean, reproducible project
with a realistic continuation plan for the Spring symposium.

\bookmarksetup{startatroot}

\chapter{Summary}\label{summary}

In summary, this book has no content whatsoever.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{+} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\bookmarksetup{startatroot}

\chapter*{References}\label{references-1}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{1}
\end{CSLReferences}




\end{document}
